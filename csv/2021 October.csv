,id,title,authorids,authors,TL;DR,abstract,pdf,software,preprint,existing_preprints,preferred_venue,consent,paperhash,reviewer/Editor_reassignment_request,reviewer/Editor_reassignment_justification,data,previous_URL,previous_PDF,response_PDF
0,72QrFBWytu5,Attention Temperature Matters in Abstractive Summarization Distillation,['aclweb.org/ACL/ARR/2021/October/Paper314/Authors'],['Anonymous'],,"Recent progress of abstractive text summarization largely relies on large pre-trained sequence-to-sequence Transformer models, which are computationally expensive. This paper aims to distill these large models into smaller ones for faster inference and with minimal performance loss. Pseudo-labeling based methods are popular in sequence-to-sequence model distillation. In this paper, we find simply manipulating attention temperatures in Transformers can make pseudo labels easier to learn for student models. Our experiments on three summarization datasets show our proposed method consistently improves vanilla pseudo-labeling based methods. Further empirical analysis shows that both pseudo labels and summaries produced by our students are shorter and more abstractive.",/pdf/0babb142838c3770433264dbdec5b614af982feb.pdf,/attachment/699974c25d1a534f755767fbf9f02b8a71e7f53d.zip,,,,,anonymous|attention_temperature_matters_in_abstractive_summarization_distillation,,,,,,
1,_zW5Fa82Fbm,Compositional Generalization Requires Compositional Parsers,['aclweb.org/ACL/ARR/2021/October/Paper199/Authors'],['Anonymous'],,"A growing body of research has focused on the task of \textit{compositional generalization}, the ability of a semantic parser to dynamically combine known linguistic elements in novel structures. We analyze the accuracy of different parsers on the recent COGS corpus (Kim and Linzen, 2020). While lexical generalization tasks are solvable by almost all existing models, tasks involving changes to the linguistic structure are hard for even the best sequence-to-sequence models. Structural generalization tasks can be solved with models that have compositionality built in; we present new results confirming this from the AM parser (Groschwitz et al., 2021). We further analyze the role of syntactic generalization in compositional generalization, and we discuss ramifications for the design of both semantic parsers and compositional generalization datasets.",/pdf/f5b1a18c01b55f627df8bcda3520d2da2a506116.pdf,,,,,,anonymous|compositional_generalization_requires_compositional_parsers,,,,,,
2,46M3BddHNrp,Can Language Models Take A Hint? Prompting for Controllable Contextualized Commonsense Inference,['aclweb.org/ACL/ARR/2021/October/Paper346/Authors'],['Anonymous'],,"Generating commonsense assertions, given a certain story context, is a tough challenge even for modern language models. One of the reasons for this may be that the model has to ""guess"" what topic or entity in a story to generate an assertion about.  Prior work has tackled part of the problem, by providing techniques to align commonsense inferences with stories and training language generation models on these.  However, none of the prior work provides means to control the parts of a generated assertion. In this work, we present ""hinting"", a data augmentation technique for improving inference of contextualized commonsense assertions. Hinting is a prefix prompting strategy that uses both hard and soft prompts.  We demonstrate the effectiveness of hinting by showcasing its effect on two contextual commonsense inference frameworks: ParaCOMET and  GLUCOSE, for both general and context-specific inference.   ",/pdf/5de09d7de8ec7f91f9160d7b51f6792eaf1de304.pdf,/attachment/3b5e1ce2678d84852c27c50156e523c258a3941b.zip,,,,,anonymous|can_language_models_take_a_hint_prompting_for_controllable_contextualized_commonsense_inference,,,/attachment/625af457c5ffd48883db1788838a243af014f90b.zip,,,
3,lL3G1FFeuw7,Better Sample Efficiency Does Not Imply Out-of-Distribution Robustness,['aclweb.org/ACL/ARR/2021/October/Paper318/Authors'],['Anonymous'],,"We study the relationship between sample efficiency and out-of-distribution performance---if two models have the same in-distribution performance, does the model trained on fewer labeled training examples (higher sample efficiency) perform better out-of-distribution? First, we find that models with higher sample efficiency can have worse out-of-distribution robustness than models that are less sample-efficient. We then empirically study the correlation between sample efficiency and out-of-distribution robustness across three tasks, 23 total ID-OOD settings, and four broadly-applicable methods that change sample efficiency: (1) changing the pre-training data source; (2) using natural language prompts; (3) increasing model size; and (4) increasing the amount of pre-training data. Given that better sample efficiency does not necessarily give rise to robust models, our results underscore the importance of developing and evaluating whether interventions jointly improve both.",/pdf/f50b2e51203e3e0a0a659b10a58c0185471ce9d9.pdf,,,,,,anonymous|better_sample_efficiency_does_not_imply_outofdistribution_robustness,,,,,,
4,mu5Lr9cL2-,IMPLI: Investigating NLI Models' Performance on Figurative Language,['aclweb.org/ACL/ARR/2021/October/Paper47/Authors'],['Anonymous'],,"Natural language inference (NLI) has been widely used as a task to train and evaluate models for language understanding. However, the ability of NLI models to perform inferences that require understanding of figurative languages such as idioms and metaphors remains understudied. We introduce the IMPLI (Idiomatic and Metaphoric Paired Language Inference) dataset consisting of over 25K semi-automatically generated and 1.5K hand-written English sentence pairs based on idiomatic and metaphoric phrases. We use \dataset to evaluate NLI models based on RoBERTa fine-tuned on the MNLI dataset, and show that while they can reliably detect entailment relationship between figurative phrases with their literal definition, they perform poorly on examples where the phrases are designed to not entail the paired definition. This dataset suggests the limits of current NLI models with regard to understanding figurative language and provides a benchmark for future improvements in this direction.",/pdf/ebaa27b1f68c5ce789e8f6ecdd998fd0d79dbbce.pdf,,,,,,anonymous|impli_investigating_nli_models_performance_on_figurative_language,,,/attachment/f2cf00458f3caf9180d315a33fad940dd0c1af11.zip,,,
5,P1Ug5CYxkn,,,,,,,,,,,,,,,,,,
6,er878dahRoP,Modeling Context With Linear Attention for Scalable Document-Level Translation,['aclweb.org/ACL/ARR/2021/October/Paper130/Authors'],['Anonymous'],,"Document-level neural machine translation allows models to leverage dependencies beyond sentence-internal context to produce more coherent and consistent translations. However, these models, predominantly based on transformers, are difficult to scale to long documents due to the quadratic time and space complexity of their self-attention layers. Recent efforts on efficient attention variants improve scalability, but it is yet unclear if and to what extent their inductive biases are suitable for document translation. In this paper, we explore the efficacy of a recent linear attention model by Peng et al. (2021) on document-level translation and augment it with a sentential gating mechanism. We evaluate the model on the IWSLT 2015 and OpenSubtitles 2018 datasets against a strong transformer baseline and achieve up to 40% decoding speedup with similar or improved BLEU scores. We show that the sentential gate further improves translation quality on IWSLT, a dataset with long sequences.",/pdf/1c3beced74d9ed9c409797fb46002d8185bcace4.pdf,,,,,,anonymous|modeling_context_with_linear_attention_for_scalable_documentlevel_translation,,,,,,
7,WO4a5buL8OV,A Unified Abstractive Model for Generating Question-Answer Pairs,['aclweb.org/ACL/ARR/2021/October/Paper343/Authors'],['Anonymous'],,"Large-scale question-answer pairs (QAP) are valuable for many applications, such as knowledge bases construction and machine reading comprehension. Although its importance has been widely recognized, existing approaches are still faced with critical challenges. On the one hand, QAPs are obtained by selecting spans from original texts as their answers, while abstractive answer generation is more suitable and natural for complex QA applications. On the other hand, the interaction between the sub-tasks of answer generation and question generation should be well captured to enhance each other mutually. To this end, we propose a Unified Abstractive model for Question-Answer Pairs generation (UA-QAP). Specifically, we devise the joint model with a query-guided gate to collectively model the two sub-tasks simultaneously and capture the interaction information between them. Therefore, our model can generate semantically comprehensive question-answer pairs. We conduct extensive experiments on three large-scale datasets. The experimental results demonstrate that our model achieves state-of-the-art performance.",/pdf/0cc42f0e7fc7bd59ab4dc27fb0f18cf9cdd69058.pdf,/attachment/48c519d4bbd3cb5f281180f2d4429e5b13d484eb.zip,,,,,anonymous|a_unified_abstractive_model_for_generating_questionanswer_pairs,,,/attachment/c369f0e863dab1e456d34f67b8fb93beeedef498.zip,https://openreview.net/forum?id=A52cED1DCyR,,
8,pA5DDb-aaBJ,Use of a Taxonomy of Empathetic Response Intents to Control and Interpret Empathy in Neural Chatbots,['aclweb.org/ACL/ARR/2021/October/Paper195/Authors'],['Anonymous'],,"A recent trend in the domain of open-domain conversational agents is enabling them to converse empathetically to emotional prompts. Current approaches either follow an end-to-end approach or condition the responses on similar emotion labels to generate empathetic responses. But empathy is a broad concept that refers to the cognitive and emotional reactions of an individual to the observed experiences of another and it is more complex than mere mimicry of emotion. Hence, it requires identifying complex human conversational strategies and dynamics in addition to generic emotions to control and interpret empathetic responding capabilities of chatbots. In this work, we make use of a taxonomy of eight empathetic response intents in addition to generic emotion categories in building a dialogue response generation model capable of generating empathetic responses in a controllable and interpretable manner. It consists of two modules: 1) a response emotion/intent prediction module; and 2) a response generation module. We propose several rule-based and neural approaches to predict the next response's emotion/intent and generate responses conditioned on these predicted emotions/intents. Automatic and human evaluation results emphasize the importance of the use of the taxonomy of empathetic response intents in producing more diverse and empathetically more appropriate responses than end-to-end models.",/pdf/10f2af0f43e553f4151f966722f2a848815bef73.pdf,/attachment/43a2da42e4d3f584a3f2e74db6ed9606a0dd0b9e.zip,,,,,anonymous|use_of_a_taxonomy_of_empathetic_response_intents_to_control_and_interpret_empathy_in_neural_chatbots,,,/attachment/b3c594dc75fc3abd757b7e823c2e3cb92ddb9dd8.zip,,,
9,nuhqPF12ec,Cross-lingual Inference with A Chinese Entailment Graph,['aclweb.org/ACL/ARR/2021/October/Paper42/Authors'],['Anonymous'],,"Predicate entailment detection is a crucial task for question-answering from text, where previous work has explored unsupervised learning of entailment graphs from typed open relation triples. In this paper, we present the first pipeline for building Chinese entailment graphs. In this pipeline, we present a novel high-recall open relation extraction (ORE) method and the first Chinese fine-grained entity typing dataset following the FIGER type ontology. Through experiments on the popular Levy-Holt dataset, translated into Chinese, we show that our Chinese entailment graph outperforms a range of strong baselines by large margins. Moreover, an ensemble of Chinese and English entailment graphs sets a new unsupervised SOTA on the original Levy-Holt dataset, surpassing previous SOTA by more than 4 AUC points.",/pdf/babbbfa2b3ab940a9e3d4be2f5bd8450f094cd30.pdf,/attachment/7f9ff82ccaa66e5bb53b355074a39dd7c5a3d5bb.zip,,,,,anonymous|crosslingual_inference_with_a_chinese_entailment_graph,,,/attachment/765229ea4eae27f6b5a4a22b8a44418f7a2f43e9.zip,,,
10,S2tWDJiE5R,DEMix Layers: Disentangling Domains for Modular Language Modeling,['aclweb.org/ACL/ARR/2021/October/Paper3/Authors'],['Anonymous'],,"We introduce a new domain expert mixture (DEMix) layer that enables conditioning a language model (LM) on the domain of the input text.  A DEMix layer is a collection of expert feedforward networks, each specialized to a domain, that makes the LM modular: experts can be mixed, added, or removed after initial training. Extensive experiments with autoregressive transformer LMs (up to 1.3B parameters) show that DEMix layers reduce perplexity, increase training efficiency, and enable rapid adaptation. Mixing experts during inference, using a parameter-free weighted ensemble, enables better generalization to heterogeneous or unseen domains. Adding experts incorporates new domains without forgetting older ones, and removing experts restricts access to unwanted domains without additional training. Overall, these results demonstrate benefits of explicitly conditioning on textual domains during language modeling.
",/pdf/b72bb1c68e4abcb4c16871089a52f5d5a7b99c2d.pdf,,,,,,anonymous|demix_layers_disentangling_domains_for_modular_language_modeling,,,,,,
11,5H6ycWfJywO,Explainable Assessment of Healthcare Articles with QA,['aclweb.org/ACL/ARR/2021/October/Paper40/Authors'],['Anonymous'],,"The healthcare domain suffers from the spread of poor quality articles on the Internet. While manual efforts exist, they are not sufficient to assess the amount of articles in circulation. The task can be automated as text classification, however explanations for the labels are necessary for the users. While current explainable systems tackle explanation generation as summarization, we propose a new approach based on Question-Answering that allows us to generate explanations for multiple criteria. We show that QA-based models are competitive with current state-of-the-art systems and complement summarization-based models for explainable quality assessment.
",/pdf/0f4a47bb8933ac4cbf82bbad7e121d8a80adda38.pdf,,,,,,anonymous|explainable_assessment_of_healthcare_articles_with_qa,,,,,,
12,F0EkIHMrapS,Should We Trust This Summary? Bayesian Abstractive Summarization to The Rescue,['aclweb.org/ACL/ARR/2021/October/Paper21/Authors'],['Anonymous'],,"We explore the notion of uncertainty in the context of modern abstractive summarization models, using the tools of Bayesian Deep Learning. Our approach approximates Bayesian inference by first extending state-of-the-art summarization models with Monte Carlo dropout and then using them to perform multiple stochastic forward passes. Based on Bayesian inference we are able to effectively quantify uncertainty at prediction time. Having a reliable uncertainty measure, we can improve the experience of the end user by filtering out generated summaries of high uncertainty. Furthermore, uncertainty estimation could be used as a criterion for selecting samples for annotation, and can be paired nicely with active learning and human-in-the-loop approaches. Finally, Bayesian inference enables us to find a Bayesian summary which performs better than a deterministic one and is more robust to uncertainty. In practice, we show that our Variational Bayesian equivalents of BART and PEGASUS can outperform their deterministic counterparts on multiple benchmark datasets.",/pdf/08eba79a3f7ec903daa4d0fd557b1d01aa6dac23.pdf,,,,,,anonymous|should_we_trust_this_summary_bayesian_abstractive_summarization_to_the_rescue,,,,,,
13,cYridOBBWx7,Multimodal Entity Tagging with Multimodal Knowledge Base,['aclweb.org/ACL/ARR/2021/October/Paper146/Authors'],['Anonymous'],,"To enhance research on multimodal knowledge base and multimodal information processing, we propose a new task called multimodal entity tagging (MET) with a multimodal knowledge base (MKB). We also develop a dataset for the problem using an existing MKB. In an MKB, there are entities and their associated texts and images. In MET, given a text-image pair, one uses the information in the MKB to automatically identify the related entity in the text-image pair. We solve the task by using the information retrieval paradigm and implement several baselines using state-of-the-art methods in NLP and CV.  We conduct extensive experiments and make analyses on the experimental results. The results show that the task is challenging, but current technologies can achieve relatively high performance. We will release the dataset, code, and models for future research.",/pdf/878288e4982cbc89111cb7bbad4db2cbf66bc56c.pdf,/attachment/9fbb995e913486e8160319f3c6494d5121f4014c.zip,,,,,anonymous|multimodal_entity_tagging_with_multimodal_knowledge_base,,,,,,
14,ok4mJrp4C-P,FarFetched: An Entity-centric Approach for Reasoning on Textually Represented Environments,['aclweb.org/ACL/ARR/2021/October/Paper164/Authors'],['Anonymous'],,"We address the problem of automatically acquiring knowledge from news articles and leverage it to estimate the veracity of a user's claim based on the supporting or refuting content within the accumulated evidence. We present FarFetched, an entity-centric approach for reasoning based on news, where latent connections between events, actions or statements are discovered via their identified entity mentions and are represented with the help of a knowledge graph. We propose a way of selecting specific subsets from the accumulated wealth of information based on the user hypothesis and construct relevant premises relying on the semantic similarity between them. We leverage textual entailment recognition to provide a measurable way for assessing whether the user claim is plausible based on the selected evidence. Our work is demonstrated on the less-resourced Greek language and supported by the training of state-of-the-art models for STS and NLI that are evaluated on benchmark datasets.",/pdf/f83a7cc8bde45c1ce7605e5e43608cdc42f29d67.pdf,/attachment/3cb87974d7ceafbb0dfe1a1f1c8b5d71a914f5b3.zip,,,,,anonymous|farfetched_an_entitycentric_approach_for_reasoning_on_textually_represented_environments,,,/attachment/c8c4896f1e4fb4a004fcf425ab2c65c3dfce5fe1.zip,,,
15,Y-iPSD-_ZTl,Zero-shot Cross-Language Transfer of Monolingual Entity Linking Models,['aclweb.org/ACL/ARR/2021/October/Paper182/Authors'],['Anonymous'],,"Most entity linking systems, whether mono or multilingual, link mentions to a single English knowledge base. Few have considered linking non-English text to a non-English KB, and therefore, transferring an English entity linking model to both a new document and new KB language. We consider the task of zero-shot cross-lingual transfer of entity linking systems to a new language and KB. We find that a system trained with multilingual representations does reasonably well, and propose improvements to system training that lead to improved recall in most datasets, often matching the in-language performance. We further conduct a detailed evaluation to elucidate the challenges of this setting.",/pdf/e02783e8029973a3fd6662fde3f86fd5be48d131.pdf,,,,,,anonymous|zeroshot_crosslanguage_transfer_of_monolingual_entity_linking_models,,,,,,
16,nXMPy9wIIz,CTRLsum: Towards Generic Controllable Text Summarization,['aclweb.org/ACL/ARR/2021/October/Paper360/Authors'],['Anonymous'],,"Current summarization systems yield generic summaries that are disconnected from users' preferences and expectations. To address this limitation, we present CTRLsum, a generic framework to control generated summaries through a set of keywords. During training keywords are extracted automatically without requiring additional human annotations. At test time CTRLsum features a control function to map control signal to keywords; through engineering the control function, the same trained model is able to be applied to control summaries on various dimensions, while neither affecting the model training process nor the pretrained models.  We additionally explore the combination of keywords and text prompts for more control tasks. Experiments demonstrate the effectiveness of CTRLsum on three domains of summarization datasets and five control tasks: (1) entity-centric and (2) length-controllable summarization, (3) contribution summarization on scientific papers, (4) invention purpose summarization on patent filings, and (5) question-guided summarization on news articles. Moreover, when used in a standard, unconstrained summarization setting, CTRLsum is comparable or better than the state-of-the-art systems.",/pdf/39daaffe1f180bc69a64ec348b8509f17c8391af.pdf,/attachment/eb933a513f19145743453af8f34da68a4c56662b.zip,,,,,anonymous|ctrlsum_towards_generic_controllable_text_summarization,,,,https://openreview.net/forum?id=OUPw2V0lX4_,/attachment/1bd1c8ed2a54d76f22af70f1a57d2a25266aae85.pdf,/attachment/cfd03787fcfaa6682e5bd691ea866d35add8aa61.pdf
17,8AKEjP3SsZ,Learning to Prioritize: Precision-Driven Sentence Filtering for Long Text Summarization,['aclweb.org/ACL/ARR/2021/October/Paper264/Authors'],['Anonymous'],,"Neural text summarization has shown great potential in recent years. However, current state-of-the-art summarization models are limited by their maximum input length, posing a challenge to summarize longer texts comprehensively. As part of a layered summarization architecture, we introduce PureText, a simple yet effective precision-driven sentence filtering layer that learns to remove low-quality sentences in texts to improve existing summarization models. When evaluated on popular datasets like WikiHow and Reddit TIFU, we show up to 3 and 8 point Rouge-1 absolute improvement on the full test set and the long article subset, respectively, for state-of-the-art summarization models such as BertSum and Bart. Our approach provides downstream models with higher-quality sentences for summarization, improving overall model performance, especially on long text articles.",/pdf/e8717e56cc272ca6c5f651a5c72685adec3b1769.pdf,,,,,,anonymous|learning_to_prioritize_precisiondriven_sentence_filtering_for_long_text_summarization,,,,,,
18,yeun8f9dgaW,BotsTalk: Machine-Sourced Framework for Automatic Curation of Large-scale Multi-skill Dialogue Datasets,['aclweb.org/ACL/ARR/2021/October/Paper290/Authors'],['Anonymous'],,"Previous work in open-domain chatbots has introduced dialogue corpora and tasks that aim to inject dialogue systems different communicative skills such as being personable, knowledgeable and empathetic. With the advent of conversational agents grounded to specific skills, a new challenge in open-domain chatbots has been posed: A good open-domain chatbot should retain a well-rounded set of skills and seamlessly blend them into a conversation. To this end, a new dialogue dataset Blended Skill Talk is collected via crowdsourcing and commonly used as a benchmark for multi-skill dialogue generation. However, such data construction approach requires labor intensive manual annotation, which severely limits their utility on large-scale learning. In this work, we propose BotsTalk, a novel machine-sourced framework, where several agents participate in a conversation to automatically annotate multi-skill dialogues. We then present Blended Skill BotsTalk (BS$\mathbb{B}$T), a large-scale multi-skill dialogue dataset of 200K conversations. Experimental results show that our dataset can be effectively used as training data for multi-skill dialogue systems which require an understanding of both skill blending and grounding. We also demonstrate the dataset is orthogonally applicable to diverse learning schemes such as fine-tuning and multi-task learning.",/pdf/0294bde3da59782b86f910c18e704d090ec98496.pdf,/attachment/0fe7703fef53da7842ea05a7fa447eb0777ac170.zip,,,,,anonymous|botstalk_machinesourced_framework_for_automatic_curation_of_largescale_multiskill_dialogue_datasets,,,/attachment/a4b88e824702a79c06c3a565ee7fb34883f802cd.zip,,,
19,QpiAIRMyxy,Learning Meta Word Embeddings by Unsupervised Weighted Concatenation of Source Embeddings,['aclweb.org/ACL/ARR/2021/October/Paper207/Authors'],['Anonymous'],,"We propose a method to protect the privacy of search engine users by decomposing the queries using
semantically \emph{related} and unrelated \emph{distractor} terms. Instead of a single query, the search engine
receives multiple decomposed query terms. Next, we reconstruct the search results relevant to the original
query term by aggregating the search results retrieved for the decomposed query terms.
We show that the word embeddings learnt using a distributed representation learning method can be used to find semantically related and distractor query terms.
We derive the relationship between the \emph{obfuscity} achieved through the proposed query anonymisation method and the \emph{reconstructability} of the original search results using the decomposed queries.
We analytically study the risk of discovering the search engine users' information intents under the proposed
query obfuscation method, and empirically evaluate its robustness against clustering-based attacks.
Our experimental results show that the proposed method can accurately reconstruct the search results for user queries, without compromising the privacy of the search engine users.
",/pdf/1c4cb373a3a37f644f7f7c4e2519a3dd6e58a2e9.pdf,,,,,,anonymous|learning_meta_word_embeddings_by_unsupervised_weighted_concatenation_of_source_embeddings,,,,,,
20,hGdyEIebn0,Slangvolution: A Causal Analysis of Semantic Change and Frequency Dynamics in Slang,['aclweb.org/ACL/ARR/2021/October/Paper245/Authors'],['Anonymous'],,"Words are not static in their usage and meaning, but evolve over time. An interesting phenomenon in languages is slang, which is an informal language that is considered ephemeral and is often associated with contemporary trends. In this work, we study the semantic change and relative frequency shift of slang words and compare this change with standard, nonslang words. To measure semantic change, we obtain contextualized representations of words, reduce their dimensionality and propose a metric to measure their average pairwise distances between two time periods. We apply causal discovery algorithms and causal inference to uncover the dynamics of language evolution and measure the effect that word type (slang/nonslang) has on both semantic change and frequency shift, as well as its relationship to absolute frequency and polysemy. Our causal analysis shows that slang words undergo less semantic change even though they have larger frequency shifts over time.",/pdf/1c81710264768e06a7c47d08c0a077efb1d42f31.pdf,/attachment/444b23bfa8d66e33a7699a668ce8733cfb799744.zip,,,,,anonymous|slangvolution_a_causal_analysis_of_semantic_change_and_frequency_dynamics_in_slang,,,/attachment/1a2d660bf85b07659a6e42ae9e463da684848296.zip,,,
21,2slgD-kSWgN,DoTAT: A Domain-oriented Text Annotation Tool,['aclweb.org/ACL/ARR/2021/October/Paper5/Authors'],['Anonymous'],,"We propose DoTAT, a domain-oriented text annotation tool. The tool designs and implements functions heavily in need in domain-oriented information extraction. Firstly, the tool supports a multi-person collaborative process with automatically merging and review, which can greatly improve the annotation accuracy. Secondly, the tool provides annotation of event, nested event, and nested entity, which are frequently required in domain-related text structuring tasks. Finally, DoTAT provides visualized annotation specification definition, automatic batch annotation, and iterative annotation to improve annotation efficiency. Experiments on the ACE2005 dataset show that DoTAT can reduce the event annotation time by 19.7% compared with existing annotation tools. The accuracy without review is 84.09%, 1.35% higher than Brat, and 2.59% higher than Webanno. The accuracy of DoTAT even reaches 93.76% with the review. The demonstration video can be accessed from https://ecust-nlp-docker.oss-cn-shanghai.aliyuncs.com/dotat_demo.mp4. A live demo website is available at https://github.com/FXLP/MarkTool.",/pdf/46b32307f05d050d911ea20c52f81c3ffa53acbf.pdf,,,,,,anonymous|dotat_a_domainoriented_text_annotation_tool,,,,,,
22,kL8xTwwFMCT,C-MORE: Pretraining to Answer Open-Domain Questions by Consulting Millions of References,['aclweb.org/ACL/ARR/2021/October/Paper303/Authors'],['Anonymous'],,"We consider the problem of pretraining a two-stage open-domain question answering (QA) system (retriever + reader) with strong transfer capabilities. The key challenge is how to construct a large amount of high-quality question-answer-context triplets without task-specific annotations. Specifically, the triplets should align well with downstream tasks by: (i) covering a wide range of domains (for open-domain applications), (ii) linking a question to its semantically relevant context with supporting evidence (for training the retriever), and (iii) identifying the correct answer in the context (for training the reader). Previous pretraining approaches generally fall short of one or more of these requirements. In this work, we automatically construct a large-scale corpus that meets all three criteria by consulting millions of references cited within Wikipedia. The well-aligned pretraining signals benefit both the retriever and the reader significantly. Our pretrained retriever leads to 2%-10% absolute gains in top-20 accuracy. And with our pretrained reader, the entire system improves by up to 4% in exact match.",/pdf/4508d8b4b101221cf31583ea637fb0f2b871f0e4.pdf,,,,,,anonymous|cmore_pretraining_to_answer_opendomain_questions_by_consulting_millions_of_references,,,,,,
23,KSvkXL6bRU7,"Hate a Little Less, Love a Little More! Proactively Curbing Online Hatred via Hate Speech Normalization",['aclweb.org/ACL/ARR/2021/October/Paper317/Authors'],['Anonymous'],,"Curbing online hate speech has become the need of the hour; however, a blanket ban on such activities is infeasible due to several political, geographical, and cultural reasons. To reduce the severity of the problem, in this paper, we introduce a novel task, hate speech normalization – weakening the intensity of hatred exhibited by an online post by paraphrasing the original content. The intention of hate speech normalization is to not support hate but instead, provide the users with a stepping stone towards non-hate while giving online platforms more time to monitor any improvement in the user’s behaviour. To this end, we manually curated a parallel corpus of hate texts and their normalized counterparts (a normalized text is less hateful and more benign). We then introduce NACL, a
Neural hAte speeCh normaLizer that operates in three stages – first, it measures the hate intensity of the original sample; second, it identifies the harmful span(s) within it; and finally, it reduces hate intensity by paraphrasing the hate spans. We perform extensive experiments to measure the efficacy of individual components and the overall performance of NACL via three-way evaluation (intrinsic, extrinsic, and human-study). We observe that NACL outperforms its respective baselines – NACL yields a score of 0.683 Pearson correlation for the intensity prediction, 0.6911 F1-score in the span identification, and 67.71 BLEU and 75.83 perplexity for the normalized text generation. We further show the generalizability of NACL across other platforms (Reddit, Facebook, Gab). A scalable prototype of NACL was also deployed for the user study.",/pdf/8f022e322ace0dd0b1d0dabb8692e5f954c1c3d4.pdf,,,,,,anonymous|hate_a_little_less_love_a_little_more_proactively_curbing_online_hatred_via_hate_speech_normalization,,,,,,
24,BxSvC2DvNH9,Qualitative and Quantitative Analysis of Diversity in Cross-document Coreference Resolution Datasets,['aclweb.org/ACL/ARR/2021/October/Paper31/Authors'],['Anonymous'],,"Established cross-document coreference resolution (CDCR) datasets contain manually annotated event-centric mentions of events and entities that form coreference chains with identity relations. In this paper, we qualitatively and quantitatively compare the annotation schemes of ECB+, a CDCR dataset with identity coreference relations, and NewsWCL50, a CDCR dataset with identity, bridging, and near-identity coreference relations. The analysis shows that coreference chains of NewsWCL50 are more lexically diverse ECB+ but annotating of NewsWCL50 leads to the lower inter-coder reliability. We propose a phrasing diversity metric (PD) that encounters for the diversity of full phrases unlike the previously proposed metrics. We discuss the different tasks that both CDCR datasets create, i.e., lexical disambiguation and lexical diversity challenges for CDCR models, and propose a direction for further CDCR evaluation.",/pdf/c11d02166bc62c58502c1966b6d8a55b952038d5.pdf,,,,,,anonymous|qualitative_and_quantitative_analysis_of_diversity_in_crossdocument_coreference_resolution_datasets,,,,,,
25,jOZWKPtPgk,Event Detection for Suicide Understanding,['aclweb.org/ACL/ARR/2021/October/Paper258/Authors'],['Anonymous'],,"Suicide is a serious problem in every society. Understanding life events of a potential patient is essential for successful suicide-risk assessment and prevention. In this work, we focus on the Event Detection (ED) task to identify event trigger words of suicide-related events in public posts of discussion forums. In particular, we introduce a new dataset for ED (called SuicideED) that features seven suicidal event types to comprehensively capture suicide actions and ideation, and general risk and protective factors. Our experiments with current state-of-the-art ED systems suggest that there is still room for improvement of ED models in this domain. We will publicly release SuicideED to support future research in this important area.",/pdf/c2d0d77dde03bda3e32714e348bf0d26aa4db423.pdf,,,,,,anonymous|event_detection_for_suicide_understanding,,,/attachment/936664da0b7cec0e76c8781621e6c0aae6d2cfc2.zip,,,
26,uFXjHTmvBph,A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools Meme Stock Prediction,['aclweb.org/ACL/ARR/2021/October/Paper263/Authors'],['Anonymous'],,"More and more investors and machine learning models rely on social media (e.g., Twitter and Reddit) to gather information and predict certain stocks' prices (meme stock). However, text-based models are known to be vulnerable to adversarial attacks, but whether stock prediction models have similar adversarial vulnerability is underexplored.
In this paper, we experiment with a variety of adversarial attack configurations to fool three stock prediction victim models (StockNet, FinGRU, FinLSTM). We address the task of adversarial generation by solving combinatorial optimization problems with semantics and budget constraints. Our results show that the proposed attack method can achieve consistent success rates, with capabilities of causing thousands of dollars loss (with Long-Only Buy-Hold-Sell investing strategy) by simply concatenating a perturbed but semantically similar tweet. ",/pdf/d8b4a90a6b8851d43825d680f38915af94d66fe8.pdf,,,,,,anonymous|a_word_is_worth_a_thousand_dollars_adversarial_attack_on_tweets_fools_meme_stock_prediction,,,,,,
27,nLtWw6gVFYt,Towards Using Diachronic Distributed Word Representations as Models of Lexical Development,['aclweb.org/ACL/ARR/2021/October/Paper344/Authors'],['Anonymous'],,"Recent work has shown that distributed word representations can encode abstract information from child-directed speech. In this paper, we use diachronic distributed word representations to perform temporal modeling and analysis of lexical development in children. Unlike all previous work, we use temporally sliced corpus to learn distributed word representations of child-speech and child-directed speech under a curriculum-learning setting. In our experiments, we perform a lexical categorization task to plot the semantic and syntactic knowledge acquisition trajectories in children. Next, we perform linear mixed-effects modeling over the diachronic representational changes to study the role of input word frequencies in the rate of word acquisition in children. We also perform a fine-grained analysis of lexical knowledge transfer from adults to children using Representational Similarity Analysis. Finally, we perform a qualitative analysis of the diachronic representations from our model, which reveals the grounding and word associations in the mental lexicon of children. Our experiments demonstrate the ease of usage and effectiveness of diachronic distributed word representations in modeling lexical development.",/pdf/51c2e10ad369c98b387589fe361a787fa03fa4c9.pdf,,,,,,anonymous|towards_using_diachronic_distributed_word_representations_as_models_of_lexical_development,,,,,,
28,uUIH-5nW-B,Attending to Visual Differences for Situated Language Generation in Changing Scenes,['aclweb.org/ACL/ARR/2021/October/Paper29/Authors'],['Anonymous'],,"We investigate the problem of generating utterances from pairs of images showing a before and an after state of a change in a visual scene. We present a transformer model with difference attention heads that learns to attend to visual changes in consecutive images via a difference key. We test our approach in instruction generation, change captioning, and difference spotting and compare these tasks in terms of their linguistic phenomena and reasoning abilities. Our model outperforms the state-of-the-art for instruction generation on the BLOCKS and difference spotting on the Spot-the-diff dataset and generates accurate referential and compositional spatial expressions. Finally, we identify linguistic phenomena that pose challenges for generation in changing scenes. ",/pdf/d95bb6d897bb261715b3191158d85d921eccb8ff.pdf,,,,,,anonymous|attending_to_visual_differences_for_situated_language_generation_in_changing_scenes,,,,,/attachment/8dd2eff964eb443506b77817e8c43d7e3a84eed3.pdf,
29,nxEqWd4Ddth,CONTaiNER: Few-Shot Named Entity Recognition via Contrastive Learning,['aclweb.org/ACL/ARR/2021/October/Paper294/Authors'],['Anonymous'],,"Named Entity Recognition (NER) in Few-Shot setting is imperative for entity tagging in low resource domains. Existing approaches only learn class-specific semantic features and intermediate representations from source domains. This affects generalizability to unseen target domains, resulting in suboptimal performances. To this end, we present CONTaiNER, a novel contrastive learning technique that optimizes the inter-token distribution distance for Few-Shot NER. Instead of optimizing class-specific attributes, CONTaiNER optimizes a generalized objective of differentiating between token categories based on their Gaussian-distributed embeddings. This effectively alleviates overfitting issues originating from training domains. Our experiments in several traditional test domains (OntoNotes, CoNLL'03, WNUT '17, GUM) and a new large scale Few-Shot NER dataset (Few-NERD) demonstrate that on average, CONTaiNER outperforms previous methods by 3%-13% absolute F1 points while showing consistent performance trends, even in challenging scenarios where previous approaches could not achieve appreciable performance. ",/pdf/f4ee55395c68408570f7f989cab855f22c36c8df.pdf,,,,,,anonymous|container_fewshot_named_entity_recognition_via_contrastive_learning,,,,,,
30,crmo4E_b63,xGQA: Cross-Lingual Visual Question Answering,['aclweb.org/ACL/ARR/2021/October/Paper64/Authors'],['Anonymous'],,"Recent advances in multimodal vision and language modeling have predominantly focused on the English language, mostly due to the lack of multilingual multimodal datasets to steer modeling efforts. In this work, we address this gap and provide xGQA, a new multilingual evaluation benchmark for the visual question answering task. We extend the established English GQA dataset to 7 typologically diverse languages, enabling us to detect and explore crucial challenges in cross-lingual visual question answering. We further propose new adapter-based approaches to adapt multimodal transformer-based models to become multilingual, and---vice versa---multilingual models to become multimodal. Our proposed methods outperform current state-of-the-art multilingual multimodal models (e.g., M3P) in zero-shot cross-lingual settings, but the accuracy remains low across the board; a performance drop of around 38 accuracy points in target languages showcases the difficulty of zero-shot cross-lingual transfer for this task. Our results suggest that simple cross-lingual transfer of multimodal models yields latent multilingual multimodal misalignment, calling for more sophisticated methods for vision and multilingual language modeling. The xGQA dataset is available online at: URL",/pdf/4825fb561af3c989c4f2c3a1b09612a6d21a035c.pdf,,,,,,anonymous|xgqa_crosslingual_visual_question_answering,,,/attachment/a3f57a015b0668fcf51f980b3a8471b5d54a59fc.zip,,,
31,bdr9YwacFP,Hallucinated but Factual! Inspecting the Factuality of Hallucinations in Abstractive Summarization,['aclweb.org/ACL/ARR/2021/October/Paper239/Authors'],['Anonymous'],,"State-of-the-art abstractive summarization systems often generate hallucinations; i.e., content that is not directly inferable from the source text. Despite being assumed to be incorrect, we find that much hallucinated content is actually consistent with world knowledge, which we call factual hallucinations. Including these factual hallucinations in a summary can be beneficial because they provide useful background information. 
In this work, we propose a novel detection approach that separates factual from non-factual hallucinations of entities. 
Our method is based on an entity's prior and posterior probabilities according to pre-trained and finetuned masked language models, respectively. Empirical results suggest that our method vastly outperforms two baselines in both accuracy and F1 scores and has a strong correlation with human judgments on factuality classification tasks.
Furthermore, we use our method as a reward signal to train a summarization system using an off-line reinforcement learning (RL) algorithm that can significantly improve the factuality of generated summaries while maintaining the level of abstractiveness. ",/pdf/290c5aa48a97bc11ac53c4feb802c832b6799975.pdf,/attachment/d93ebce53854d4e9368d509654b7dc2514048862.zip,,,,,anonymous|hallucinated_but_factual_inspecting_the_factuality_of_hallucinations_in_abstractive_summarization,,,/attachment/5d44913a75b91769e0159cdde0b2edeacce413c9.zip,,,
32,XnwgpvL4PRf,A Recipe for Arbitrary Text Style Transfer with Large Language Models,['aclweb.org/ACL/ARR/2021/October/Paper15/Authors'],['Anonymous'],,"In this paper, we leverage large language models (LLMs) to perform zero-shot text style transfer. We present a prompting method that we call augmented zero-shot learning, which frames style transfer as a sentence rewriting task and requires only a natural language instruction, without model fine-tuning or exemplars in the target style. Augmented zero-shot learning is simple and demonstrates promising results not just on standard style transfer tasks such as sentiment, but also on arbitrary transformations such as 'make this melodramatic' or 'insert a metaphor.'",/pdf/110adafcdea6c652f065714cc2aad50dfb26d66d.pdf,/attachment/403a48d1c5b01bd392561b679b586251142bdacc.zip,,,,,anonymous|a_recipe_for_arbitrary_text_style_transfer_with_large_language_models,,,/attachment/3f6727a57fac8d0e7874a24bd396bbe9c28f3cab.zip,https://openreview.net/forum?id=tTwG1UKHRB1,/attachment/b554daf1cadf8863b8e9c50d08788c6abfaf3fea.pdf,/attachment/d729e9d1e8807358559014a11cb9f2eef23fdf2a.pdf
33,UhWxRIIb0Bd,Decomposing Natural Logic Inferences in Neural NLI,['aclweb.org/ACL/ARR/2021/October/Paper363/Authors'],['Anonymous'],,"In the interest of interpreting neural NLI models and their reasoning strategies, 
we carry out a systematic probing study which investigates whether these models
capture the crucial semantic features central to natural logic: \emph{monotonicity} and \emph{concept inclusion}.
Correctly identifying valid inferences in \emph{downward-monotone contexts} is a known stumbling block for NLI performance,
subsuming linguistic phenomena such as negation scope and generalized quantifiers.
To understand this difficulty, we emphasize monotonicity as a property of a \emph{context} and examine the extent to which 
models capture monotonicity information in the contextual embeddings which are 
intermediate to their decision making process.
Drawing on the recent advancement of the probing paradigm,
we compare the presence of monotonicity features across various models.
We find that monotonicity information is notably weak in the representations of popular
NLI models which achieve high scores on benchmarks, 
and observe that previous improvements to these models based on fine-tuning strategies 
have introduced stronger monotonicity features together with their improved performance on challenge sets.",/pdf/4f2a1bd7f870bebdee57e3795aef9fa9a8d0f424.pdf,/attachment/beba6512f7204b988e1a7330ee7ab12e1ca8ca5f.zip,,,,,anonymous|decomposing_natural_logic_inferences_in_neural_nli,,,/attachment/7c6d5996a47eccea8294dbd76f56c5fc0fa33625.zip,,,
34,f6VUHB7dzXU,On the current state of reproducibility and reporting of uncertainty for Aspect-based Sentiment Analysis,['aclweb.org/ACL/ARR/2021/October/Paper212/Authors'],['Anonymous'],,"For the latter part of the past decade, Aspect-Based Sentiment Analysis has been a field of great interest within Natural Language Processing. Supported by the Semantic Evaluation Conferences in 2014 -- 2016, a variety of methods has been developed competing in improving performances on benchmark data sets. Exploiting the transformer architecture behind BERT, results improved rapidly and efforts in this direction still continue today. Our contribution to this body of research is a holistic comparison of six different architectures which achieved (near) state-of-the-art results at some point in time. We utilize a broad spectrum of five benchmark data sets and introduce a fixed setting with respect to the pre-processing, the train/validation splits, the performance measures and the quantification of uncertainty. Overall, our findings are two-fold: First, we find that the results reported in the scientific articles are hardly reproducible, since in our experiments the observed performance (most of the time) fell short of the reported one. Second, the results are burdened with notable uncertainty (depending on the data splits) which is why a reporting of uncertainty measures is crucial.",/pdf/1d5d6333f0571f7d420bad6a8a4b24c72ca6e654.pdf,/attachment/b01f9c493ee67bea1a28e4f0cffede62d9c0004c.zip,,,,,anonymous|on_the_current_state_of_reproducibility_and_reporting_of_uncertainty_for_aspectbased_sentiment_analysis,,,,,,
35,KGZuSjDfD9X,Know your tools well: Better $\textit{and}$ faster QA with synthetic examples,['aclweb.org/ACL/ARR/2021/October/Paper273/Authors'],['Anonymous'],,"Synthetic training data---commonly used to augment human-labeled examples in supervised learning---are often noisy, but can be generated in very large quantities and diversity. This paper proposes to leverage these unique attributes in a targeted manner to maximize the utility of synthetic examples. Via two novel applications that utilize synthetic data for targeted pre-training and knowledge distillation, we demonstrate the feasibility of this idea for machine reading comprehension (MRC). Using our proposed methods, we are able to train simultaneously $\textbf{\textit{smaller}}$, $\textbf{\textit{faster}}$ and $\textbf{\textit{more accurate}}$ MRC models than existing synthetic augmentation methods. Our methods are generic in nature and can be applied to any task for which synthetic data can be generated.",/pdf/0b6b0f6676edf5e08e28d56545605f7e822f245f.pdf,,,,,,anonymous|know_your_tools_well_better_\textitand_faster_qa_with_synthetic_examples,,,,,,
36,Zei8z8tt3eN,Finding the Right Recipe for Low Resource Domain Adaptation in Neural Machine Translation,['aclweb.org/ACL/ARR/2021/October/Paper276/Authors'],['Anonymous'],,"Despite the considerable amount of parallel data used to train neural machine translation models, they can still struggle to generate fluent translations in technical domains. In-domain parallel data is often very low resource and synthetic domain data generated via back-translation is frequently lower quality. To guide machine translation practitioners and characterize the effectiveness of domain adaptation methods under different data availability scenarios, we conduct an in-depth empirical exploration of monolingual and parallel data approaches to domain adaptation. We compare mixed domain fine-tuning, traditional back-translation, tagged back-translation, and shallow fusion with domain specific language models in isolation and combination. We study method effectiveness in very low resource (8k parallel examples) and moderately low resource (46k parallel examples) conditions. We demonstrate the advantages of augmenting clean in-domain parallel data with noisy mined in-domain parallel data and propose an ensemble approach to alleviate reductions in original domain translation quality. Our work includes three domains: consumer electronic, clinical, and biomedical and spans four language pairs - Zh-En,  Ja-En, Es-En, and Ru-En. We make concrete recommendations for achieving high in-domain performance. We release our consumer electronic and clinical domain datasets for all languages and make our code publicly available.",/pdf/15838e9a31392520fe49ab1f09b2600670e83edc.pdf,,,,,,anonymous|finding_the_right_recipe_for_low_resource_domain_adaptation_in_neural_machine_translation,,,,,,
37,IJ5h6WGQQOi,Knowledge Inheritance for Pre-trained Language Models,['aclweb.org/ACL/ARR/2021/October/Paper189/Authors'],['Anonymous'],,"Recent explorations of large-scale pre-trained language models (PLMs) such as GPT-3 have revealed the power of PLMs with huge amounts of parameters, setting off a wave of training ever-larger PLMs. However, training a large-scale PLM requires tremendous amounts of computational resources, which is time-consuming and expensive. In addition, existing large-scale PLMs are mainly trained from scratch individually, ignoring the availability of many existing well-trained PLMs. To this end, we explore the question that how can previously trained PLMs benefit training larger PLMs in future. Specifically, we introduce a novel pre-training framework named ""knowledge inheritance"" (KI), which combines both self-learning and teacher-guided learning to efficiently train larger PLMs. Experimental results demonstrate the superiority of our KI framework. We also conduct empirical analyses to explore the effects of teacher PLMs' pre-training settings, including model architecture, pre-training data, etc. Finally, we show that KI can well support lifelong learning and knowledge transfer. All source code and model parameters will be available to advance further research explorations.",/pdf/c6ad87a536be25432f1d193776ee8b4cabf55020.pdf,/attachment/b87b3cc66aad70693a6c1d02218281650e313942.zip,,,,,anonymous|knowledge_inheritance_for_pretrained_language_models,,,,,,
38,8-f2mY3-Wz7,Echo-Attention: Attend Once and Get $N$ Attentions for Free,['aclweb.org/ACL/ARR/2021/October/Paper69/Authors'],['Anonymous'],,"This paper proposes echo-attention layers, an efficient method for improving the expressiveness of the self-attention layers without incurring significant parameter or training time costs. The key idea is to iteratively refine the attentional activations via stateful repeated computation, i.e., we compute the activations once and get $N$ refinements (echo-attentions) at a relatively cheap cost. To this end, we introduce an update and state transition function that operates over these attentional activations. Via a set of extensive experiments, we show that this the proposed Echoformer model demonstrates widespread benefits across 21 datasets including language modeling, machine translation, language understanding and question answering.",/pdf/3df32c1993ee1040c6d5cf99aa1e5dea51493119.pdf,,,,,,anonymous|echoattention_attend_once_and_get_n_attentions_for_free,,,,,,
39,T9c1RQjUX9a,,,,,,,,,,,,,,,,,,
40,Y53vqNr36P,3M:Multi-document Summarization Considering Main and Minor Relationship,['aclweb.org/ACL/ARR/2021/October/Paper98/Authors'],['Anonymous'],,"The multi-document summary task is an important branch of the information aggregation task. Compared with the single-document summary, the input of multi-document summary is much longer and the logic is more complicated. This article proposes a hypothesis: taking the content of a document as the main body and the content of other documents as auxiliary information, a summary that combines all the information in the document collection can be generated. Based on this assumption, the multi-document summarization task can select one main document, and then combine the information of other documents for summary generation. This paper combines CopyTransformer and the Maximal Marginal Relevance (MMR) to design Multi-document summarization considering Main and Minor relationship model(3M). Empirical results on the Multi-News and DUC 2004 dataset show that the 3M brings substantial improvements over several strong baselines, manual evaluation shows that the generated abstract is fluent and can better express the content of the main document. In addition, by selecting different main documents, 3M can generate multiple abstracts with different styles for a set of documents.",/pdf/0c6a3b12e4d0e234f6ca13a3485ab291ac2f3c27.pdf,,,,,,anonymous|3mmultidocument_summarization_considering_main_and_minor_relationship,,,,,,
41,fcCZfRuN3L,Re-Examining System-Level Correlations of Automatic Summarization Evaluation Metrics,['aclweb.org/ACL/ARR/2021/October/Paper218/Authors'],['Anonymous'],,"How reliably an automatic summarization evaluation metric replicates human judgments of summary quality is quantified by system-level correlations. We identify two ways in which the definition of the system-level correlation is inconsistent with how metrics are used to evaluate systems in practice and propose changes to rectify this disconnect. First, we calculate the system score for an automatic metric using the full test set instead of the subset of summaries annotated by humans, which is currently standard practice. We demonstrate how this small change leads to more precise estimates of system-level correlations. Second, we propose to calculate correlations only on pairs of systems which are separated by differences in automatic scores that are commonly used to argue one system is of higher quality. This allows us to demonstrate that our best estimate of the correlation of ROUGE to human judgments is near 0 in realistic scenarios. Finally, the results from both analyses point to the need for future research to focus on developing more consistent and reliable human evaluations of summaries.",/pdf/a017cc9c40825d00da8e0e1b674fb15e5a01bf46.pdf,,,,,,anonymous|reexamining_systemlevel_correlations_of_automatic_summarization_evaluation_metrics,,,,,,
42,_oLmflkKwvd,Fully Hyperbolic Neural Networks,['aclweb.org/ACL/ARR/2021/October/Paper92/Authors'],['Anonymous'],,"Hyperbolic neural networks have shown great potential for modeling complex data. However, existing hyperbolic networks are not completely hyperbolic, as they encode features in the hyperbolic space yet formalize most of their operations in the tangent space (a Euclidean subspace) at the origin of the hyperbolic model. This hybrid method greatly limits the modeling ability of networks. In this paper, we propose a fully hyperbolic framework to build hyperbolic networks based on the Lorentz model by adapting the Lorentz transformations (including boost and rotation) to formalize essential operations of neural networks. Moreover, we also prove that linear transformation in tangent spaces used by existing hyperbolic networks is a relaxation of the Lorentz rotation and does not include the boost, implicitly limiting the capabilities of existing hyperbolic networks. The experimental results on four NLP tasks show that our method has better performance for building both shallow and deep networks. Our code will be released to facilitate follow-up research.",/pdf/82f5a8cec2f282cfad2d55b2623bb66918a679fb.pdf,,,,,,anonymous|fully_hyperbolic_neural_networks,,,,,,
43,X3Nrd_CQEY,VALSE: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena,['aclweb.org/ACL/ARR/2021/October/Paper104/Authors'],['Anonymous'],,"We propose VALSE (Vision And Language Structured Evaluation), a novel benchmark designed for testing general-purpose pretrained vision and language (V&L) models for their visio-linguistic grounding capabilities on specific linguistic phenomena. VALSE offers a suite of six tests covering various linguistic constructs. Solving these requires models to ground linguistic phenomena in the visual modality, allowing more fine-grained evaluations than hitherto possible. We build VALSE using methods that support the construction of valid foils, and report results from evaluating five widely-used V&L models. Our experiments suggest that current models have considerable difficulty addressing most phenomena. Hence, we expect VALSE to serve as an important benchmark to measure future progress of pretrained V&L models from a linguistic perspective, complementing the canonical task-centred V&L evaluations.",/pdf/980d81b44bcc24ff476bc20f60aed12fa9e1c1e5.pdf,,,,,,anonymous|valse_a_taskindependent_benchmark_for_vision_and_language_models_centered_on_linguistic_phenomena,,,,https://openreview.net/forum?id=p-4qeZrTeCy,/attachment/4abf028b4ea9e5776bdad2d7c0ae168d6bd41660.pdf,/attachment/716295ecc82fc5f46cdfb7c85c657b9371ead899.pdf
44,nQgLq6RFXhE,Safety Bench: Identifying Safety-Sensitive Situations for Open-domain Conversational Systems,['aclweb.org/ACL/ARR/2021/October/Paper106/Authors'],['Anonymous'],,"The social impact of natural language processing and its applications has received increasing attention. Here, we focus on the problem of safety for end-to-end conversational AI.  We survey the problem landscape therein, introducing a taxonomy of three observed phenomena: the Instigator, Yea-Sayer, and Impostor effects. To help researchers better understand the impact of their conversational models with respect to these scenarios, we present Safety Bench, a set of open-source tooling for quickly assessing safety issues. Finally, we provide extensive analysis of these tools using five popular models and make recommendations for future use.",/pdf/a92ec0b4f81eccde340e7d97441e6a6edd59864f.pdf,,,,,,anonymous|safety_bench_identifying_safetysensitive_situations_for_opendomain_conversational_systems,,,,,,
45,lOW4PwR18Nw,A Federated Approach to Predict Emojis in Hindi Tweets,['aclweb.org/ACL/ARR/2021/October/Paper224/Authors'],['Anonymous'],,"The use of emojis provide for adding a visual modality to textual communication.The task of predicting emojis however provides a challenge for computational approaches as emoji use tends to cluster into the frequently used and the rarely used emojis. Much of the research on emoji use has focused on high resource languages and conceptualised the task of predicting emojis around traditional servers-side machine learning approaches, which can introduce privacy concerns, as user data is transmitted to a central storage. In this paper, we provide a benchmark dataset of $118$k tweets for emoji prediction in Hindi.Specifically, we show that a privacy preserving approach, Federated Learning exhibits comparable performance to traditional servers-side transformer models.",/pdf/3b8a5f58f674d75ef1161e7764a7e2ed2f304b5c.pdf,,,,,,anonymous|a_federated_approach_to_predict_emojis_in_hindi_tweets,,,,,,
46,L-j8a3P22cy,Ditch the Gold Standard: Re-evaluating Conversational Question Answering,['aclweb.org/ACL/ARR/2021/October/Paper256/Authors'],['Anonymous'],,"Conversational question answering (CQA) systems aim to provide natural-language answers to users in information-seeking conversations. Existing benchmarks compare CQA models on pre-collected human-human conversations, with ground-truth answers provided in conversational history. It remains unclear whether we can rely on this static evaluation for model development, or current systems can well generalize to real-world human-machine conversations. In this work, we conduct the first large-scale human evaluation of state-of-the-art CQA systems, where human evaluators converse with models and judge the correctness of their answers. We ﬁnd that the distribution of human-machine conversations drastically differs from that of human-human conversations, and evaluations using gold answers are inconsistent with human evaluations. We further investigate how to improve automatic evaluations and propose a question rewriting mechanism based on predicted history, which better correlates with human judgments. Finally, we analyze the impact of various modeling strategies. We hope that our ﬁndings can shed light on how to develop better CQA systems in the future.",/pdf/23851e8676707e1a3fc64e2735520a37801e0edb.pdf,,,,,,anonymous|ditch_the_gold_standard_reevaluating_conversational_question_answering,,,/attachment/adc883a124eb4c40f79482f0b700d5191cb111fd.zip,,,
47,8OO6o2onCsk,,,,,,,,,,,,,,,,,,
48,vHlVmubdlFI,BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models,['aclweb.org/ACL/ARR/2021/October/Paper155/Authors'],['Anonymous'],,"We show that with small-to-medium training data, fine-tuning only the bias terms (or a subset of the bias terms) of pre-trained BERT models is competitive with (and sometimes better than) fine-tuning the entire model. For larger data, bias-only fine-tuning is competitive with other sparse fine-tuning methods.
Besides their practical utility, these findings are relevant for the question of understanding the commonly-used process of finetuning: they support the hypothesis that finetuning is mainly about exposing knowledge induced by language-modeling training, rather than learning new task-specific linguistic knowledge. ",/pdf/3c445a2a0d70fbc2b9b2dbd40ee9bf8750975fa3.pdf,/attachment/1920be230f65ab722724812289314396cfeba059.zip,,,,,anonymous|bitfit_simple_parameterefficient_finetuning_for_transformerbased_masked_languagemodels,,,,,,
49,zBuFuBG3SN,Exploring the Impact of Negative Samples of Contrastive Learning:  A Case Study of Sentence Embedding,['aclweb.org/ACL/ARR/2021/October/Paper177/Authors'],['Anonymous'],,"Contrastive learning is emerging as a powerful self-supervised technique for extracting knowledge from unlabeled image and text data. This technique requires a balanced mixture of two ingredients: positive (similar) and negative (dissimilar) samples. This is typically achieved by maintaining a queue of negative samples during training. Prior works in the area typically uses a fixed-length negative sample queue, but how the negative sample size affects the model performance remains unclear. The opaque impact of the number of negative samples on performance when employing contrastive learning aroused our in-depth exploration. This paper presents a momentum contrastive learning model with negative sample queue for sentence embedding, namely MoCoSE. We add the prediction layer to the online branch to make the model asymmetric and together with EMA update mechanism of the target branch to prevent model from collapsing. We define a maximum traceable distance metric, through which we learn to what extent the text contrastive learning benefits from the historical information of negative samples. Our experiments find that the best results are obtained when the maximum traceable distance is at a certain range, demonstrating that there is an optimal range of historical information for a negative sample queue. We evaluate the proposed unsupervised MoCoSE on the semantic text similarity (STS) task and obtain an average Spearman's correlation of $77.27\%$. Source code is available at https://anonymous.4open.science/r/mocose-3E3C.",/pdf/97facd4677f860413885625b8a2359519590d3a5.pdf,,,,,,anonymous|exploring_the_impact_of_negative_samples_of_contrastive_learning_a_case_study_of_sentence_embedding,,,,,,
50,Tvq2rUcMgZY,Alleviating the Inequality of Attention Heads for Neural Machine Translation,['aclweb.org/ACL/ARR/2021/October/Paper63/Authors'],['Anonymous'],,"Recent studies show that the attention heads in Transformer are not equal. We relate this phenomenon to the imbalance training of multi-head attention and the model dependence on specific heads. To tackle this problem, we propose a simple masking method: HeadMask, in two specific ways. Experiments show that translation improvements are achieved on multiple language pairs. Subsequent empirical analyses also support our assumption and confirm the effectiveness of the method.",/pdf/9b73b74f1be4643a24810c507bf5d69b27ae780b.pdf,,,,,,anonymous|alleviating_the_inequality_of_attention_heads_for_neural_machine_translation,,,,,,
51,wqb7tteMHFI,Re-evaluating Extreme Multi-label Text Classification Methods in Tail Label Prediction,['aclweb.org/ACL/ARR/2021/October/Paper255/Authors'],['Anonymous'],,"Extreme multi-label text classification (XMTC) is the task of tagging each document with the relevant labels in a very large set of predefined category labels. The most challenging part of the problem is due to a highly skewed label distribution where the majority of the categories (namely the tail labels) have very few training instances. Recent benchmark evaluations
have focused on micro-averaging metrics, where the performance on tail labels can be easily overshadowed by that on the
high-frequency labels (namely the head labels). This paper presents a re-evaluation of state-of-the-art (SOTA) methods based on the binned macro-averaging F1 instead, revealing new insights into the strengths and weaknesses of representative methods, especially in tail label prediction.",/pdf/f3b11c7c5394c5b53ca5b1ecf95780d52e2627d5.pdf,,,,,,anonymous|reevaluating_extreme_multilabel_text_classification_methods_in_tail_label_prediction,,,,https://openreview.net/forum?id=UboX_l0hKrf#authors,/attachment/3386562811bd3b00a8849c2d2189fc952f281ab3.pdf,/attachment/9fd8e7a2301e5274458479d42ace690c0113c070.pdf
52,AyY4k4BXLVL,D2U: Distance-to-Uniform Learning for Out-of-Scope Detection,['aclweb.org/ACL/ARR/2021/October/Paper46/Authors'],['Anonymous'],,"Supervised models trained for single-label classification tasks with cross-entropy loss are implicitly enforced to produce probability distributions that follow a discrete delta distribution in training. Model predictions in test time are expected to be similar to delta distributions given that the classifier determines the class of an input correctly. However, the shape of the predicted probability distribution becomes similar to the uniform distribution when the model cannot infer properly. We exploit this observation for detecting out-of-scope (OOS) utterances in conversational systems. Specifically, we propose a zero-shot post-processing step, called Distance-to-Uniform (D2U), exploiting not only the classification confidence score, but the shape of the entire output distribution. We also introduce a learning procedure that uses D2U for loss calculation in the supervised setup. We conduct experiments using six publicly available datasets. Experimental results show that the performance of out-of-scope detection is improved with our post-processing when there is no OOS training data, as well as with D2U learning procedure when OOS training data is available.",/pdf/049338ab08a2fc3dadd4c1653c4359791bc3e1a7.pdf,,,,,,anonymous|d2u_distancetouniform_learning_for_outofscope_detection,,,,,,
53,vt2mKMUI0vN,PPT: Pre-trained Prompt Tuning for Few-shot Learning,['aclweb.org/ACL/ARR/2021/October/Paper30/Authors'],['Anonymous'],,"Prompts for pre-trained language models (PLMs) have shown remarkable performance by bridging the gap between pre-training tasks and various downstream tasks. Among these methods, prompt tuning, which freezes PLMs and only tunes soft prompts, provides an efficient and effective solution for adapting large-scale PLMs to downstream tasks. However, prompt tuning is yet to be fully explored. In our pilot experiments, we find that prompt tuning performs comparably with conventional full-model tuning when downstream data are sufficient, whereas it is much worse under few-shot learning settings, which may hinder the application of prompt tuning. We attribute this low performance to the manner of initializing soft prompts. Therefore, in this work, we propose to pre-train prompts by adding soft prompts into the pre-training stage to obtain a better initialization. We name this Pre-trained Prompt Tuning framework ""PPT"". To ensure the generalization of PPT, we formulate similar classification tasks into a unified task form and pre-train soft prompts for this unified task. Extensive experiments show that tuning pre-trained prompts for downstream tasks can reach or even outperform full-model fine-tuning under both full-data and few-shot settings. Our approach is effective and efficient for using large-scale PLMs in practice.",/pdf/c54f3c315107c9749079bfc03a032dc29b59ffa1.pdf,/attachment/a416b182887ad47c707c0ed0765ecfd3f70c8130.tgz,,,,,anonymous|ppt_pretrained_prompt_tuning_for_fewshot_learning,,,,,,
54,XT4BaluDTo,Multi-Label Text Classification by Graph Neural Network with Mixing Operations,['aclweb.org/ACL/ARR/2021/October/Paper26/Authors'],['Anonymous'],,"Multi-label text classification is one of the fundamental tasks in natural language processing. Recently, the graph convolution network (GCN) is leveraged to boost the performance of such a task. However, the best way for label correlation modeling and feature learning with label system awareness is still unclear. This paper proposes Mix-GCN, a graph network with two mixing operations, to improve the conventional GCN framework for multi-label text classification in the following two steps. Firstly, we model the label correlations by mixing the graph built from statistical co-occurrence information and the graph constructed from prior knowledge. Secondly, we propose a mixing operation to continuously inject GCN embedding into LSTM representation learning for better label-aware representation. Experimental results on four benchmarks demonstrate that Mix-GCN significantly outperforms the state-of-the-art models and performs better in long-tail label cases.",/pdf/1c4d279c48cfdf9889a51579ca125c8a68f43589.pdf,,,,,,anonymous|multilabel_text_classification_by_graph_neural_network_with_mixing_operations,,,,,,
55,cOm0MGvnw-m,On the Sensitivity and Stability of Model Interpretations,['aclweb.org/ACL/ARR/2021/October/Paper277/Authors'],['Anonymous'],,"Recent years have witnessed the emergence of a variety of post-hoc interpretations that aim to uncover how natural language processing (NLP) models make predictions. Despite the surge of new interpretation methods, it remains an open problem how to define and quantitatively measure the faithfulness of interpretations, i.e., to what extent interpretations reflect the reasoning process by a model. We propose two new criteria, sensitivity and stability, that provide complementary notions of faithfulness to the existed removal-based criteria. Our results show that the conclusion for how faithful interpretations are could vary substantially based on different notions. Motivated by the desiderata of sensitivity and stability, we introduce a new class of interpretation methods that adopt techniques from adversarial robustness. Empirical results show that our proposed methods are effective under the new criteria and overcome limitations of gradient-based methods on removal-based criteria. Besides text classification, we also apply interpretation methods and metrics to dependency parsing. Our results shed light on understanding the diverse set of interpretations. ",/pdf/4e85bc7c1eb89361821e62e9455338ad263b3a3f.pdf,,,,,,anonymous|on_the_sensitivity_and_stability_of_model_interpretations,,,,,,
56,za_XIJLkkB8,Few-Shot Learning with Siamese Networks and Label Tuning,['aclweb.org/ACL/ARR/2021/October/Paper17/Authors'],['Anonymous'],,"We study the problem of building text classifiers with little or no training data, commonly known as zero and few-shot text classification.
In recent years, an approach based on neural textual entailment models has been found to give strong results on a diverse range of tasks.
In this work, we show that with proper pre-training, Siamese networks that embed texts and labels are
a competitive alternative.
These models allow for a large reduction in inference cost: constant in the number of labels rather than linear.
Furthermore, we introduce label tuning, a simple and computationally efficient approach that allows to adapt the models in a few-shot setup by only changing the label embeddings.
While giving lower performance than model fine-tuning, this approach has the architectural advantage that a single encoder can be shared by many different tasks.",/pdf/1f6c0d983c4888f835f2500f7262fe179b8e0997.pdf,,,,,,anonymous|fewshot_learning_with_siamese_networks_and_label_tuning,,,,,,
57,pjIGcGEI39,OkwuGbé: End-to-End Speech Recognition for Fon and Igbo,['aclweb.org/ACL/ARR/2021/October/Paper8/Authors'],['Anonymous'],,"Language is inherent and compulsory for human communication. Whether expressed in a written or spoken way, it ensures understanding between people of the same and different regions. With the growing awareness and effort to include more low-resourced languages in NLP research, African languages have recently been a major subject of research in machine translation, and other text-based areas of NLP. However, there is still very little comparable research in speech recognition for African languages. Interestingly, some of the unique properties of African languages affecting NLP, like their diacritical and tonal complexities, have a major root in their speech, suggesting that careful speech interpretation could provide more intuition on how to deal with the linguistic complexities of African languages for text-based NLP. OkwuGbé is a step towards building speech recognition systems for African low-resourced languages. Using Fon and Igbo as our case study, we conduct a comprehensive linguistic analysis of each language and describe the creation of end-to-end, deep neural network-based speech recognition models for both languages. We present a state-of-the-art ASR model for Fon, as well as benchmark ASR model results for Igbo. Our linguistic analyses (for Fon and Igbo) provide valuable insights and guidance into the creation of speech recognition models for other African low-resourced languages, as well as guide future NLP research for Fon and Igbo. The Fon and Igbo models source code will be publicly available.",/pdf/cb0b9283194f27dc85c24bfce70efff60e540a34.pdf,,,,,,anonymous|okwugbé_endtoend_speech_recognition_for_fon_and_igbo,,,,,,
58,yD9xAnPpWUV,N-Shot Learning for Augmenting Task-Oriented Dialogue State Tracking,['aclweb.org/ACL/ARR/2021/October/Paper158/Authors'],['Anonymous'],,"We introduce an augmentation framework that utilizes belief state annotations to match turns from various dialogues and forms new synthetic dialogues in a bottom-up manner. Unlike other augmentation strategies, it operates with as few as five examples. Our augmentation strategy yields significant improvements when both adapting a DST model to a new domain, and when adapting a language model to the DST task, on evaluations with TRADE and TOD-BERT models. Further analysis shows that our model performs better on seen values during training, and it is also more robust to unseen values even though we do not use any external dataset for augmentation. We conclude that exploiting belief state annotations enhances dialogue augmentation and results in improved models in $n$-shot training scenarios.",/pdf/4fdb4d0e7a2ead7335a0e882e990bd7587c902cc.pdf,,,,,,anonymous|nshot_learning_for_augmenting_taskoriented_dialogue_state_tracking,,,,https://openreview.net/forum?id=9RPBbhNN9lC,/attachment/40d06a8efe21ec1ca3b167a4b5ab63c62d3cd2bd.pdf,/attachment/b0f82f63d7dea088d332bd12414a26663c82ae49.pdf
59,EHzvRqy6kD,TableFormer: Robust Transformer Modeling for Table-Text Encoding,['aclweb.org/ACL/ARR/2021/October/Paper241/Authors'],['Anonymous'],,"Understanding tables is an important aspect of natural language understanding. Existing models for table understanding require linearization of the table structure, where row or column order is encoded as an unwanted bias. Such spurious biases make the model vulnerable to row and column order perturbations. Additionally, prior work has not explicitly modeled the table structure, hindering the table-text modeling ability. In this work, we propose a robust and structurally aware table-text encoding architecture TableFormer, where tabular structural biases are incorporated completely through learnable attention biases. TableFormer is strictly invariant to row and column orders, and could understand tables better due to its tabular inductive biases. Our evaluations showed that TableFormer outperforms strong baselines in all settings on SQA, WTQ and TabFact table reasoning datasets, and achieves state-of-the-art performance on SQA, especially when facing answer-invariant row and column order perturbations (6% improvement over the best baseline), because previous SOTA models' performance drops by 4% - 6% when facing such perturbations while TableFormer is not affected. ",/pdf/243f895b627124c7b3c87501f50ccf2a2f410949.pdf,,,,,,anonymous|tableformer_robust_transformer_modeling_for_tabletext_encoding,,,,,,
60,CwI43NHUsB,Joint Content-Context Analysis of Scientific Publications: Identifying Opportunities for Collaboration in Cognitive Science,['aclweb.org/ACL/ARR/2021/October/Paper252/Authors'],['Anonymous'],,"This work studies publications in cognitive science and utilizes natural language processing and graph theoretical techniques to connect the analysis of the papers' content (abstracts) to the context (citation, journals). We apply hierarchical topic modeling on the abstracts and community detection algorithms on the citation network, and measure content-context discrepancy to find academic fields that study similar topics but do not cite each other or publish in the same venues. These results show a promising, systemic framework to identify opportunities for scientific collaboration in highly interdisciplinary fields such as cognitive science and machine learning.",/pdf/a4f812ff9b30c1fc7b2db90fa0255600af06cbc1.pdf,/attachment/206f8b096beca9f03b15914c49721ac9d1f52600.zip,,,,,anonymous|joint_contentcontext_analysis_of_scientific_publications_identifying_opportunities_for_collaboration_in_cognitive_science,,,,,,
61,-B3vVVeVyTr,Measuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment,['aclweb.org/ACL/ARR/2021/October/Paper345/Authors'],['Anonymous'],,"Recently, the challenge of compositional generalization in NLP has attracted more and more attention. Specifically, many prior works show that neural networks struggle with compositional generalization where training and testing distributions differ. However, most of these works are based on word-level synthetic data or a specific data split method to generate compositional biases. In this work, we propose a clause-level compositional example generation method, and we focus on text-to-SQL tasks. We start by splitting the sentences in the Spider text-to-SQL dataset into several sub-sentences, annotating each sub-sentence with its corresponding SQL clause, resulting in a new dataset, Spider-SS. Building upon Spider-SS, we further construct a new dataset named Spider-CG, by substituting and appending Spider-SS sub-sentences to test the ability of models to generalize compositionally. Experiments show that previous models suffer significant performance degradation when evaluated on Spider-CG, even though every sub-sentence has been seen during training. To deal with this problem, we modify the RATSQL+GAP model to fit the segmented data of Spider-SS, and results show that this method can improve generalization performance.",/pdf/7e3fb462bd32ebd39629c33c78bbadf44afe9be5.pdf,,,,,,anonymous|measuring_and_improving_compositional_generalization_in_texttosql_via_component_alignment,,,,,,
62,5E6D-RXKm67,Emotion Flip Reasoning in Multiparty Conversations,['aclweb.org/ACL/ARR/2021/October/Paper319/Authors'],['Anonymous'],,"Emotion plays a major role in conversation analysis. To understand the emotional dynamics of the speakers in a conversation, it is imperative to reason out any change/flip of the emotion of a particular speaker. In this paper, we introduce a novel task -- Emotion Flip Reasoning (aka EFR) that aims to find a rationale or instigator behind the emotion flip of a speaker within a conversational dialog, e.g., joy --> anger. To this end, we introduce MELD-I, a new dataset with ground-truth EFR instigator labels. Following emotion psychology, we define 27 instigator labels in a hierarchical fashion - the coarse-grained set contains 14 instigators, while the fine-grained set comprises all 27 instigators. To benchmark the dataset, we propose TGIF, an efficient neural architecture that captures the dialog context, speaker dynamics, and emotion sequence in a conversation using Transformer encoders and stacked GRUs. Our evaluation yields state-of-the-art performance against five baselines adopted for our task. A detailed diagnosis of the competing models further illustrates the advantages and pitfalls of the neural architecture.",/pdf/184f72803273af0e76adc7787126c2d9cebcc778.pdf,,,,,,anonymous|emotion_flip_reasoning_in_multiparty_conversations,,,,,,
63,mVJ-hJVpq3r,A Novel Metric for Evaluating Semantics Preservation,['aclweb.org/ACL/ARR/2021/October/Paper94/Authors'],['Anonymous'],,"In this paper, we leverage pre-trained language models (PLMs) to precisely evaluate the semantics preservation of edition process on sentences. Our metric, Neighboring Distribution Divergence (NDD), evaluates the disturbance on predicted distribution of neighboring words from mask language model (MLM). NDD is capable of detecting precise changes in semantics which are easily ignored by text similarity. By exploiting the property of NDD, we implement a unsupervised and even training-free algorithm for extractive sentence compression. We show that NDD-based algorithm outperforms previous perplexity-based unsupervised algorithm by a large margin. For further exploration on interpretability, we evaluate NDD by pruning on syntactic dependency treebanks and apply NDD for predicate detection as well.",/pdf/3598ba2a1426dbc1e10df9a80fda3e37f05bc94d.pdf,,,,,,anonymous|a_novel_metric_for_evaluating_semantics_preservation,,,,,,
64,-QbSweqQGH,Semantic Search as Extractive Paraphrase Span Detection,['aclweb.org/ACL/ARR/2021/October/Paper162/Authors'],['Anonymous'],,"In this paper, we approach the problem of semantic search by framing the search task as paraphrase span detection, i.e. given a segment of text as a query phrase, the task is to identify its paraphrase in a given document, the same modelling setup as typically used in extractive question answering. On the Turku Paraphrase Corpus of 100,000 manually extracted Finnish paraphrase pairs including their original document context, we find that our paraphrase span detection model outperforms two strong retrieval baselines (lexical similarity and BERT sentence embeddings) by 31.9pp and 22.4pp respectively in terms of exact match, and by 22.3pp and 12.9pp in terms of token-level F-score. This demonstrates a strong advantage of modelling the task in terms of span retrieval, rather than sentence similarity. Additionally, we introduce a method for creating artificial paraphrase data through back-translation, suitable for languages where manually annotated paraphrase resources for training the span detection model are not available.",/pdf/5eaa29d04270b1da61b510d75d520ccb3a023118.pdf,,,,,,anonymous|semantic_search_as_extractive_paraphrase_span_detection,,,,,,
65,MPYhVVHOjrX,About Time: Do Transformers Learn Temporal Verbal Aspect?,['aclweb.org/ACL/ARR/2021/October/Paper271/Authors'],['Anonymous'],,"Aspect is a linguistic concept that describes how an action, event, or state of a verb phrase is situated in time. In this paper, we explore whether different transformer models are capable of identifying aspectual features. We focus on two specific aspectual features: telicity and duration. Telicity marks whether the verb's action or state has an endpoint or not (telic/atelic), and duration denotes whether a verb expresses an action (dynamic) or a state (stative). These features are integral to the interpretation of natural language, but also hard to annotate and identify with NLP methods. Our results show that transformer models adequately capture information on telicity and duration in their vectors, even in their pretrained forms, but are somewhat biased with regard to verb tense and word order.",/pdf/2f96c2001d5aa760982b3921e1813a519cf51f21.pdf,,,,,,anonymous|about_time_do_transformers_learn_temporal_verbal_aspect,,,,,,
66,3YX-sCVoGl,GCPG: A General Framework for Controllable Paraphrase Generation,['aclweb.org/ACL/ARR/2021/October/Paper55/Authors'],['Anonymous'],,"Controllable paraphrase generation (CPG) incorporates various external conditions to obtain desirable paraphrases. However, existing works only highlight a special condition under two indispensable aspects of CPG (i.e., lexically and syntactically CPG) individually, lacking a unified circumstance to explore and analyze their effectiveness. In this paper, we propose a general controllable paraphrase generation framework (GCPG), which represents both lexical and syntactical conditions as text sequences and uniformly processes them in an encoder-decoder paradigm. Under GCPG, we reconstruct commonly adopted lexical condition (i.e., Keywords) and syntactical conditions (i.e., Part-Of-Speech sequence, Constituent Tree, Masked Template and Sentential Exemplar) and study the combination of the two types. In particular, for Sentential Exemplar condition, we propose a novel exemplar construction method --- Syntax-Similarity based Exemplar (SSE). SSE retrieves a syntactically similar but lexically different sentence as the exemplar for each target sentence, avoiding exemplar-side words copying problem. Extensive experiments demonstrate that GCPG with SSE achieves state-of-the-art performance on two popular benchmarks. In addition, the combination of lexical and syntactical conditions shows the significant controllable ability of paraphrase generation, and these empirical results could provide novel insight to user-oriented paraphrasing.",/pdf/59ca231b7d1ab6f28d0b5a22b9bf5d9e875bf184.pdf,/attachment/c06c4161e6a6cb0fa4378e82b8d179a3ec0be35b.zip,,,,,anonymous|gcpg_a_general_framework_for_controllable_paraphrase_generation,,,,,,
67,SCudycRjg9e,,,,,,,,,,,,,,,,,,
68,tH3Yyx9kCw,Dataset Geography: Mapping Language Data to Language Users,['aclweb.org/ACL/ARR/2021/October/Paper250/Authors'],['Anonymous'],,"As language technologies become more ubiquitous, there are increasing efforts towards expanding the language diversity and coverage of natural language processing (NLP) systems. Arguably, the most important factor influencing the quality of modern NLP systems is data availability. In this work, we study the geographical representativeness of NLP datasets, aiming to quantify if and by how much do NLP datasets match the expected needs of the language speakers. In doing so, we use entity recognition and linking systems, also making important observations about their cross-lingual consistency and giving suggestions for more robust evaluation. Last, we explore some geographical and economic factors that may explain the observed dataset distributions.",/pdf/60e33859c09d416832ede1b98711c621d7c9e34b.pdf,,,,,,anonymous|dataset_geography_mapping_language_data_to_language_users,,,,,,
69,xMyI35L_ByV,,,,,,,,,,,,,,,,,,
70,tt0rsQYp2ig,SPE: Symmetrical Prompt Enhancement for Factual Knowledge Retrieval,['aclweb.org/ACL/ARR/2021/October/Paper247/Authors'],['Anonymous'],,"Pretrained language models (PLMs) have been shown to accumulate factual knowledge from their unsupervised pretraining procedures  (Petroni et al., 2019). Prompting is an effective way to query such knowledge from PLMs. Recently, continuous prompt methods have been shown to have a larger potential than discrete prompt methods in generating effective queries (Liu et al., 2021a). However, these methods do not consider symmetry of the task. In this work, we propose Symmetrical Prompt Enhancement (SPE), a continuous prompt-based method for fact retrieval that leverages the symmetry of the task. Our results on LAMA, a popular fact retrieval dataset, show significant improvement of SPE over previous prompt methods.",/pdf/6518189a14a4f404218074be655a764a243babdf.pdf,,,,,,anonymous|spe_symmetrical_prompt_enhancement_for_factual_knowledge_retrieval,,,,,,
71,D5u046Zw_2F,Multi-Task End-to-End Training Improves Conversational Recommendation,['aclweb.org/ACL/ARR/2021/October/Paper124/Authors'],['Anonymous'],,"In this paper, we analyze the performance of a multitask end-to-end transformer model on the task of conversational recommendations, which aim to provide recommendations based on a user’s explicit preferences expressed in dialogue. While previous works in this area adopt complex multi-component approaches where the dialogue generation and entity recommendation tasks are handled by separate components, we show that a unified transformer model, based on the T5 text-to-text transformer model, can perform competitively in both recommending relevant items and generating conversation dialogue. We fine-tune our model on the ReDIAL conversational movie recommendation dataset, and create additional training tasks derived from MovieLens (such as the prediction of movie attributes and related movies based on an input movie), in a multitask learning setting. Using a series of probe studies, we demonstrate that the learned knowledge in the additional tasks is transferred to the conversational setting, where each task leads to a $9\% - 52\%$ increase in its related probe score.",/pdf/406ab9dbe363aec3caaf2ed2823ff08b0c1fa089.pdf,,,,,,anonymous|multitask_endtoend_training_improves_conversational_recommendation,,,,,,
72,ditvg5hEWc,How Does Data Corruption Affect Natural Language Understanding Models? A Study on GLUE datasets,['aclweb.org/ACL/ARR/2021/October/Paper126/Authors'],['Anonymous'],,"A central question in natural language understanding (NLU) research is whether high performance demonstrates the models' strong reasoning capabilities. We present an extensive series of controlled experiments where pre-trained language models are exposed to data that have undergone specific corruption transformations. The transformations involve removing instances of specific word classes and often lead to non-sensical sentences. Our results show that performance remains high for most GLUE tasks when the models are fine-tuned or tested on corrupted data, suggesting that the models leverage other cues for prediction even in non-sensical contexts. ",/pdf/1b35bd098692f03df666b7afd8a3c58ec7f9af9d.pdf,,,,,,anonymous|how_does_data_corruption_affect_natural_language_understanding_models_a_study_on_glue_datasets,,,,,,
73,IKcA7NsTqU,Curriculum Data Augmentation for Low-Resource Slides Summarization,['aclweb.org/ACL/ARR/2021/October/Paper282/Authors'],['Anonymous'],,"Data augmentation is commonly used in training in low-resource scenarios. However, there are sometimes large discrepancy between distributions of augmented data and target data. How to bridge the gap between the augmented and target data, especially when target data is harder-to-learn? In this paper, we study improved data augmentation strategies in the scenario of scientific slides text summarization, where we generate a textual summary based on texts of presentation slides. Since slides are messy and difficult to understand by current models, we introduce an easier form of data, i.e., articles in natural language. The basic idea is that we generate the transition data between slides and articles, and all three of them form a curriculum for neural models to learn the distribution transition from article data to slides data. We find that our approach achieves consistent improvements over different backbone summarization models. The curriculum-oriented data augmentation method can generate data that fill the gap between the easy-to-obtain data and the low-resource task data. We show that curriculum learning and data augmentation can be combined to help NLP models learn from otherwise hard-to-learn data.",/pdf/90b74d9d8ee2d0ef140d82733b70725412cbeec0.pdf,,,,,,anonymous|curriculum_data_augmentation_for_lowresource_slides_summarization,,,,,,
74,_3b3b6YZ-yK,InducT-GCN: Inductive Graph Convolutional Networks for Text Classification,['aclweb.org/ACL/ARR/2021/October/Paper300/Authors'],['Anonymous'],,"Text classification aims to assign labels to textual units by making use of global information. Recent studies have applied graph neural network (GNN) techniques to capture the global word co-occurrence in a corpus. Most existing approaches require that all the nodes (training and test) in a graph are present during training, which are transductive and do not naturally generalise to unseen nodes. To make those models \textit{inductive}, previous works use extra resources, like pretrained word embedding. However, high-quality resource is not always available and can be hard to train. Under the extreme settings 
with no extra resource and limited amount of training set, can we still learn an inductive graph-based text classification model? In this paper, we introduce a novel inductive graph-based text classification framework, namely InducT-GCN (InducTive Graph Convolutional Networks for Text classification). 
Compared to transductive models that require test documents in training, we construct a graph based on the statistics of training documents only and represent document vectors with a weighted sum of word vectors. We then conduct one-directional GCN propagation during testing. Across five text classification benchmarks, our InducT-GCN outperformed state-of-the-art methods that are either transductive in nature or pre-trained additional resources. We also conducted scalability testing by gradually increasing the data size and revealed that our InducT-GCN can reduce the time and space complexity.",/pdf/283929d552afe9c4223730390290ecf12992259e.pdf,/attachment/37a6661b9410946582e653888908ad45b0e8c8fb.zip,,,,,anonymous|inductgcn_inductive_graph_convolutional_networks_for_text_classification,,,/attachment/3ab565d14a7a3f2f1cbc5abc0c4532f1d42f73da.zip,,,
75,xCcOlhiNyu,Turkish Named Entity Recognition: A Survey and Comparative Analysis,['aclweb.org/ACL/ARR/2021/October/Paper362/Authors'],['Anonymous'],,"Named entity recognition is a challenging task that has been widely studied in English. Although there are some efforts for named entity recognition in Turkish language, the reported results are limited to particular datasets and models. Moreover, there is a lack of comparative analysis for named entity recognition in Turkish. In this study, we contribute to the literature in three folds. First, we provide an up-to-date short survey on Turkish named entity recognition studies. Second, we compare state-of-the-art named entity recognition models on various Turkish datasets that we can access to. Lastly, we analyze a set of linguistic processing steps that would affect the performance of Turkish named entity recognition. ",/pdf/21661b3d7af3eab85f3bb10f4934f11089bd3549.pdf,,,,,,anonymous|turkish_named_entity_recognition_a_survey_and_comparative_analysis,,,,,,
76,oRfb1OZt5r,Unmasking the Trade-off: Measuring Gender Bias Mitigation and Over-debiasing Effects in Pretrained Language Models,['aclweb.org/ACL/ARR/2021/October/Paper135/Authors'],['Anonymous'],,"Pretrained language models (PLMs) have demonstrated success across many natural language processing tasks. However, evidence suggests that they encode gender bias present in the corpora they are trained on. Existing bias mitigation methods are usually devised to remove all associations related to gender. This can hurt the performance of PLMs, because it can lead to a loss of genuine and factual associations (e.g., not associating the word ""mother"" with females over males). To measure the extent of undesirable loss of gender associations (i.e. over-debiasing), we introduce the Desirable Associations evaluation corpus for Gender (DA-Gender). We find that three popular debiasing methods result in substantial undesirable loss of gender associations. Our results highlight the importance of mitigating bias without removing genuine gender association, and our dataset constitutes the first benchmark to evaluate over-debiasing.",/pdf/16c6e5d40df1076c68a175249def44e9733be92b.pdf,/attachment/e025157a19034364c156c6518d11f80d319429fc.zip,,,,,anonymous|unmasking_the_tradeoff_measuring_gender_bias_mitigation_and_overdebiasing_effects_in_pretrained_language_models,,,/attachment/6ce037113c23031f942ae0d6c5553d17e124fdcd.zip,,,
77,NkMfx104Bvw,Attention as Grounding: Exploring Textual and Cross-Modal Attention on Entities and Relations in Language-and-Vision Transformer,['aclweb.org/ACL/ARR/2021/October/Paper367/Authors'],['Anonymous'],,"We explore how a multi-modal transformer trained for generation of longer image descriptions learns syntactic and semantic representations about entities and relations grounded in objects at the level of masked self-attention (text generation) and cross-modal attention (information fusion). We observe that cross-attention learns the visual grounding of noun phrases into objects and high-level semantic information about spatial relations, while text-to-text attention captures low-level syntactic knowledge between words. This concludes that language models in a multi-modal task learn different semantic information about objects and relations cross-modally and uni-modally (text-only). Our code is available here: [the GitHub link placeholder].",/pdf/40ded86fdc3edfd3ef6a765557628b9e1b00df1c.pdf,,,,,,anonymous|attention_as_grounding_exploring_textual_and_crossmodal_attention_on_entities_and_relations_in_languageandvision_transformer,,,,,,
78,HiHA7Ct6a-J,A Two-Stage Curriculum Training Framework for NMT,['aclweb.org/ACL/ARR/2021/October/Paper209/Authors'],['Anonymous'],,"Neural Machine Translation (NMT) models are typically trained on heterogeneous data that are concatenated and randomly shuffled. Curriculum training aims to present the data to the NMT systems in a meaningful order. In this work, we introduce a two-stage curriculum training framework for NMT where we fine-tune a base NMT model on subsets of data, selected by both deterministic scoring using pre-trained methods and online scoring that consider prediction scores of the emerging NMT model. Through extensive experiments on six language pairs comprising low- and high-resource languages from WMT'21, we have shown that our curriculum strategies consistently demonstrate better quality (up to +2.2 BLEU improvement) and faster convergence (approximately 50% fewer updates).",/pdf/ecaae7ef4119ae1c3f8b5364a5a0da89c6c8f9de.pdf,,,,,,anonymous|a_twostage_curriculum_training_framework_for_nmt,,,,,,
79,mSw7ck7b7L,Learning Rich Representation of Keyphrases from Text,['aclweb.org/ACL/ARR/2021/October/Paper272/Authors'],['Anonymous'],,"In this work, we explore how to learn task-specific language models aimed towards learning rich representation of keyphrases from text documents. We experiment with different masking strategies for training transformer language models (LMs) in discriminative as well as generative settings. In the discriminative setting, we introduce a new pre-training objective - Keyphrase Boundary Infilling with Replacement (KBIR), showing large gains in performance (upto 9.26 points in F1) over SOTA, when LM pre-trained using KBIR is fine-tuned for the task of keyphrase extraction. In the generative setting, we introduce a new training setup for BART - KeyBART, that reproduces the keyphrases related to the input text in the CatSeq format, instead of the denoised original input. This also led to gains in performance (upto 4.33 points in F1@M) over SOTA for keyphrase generation. Additionally, we also fine-tune the pre-trained language models on named entity recognition (NER), question answering (QA), relation extraction (RE), abstractive summarization and achieve comparable performance with that of the SOTA, showing that learning rich representation of keyphrases is indeed beneficial for many other fundamental NLP tasks.",/pdf/e164e22c576a39841c499622cb263a638b9882cc.pdf,,,,,,anonymous|learning_rich_representation_of_keyphrases_from_text,,,,,,
80,JFEPWILzYU,ME-GCN: Multi-dimensional Edge-Embedded Graph Convolutional Networks for Semi-supervised Text Classification,['aclweb.org/ACL/ARR/2021/October/Paper295/Authors'],['Anonymous'],,"Compared to sequential learning models, graph-based neural networks exhibit excellent ability in capturing global information and have been used for semi-supervised learning tasks, including citation network analysis or text classification. However, most GCNs are designed with the single-dimensional edge feature and neglected to utilise the rich edge information about graphs. In this paper, we introduce the ME-GCN (Multi-dimensional Edge-enhanced Graph Convolutional Networks) for semi-supervised text classification. A text graph for an entire corpus is firstly constructed to describe the undirected and multi-dimensional relationship of word-to-word, document-document, and word-to-document. The graph is initialised with corpus-trained multi-dimensional word and document node representation, and the relations are represented according to the distance of those words/documents nodes. Then, the generated graph is trained with ME-GCN, which considers the edge features as multi-stream signals, and each stream performs a separate graph convolutional operation. Our ME-GCN can integrate a rich source of graph edge information of the entire text corpus. The results have demonstrated that our proposed model has significantly outperformed the state-of-the-art methods across eight benchmark datasets.",/pdf/d71c2d3d13706ede46594999a8d0b8c627678b30.pdf,/attachment/fb53493fe55c5d9876c0afc82bc40e50de9bbbdb.zip,,,,,anonymous|megcn_multidimensional_edgeembedded_graph_convolutional_networks_for_semisupervised_text_classification,,,,,,
81,tVPlfWCfxh4,Can Synthetic Translations Improve Bitext Quality?,['aclweb.org/ACL/ARR/2021/October/Paper268/Authors'],['Anonymous'],,"Synthetic translations have been used for a wide range of NLP tasks primarily as a means of data augmentation. This work explores instead, how we can use synthetic translations to selectively replace potentially imperfect reference translations in mined bitext. We find that synthetic samples can improve bitext quality without any additional bilingual supervision, when they replace the originals based on a semantic equivalence classifier that helps mitigate NMT noise. The improved quality of the revised bitext is confirmed intrinsically via human evaluation and extrinsically through bilingual induction and MT tasks.",/pdf/6e0fdff6d0b43f9819587faa694db98487d81890.pdf,,,,,,anonymous|can_synthetic_translations_improve_bitext_quality,,,,,,
82,JcfISE1-u4,WECHSEL: Effective initialization of subword embeddings for cross-lingual transfer of monolingual language models,['aclweb.org/ACL/ARR/2021/October/Paper237/Authors'],['Anonymous'],,"Recently, large pretrained language models (LMs) have gained popularity. Training these models requires ever more computational resources and most of the existing models are trained on English text only. It is exceedingly expensive to train these models in other languages. To alleviate this problem, we introduce a method – called WECHSEL – to transfer English models to new languages. We exchange the tokenizer of the English model to a tokenizer in the target language and initialize token embeddings such that they are close to semantically similar English tokens by utilizing multilingual static word embeddings covering English and the target language. We use WECHSEL to transfer GPT-2 and RoBERTa models to 4 other languages (French, German, Chinese and Swahili). WECHSEL improves over a previously proposed method for cross-lingual parameter transfer and outperforms models of comparable size trained from scratch in the target language with up to 64x less training effort. Our method makes training large language models for new languages more accessible and less damaging to the environment. We make our code and models publicly available.",/pdf/439d15beef809b5dafeef800c995df4e10a3ffa4.pdf,,,,,,anonymous|wechsel_effective_initialization_of_subword_embeddings_for_crosslingual_transfer_of_monolingual_language_models,,,,,,
83,S8x2x5EpWj,Generating Scientific Definitions with Controllable Complexity,['aclweb.org/ACL/ARR/2021/October/Paper32/Authors'],['Anonymous'],,"Unfamiliar terminology and complex language can present barriers to understanding  science. Natural language processing stands to help address these issues by automatically defining unfamiliar terms. We introduce a new task and dataset for defining scientific terms and controlling the complexity of generated definitions as a way of adapting to a specific reader's background knowledge. We test four definition generation methods for this new task, finding that a sequence-to-sequence approach is most successful. We then explore the version of the task in which definitions are generated at a target complexity level.  We introduce a novel reranking approach and find in human evaluations that it offers superior fluency while also controlling complexity, compared to several controllable generation baselines. ",/pdf/aeca2274afe79966f4448f2eb5ba361379305eac.pdf,,,,,,anonymous|generating_scientific_definitions_with_controllable_complexity,,,/attachment/b9ba052123089113cce83f3d12869f56b76765ae.zip,,,
84,6jLBTIj0-PS,Rare but Severe Errors Induced by Minimal Deletions in English-Chinese Neural Machine Translation,['aclweb.org/ACL/ARR/2021/October/Paper34/Authors'],['Anonymous'],,"We examine the inducement of rare but severe errors in English-Chinese and Chinese-English Transformer-based neural machine translation by minimal deletion in the source text. We also examine the effect of training data size on the number and types of pathological cases induced by these perturbations, finding significant variation. We find that one type of hallucination can be remedied through data preprocessing and that deleting words hurts more than deleting characters in a character-based model, even though deleting characters introduces nonsense words.",/pdf/e7ccfcbbf8fb86539c0bcbe75515885546a77f15.pdf,,,,,,anonymous|rare_but_severe_errors_induced_by_minimal_deletions_in_englishchinese_neural_machine_translation,,,,,,
85,MQ4TDB019Mc,Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization,['aclweb.org/ACL/ARR/2021/October/Paper320/Authors'],['Anonymous'],,"Despite recent progress in abstractive summarization, systems still suffer from faithfulness errors. While prior work has proposed models that improve faithfulness, it is unclear whether the improvement comes from an increased level of extractiveness of the model outputs as one naive way to improve faithfulness is to make summarization models more extractive. In this work, we present a framework for evaluating the effective faithfulness of summarization systems, by generating a faithfulness-abstractiveness trade-off curve that serves as a control at different operating points on the abstractiveness spectrum. We then show that the Maximum Likelihood Estimation (MLE) baseline as well as recently proposed methods for improving faithfulness, fail to consistently improve over the control at the same level of abstractiveness. Finally, we learn a selector to identify the most faithful and abstractive summary for a given document, and show that this system can attain higher faithfulness scores in human evaluations while being more abstractive than the baseline system on two datasets. Moreover, we show that our system is able to achieve a better faithfulness-abstractiveness trade-off than the control at the same level of abstractiveness.",/pdf/f07723854cd68059e17866739ce33f5f3aa8d1d7.pdf,,,,,,anonymous|faithful_or_extractive_on_mitigating_the_faithfulnessabstractiveness_tradeoff_in_abstractive_summarization,,,,,,
86,c_aHR1YrL4o,Zero-shot Cross-lingual Transfer is Under-specified Optimization,['aclweb.org/ACL/ARR/2021/October/Paper121/Authors'],['Anonymous'],,"Pretrained multilingual encoders enable zero-shot cross-lingual transfer performance, but often produce unreliable models that exhibit high performance variance on the target language. We postulate that high variance results from zero-shot cross-lingual transfer solving an under-specified optimization problem. We show that the source language monolingual model and source + target bilingual model are linearly connected using a model interpolation, suggesting that the model struggles to identify good solutions for both source and target languages using the source language alone.
",/pdf/05874023c215b5ac5ebc57c7bd82e194a1267696.pdf,,,,,,anonymous|zeroshot_crosslingual_transfer_is_underspecified_optimization,,,,,,
87,K6Jvy88liK,,,,,,,,,,,,,,,,,,
88,jMKxETwI9fK,Hierarchical Transformer Networks for Long-sequence and Multiple Clinical Documents Classification,['aclweb.org/ACL/ARR/2021/October/Paper267/Authors'],['Anonymous'],,"We present a Hierarchical Transformer Network for modeling long-term dependencies across clinical notes for the purpose of patient-level prediction. The network is equipped with three levels of Transformer-based encoders to learn progressively from words to sentences, sentences to notes, and finally notes to patients. The first level from word to sentence directly applies a pre-trained BERT model as a fully trainable component. While the second and third levels both implement a stack of transformer-based encoders, before the final patient representation is fed into a classification layer for clinical predictions. Compared to conventional BERT models, our model increases the maximum input length from 512 tokens to much longer sequences that are appropriate for modeling large numbers of clinical notes.
We empirically examine different hyper-parameters to identify an optimal trade-off given computational resource limits. Our experiment results on the MIMIC-III dataset for different prediction tasks demonstrate that the proposed Hierarchical Transformer Network outperforms previous state-of-the-art models, including but not limited to BigBird.",/pdf/f4212847b1ebb5d12a11291524221f9db206741c.pdf,/attachment/dd3e0c7df70b48574092c4ce9a10714099fcf6e2.zip,,,,,anonymous|hierarchical_transformer_networks_for_longsequence_and_multiple_clinical_documents_classification,,,/attachment/55066a9ef773f5325656a98c48f4c0554c577151.zip,,,
89,iy5JBDFkbqx,Measuring the Language of Self-Disclosure across Corpora,['aclweb.org/ACL/ARR/2021/October/Paper214/Authors'],['Anonymous'],,"Being able to reliably estimate self-disclosure -- a key component of friendship and intimacy -- from language is important for many psychology studies. We build single-task models on five self-disclosure corpora, but find that these models generalize poorly; the within-domain accuracy of predicted message-level self-disclosure of the best-performing model (mean Pearson's r=0.69) is much higher than the respective across data set accuracy (mean Pearson's r=0.32), due to both variations in the corpora (e.g., medical vs. general topics) and labeling instructions (target variables: self-disclosure, emotional disclosure, intimacy). However, some lexical features, such as expression of negative emotions and use of first person personal pronouns such as 'I' reliably predict self-disclosure across corpora. We develop a multi-task model that yields better results, with an average Pearson's r of 0.37 for out-of-corpora prediction.",/pdf/fa730e82e46bd53f378159c57f9ccc6426708640.pdf,,,,,,anonymous|measuring_the_language_of_selfdisclosure_across_corpora,,,,,,
90,2SR9p6qMOI,Cross-lingual Constituency Parsing with Linguistic Typology Knowledge,['aclweb.org/ACL/ARR/2021/October/Paper117/Authors'],['Anonymous'],,"Cross-lingual Transfer learning (CLT) has successfully been applied to the dependency parsing task. This is the first work that evaluates a CLT based approach to the Constituency parsing task. Furthermore, we utilized the linguistic typology knowledge in WALS database to improve the cross-lingual transferring ability of our proposed parser. ",/pdf/112ee55376dd67fb75c401e112d14bfec5270709.pdf,,,,,,anonymous|crosslingual_constituency_parsing_with_linguistic_typology_knowledge,,,,,,
91,n5cqIjCyFDl,On the Importance of Effectively Adapting Pretrained Language Models for Active Learning,['aclweb.org/ACL/ARR/2021/October/Paper178/Authors'],['Anonymous'],,"Recent active learning (AL) approaches  in Natural Language Processing (NLP) proposed using off-the-shelf pretrained language models (LMs). In this paper, we argue that these LMs are not adapted effectively to the downstream task during AL and we explore ways to address this issue. We suggest to first adapt the pretrained LM to the target task by continuing training with all the available unlabeled data and then use it for AL. We also propose a simple yet effective fine-tuning method to ensure that the adapted LM is properly trained in both low and high resource scenarios during AL. Our experiments demonstrate that our approach provides substantial data efficiency improvements compared to the standard fine-tuning approach, suggesting that a poor training strategy can be catastrophic for AL.",/pdf/781ef20e172f055aa767f55074289fc60410080e.pdf,,,,,,anonymous|on_the_importance_of_effectively_adapting_pretrained_language_models_for_active_learning,,,,,,
92,S3PyN9Xz6q2,Subword-based Cross-lingual Transfer of Embeddings from Hindi to Marathi,['aclweb.org/ACL/ARR/2021/October/Paper111/Authors'],['Anonymous'],,"Word embeddings are growing to be a crucial resource in the field of NLP for any language. This work focuses on static subword embeddings transfer for Indian languages from a relatively higher resource language to a genealogically related low resource language. We work with Hindi-Marathi as our language pair, simulating a low-resource scenario for Marathi. We demonstrate the consistent benefits of unsupervised morphemic segmentation on both source and target sides over the treatment performed by FastText. We show that a trivial ""copy-and-paste'' embeddings transfer based on even perfect bilingual lexicons is inadequate in capturing language-specific relationships. Our best-performing approach uses an EM-style approach to learning bilingual subword embeddings; the resulting embeddings are evaluated using the publicly available Marathi Word Similarity task as well as WordNet-Based Synonymy Tests. We find that our approach significantly outperforms the FastText baseline on both tasks; on the former task, its performance is close to that of pretrained FastText Marathi embeddings that use two orders of magnitude more Marathi data.",/pdf/1d115630123594fb901fe9b5f904f2f4dbf9139c.pdf,/attachment/839fec8a98dbfdbf7605c359720de3731ad44a00.zip,,,,,anonymous|subwordbased_crosslingual_transfer_of_embeddings_from_hindi_to_marathi,,,,,,
93,Jr_BFi8zgj,Graph-to-Graph Annotation Conversion Based on Pretrained Models,['aclweb.org/ACL/ARR/2021/October/Paper165/Authors'],['Anonymous'],,"Annotation conversion is an effective way to construct datasets under new annotation guidelines based on existing datasets with little human labour. Previous work has been limited in conversion between tree-structured datasets and mainly focused on feature-based models which are not easily applicable to new conversion. In this paper, we propose two pretrained model-based graph-to-graph annotation conversion approaches, namely Label Switching and Graph2Graph Linear Transfer, which are able to deal with conversion between graph-structured annotations and require no manually designed feature. We manually construct a graph-structured parallel annotated dataset and evaluate the proposed approaches on it as well as four existing parallel annotated datasets. Experimental results show that the proposed approaches outperform two strong baselines across all the datasets. Furthermore, the combination of the two models have a better effect.",/pdf/6269876fc290a547c8b3cdfef7129201216830fb.pdf,,,,,,anonymous|graphtograph_annotation_conversion_based_on_pretrained_models,,,/attachment/77a1d1add72e6542adde89091fdc7587a36649ec.zip,,,
94,MI0u7SxltzY,Benchmarking Biomedical Nested NER and Relation Extraction Models,['aclweb.org/ACL/ARR/2021/October/Paper208/Authors'],['Anonymous'],,"The Open EPPI corpus comprises $151$ full-text papers annotated by domain experts for entity mentions, protein-protein interactions (PPIs), and normalisation of entities to publicly available ontologies.
The corpus is publicly available at [ANON].
We benchmark recent nested NER and relation extraction models.
Results show that, although existing nested NER models achieve good performance on outermost and innermost entity mentions, they struggle with other types of nested mentions.
Benchmark results for relation extraction show substantial room for improvement with precision under $70$ and recall around $40$ to $52$.",/pdf/f9a0cd41439ed7bf3bc427aaa167910c4ee6be46.pdf,,,,,,anonymous|benchmarking_biomedical_nested_ner_and_relation_extraction_models,,,/attachment/42e70c41beab490a710fda21ce9136e674f0ae09.zip,,,
95,MqFyjnIPSkZ,CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation,['aclweb.org/ACL/ARR/2021/October/Paper109/Authors'],['Anonymous'],,"As the use of interactive machines grow, the task of Emotion Recognition in Conversation (ERC) became more important. If the machine generated sentences reflect emotion, more human-like sympathetic conversations are possible. Since emotion recognition in conversation is inaccurate if the previous utterances are not taken into account, many studies reflect the dialogue context to improve the performances. We introduce CoMPM, a context embedding module (CoM) combined with a pre-trained memory module (PM) that tracks memory of the speaker's previous utterances within the context, and show that the pre-trained memory significantly improves the final accuracy of emotion recognition. We achieve competitive performance with previous methods on English datasets (MELD, EmoryNLP, IEMOCAP, DailyDailog), and achieve good performance with small data sets. In addition, our method shows that it can be extended to other languages because structured knowledge is not required unlike existing methods.",/pdf/2b3fbb4e74449802e690c06786eb37f71f2f2385.pdf,/attachment/7516385631f8f0d6259c249dd479327e4f68c2b2.zip,,,,,anonymous|compm_context_modeling_with_speakers_pretrained_memory_tracking_for_emotion_recognition_in_conversation,,,/attachment/ce9cd604ea70e981d5e47a8e3efd656d615ecb2f.zip,,,/attachment/d6f8649b3f12136b725186ed217758b7661f5f4e.pdf
96,9RHCjj-vhq3,A Copy-Augmented Generative Model for Open-Domain Question Answering,['aclweb.org/ACL/ARR/2021/October/Paper349/Authors'],['Anonymous'],,"Open-domain question answering is a challenging task with a wide variety of practical applications. Existing modern approaches mostly follow a standard two-stage paradigm: retriever then reader. In this article, we focus on improving the effectiveness of the reader module and propose a novel copy-augmented generative approach that integrates the merits of both extractive and generative readers. In particular, our model is built upon the powerful generative model FiD \citep{FiD}. We enhance the original generative reader by incorporating a pointer network to encourage the model to directly copy words from the retrieved passages. We conduct experiments on the two benchmark datasets, Natural Questions and TriviaQA, and the empirical results demonstrate the performance gains of our proposed approach.",/pdf/eab6c33669668e22ec29a317001039196fae7ec4.pdf,,,,,,anonymous|a_copyaugmented_generative_model_for_opendomain_question_answering,,,,,,
97,D_cn13hnmG,Best K-best: Efficient Item Selection for Rapid Data Annotation,['aclweb.org/ACL/ARR/2021/October/Paper227/Authors'],['Anonymous'],,"We wish to leverage low-resource parsers in a human-in-the-loop process for rapidly increasing available training data. Historically, constructing rich natural language interfaces has been enabled through large annotated datasets with complex annotations. Research has shifted to developing low resource semantic parsers that make more efficient use of limited training data. While it is significant that initial parsing solutions are now viable based on limited examples, these parsers are not state of the art: the goal remains to enable highly accurate and rich interactions, the sort supported by earlier models when provided sufficient data. Here we investigate how to improve upon the simple idea of selecting new training examples from a list of model predictions. What makes for the ""best $K$-best"" solution for minimizing the effort of a human annotator, and maximizing the amount of new training data we can collect on a fixed budget?",/pdf/dc86a8e659cfec057b3b7e6b2941c91078b53e44.pdf,,,,,,anonymous|best_kbest_efficient_item_selection_for_rapid_data_annotation,,,/attachment/eb8aa6ed997d7fffba1b4c279ad69e5f894b01d4.tgz,,,
98,5zxEabUyW9K,Models In a Spelling Bee: Language Models Implicitly Learn the Character Composition of Tokens,['aclweb.org/ACL/ARR/2021/October/Paper129/Authors'],['Anonymous'],,"Standard pretrained language models operate
on sequences of subword tokens without direct access to the characters that compose each
token’s string representation. We probe the
embedding layer of pretrained language models and show that models learn the internal
character composition of whole word and subword tokens to a surprising extent, without
ever seeing the characters coupled with the tokens. Our results show that the embedding
layer of RoBERTa holds enough information
to accurately spell up to a third of the vocabulary and reach high average character ngram
overlap on all token types. We further test
whether enriching subword models with additional character information can improve language modeling, and observe that this method
has a near-identical learning curve as training without spelling-based enrichment. Overall, our results suggest that language modeling
objectives incentivize the model to implicitly
learn some notion of spelling, and that explicitly teaching the model how to spell does not
enhance its performance on such tasks.",/pdf/4efb5c1066998652d212c34d7aab4f000e6c331a.pdf,,,,,,anonymous|models_in_a_spelling_bee_language_models_implicitly_learn_the_character_composition_of_tokens,,,,,,
99,5uUygAMNYg-,MTG: A Benchmarking Suite for Multilingual Text Generation,['aclweb.org/ACL/ARR/2021/October/Paper353/Authors'],['Anonymous'],,"We introduce MTG, a new benchmark suite for training and evaluating multilingual text generation. It is the first and largest multilingual multiway text generation benchmark with 400k human-annotated data for four tasks (story generation, question generation, title generation and text summarization) across five languages (English, German, French, Spanish and Chinese). Its multiway characteristic makes it possible to create cross-lingual data between any of two languages and thus boosts the direct cross-lingual knowledge transfer. Based on it, we set various evaluation scenarios and make a deep analysis of several popular multilingual generation models from different aspects. Our benchmark suite will encourage multilingualism for the text generation community with more human-annotated parallel data and more diverse generation scenarios.",/pdf/5114902fac272e88fcf1ec182f396b2c8077fb0a.pdf,,,,,,anonymous|mtg_a_benchmarking_suite_for_multilingual_text_generation,,,,,,
100,NcnMwJIeb93,SpelLM: Augmenting Chinese Spell Check Using Input Salience,['aclweb.org/ACL/ARR/2021/October/Paper43/Authors'],['Anonymous'],,"The task of Chinese Spell Check (CSC) has a goal of detecting and correcting the misspelled Chinese characters in a sentence.  Due to the complex nature of Chinese characters, the CSC task is very challenging and has attracted great attention in the literature. Recent works have shown that the masked language models (e.g. BERT), if combined with the use of confusion sets or filtering mechanisms, can be used for handling the error sparsity and domain shift issues inherent in the CSC task.However, the confusion sets require human intervention and have to be regularly updated to cater for new errors. Also, the filtering methods are sensitive to the similarity measurement between characters. Moreover, the manually-determined filters rely on expert experience and are not adaptable to changed errors. To overcome the shortcomings, we develop a two-stage model, SpelLM, which can exploit BERT for the CSC task without relying on the confusion sets or filtering mechanisms. Specifically, in the first stage, we tune BERT as a binary classifier to predict whether a sentence contains spell errors. Then, we can compute the ``salience'' of each character in the input sentence, which measures how much a character contributes to the prediction. In the second stage, we tune another BERT using error pairs and incorporate at each self-attention layer the salience information of each input sentence. We train a linear layer to distribute the salience information into the query vectors, which serves as prior knowledge pertaining to spell errors for the attention computation. Finally, for each character we use the encoding output by the second BERT to predict the correction. As shown in our empirical study, our model-only method outperforms existing BERT solutions with the confusion sets and the filtering scheme by a notable margin.",/pdf/f4d722c80a55ab96b6bd76c143c291766f43aebc.pdf,/attachment/6d00d50902fc4b55e99b54c0e518503f89f6ae7a.zip,,,,,anonymous|spellm_augmenting_chinese_spell_check_using_input_salience,,,/attachment/da529f5c4d08ce265a7776145afd8410180f9989.zip,,,
101,QYGYFIV2dxs,Large-Scale Hate Speech Detection with Cross-Domain Transfer,['aclweb.org/ACL/ARR/2021/October/Paper181/Authors'],['Anonymous'],,"Hate speech towards people with different backgrounds is a major problem observed in social media. Although there are various attempts to detect hate speech automatically via supervised learning models, the performance of such models simply rely on limited datasets on which models are trained. In this study, we construct large-scale tweet datasets for supervised hate speech detection in English and Turkish, including human-labeled 100k tweets per each. Our datasets are designed to have equal number of tweets distributed over five domains; namely religion, gender, race, politics, and sports. We analyze the performance of state-of-the-art language models on large-scale hate speech detection with a special focus on model scalability. We also examine cross-domain transfer ability of hate speech detection.",/pdf/d3ce5c6ac207646a4ad7472088db19df9c595dbc.pdf,,,,,,anonymous|largescale_hate_speech_detection_with_crossdomain_transfer,,,,,,
102,DumXh6BkWFO,Gendered Language in Resumes,['aclweb.org/ACL/ARR/2021/October/Paper240/Authors'],['Anonymous'],,"Despite growing concerns around gender bias in NLP models used in algorithmic hiring, there is little empirical work studying the extent and nature of gendered language in resumes.
Using a corpus of 709k resumes from IT firms, we train a series of models to classify the gender of the applicant, thereby measuring the extent of gendered information encoded in resumes.
We also investigate whether it is possible to obfuscate gender from resumes by removing gender identifiers, removing gender sub-space in embedding models, etc.
We find that there is a significant amount of gendered information in resumes even after obfuscation.
A simple Tf-Idf model can learn to classify gender with AUROC=0.75, and more sophisticated transformer-based models achieve AUROC=0.8.
We further find that gender predictive values have little correlation with gender direction of embeddings -- meaning that, what is predictive of gender is not necessarily ``gendered'' in the masculine/feminine sense.
We discuss the implications of these findings in the algorithmic hiring context.",/pdf/4436ccc649c126b4ec6ebc76db359f792fa1224b.pdf,,,,,,anonymous|gendered_language_in_resumes,,,,,,
103,MumjPUzCXa,Learning to Acquire Knowledge from a Search Engine for Dialogue Response Generation,['aclweb.org/ACL/ARR/2021/October/Paper215/Authors'],['Anonymous'],,"Knowledge-aided dialogue response generation aims at augmenting chatbots with relevant external knowledge in the hope of generating more informative responses.
The majority of previous work assumes that the relevant knowledge is given as input or retrieved from a static pool of knowledge. However, this assumption violates the real-world situation, where knowledge is continually updated and a chatbot has to \emph{dynamically} retrieve useful knowledge.
In this paper, we propose a dialogue model that can access the vast and dynamic information from any search engine for response generation. To this end, we design a query producer that generates queries from a dialogue context to interact with a search engine. The query producer is trained without any human annotation of gold queries, making it easily transferable to other domains and search engines. More specifically, we design a reinforcement learning algorithm to train the query producer, where rewards are obtained by comparing retrieved articles and gold responses. 
Experiments show that our query producer can achieve R@$1$ and R@$5$ rates of 62.4\% and 74.8\% for retrieving gold knowledge, and the overall model generates better responses over a strong BART (Lewis et al., 2020) model and other typical baselines.",/pdf/196dde158f6e81d4f58cbfebf272e7cdc1b490de.pdf,,,,,,anonymous|learning_to_acquire_knowledge_from_a_search_engine_for_dialogue_response_generation,,,,,,
104,fjDOvJ4fZUB,Making Pre-trained Language Models End-to-end Few-shot Learners with Contrastive Prompt Tuning,['aclweb.org/ACL/ARR/2021/October/Paper313/Authors'],['Anonymous'],,"Prompt-based learning for Pre-trained Language Models (PLMs) has achieved remarkable performance in few-shot learning by exploiting prompts as task guidance and turning downstream tasks into masked language problems. In most existing approaches, the high performance of prompt-based learning heavily relies on handcrafted prompts and verbalizers, which may limit the application of such approaches in real-world scenarios. To solve this issue, we present CP-Tuning, the first end-to-end Contrastive Prompt Tuning framework for PLMs without any manual engineering of task-specific prompts and verbalizers. It is integrated with the task-invariant continuous prompt encoding technique with fully trainable prompt parameters. We further propose a pair-wise cost-sensitive contrastive loss to optimize the model in order to achieve verbalizer-free class mapping and enhance the task-invariance of prompts. Experiments over a variety of NLP tasks show CP-Tuning consistently outperforms state-of-the-art methods.",/pdf/134b7b7680ecefadb79059dfa4b234cd4f7d6bf3.pdf,/attachment/5ddd3b2778fa57e9fb75c780fb763a0befbe2d11.zip,,,,,anonymous|making_pretrained_language_models_endtoend_fewshot_learners_with_contrastive_prompt_tuning,,,/attachment/c79e5c0e513e2fe3d7329dab4b338fed9f3c9aef.zip,,,
105,foZ5WS4Vdu,Cooperative Semi-Supervised Transfer Learning of Machine Reading Comprehension,['aclweb.org/ACL/ARR/2021/October/Paper297/Authors'],['Anonymous'],,"Pretrained language models have significantly improved the performance of down-stream language understanding tasks, including extractive question answering, by providing high-quality contextualized word embeddings. However, training question answering models still requires large amounts of annotated data for specific domains. In this work, we propose a cooperative, self-play learning framework, REGEX, for automatically generating more non-trivial question-answer pairs to improve model performance. REGEX is built upon a masked answer extraction task with an interactive learning environment containing an answer entity REcognizer, a question Generator, and an answer EXtractor. Given a passage with a masked entity, the generator generates a question around the entity, and the extractor is trained to extract the masked entity with the generated question and raw texts. The framework allows the training of question generation and answering models on any text corpora without annotation. We further leverage a reinforcement learning technique to reward generating high-quality questions and to improve the answer extraction model's performance. Experiment results show that REGEX outperforms the state-of-the-art (SOTA) pretrained language models and transfer learning approaches on standard question-answering benchmarks, and yields the new SOTA performance under given model size and transfer learning settings.",/pdf/04bdd148950957d0355f62823b57d6a87abdce4c.pdf,,,,,,anonymous|cooperative_semisupervised_transfer_learning_of_machine_reading_comprehension,,,,,,
106,A4Iv-OJ787d,Evaluation of Transfer Learning for Polish with a text-to-text model,['aclweb.org/ACL/ARR/2021/October/Paper108/Authors'],['Anonymous'],,"We present polT - a general purpose text-to-text model for Polish that can be fine-tuned on a variety on Natural Language Processing (NLP) tasks with a single training objective. Unsupervised denoising pre-training is performed efficiently by initializing the model weights with multi-lingual T5 (mT5) counterpart. We evaluate performance of polT, mT5, Polish BART (plBART) and Polish GPT-2 (papuGaPT2) on diverse downstream tasks such as: text-to-text KLEJ benchmark, en-pl machine translation, question answering and summarization. The polT scores top on all of this tasks except summarization where plBART is best. In general (except summarization), the larger the model the better the results. The encoder-decoder architectures prove to be better than decoder-only equivalent. Additionally, since summarization and question answering lack benchmark datasets for Polish language we describe in detail their construction and will make them publicly available.",/pdf/0a95a166bcf98f4b13b73f3e6377b6b6bf9dec7d.pdf,,,,,,anonymous|evaluation_of_transfer_learning_for_polish_with_a_texttotext_model,,,,,,
107,l6Pj9MziA0,Challenges in Generalization in Open Domain Question Answering,['aclweb.org/ACL/ARR/2021/October/Paper120/Authors'],['Anonymous'],,"Recent work on Open Domain Question Answering has shown that there is a large discrepancy in model performance between novel test questions and those that largely overlap with training questions. However, it is as of yet unclear which aspects of novel questions that make them challenging. Drawing upon studies on systematic generalization, we introduce and annotate questions according to three categories that measure different levels and kinds of generalization: training set overlap, compositional generalization (comp-gen), and novel entity generalization (novel-entity). When evaluating six popular parametric and non-parametric models, we find that for the established Natural Questions and TriviaQA datasets, even the strongest model performance for comp-gen/novel-entity is 13.1/5.4% and 9.6/1.5% lower compared to that for the full test set – indicating the challenge posed by these types of questions. Furthermore, we show that whilst non-parametric models can handle questions containing novel entities, they struggle with those requiring compositional generalization. Through thorough analysis we find that key question difficulty factors are: cascading errors from the retrieval component, frequency of question pattern, and frequency of the entity.",/pdf/6550386da56c8f41a689b3300380bac6ff8ce75d.pdf,,,,,,anonymous|challenges_in_generalization_in_open_domain_question_answering,,,/attachment/b8ded7664ac4d073bcfe0fb30bb98a14618807f7.zip,,,
108,XYr2ZV9dsDl,On the Complementarity of Data Selection and Fine Tuning for Domain Adaptation,['aclweb.org/ACL/ARR/2021/October/Paper87/Authors'],['Anonymous'],,"Domain adaptation of neural networks commonly relies on three training phases: pretraining, selected data training and then fine tuning. Data selection improves target domain generalization by training further on pretraining data identified by relying on a small sample of target domain data. This work examines the benefit of data selection for language modeling and machine translation. Our experiments assess the  complementarity of selection with fine tuning and result in practical recommendations: 
(i) selected data must be similar to the fine-tuning domain but not so much as to erode the complementary effect of fine-tuning;
(ii) there is a trade-off between selecting little data for fast but limited progress or much data for slow but long lasting progress;
(iii) data selection can be applied early during pretraining, with performance gains comparable to long pretraining session; 
(iv) data selection from domain classifiers is often more effective than the popular contrastive data selection method.",/pdf/bf07c37b46f3f939c620157ede2f3452049df701.pdf,,,,,,anonymous|on_the_complementarity_of_data_selection_and_fine_tuning_for_domain_adaptation,,,,,,
109,imubXdqv9hD,Semantic Tokenizer for Enhanced Natural Language Processing,['aclweb.org/ACL/ARR/2021/October/Paper231/Authors'],['Anonymous'],,"Traditionally, NLP performance improvement has been focused on improving models and increasing the number of parameters. Little attention has been paid to vocabulary optimization. We present a novel tokenizer that uses semantics to drive subword formation. 
The tokenizer includes a trainer that uses stemming to enhance subword formation. Further optimizations and adaptations are implemented to minimize the number of words that cannot be encoded. The encoder is updated to integrate with the trainer. The tokenizer is implemented as a drop-in replacement for the SentencePiece tokenizer.
The new tokenizer more than doubles the number of wordforms represented in the vocabulary. The enhanced vocabulary significantly improves model convergence, quality of word and sentence embeddings. Our experimental results show top performance on two Glue tasks using BERT-base, improving on models more than $20\times$ in size.  ",/pdf/c0f865911c0d01f37515af36f63817d2a05fe3c8.pdf,,,,,,anonymous|semantic_tokenizer_for_enhanced_natural_language_processing,,,,,,
110,lhYV4p6rL_3,Comparing Apples and Oranges: Recognizing Political Heterogeneity on Reddit and Its Implications for Behavioral Analysis,['aclweb.org/ACL/ARR/2021/October/Paper296/Authors'],['Anonymous'],,"Reddit is home to a broad spectrum of political activity and users signal their political affiliations in multiple ways—from self-declarations to community participation. Commonly, political studies have assumed political users are a single bloc, both in developing models to infer political leaning and in studying political behavior. Here, test this model assumption of political users. We show that a variety of commonly-used political-inference approaches models do not generalize, indicating heterogeneous types of political users, and remains imprecise at best for most users, regardless of which sources of data or methods are used. Across a 14-year longitudinal analysis, we demonstrate that the choice in definition of a political user has significant implications for behavioral analysis. Controlling for multiple factors, political users are more toxic on the platform and inter-party interactions are even more toxic---but not all political users behave this way.  Last, we identify a subset of political users who repeatedly flip affiliations, showing that these users are the most controversial of all, acting as provocateurs by more frequently bringing up politics, and are more likely to be banned, suspended, or deleted.",/pdf/910160fb97ec78811748468cb62092fec80164ab.pdf,,,,,,anonymous|comparing_apples_and_oranges_recognizing_political_heterogeneity_on_reddit_and_its_implications_for_behavioral_analysis,,,,,,
111,rtHdqGVRfnX,Lexicon Creation for Interpretable NLP Models,['aclweb.org/ACL/ARR/2021/October/Paper351/Authors'],['Anonymous'],,"Lexica--words and associated scores--are widely used as simple, interpretable, generalizable language features to predict sentiment, emotions, mental health, and personality traits.  Applying different feature importance methods to different predictive models yields lexica of varying quality. In this paper, we train diverse sequence classification models, including context-oblivious (SVMs, Feed-forward neural networks) and context-sensitive (RoBERTa, DistilBERT) models, and generate lexica based on different feature importance measurements, including attention, masking, and SHAP (SHapley Additive exPlanations) values. We evaluate the generated lexica on their predictive performance on test sets within the same corpus domain and on their generalization to different but similar domains. We find that simple context-oblivious models produce lexica of similar accuracy within domain and of better accuracy across domains to those from complex context-sensitive models. Based on human evaluator ratings of these lexica, we also find that context-oblivious models generate similar lexica that are more aligned with human judgments.",/pdf/76e3471ae25af78cc2501ac5e3c88a43f61cdbf0.pdf,,,,,,anonymous|lexicon_creation_for_interpretable_nlp_models,,,,,,
112,ZIGxvGSu9pn,Learning-based Memetic Algorithm for Hard-label Textual Attack,['aclweb.org/ACL/ARR/2021/October/Paper88/Authors'],['Anonymous'],,"Deep neural networks are widely known to be vulnerable to adversarial examples in Natural Language Processing. However, existing textual adversarial attacks usually utilize the gradient or prediction confidence to generate adversarial examples, making it hard to be applied in real-world applications. To this end, we consider a more rigorous setting, namely hard-label attack, in which the attacker could only access the prediction labels. There are only a few hard-label attacks proposed currently, among which the one based on genetic algorithm exhibits high attack performance. It inspires us to design a new hard-label attack for better performance based on a combinatorial optimization approach. In this work, we propose a novel hard-label attack, named Learning-based Memetic Algorithm (LMA), which integrates the word importance learned from the attack history into the search of memetic algorithm to optimize the adversary perturbation. Extensive evaluations for text classification and textual entailment using various datasets and models demonstrate that the proposed LMA significantly outperforms existing hard-label attack regarding attack performance and adversary quality.",/pdf/89e6e32e8fb00bd10afa8c21694d3c5f7c1a0e66.pdf,/attachment/24a3a47f55e0c8b36dc4e0cce0d2098a8559ad47.zip,,,,,anonymous|learningbased_memetic_algorithm_for_hardlabel_textual_attack,,,,,,
113,vI6S-Z7abCc,ODE Transformer: An Ordinary Differential Equation-Inspired Model for Sequence Generation,['aclweb.org/ACL/ARR/2021/October/Paper65/Authors'],['Anonymous'],,"Residual networks are an Euler discretization of solutions to Ordinary Differential Equations (ODE). This paper explores a deeper relationship between Transformer and numerical ODE methods. We first show that a residual block of layers in Transformer can be described as a higher-order solution to ODE. Inspired by this, we design a new architecture, {\it ODE Transformer}, which is analogous to the Runge-Kutta method that is well motivated in ODE. As a natural extension to Transformer, ODE Transformer is easy to implement and efficient to use. Experimental results on the large-scale machine translation, abstractive summarization, and grammar error correction tasks demonstrate the high genericity of ODE Transformer. It can gain large improvements in model performance over strong baselines (e.g., 30.77 and 44.11 BLEU scores on the WMT'14 English-German and English-French benchmarks) at a slight cost in inference efficiency.",/pdf/5903cc874e5cabf509fa1d8c1dfcaf4c9f20a98d.pdf,/attachment/45aebac84b315f1d28870bbd84f68bfb0c554705.zip,,,,,anonymous|ode_transformer_an_ordinary_differential_equationinspired_model_for_sequence_generation,,,,,,
114,Da9pX2_w1Kf,,,,,,,,,,,,,,,,,,
115,cbvzw4hPS1B,HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation,['aclweb.org/ACL/ARR/2021/October/Paper66/Authors'],['Anonymous'],,"Tables are often created with hierarchies, but existing works on table reasoning mainly focus on flat tables and neglect hierarchical tables. Hierarchical tables challenge numerical reasoning by complex hierarchical indexing, as well as implicit relationships of calculation and semantics. We present a new dataset, HiTab, to study question answering (QA) and natural language generation (NLG) over hierarchical tables. HiTab is a cross-domain dataset constructed from a wealth of statistical reports and Wikipedia pages, and has unique characteristics: (1) nearly all tables are hierarchical, and (2) QA pairs are not proposed by annotators from scratch, but are revised from real and meaningful sentences authored by analysts. (3) to reveal complex numerical reasoning in statistical reports, we provide fine-grained annotations of quantity and entity alignment. 
Experiments suggest that this HiTab presents a strong challenge for existing baselines and a valuable benchmark for future research. Targeting hierarchical structure, we devise a hierarchy-aware logical form for symbolic reasoning over tables, which shows high effectiveness. Targeting table reasoning, we leverage entity and quantity alignment to explore partially supervised training in QA and conditional generation in NLG, and largely reduce spurious predictions in QA and produce better descriptions in NLG. ",/pdf/8791100cba39b6aebc1cb28aed7fab2fbbcd6b0c.pdf,/attachment/0ec37be0b8ef3824d1d289c8ca7257c17c830d88.zip,,,,,anonymous|hitab_a_hierarchical_table_dataset_for_question_answering_and_natural_language_generation,,,/attachment/267a08240ab5c14d074da427225ac8fd2ae8be0c.zip,,,
116,SxjHNPxDiZe,,,,,,,,,,,,,,,,,,
117,KHBzMrQt6-W,"Old BERT, New Tricks: Artificial Language Learning for Pre-Trained Language Models",['aclweb.org/ACL/ARR/2021/October/Paper173/Authors'],['Anonymous'],,"We extend the artificial language learning experimental paradigm from psycholinguistics and apply it to pre-trained language models -- specifically, BERT (Devlin et al., 2019). We treat a pretrained model as a subject in an artificial language learning experimental setting: in order to learn the relation between two linguistic properties A and B, we introduce a set of new, non-existent, linguistic items, give the model information about their variation along property A, then measure to what extent the model learns property B for these items as a result of training. We show this method at work for degree modifiers (expressions like *slightly*, *very*, *rather*, *extremely*) and test the hypothesis that the degree expressed by the modifier (low, medium or high degree) is related to its sensitivity to sentence polarity (whether it shows preference for affirmative or negative sentences or neither). Our experimental results are compatible with existing linguistic observations that relate degree semantics to polarity-sensitivity, including the main one: low degree semantics leads to positive polarity sensitivity (that is, to preference towards affirmative contexts). 
The method can be used in linguistic theory to elaborate on hypotheses and interpret experimental results, as well as for more insightful evaluation of linguistic representations in language models.",/pdf/bb093a012e9a5cb7a37e8cade2fe18415d89ddb5.pdf,,,,,,anonymous|old_bert_new_tricks_artificial_language_learning_for_pretrained_language_models,,,,,,
118,0QzSyBEgPI,Seeing things or seeing scenes: Investigating the capabilities of V&L models to align scene descriptions to images,['aclweb.org/ACL/ARR/2021/October/Paper156/Authors'],['Anonymous'],,"Images can be described in terms of the objects they contain, or in terms of the types of scene or place that they instantiate. In this paper we address to what extent pretrained Vision and Language models can learn to align descriptions of both types with images. We compare 3 state-of-the-art models, VisualBERT, LXMERT and CLIP. We find that (i) V\&L models are susceptible to stylistic biases acquired during pretraining; (ii) only CLIP performs consistently well on both object- and scene-level descriptions. A follow-up ablation study shows that CLIP uses object-level information in the visual modality to align with scene-level textual descriptions.",/pdf/8f9c177bc63e6f0f82d80529cc9e0cb9e0f83d66.pdf,,,,,,anonymous|seeing_things_or_seeing_scenes_investigating_the_capabilities_of_vl_models_to_align_scene_descriptions_to_images,,,/attachment/440ba867e4b44ef40906f99aad7467fd956a5954.zip,,,
119,lLmoPZuwfLq,Emotion Style Transfer with a Specified Intensity Using Deep Reinforcement Learning,['aclweb.org/ACL/ARR/2021/October/Paper167/Authors'],['Anonymous'],,"Text style transfer is a widely explored task in natural language generation which aims to change the stylistic properties of the text while retaining its style-independent content. In this work, we propose the task of emotion style transfer with a specified intensity in an unsupervised setting. The aim is to rewrite a given sentence, in any emotion, to a target emotion while also controlling the intensity of the target emotion. Emotions are gradient in nature, some words/phrases represent higher emotional intensity, while others represent lower intensity. In this task, we want to control this gradient nature of the emotion in the output. Additionally, we explore the issues with the existing datasets and address them. A novel BART-based model is proposed that is trained for the task by direct rewards. Unlike existing work, we bootstrap the BART model by training it to generate paraphrases so that it can explore lexical and syntactic diversity required for the output. Extensive automatic and human evaluations show the efficacy of our model in solving the problem.",/pdf/244aab2029b8ed7c09a61814031d2b2caa7ddefb.pdf,/attachment/acdf67de793a1f4f2d33c3146799ec2b86f785d9.zip,,,,,anonymous|emotion_style_transfer_with_a_specified_intensity_using_deep_reinforcement_learning,,,/attachment/93db03fff7fd843bf90c67cbb078164fcd2655ae.zip,,,
120,PgeQynzAX9,DialogueScript: Using Dialogue Agents to Produce a Script,['aclweb.org/ACL/ARR/2021/October/Paper230/Authors'],['Anonymous'],,"We present a novel approach to generating scripts by using agents with different personality types. To manage character interaction in the script, we employ simulated dramatic networks. Automatic and human evaluation on multiple criteria shows that our approach outperforms a vanilla-GPT2-based baseline. We further introduce a new metric to evaluate dialogue consistency based on natural language inference and demonstrate its validity.",/pdf/daaa1df6f87e93106ad0b35369a0a9bca53c6eab.pdf,,,,,,anonymous|dialoguescript_using_dialogue_agents_to_produce_a_script,,,,,,
121,HAI_JjK5rXi,Collaborative Multi-Task Representation for Natural Language Understanding,['aclweb.org/ACL/ARR/2021/October/Paper38/Authors'],['Anonymous'],,"Multi-task learning has shown large benefits in natural language understanding tasks. However, the seesaw phenomenon is still prominent in existing multi-task learning solutions. In other words, it is difficult to balance the importance of different tasks to learn a unified representation of natural language. In this paper, we propose a Collaborative Multi-Task Representation (CMTR) framework to tackle this problem. Specifically, we capture instance-level task relations by a task interaction layer and calculate the final representation for each instance as a mixture of task-oriented representations. We also introduce auxiliary losses to ease optimization and improve the generalization ability of multi-task representations. Empirically, CMTR outperforms state-of-the-art multi-task learning frameworks for natural language understanding tasks. We also reveal the effectiveness of CMTR through extensive analyses.",/pdf/da6851ded9511b31e9aefb12141f8bd21c5d8cb8.pdf,,,,,,anonymous|collaborative_multitask_representation_for_natural_language_understanding,,,,,,
122,sKnHcAEJ2EI,,,,,,,,,,,,,,,,,,
123,STUnTbwKMXm,A Double-Graph Based Framework for Frame Semantic Parsing,['aclweb.org/ACL/ARR/2021/October/Paper348/Authors'],['Anonymous'],,"Frame semantic parsing is a fundamental NLP task, which consists of three subtasks: frame identification, argument identification and role classification. Most previous studies tend to neglect relations between different subtasks and arguments and pay little attention to ontological frame knowledge defined in FrameNet. In this paper, we propose a Knowledge-guided Incremental semantic parser with Double-graph (KID). We first introduce Frame Knowledge Graph (FKG), a heterogeneous graph containing both frames and FEs (Frame Elements) built on the frame knowledge so that we can derive knowledge-enhanced representations for frames and FEs. Besides, we propose Frame Semantic Graph (FSG) to represent frame semantic structures extracted from the text with graph structures. In this way, we can transform frame semantic parsing into an incremental graph construction problem to strengthen interactions between subtasks and relations between arguments. Our experiments show that KID outperforms the previous state-of-the-art method by up to 1.7 F1-score on two FrameNet datasets.",/pdf/b6909d05a5686f00284346d8773020df57c1ee78.pdf,,,,,,anonymous|a_doublegraph_based_framework_for_frame_semantic_parsing,,,,,,
124,gro2GtKb2VY,It's my Job to be Repetitive! My Job! My Job! --  Linking Repetitions to In-Context Learning in Language Models,['aclweb.org/ACL/ARR/2021/October/Paper192/Authors'],['Anonymous'],,"Recent studies have shown that large language models can display surprising accuracy at learning tasks from few examples presented in the input context, which goes under the name of in-context learning. Other studies have shown that language models can sometimes display the undesirable behavior of falling back into loops in which an utterance is repeated infinitely often. Here, we observe that the model's capacity to produce repetitions goes well beyond frequent or well-formed utterances, and generalizes to repeating completely arbitrary sequences of tokens. Construing this as a simple form of in-context learning, we hypothesize that these two phenomena are linked through shared processing steps. With controlled experiments, we show that impairing the network from producing repetitions severely affects in-context learning, without reducing its overall predictive performance, thus supporting the proposed hypothesis.",/pdf/a837ee852e19fdaffd6456abcfcdc3692b9faa2f.pdf,/attachment/f94a266b910604257ea0d4056bb2fe824fd6fb5b.zip,,,,,anonymous|its_my_job_to_be_repetitive_my_job_my_job_linking_repetitions_to_incontext_learning_in_language_models,,,/attachment/2264827249c0a18877611c5821cb202fe317d88e.zip,,,
