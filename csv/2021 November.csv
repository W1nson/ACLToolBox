,id,title,authorids,authors,abstract,pdf,software,preprint,consent,consent_to_review,paperhash,TL;DR,existing_preprints,preferred_venue,reviewer/Editor_reassignment_request,reviewer/Editor_reassignment_justification,data,previous_PDF,previous_URL,response_PDF
0,5aeBigqvO-P,Few-Shot Named Entity Recognition with Biaffine Span Representation,['aclweb.org/ACL/ARR/2021/November/Paper1126/Authors'],['Anonymous'],"While Named Entity Recognition (NER) is a widely studied task, making inferences of entities with only a few labeled data (i.e., few-shot NER) has been challenging. Correspondingly, the N-way K-shot NER task is proposed to recognize entities in the given N categories with only K labeled samples for each category. Existing methods treat this task as a sequence labeling problem, while this paper regards it as an entity span classification problem and designs a Biaffine Span Representation (BSR) method to learn contextual span dependency representation to fit into the classification algorithm. The BSR applies a biaffine pooling module to establish the dependencies of each word on the whole sentence and to reduce the dimension of word features, thus, the span representation could gain contextual dependency information to help improve recognition accuracies. Experimental study on four standard NER datasets shows that our proposed BSR method outperforms pre-trained language models and existing N-way K-shot NER algorithms in two types of adaptations (i.e., Intra-Domain Cross-Type Adaptation and Cross-Domain Cross-Type Adaptation). Notably, F_1 value has increased by an average of 13.77% and 18.30% on the 5-way 1-shot task and the 5-way 5-shot task, respectively.",/pdf/7febb0779bbb9d02819a4fc044de27902056be68.pdf,/attachment/a0218ab754ecfc9edcc5d9be27f9b02807edbac1.zip,,,,anonymous|fewshot_named_entity_recognition_with_biaffine_span_representation,,,,,,,,,
1,EI9qCtD7u54,SegMix: A Simple Structure-Aware Data Augmentation Method,['aclweb.org/ACL/ARR/2021/November/Paper1204/Authors'],['Anonymous'],"Many Natural Language Processing tasks involve predicting structures, such as Syntax Parsing and Relation Extraction (RE). One central challenge in supervised structured prediction is the lack of high-quality annotated data. The recently proposed interpolation-based data augmentation (DA) algorithms (i.e. mixup) augment the training set via making convex interpolation between training data points. However, current algorithms (e.g. SeqMix, LADA) that apply mixup to language structured prediction tasks are not aware of the syntactic or output structures of the tasks, making their performance unstable and requiring additional heuristic constraints. Furthermore, SeqMix-like algorithms expect a linear encoding scheme of the output structure, such as BIO-Scheme for Named Entity Recognition (NER), restricting its applicability.

To this end, we propose SegMix, a simple framework of interpolation-based algorithms that can adapt to both the syntactic and output structures, making it robust to hyper-parameters and applicable to different tasks. We empirically show that SegMix consistently improves performance over several strong baseline models on two structured prediction tasks (NER and RE). SegMix is a flexible framework that unifies existing rule-based language DA methods, creating interesting mixtures of DA techniques. Furthermore, the method is easy to implement and adds negligible overhead to training and inference.",/pdf/f987363699020b4599d2e088b2eb5fcad674b459.pdf,,,,,anonymous|segmix_a_simple_structureaware_data_augmentation_method,,,,,,,,,
2,cbJwLMMduMs,Tell me who you are and i'll tell you what to do: A Persona Grounded Task Oriented Dialogue Generation System,['aclweb.org/ACL/ARR/2021/November/Paper1313/Authors'],['Anonymous'],"Modern dialogue agents can broadly be categorized as either chit-chat or task-oriented systems. While the purpose of a chit-chat agent is to entertain and engage the user- lubricating the conversation, so to say-, the task oriented chat-bot is dedicated to fulfilling specific requests (e.g., ticket booking). Current task-oriented agents produce precise but bland and uninteresting responses. While using such agents a user may interpose personal remarks, and the failure of the agent to process and respond to such statements could be a put-off for the user. In this paper we propose a system that is persona-specific, can handle chit-chat utterances, and produces responses that add a human element to the conversation, while always remaining grounded on the task. Since current task-oriented datasets do not have persona-profiles, and do not consist of personalized remarks in utterances, we modify an existing dataset (MultiWOZ 2.1) to suit our needs. We give a semi-automated dataset creation method that uses GPT-2 model trained on the PERSONA-CHAT dataset. A small subset of the obtained data is also manually crafted to acquire a gold standard data. Our framework is based on GPT-2, Graph Convolution Network (GCN) and Memory Network that is trained on this dataset to generate persona-grounded task-oriented responses. Both automatic and manual evaluation show the effectiveness of our model and dataset. Our proposed system achieves a BLEU score of 12.12 on this new dataset. ",/pdf/5c1ee7b2023b4843b58e77c02cfd211ad38b617e.pdf,/attachment/4a2eda65079d1ac69b21178b66f6ae5a460d7b76.zip,,,,anonymous|tell_me_who_you_are_and_ill_tell_you_what_to_do_a_persona_grounded_task_oriented_dialogue_generation_system,,,,,,/attachment/d6b6a2c7fce366e27e1287d496ef519b5b967851.zip,,,
3,X0EjCsA_c8l,Counting What Deserves to be Counted for Graph Parsing,['aclweb.org/ACL/ARR/2021/November/Paper1785/Authors'],['Anonymous'],"   Graph parsers rely on scoring every subgraphs for building a complete graph. In real syntactic parsing or semantic parsing, every types of subgraphs in terms of syntactic or semantic roles may generate quite unbalanced distribution, which seems not well captured by the current graph paring models. Thus we propose an enhanced model design to let the parser explicitly capture such kind of unbalanced distribution. In detail, we introduce Accumulative Operation-based Induction (AOI) attention mechanism to assign accumulative  scores for words. AOI scorer successfully approximates word-level unbalanced distribution. With conceptually simple but general-purpose design, our proposed AOI attention enhancement indeed leads to better parsing performance on a wide range of datasets of different parsing tasks, which verifies the scalability and robustness of capturing diverse subgraph distribution.",/pdf/4fef5f07a735b35682f16c2209898c5cf0f0488f.pdf,,,,,anonymous|counting_what_deserves_to_be_counted_for_graph_parsing,,,,,,,,,
4,ydSsRlGlDfD,Real-Time Visual Feedback to Guide Benchmark Creation: A Human-and-Metric-in-the-Loop Workflow,['aclweb.org/ACL/ARR/2021/November/Paper2525/Authors'],['Anonymous'],"Recent research has shown that language models exploit 'artifacts' in benchmarks to solve tasks, rather than truly learning them, leading to inflated model performance. In pursuit of creating better benchmarks, we propose VAIDA, a novel benchmark creation paradigm for NLP, that focuses on guiding crowdworkers, an under-explored facet of addressing benchmark idiosyncrasies. VAIDA facilitates sample correction by providing realtime visual feedback and recommendations to improve sample quality. Our approach is domain, model, task, and metric agnostic, and constitutes a paradigm shift for robust, validated, and dynamic benchmark creation via human-and-metric-in-the-loop workflows. We evaluate via expert review and a user study with NASA TLX. We find that VAIDA decreases effort, frustration, mental, and temporal demands of crowdworkers and analysts, simultaneously increasing the performance of both user groups with a 45.8% decrease in the level of artifacts in created samples. As a by product of our user study, we observe that created samples are adversarial across models, leading to decreases of 31.3% (BERT), 22.5% (RoBERTa), 14.98% (GPT-3 fewshot) in performance.",/pdf/2fd3e63f4a24f54cc0623d71a21279d16f7a4292.pdf,/attachment/d7a3f412c2f2cfd5faf5c4d7b53dc2cb86c9614e.zip,,,,anonymous|realtime_visual_feedback_to_guide_benchmark_creation_a_humanandmetricintheloop_workflow,,,,,,/attachment/7f23b6c9388b99cc5644965b0723fea7c7bc868b.zip,,,
5,qPUpmrqK2K8,Revisiting Transformer-based Models for Long Document Classification,['aclweb.org/ACL/ARR/2021/November/Paper2166/Authors'],['Anonymous'],"The recent literature in text classification is biased towards short text sequences (e.g., sentences or paragraphs). 
In real-world applications, multi-page multi-paragraph documents are common and they cannot be efficiently encoded by vanilla Transformer-based models.  
We compare different long document classification approaches that aim to mitigate the computational overhead of vanilla transformers to encode much longer text, namely sparse attention and hierarchical encoding methods.
We examine several aspects of sparse attention (e.g., size of attention window, use of global attention) and hierarchical based (e.g., document splitting strategy) transformers on two different datasets, and we derive practical advice of applying Transformer-based models on long document classification tasks.
We find that, if applied properly, Transformer-based models can outperform former state-of-the-art CNN based models on MIMIC-III, a challenging dataset from the clinical domain.",/pdf/c4706a3bf19a434ea9b342388c523be7895670da.pdf,,,,,anonymous|revisiting_transformerbased_models_for_long_document_classification,,,,,,,,,
6,jO0vmMUrlMB,Exploring Human-judged and Automatically-induced Correction Difficulty for Grammatical Error Correction,['aclweb.org/ACL/ARR/2021/November/Paper2419/Authors'],['Anonymous'],"While grammatical error correction (GEC) has improved in its correction performance, one of the key challenges in GEC research still remains in evaluation. Specifically, all errors are equally treated in the conventional performance measures despite the fact that some errors are more difficult to correct than others. Ideally, difficult errors should be regarded to be more important than easy ones in evaluation. This leads to the following ultimate research question --- Can even human experts estimate correction difficulty well? In this paper, we explore questions about correction difficulty centering on this research question. For this purpose, we first introduce a method for estimating agreement rates in correction difficulty judgements based on pairwise comparison. With the annotation of 2,025 instances using this method, we show that human experts exhibit a moderate agreement rate of 66.39\% (Cohen's-$\kappa$: 0.42) in judging correction difficulty. We also show that the agreement between this human-based difficulty and an automatically induced difficulty is comparable (64.50\% and $\kappa=0.35$ on average). We further look into the annotation results to reveal the insights of the human-judged and machine-judged correction difficulties, reporting on following three findings: (i) where the human-judged and machine-judged difficulties are strong and weak; (ii) based on (i), correction difficulty can be GEC-algorithm- and training-corpus-dependent; (iii) human-judged and machine-judged correction difficulties complement each other.",/pdf/88bde43c140a0b3b3bc7ab92ec8a37029d4a9d12.pdf,,,,,anonymous|exploring_humanjudged_and_automaticallyinduced_correction_difficulty_for_grammatical_error_correction,,,,,,,,,
7,-GpDH3hu9m6,Speech Synthesis for Low Resource Languages using Transliteration  Enabled Transfer Learning,['aclweb.org/ACL/ARR/2021/November/Paper1042/Authors'],['Anonymous'],"In the area of Human Computer Interaction (HCI), Text To Speech (TTS) synthesis has received a significant boost in recent years, especially with the development of various deep learning techniques capable of generating excellent quality speech.  However, deep learning demands a vast quantity of data, with speech recognition and synthesis systems requiring more than thousand hours of aligned corpus to train end-to-end systems. While a large amount of data is available in open-source for high resource languages such as English, Spanish, and Italian, the majority of languages like Asian and  African  have little to no training data. To develop good speech synthesis systems in these low resource languages, we need innovative ideas based, for example, on transfer learning and knowledge-sharing. This paper gives a novel method for doing TTS through transliteration activated transfer learning, an intuitive yet powerful method to boost the learning process in speech synthesis. Transliteration is essential in transferring phonetic information from one language to another. By incorporating this method in a novel speech synthesis pipeline, we demonstrate accelerated training and improved speech quality. We show the efficacy of fine-tuning the pretrained models trained on high resource languages, on the smaller annotated corpus of low resource language to jumpstart the training process. Our approach received an average Mean Opinion Score of 4.65 out of 5 based on a survey of 100+ persons, which is better than State of Art transfer learning based speech synthesis systems. We also make our code repository available to boost future research.",/pdf/85a7fbec9a54cc13032c30552f3b76638d6a5f35.pdf,,,,,anonymous|speech_synthesis_for_low_resource_languages_using_transliteration_enabled_transfer_learning,,,,,,,,,
8,xfBbBwOkwgQ,HonestBait: Headline Generation via Faithful Forward Reference,['aclweb.org/ACL/ARR/2021/November/Paper637/Authors'],['Anonymous'],"Current methods for generating attractive headlines often learn directly from data, which bases attractiveness on the number of user clicks and views. Although clicks or views do reflect user interest, they can fail to reveal how much interest is raised by the writing style and how much is caused by the event or topic itself. Also, such approaches can lead to harmful hallucinations by over-exaggerating the content, aggravating the spread of false information.  In this work, we  propose  HonestBait,  a  novel  framework for solving these issues from another aspect generating headlines using forward references(FR), a writing technique often used in clickbait. A self-verification process is also included in training to avoid harmful hallucinations. We start with a preliminary user study to understand how FR affects user interest, after which we present PANCO, an innovative dataset containing pairs of fake news with verified news020for attractive but faithful news headline generation. Automatic metrics and human evaluations show our framework yields better results in attractiveness while maintaining high veracity.",/pdf/62fd4d25f9d4a5d0aef39dafd8dc3b035d1f8bd1.pdf,/attachment/468875bf247ce0e19a06ac466a0420acf5708980.zip,,,,anonymous|honestbait_headline_generation_via_faithful_forward_reference,,,,,,/attachment/078c5e75e332d07db46957ad81d3f3a877ef06fe.zip,,,
9,KkrkpXyyDky,,,,,,,,,,,,,,,,,,,
10,qTNMTzkWhgT,KALA: Knowledge-Augmented Language Model Adaptation,['aclweb.org/ACL/ARR/2021/November/Paper189/Authors'],['Anonymous'],"Pre-trained language models (PLMs) have achieved remarkable success on various natural language understanding tasks. Simple fine-tuning of PLMs, on the other hand, might be suboptimal for domain-specific tasks because they cannot possibly cover knowledge from all domains. While adaptive pre-training of PLMs can help them obtain domain-specific knowledge, it requires a large training cost. Moreover, adaptive pre-training can harm the PLM's performance on the downstream task by causing catastrophic forgetting of its general knowledge. To overcome such limitations of adaptive pre-training for PLM adaption, we propose a novel domain adaption framework for PLMs coined as Knowledge-Augmented Language model Adaptation (KALA), which modulates the intermediate hidden representations of PLMs with domain knowledge, consisting of entities and their relational facts. We validate the performance of our KALA on question answering and named entity recognition tasks on multiple datasets across various domains. The results show that, despite being computationally efficient, our KALA largely outperforms adaptive pre-training.",/pdf/8ca52910c4bd81a783756b69f5ebebeaad551aaf.pdf,/attachment/1c20e2eb9204af77f006a134fcfe12093f8c1a60.zip,,,,anonymous|kala_knowledgeaugmented_language_model_adaptation,,,,,,,,,
11,Wl3XjEMGPsy,TREND: Trigger-Enhanced Relation-Extraction Network for Dialogues,['aclweb.org/ACL/ARR/2021/November/Paper72/Authors'],['Anonymous'],"The goal of dialogue relation extraction (DRE) is to identify the relation between two entities in a given dialogue.
During conversations, speakers may expose their relations to certain entities by some clues, such evidences called ''triggers''.  
However, none of the existing work on DRE tried to detect triggers and leverage the information for enhancing the performance.
This paper proposes TREND, a multi-tasking BERT-based model which learns to identify triggers for improving relation extraction.
The experimental results show that the proposed method achieves the state-of-the-art on the benchmark datasets.",/pdf/a5bd5f4d1411e80c4eda212f130a54df7aa99bc1.pdf,/attachment/8280f6e8a7e50a03b464afb8b770d4ce2940209b.zip,,,,anonymous|trend_triggerenhanced_relationextraction_network_for_dialogues,,,,,,,,,
12,Udw4IUCPew6,Multimodal Semi-supervised Learning for Disaster Tweet Classification,['aclweb.org/ACL/ARR/2021/November/Paper1506/Authors'],['Anonymous'],"During natural disasters, people often use social media platforms, such as Twitter, to post  information about casualties and damage produced by  disasters. This information can help relief authorities gain situational awareness in nearly real time, and enable them to quickly  distribute resources where most needed. However, annotating data for this purpose can be burdensome, subjective and expensive. In this paper, we investigate how to leverage the copious amounts of unlabeled data generated by disaster eyewitnesses and affected individuals during disaster events. To this end, we propose a semi-supervised learning approach to improve the performance of neural models on several multimodal disaster tweet classification tasks. Our approach shows significant improvements, obtaining up to $3.5\%$ F1 performance gain at no additional annotation cost.",/pdf/a8e3f2768d12c4a9493f1b965e35e70a3c3bc42c.pdf,,,,,anonymous|multimodal_semisupervised_learning_for_disaster_tweet_classification,,,,,,,,,
13,zikTfLBMXAg,Retrieval-based Layer-wise Adaptive Transformer for Source Code Summarization,['aclweb.org/ACL/ARR/2021/November/Paper1762/Authors'],['Anonymous'],"We propose a model that learns both the sequential and the structural features of code for source code summarization. We adopt the Abstract Syntax Tree (AST) and graph convolution to model the structural information and the Transformer to model the sequential information. We convert code snippets into ASTs and apply graph convolution to obtain structurally-encoded node representations. Then, the sequences of the graph-convolutioned AST nodes are processed by the Transformer layers. Since structurally-neighboring nodes will have similar representations in graph-convolutioned trees, the Transformer layers can effectively capture not only the sequential information but also the structural information such as sentences or blocks of source code. We show that our model outperforms the state-of-the-art for source code summarization by experiments and human evaluations.",/pdf/fa0a35fa4a91ac3c84e5eef12d1f942cea479d33.pdf,,,,,anonymous|retrievalbased_layerwise_adaptive_transformer_for_source_code_summarization,,,,,,,,,
14,WkqKzBx2UZO,Sequence-to-sequence AMR Parsing with Ancestor Information,['aclweb.org/ACL/ARR/2021/November/Paper1383/Authors'],['Anonymous'],"AMR parsing is the task that maps a sentence to an AMR semantic graph automatically. The difficulty comes from generating the complex graph structure. The previous state-of-the-art method translates the AMR graph into a sequence, then directly fine-tunes a pretrained sequence-to-sequence Transformer model (BART). However, purely treating the graph as a sequence does not take advantage of structural information about the graph. In this paper, we design several strategies to add the important \textit{ancestor information} into the Transformer Decoder. Our experiments show that we can improve the performance for both AMR 2.0 and AMR 3.0 dataset and achieve new state-of-the-art results.",/pdf/6a206864ada9deb88c196d9845c82f0a5b90efe3.pdf,,,,,anonymous|sequencetosequence_amr_parsing_with_ancestor_information,,,,,,,,,
15,fEiC5ODIGk8,,,,,,,,,,,,,,,,,,,
16,n3cvM4Phez9,Compressing Sentence Representation via Homomorphic Projective Distillation,['aclweb.org/ACL/ARR/2021/November/Paper774/Authors'],['Anonymous'],"How to learn highly compact yet effective sentence representation? Pre-trained language models have been effective in many NLP tasks. However, these models are often huge and produce large sentence embeddings. Moreover, there is a big performance gap between large and small models. In this paper, we propose Homomorphic Projective Distillation (HPD) to learn compressed sentence embeddings. Our method augments a small Transformer encoder model with learnable projection layers to produce compact representations while mimicking a large pre-trained language model to retain the sentence representation quality. We evaluate our method with different model sizes on both semantic textual similarity (STS) and semantic retrieval (SR) tasks. Experiments show that our method achieves 2.7-4.5 points performance gain on STS tasks compared with previous best representations of the same size. In SR tasks, our method improves retrieval speed (8.2×) and memory usage (8.0×) compared with state-of-the-art large models.",/pdf/30cbf97379eda14c01a610ab9c0e773562a2eec9.pdf,,,,,anonymous|compressing_sentence_representation_via_homomorphic_projective_distillation,,,,,,,,,
17,LVKqHo_PPs,Plug-Tagger: A Pluggable Sequence Labeling Framework with Pre-trained Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2391/Authors'],['Anonymous'],"Fine-tuning the pre-trained language models (PLMs) on downstream tasks is the de-facto paradigm in NLP. Despite the superior performance on sequence labeling, the fine-tuning requires large-scale parameters and time-consuming deployment for each task, which limits its application in real-world scenarios. To alleviate these problems, we propose a pluggable sequence labeling framework, plug-tagger. By switching the task-specific plugin on the input, plug-tagger allows a frozen PLM to perform different sequence labeling tasks without redeployment. Specifically, the plugin on the input are a few continuous vectors, which manipulates the PLM without modifying its parameters, and each task only needs to store the lightweight vectors rather than a full copy of PLM.  To avoid redeployment, we propose the label word mechanism,  which reuses the language model head to prevent task-specific classifiers from modifying model structures. Experimental results on three sequence labeling tasks show that the proposed method achieves comparable performance with fine-tuning by using 0.1% task-specific parameters.  Experiments show that our method is faster than other lightweight methods under limited computational resources",/pdf/f367a158202f03f41bad62b9284d3ce5d8a24946.pdf,,,,,anonymous|plugtagger_a_pluggable_sequence_labeling_framework_with_pretrained_language_models,,,,,,,,,
18,klQP_rP-QoC,A Probabilistic Framework for Analyzing Moral Perspectives in the COVID-19 Vaccine Debate,['aclweb.org/ACL/ARR/2021/November/Paper2976/Authors'],['Anonymous'],"The Covid-19 pandemic has led to infodemic of low quality information leading to poor health decisions. Combating the outcomes of this infodemic is not only a question of identifying false claims, it requires understanding the reasoning behind the decisions individuals make.
In this work we propose a holistic analysis framework connecting stance and reason analysis and fine-grained entity level moral sentiment analysis. We study how to model the dependencies between the different level of analysis and incorporate human insights into the learning process. Our experiments show that our framework can provide reliable predictions even in the low-supervision settings.",/pdf/fd3be71f0a3968956e8f4236404bd4848c5fbc7a.pdf,,,,,anonymous|a_probabilistic_framework_for_analyzing_moral_perspectives_in_the_covid19_vaccine_debate,,,,,,,,,
19,20Lgo1A-aSh,Improving Aspect Extraction based on Rules through Deep Syntax-Semantics Communication,['aclweb.org/ACL/ARR/2021/November/Paper641/Authors'],['Anonymous'],"	Recent studies show integrating language resources which consist of lexical resources, syntactic resources and semantic resources can improve the performance of natural language processing (NLP) tasks. The existing methods mostly perform simple integration through concatenating these resources successively, seldom consider complementary relationship among them, such as the deep communication of syntactic and semantic relations between words. To enhance deep syntax-semantics communication, this paper takes aspect term extraction (ATE) task as an example and  explores four integration strategies of language resources. These strategies, based on Answer Set Programming (ASP) rules, have interpretability. Experiments on eight ATE datasets show that our strategies achieve superior performance, demonstrating that they are highly effective in integrating language resources.",/pdf/4b96273aac1e05e2bb9aebe9644c5d41f7c313d8.pdf,/attachment/60d3b44a2cb6f69d24522300ca0dd8cdfd16d138.zip,,,,anonymous|improving_aspect_extraction_based_on_rules_through_deep_syntaxsemantics_communication,,,,,,/attachment/d6ea81707b1433da24dc53b37c3d863e77ff1846.zip,/attachment/f31b250d099e7503e67cbe62380de71251ef8f2a.pdf,,
20,f7ia5zVf06N,On the interpretability and significance of bias metrics in texts: a PMI-based approach,['aclweb.org/ACL/ARR/2021/November/Paper619/Authors'],['Anonymous'],"In recent years, the use of word embeddings has become popular to measure the presence of biases in texts. Despite the fact that these measures have been proven to be effective in detecting a wide variety of biases, metrics based on word embeddings lack transparency, explainability and interpretability. In this study, we propose a PMI-based metric to quantify biases in texts. We prove that this metric can be approximated by an odds ratio, which allows estimating the confidence interval and statistical significance of textual bias. This PMI-based measure can be expressed as a function of conditional probabilities, providing a simple interpretation in terms of word co-occurrences. Our approach produces a performance comparable to GloVe-based and skip-gram-based metrics in experiments of gender-occupation and gender-name associations. We discuss the advantages and disadvantages of using methods based on first-order vs second-order co-occurrences, from the point of view of the interpretability of the metric and the sparseness of the data.",/pdf/924ca04587e10f5bb2de0b22ef2b4f22803b83e4.pdf,/attachment/8c0eb2982911c86fe19884a11c661a50d00ffcb9.zip,,,,anonymous|on_the_interpretability_and_significance_of_bias_metrics_in_texts_a_pmibased_approach,,,,,,,,,
21,kFPmMu_2fVA,A Deep Generative XAI Framework for Natural Language Inference Explanations Generation,['aclweb.org/ACL/ARR/2021/November/Paper1489/Authors'],['Anonymous'],"Explainable artificial intelligence with natural language explanations (Natural-XAI) aims to produce human-readable explanations as evidence for AI decision-making. This evidence can enhance human trust and understanding of AI systems and contribute to AI explainability and transparency. However, the current approaches focus on single explanation generation only. In this paper, we conduct experiments with the state-of-the-art Transformer architecture and explore \textit{multiple explanations generation} using a public benchmark dataset, e-SNLI \cite{camburu2018snli}. We propose a novel deep generative Natural-XAI framework: \textbf{INITIATIVE}, standing for \textit{expla\underline{\textbf{I}}n a\underline{\textbf{N}}d pred\underline{\textbf{I}}c\underline{\textbf{T}} w\underline{\textbf{I}}th contextu\underline{\textbf{A}}l condi\underline{\textbf{TI}}onal \underline{\textbf{V}}ariational auto\underline{\textbf{E}}ncoder} for generating natural language explanations and making a prediction at the same time. Our method achieves competitive or better performance against the state-of-the-art baseline models on generation (4.7\% improvement in the BLEU score) and prediction (4.4\% improvement in accuracy) tasks. Our work can serve as a solid deep generative model baseline for future Natural-XAI research. Our code will be publicly available on GitHub upon paper acceptance.",/pdf/c253af67c7278a3d72a0201a7087658388031298.pdf,,,,,anonymous|a_deep_generative_xai_framework_for_natural_language_inference_explanations_generation,,,,,,,,,
22,bQt8dWKsfso,Meta-Adapter: Parameter Efficient Few-Shot Learning through Meta-Learning,['aclweb.org/ACL/ARR/2021/November/Paper1571/Authors'],['Anonymous'],"With consistent improvements in the representational capacity of large pre-trained transformers, it has become increasingly viable to serve these models as shared backbones that enable modeling a large number of tasks simultaneously. However, fine-tuning the entire model for every task of interest makes a copy of all the model parameters, rendering such scenarios highly impractical. Recently introduced Adapter methods propose a promising alternative, one where only a small number of additional parameters are introduced per task specifically for fine-tuning. However, Adapter often require large amounts of task-specific data for good performance and don't work well in data-scarce few-shot scenarios. In this paper, we take a meta-learning viewpoint for parameter-efficient fine-tuning in few-shot settings. We introduce Meta-Adapter, which are small blocks of meta-learned adapter layers inserted in a pre-trained model that re-purpose a frozen pre-trained model into a parameter-efficient few-shot learner. Meta-Adapter perform competitively with state-of-the-art few-shot learning methods, that require full fine-tuning, while only fine-tuning 0.6\% of the parameters. We evaluate Meta-Adapter along with multiple transfer learning baselines on an evaluation suite of 17 classification tasks and find that they improve few-shot learning accuracy by a large margin over competitive parameter-efficient methods while requiring significantly lesser parameters for fine-tuning.",/pdf/6dcba71e583bd57a3d731719d99cc3b7b3630abf.pdf,,,,,anonymous|metaadapter_parameter_efficient_fewshot_learning_through_metalearning,,,,,,,,,
23,2eFOOv7ufn,An Exploration of Prompt-Based Zero-Shot Relation Extraction Method,['aclweb.org/ACL/ARR/2021/November/Paper2642/Authors'],['Anonymous'],"Zero-shot relation extraction is an important method for dealing with the newly emerging relations in the real world which lacks labeled data.
However, the current zero-shot methods usually rely on large-scale and in-domain labeled data of predefined relations.
In this work, we view zero-shot relation extraction as a semantic match task optimized by prompt-tuning, which maintains a high generalization ability when using even one labeled data in per predefined relations.
Specifically, we reduce the dependence on labeled data of predefined relation with the help of the existing knowledge in the pretrained language model (PLMs). To induce this knowledge, we fuse the original input with the prompt template to formulate a cloze-style task, which is consistent with the pretraining stage. The induced knowledge facilitates new relation discovery when large-scale labeled data are not available.
Experiment results on two academic datasets show that our method achieves similar performance with only 0.05\% labeled data of pre-defined relations, compared with current state-of-the-art method. Using all labeled data, our method improves the F1 score by nearly 30\% and 9\% on the two datasets respectively.",/pdf/2f8a453a4e282cfdf852943ddcd817f003482264.pdf,,,,,anonymous|an_exploration_of_promptbased_zeroshot_relation_extraction_method,,,,,,,,,
24,cwPFJBwI0hG,Efficient Hyper-parameter Search for Knowledge Graph Embedding,['aclweb.org/ACL/ARR/2021/November/Paper1032/Authors'],['Anonymous'],"While hyper-parameters (HPs) are important for knowledge graph (KG) embedding, existing methods fail to search them efficiently. To solve this problem, we first analyze the properties of different HPs and quantize the transferability from small subgraph to the large graph. Based on the analysis, we propose an efficient two-stage search algorithm, which efficiently explores HP configurations on small subgraph at the first stage and transfers the top configurations for fine-tuning on the large whole graph at the second stage. Experiments show that our method can consistently find better HPs than the baseline algorithms with the same time budget. We achieve 10.8% average relevant improvement for four embedding models on the large-scale KGs in open graph benchmark.",/pdf/1015b682f79ff17c45fadad714401a4cb4ba4821.pdf,,,,,anonymous|efficient_hyperparameter_search_for_knowledge_graph_embedding,,,,,,,,,
25,nZdr6_UDzW,Mitigating Gender Bias in Machine Translation through Adversarial Learning,['aclweb.org/ACL/ARR/2021/November/Paper1870/Authors'],['Anonymous'],"Machine translation and other NLP systems often contain significant biases regarding sensitive attributes, such as gender or race, that worsen system performance and perpetuate harmful stereotypes. Recent preliminary research suggests that adversarial learning can be used as part of a model-agnostic bias mitigation method that requires no data modifications. However, adapting this strategy for machine translation and other modern NLP domains requires (1) restructuring training objectives in the context of fine-tuning pretrained large language models and (2) developing measures for gender or other protected variables for tasks in which these attributes must be deduced from the data itself.

We present an adversarial learning framework that addresses these challenges to mitigate gender bias in seq2seq machine translation. Our framework improves the disparity in translation quality for sentences with male vs. female entities by 86% for English-German translation and 91% for English-French translation, with minimal effect on translation quality. The results suggest that adversarial learning is a promising technique for mitigating gender bias in machine translation.",/pdf/489b4e7e33d858a056358aa56681a031033ef303.pdf,/attachment/244f521face3ffc8cee1519860a8267da793e5e2.zip,,,,anonymous|mitigating_gender_bias_in_machine_translation_through_adversarial_learning,,,,,,,,,
26,ds---HqfFWz,A Structure-Aware Argument Encoder for Literature Discourse Analysis,['aclweb.org/ACL/ARR/2021/November/Paper967/Authors'],['Anonymous'],"Existing research for argument representation learning mainly treats tokens in the sentence equally and ignores the implied structure information of argumentative context. In this paper, we propose to separate tokens into two groups, namely framing tokens and topic ones, to capture structural information of arguments. In addition, we consider high-level structure by incorporating paragraph-level position information. A novel structure-aware argument encoder is proposed for literature discourse analysis. Experimental results on both a self-constructed corpus and a public corpus show the effectiveness of our model. ",/pdf/da75b291e4d6b84b53e5a46bdf7ecd651d5eec64.pdf,/attachment/5b45aa9ea1bc82e469621428d2f16e51b585443d.zip,,,,anonymous|a_structureaware_argument_encoder_for_literature_discourse_analysis,,,,,,/attachment/c45ee5fb41945bc0e87f26b500253d73b6393b0a.zip,,,
27,zMLzqW4AC20,Placing (Historical) Events on a Timeline: A Classification cum Co-ref Resolution Approach,['aclweb.org/ACL/ARR/2021/November/Paper823/Authors'],['Anonymous'],"The event timeline provides one of the most effective ways to visualize the important historical events that occurred over a period of time, presenting the insights that may not be so apparent from reading the equivalent information in textual form. By leveraging generative adversarial learning for important event classification and by assimilating knowledge based tags for improving the performance of event coreference resolution we introduce a two staged system for event timeline generation from multiple (historical) text documents. In addition, we propose a vis-timeline based visualization technique to portray the event timeline. We demonstrate our results on two very well known historical documents --  the Collected Works of Mahatma Gandhi (CWMG) and the Collected Works of Abraham Lincoln (CWAL). Our results can be extremely helpful for historians, in advancing research in history and in understanding the socio-political landscape of a country as reflected in the writings of political leaders/scholars. Our work has some parallels with timeline summarization (TLS) tasks and therefore we use these as baselines. Rigorous experiments demonstrate that prior event detection which was hitherto absent in the TLS methods can improve summarization performance.  In order to show that our methods are very generic we reuse our method to visualize the evolution of coronavirus related events in India from a collection of various COVID-19 articles.",/pdf/6fb56021375d5830690aa771bf67eef478560e70.pdf,/attachment/e0036208c520417462564d2901fde066cf5cd336.zip,,,,anonymous|placing_historical_events_on_a_timeline_a_classification_cum_coref_resolution_approach,,,,,,/attachment/242a8d6362a075ed91db2771e44c6bb15eb2f7af.zip,/attachment/09712cb445126f0ba0e156a8124dbdcbf3054b9f.pdf,https://openreview.net/forum?id=Y5tTolyfhoP,/attachment/65becbc7b0138cc0518b4f35b1668a27ea6ad844.pdf
28,w8g-gf1wjjl,Modeling Hierarchical Syntax Structure with Triplet Position for Source Code Summarization,['aclweb.org/ACL/ARR/2021/November/Paper2930/Authors'],['Anonymous'],"Automatic code summarization, which aims to describe the source code in natural language, has become an essential task in software maintenance. Our fellow researchers have attempted to achieve such a purpose through various machine learning-based approaches. One key challenge keeping these approaches from being practical lies in the lacking of retaining the semantic structure of source code, which has unfortunately been overlooked by the state-of-the-art. Existing approaches resort to representing the syntax structure of code by modeling the Abstract Syntax Trees (ASTs). However, the hierarchical structures of ASTs have not been well explored. In this paper, we propose CODESCRIBE to model the hierarchical syntax structure of code by introducing a novel triplet position for code summarization. Specifically, CODESCRIBE leverages the graph neural network and Transformer to preserve the structural and sequential information of code, respectively. In addition, we propose a pointer-generator network that pays attention to both the structure and sequential tokens of code for a better summary generation. Experiments on two real-world datasets in Java and Python demonstrate the effectiveness of our proposed approach when compared with several state-of-the-art baselines.",/pdf/88a0b8aab27b3c6f43c7a592d5f9afbf2020f82e.pdf,,,,,anonymous|modeling_hierarchical_syntax_structure_with_triplet_position_for_source_code_summarization,,,,,,,,,
29,BecjRxs-lY5,KNN-BERT: Fine-Tuning Pre-Trained Models with KNN Classifier,['aclweb.org/ACL/ARR/2021/November/Paper708/Authors'],['Anonymous'],"Pre-trained models are widely used in fine-tuning downstream tasks with linear classifiers optimized by the cross entropy loss, which might face robustness and stability problems.
These problems can be improved by learning representations that focus on similarities in the same class and variance in different classes when making predictions.
In this paper, we utilize the K-Nearest Neighbors Classifier in pre-trained model fine-tuning.
For this KNN classifier, we introduce a supervised momentum contrastive learning framework to learn the clustered representations of the supervised downstream tasks.
Extensive experiments on text classification tasks and robustness tests show that by incorporating KNNs with the traditional fine-tuning process, we can obtain significant improvements on the clean accuracy in both rich-source and few-shot settings and can improve the robustness against adversarial attacks.
\footnote{all codes will be available at https://github.com//}",/pdf/969d6630041bf01e6c81ec5f3aa37192db1625de.pdf,,,,,anonymous|knnbert_finetuning_pretrained_models_with_knn_classifier,,,,,,/attachment/4072fddab6e3a0642521092a1d9c29598d73eaac.zip,,,
30,wqzdShr8Tie,More Than Just Attention: Improving Cross-Modal Attentions with Contrastive Constraints for Image-Text Matching,['aclweb.org/ACL/ARR/2021/November/Paper169/Authors'],['Anonymous'],"Cross-modal attention mechanisms have been widely applied to the image-text matching task and have achieved remarkable improvements thanks to its capability of learning fine-grained relevance across different modalities. However, the cross-modal attention models of existing methods could be sub-optimal and inaccurate because there is no direct supervision provided during the training process. In this work, we propose two novel training strategies, namely Contrastive Content Re-sourcing (CCR) and Contrastive Content Swapping (CCS) constraints, to address such limitations. These constraints supervise the training of cross-modal attention models in a contrastive learning manner without requiring explicit attention annotations. They are plug-in training strategies and can be easily integrated into existing cross-modal attention models. Additionally, we introduce three metrics including Attention Precision, Recall, and F1-Score to quantitatively measure the quality of learned attention models. We evaluate the proposed constraints by incorporating them into four state-of-the-art cross-modal attention-based image-text matching models. Experimental results on both Flickr30k and MS-COCO datasets demonstrate that integrating these constraints improves the model performance in terms of both retrieval performance and attention metrics.",/pdf/dad5495a801e11209ce25cb35abbc4206fdf2f3b.pdf,,,,,anonymous|more_than_just_attention_improving_crossmodal_attentions_with_contrastive_constraints_for_imagetext_matching,,,,,,,,,
31,BB1pmTFXqOS,Discriminative Models Still Outperform Generative Models in Aspect Based Sentiment Analysis In Cross-Domain and Cross-Lingual Settings,['aclweb.org/ACL/ARR/2021/November/Paper1634/Authors'],['Anonymous'],"Aspect-based Sentiment Analysis (ABSA) helps to explain customers' opinions towards products and services. In the past, ABSA models were discriminative, but more recently generative models have been used to generate aspects and polarities directly from text.  In contrast, discriminative models first select aspects from the text, and then classify the aspect's polarity. Previous results showed that generative models outperform discriminative models on several English ABSA datasets. Here, we rigorously contrast discriminative and generative models in several settings. We compare both model types in cross-lingual, cross-domain, and cross- lingual and domain, to understand generalizability in settings other than mono-lingual English in-domain. Our more thorough evaluation shows that, contrary to previous studies, discriminative models still clearly outperform generative models in almost all settings.",/pdf/f7d74390f2863656d72a908c68b8d92eff164726.pdf,/attachment/01a6a3b3dda3bcd47f52672b951324ed552fa909.zip,,,,anonymous|discriminative_models_still_outperform_generative_models_in_aspect_based_sentiment_analysis_in_crossdomain_and_crosslingual_settings,,,,,,,,,
32,Vw2vryLjiiC,Negative-aware Entity Set Expansion,['aclweb.org/ACL/ARR/2021/November/Paper1268/Authors'],['Anonymous'],"Entity Set Expansion (ESE) aims to find all entities of one target semantic class with a few seed entities describing it. However, existing ESE methods cannot express what entities we explicitly dislike, and thus hinder its application in real-world scenarios.
In this paper, to endow models with the capability of understanding the ``dislike'' relationship among seed entities, we express the target semantic class with both positive and negative seed entities.
To this end, we propose an efficient and learnable negative-aware entity set expansion framework, which is essentially a retrieval model. To facilitate this study, a large-scale Negative-aware ESE Dataset NED with more than 1M entities is further collected and annotated. Extensive experiments on NED show that the proposed framework can effectively understand the dislike relations expressed by the negative seeds and expand fewer dislike entities than baseline methods.  ",/pdf/4edf1937d9d1aec94c5fdd006abe42ce2f56ec34.pdf,/attachment/06537e649c85e88f574e44a062149f9a5992d49b.zip,,,,anonymous|negativeaware_entity_set_expansion,,,,,,/attachment/f00183bf4fb7b18ad6849ada07c7ef901db31490.zip,,,
33,CzENLR_1iTF,Mix and Match: Learning-free Controllable Text Generationusing Energy Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2168/Authors'],['Anonymous'],"Due to the unidirectional nature of prevalent autoregressive generation models, recent work on controlled generation based on global text attributes has either required attribute-based fine-tuning of the base language model, or restricted the parametrization of the attribute prediction model to be compatible with the base LM. In this work, we propose Mix and Match LM, a global score-based alternative to controllable text generation that combines arbitrary pretrained blackbox models for the desired attributes without involving any fine-tuning or structural assumptions about the blackbox models. We interpret the task of controllable generation as drawing samples from an energy-based model whose energy values are a linear combination of scores from blackbox models that are separately responsible for fluency, the control attribute, and faithfulness to any conditioning context. We use a Metropolis Hastings sampling scheme to sample from this energy-based model using bidirectional context and global attribute features. We validate the effectiveness of our approach on various conditional generation and style transfer tasks by outperforming recently proposed methods that involve extra training, finetuning, or restrictive assumptions over the form of models.   ",/pdf/cae0473a09bbf1ef88a84c2d435d67fe2bdc525d.pdf,,,,,anonymous|mix_and_match_learningfree_controllable_text_generationusing_energy_language_models,,,,,,,,,
34,LhoivcdFKwD,Improving Abstractive Dialogue Summarization with Speaker-Aware Supervised Contrastive Learning,['aclweb.org/ACL/ARR/2021/November/Paper335/Authors'],['Anonymous'],"Pre-trained models have brought remarkable success on the text summarization task. For dialogue summarization, the subdomain of text summarization, utterances are concatenated to flat text before being processed. As a result, existing summarization systems based on pre-trained models are unable to recognize the unique format of the speaker-utterance pair well in the dialogue. To investigate this issue, we conduct probing tests and manual analysis, and find that the powerful pre-trained model can not identify different speakers well in the conversation, which leads to various factual errors. Moreover, we propose three speaker-aware supervised contrastive learning (SCL) tasks: Token-level SCL, Turn-level SCL, and Global-level SCL. Comprehensive experiments demonstrate that our methods achieve significant performance improvement on two mainstream dialogue summarization datasets. According to detailed human evaluations, pre-trained models equipped with SCL tasks effectively generate summaries with better factual consistency.",/pdf/389bc5a0834f93785a6652583d939dd76e5bf498.pdf,/attachment/46a7e881cb478abc77c32be418d317bdb34e89f6.zip,,,,anonymous|improving_abstractive_dialogue_summarization_with_speakeraware_supervised_contrastive_learning,,,,,,/attachment/940c2f8ab95ed07823d1021ca9c877dac302c5d5.zip,,,
35,47v7cxS_5cE,Lifting the Curse of Multilinguality by Pre-training Modular Transformers,['aclweb.org/ACL/ARR/2021/November/Paper1200/Authors'],['Anonymous'],"Multilingual pre-trained models are known to suffer from the curse of multilinguality, which causes per-language performance to drop as they cover more languages. We address this issue by introducing language-specific modules, which allows us to grow the total capacity of the model without any additional cost in training and inference FLOPs. In contrast to prior work which learns language-specific components post-hoc, we pre-train the modules of our Cross-lingual Modular (X-Mod) models  from the start. Our experiments on natural language inference, named entity recognition and question answering show that our approach not only mitigates the negative interference between languages, but also enables positive transfer, resulting in improved monolingual and cross-lingual performance. Furthermore, our approach enables adding languages post-hoc with no measurable drop in performance, no longer limiting the model usage to the set of pre-trained languages. ",/pdf/f8eb41dc16d90460a3577a1cf2dcaf5803533e0d.pdf,,,,,anonymous|lifting_the_curse_of_multilinguality_by_pretraining_modular_transformers,,,,,,,,,
36,2GFWBz-q4-Y,Transductive Learning for Abstractive News Summarization,['aclweb.org/ACL/ARR/2021/November/Paper1416/Authors'],['Anonymous'],"Pre-trained and fine-tuned news summarizers are expected to generalize to news articles unseen in the fine-tuning (training) phase. However, these articles often contain specifics, such as events and people, a summarizer could not learn about in training. This applies to scenarios such as when a news publisher trains a summarizer on dated news and wants to summarize incoming recent news. In this work, we explore the first application of transductive learning to summarization where we further fine-tune models on test set’s input. Specifically, we construct references for learning from article salient sentences and condition on the randomly masked articles. We show that this approach is also beneficial in the fine-tuning phase when extractive references are jointly predicted with abstractive ones in the training set. In general, extractive references are inexpensive to produce as they are automatically created without human effort. We show that our approach yields state-of-the-art results on CNN/DM and NYT datasets, for instance, more than 1 ROUGE-L points improvement on the former. Moreover, we show the benefits of transduction from dated to more recent CNN news. Finally, through human and automatic evaluation, we demonstrate improvements in summary abstractiveness and coherence.",/pdf/b05585e40dd1e99b2896c80a9a1a34a64fcc19d8.pdf,,,,,anonymous|transductive_learning_for_abstractive_news_summarization,,,,,,,,,
37,JCipWpsW6R,Composable Sparse Fine-Tuning for Cross-Lingual Transfer,['aclweb.org/ACL/ARR/2021/November/Paper1532/Authors'],['Anonymous'],"Fine-tuning the entire set of parameters of a large pretrained model has become the mainstream approach for transfer learning. To increase its efficiency and prevent catastrophic forgetting and interference, techniques like adapters and sparse fine-tuning have been developed. Adapters are modular, as they can be combined to adapt a model towards different facets of knowledge (e.g., dedicated language and/or task adapters). Sparse fine-tuning is expressive, as it controls the behavior of all model components. In this work, we introduce a new fine-tuning method with both these desirable properties. In particular, we learn sparse, real-valued masks based on a simple variant of the Lottery Ticket Hypothesis. Task-specific masks are obtained from annotated data in a source language, and language-specific masks from masked language modeling in a target language. Both these masks can then be composed with the pretrained model. Unlike adapter-based fine-tuning, this method neither increases the number of parameters at inference time nor alters the original model architecture. Most importantly, it outperforms adapters in zero-shot cross-lingual transfer by a large margin in a series of multilingual benchmarks, including Universal Dependencies, MasakhaNER, and AmericasNLI. Based on an in-depth analysis, we additionally find that sparsity is crucial to prevent both 1) interference between the fine-tunings to be composed and 2) overfitting. We release the code and models at [ANONYMOUS-URL].",/pdf/7303caceaad60c745243d7481804475cc589390a.pdf,,,,,anonymous|composable_sparse_finetuning_for_crosslingual_transfer,,,,,,,,,
38,kq1EhM0vMM6,How Do Seq2Seq Models Perform on End-to-End Data-to-Text Generation?,['aclweb.org/ACL/ARR/2021/November/Paper546/Authors'],['Anonymous'],"With the rapid development of deep learning, Seq2Seq paradigm has become prevalent for end-to-end data-to-text generation, and the BLEU scores have been increasing in recent years. However, it is widely recognized that there is still a gap between the quality of the texts generated by models and the texts written by human. In order to better understand the ability of Seq2Seq models, evaluate their performance and analyze the results, we choose to use Multidimensional Quality Metric(MQM) to evaluate several representative Seq2Seq models on end-to-end data-to-text generation. We annotate the outputs of five models on four datasets with eight error types and find that  1) copy mechanism is helpful for the improvement in Omission and Inaccuracy Extrinsic errors but it increases other types of errors such as Addition; 2) pre-training techniques are highly effective, and pre-training strategy and model size are very significant; 3) the structure of the dataset also influences the model's performance greatly; 4) some specific types of errors are generally challenging for seq2seq models.",/pdf/99d0fd1e7cc5a52e2af6f1d3747577e2c1aaf491.pdf,,,,,anonymous|how_do_seq2seq_models_perform_on_endtoend_datatotext_generation,,,,,,,,,
39,jxj0WRxKSix,The Power of Prompt Tuning for Low-Resource Semantic Parsing,['aclweb.org/ACL/ARR/2021/November/Paper1718/Authors'],['Anonymous'],"Prompt tuning has recently emerged as an effective  method  for  adapting  pre-trained  language  models  to  a  number  of  language  understanding and generation tasks.   In this paper,  we investigate prompt tuning for semantic parsing—the task of mapping natural language  utterances  onto  formal  meaning  representations.    On  the  low-resource  splits  of Overnight and TOPv2, we find that a prompt tuned T5-xl significantly outperforms its fine-tuned counterpart, as well as strong GPT-3 and BART  baselines.    We  also  conduct  ablation studies  across  different  model  scales  and  target representations, finding that, with increasing model scale, prompt tuned T5 models improve at generating target representations that are far from the pre-training distribution.",/pdf/c7e16400daf3a6db459e084526852142a85cc5d8.pdf,,,,,anonymous|the_power_of_prompt_tuning_for_lowresource_semantic_parsing,,,,,,,,,
40,M2lVno3swO7,Exploring and Adapting Chinese GPT to  Pinyin Input Method,['aclweb.org/ACL/ARR/2021/November/Paper1714/Authors'],['Anonymous'],"While GPT has become the de-facto method for text generation tasks, its application to pinyin input method remains unexplored.
In this work, we make the first exploration to leverage Chinese GPT for pinyin input method.
We find that a frozen GPT achieves state-of-the-art performance on perfect pinyin.
However, the performance drops dramatically when the input includes abbreviated pinyin.
A reason is that an abbreviated pinyin can be mapped to many perfect pinyin, which links to even larger amount of Chinese characters.
We mitigate this issue with two strategies, including enriching the context with pinyin and optimizing the training process to help distinguish homophones. 
To further facilitate the evaluation of pinyin input method, we create a dataset consisting of 270K instances from 15 domains.
Results show that our approach improves the performance on abbreviated pinyin across all domains.
Model analysis demonstrates that both strategies contribute to the performance boost.",/pdf/34268dfa9902d2ffd0cbf09e2a9711e12f84681a.pdf,,,,,anonymous|exploring_and_adapting_chinese_gpt_to_pinyin_input_method,,,,,,,,,
41,C9p4LKExawN,Empirical Evaluation of Topic Zero- and Few-Shot Learning for Stance Dissonance Detection,['aclweb.org/ACL/ARR/2021/November/Paper2097/Authors'],['Anonymous'],"We address stance dissonance detection, the task of detecting conflicting stance between two input statements. Computational models for traditional stance detection have typically been trained to indicate pro/cons for a given target topic  (e.g. gun control)  and thus do not generalize well to new topics. In this paper, we systematically evaluate the generalizability of this task to situations where examples of the topic have not been seen at all (zero-shot) or only a few times (few-shot). We first build a large-scale dataset of stance dissonance detection from an online debate platform, consisting of 23.8k pairs of statements from  34 diverse topics. We show that stance dissonance detection models trained only on a small number of non-target topics already perform as well as those trained on a target topic. We also show that adding more non-target topics further boosts the performance, indicating the generalizability of non-target topics to a target topic in the stance dissonance detection task.",/pdf/8bef453b1b8a5b5ca25aba5538f4c22a0266451f.pdf,,,,,anonymous|empirical_evaluation_of_topic_zero_and_fewshot_learning_for_stance_dissonance_detection,,,,,,/attachment/5a3e6cd3dc035306ceb98c5922756aafd0f936f4.zip,/attachment/bae4243617f32e80e29632c53a42e3662e8f5efa.pdf,https://openreview.net/forum?id=x_9Efxb1Y8I,/attachment/e1ec11bd93bc52958f5c0c6a0e560dcd121f2407.pdf
42,rWPLdCIiY6g,Multilingual pre-training with Language and Task Adaptation for Multilingual Text Style Transfer,['aclweb.org/ACL/ARR/2021/November/Paper2791/Authors'],['Anonymous'],"We exploit the pre-trained seq2seq model mBART for multilingual text style transfer. Using machine translated data as well as gold aligned English sentences yields state-of-the-art results in the three target languages we consider.  Besides, in view of the general scarcity of parallel data, we propose a modular approach for multilingual formality transfer, which consists of two training strategies that target adaptation to both language and task. Our approach achieves competitive performance without monolingual task-specific parallel data and can be applied to other style transfer tasks as well as to other languages.",/pdf/935634399cd70604a9cf065dc66c6699cfb96f29.pdf,,,,,anonymous|multilingual_pretraining_with_language_and_task_adaptation_for_multilingual_text_style_transfer,,,,,,,,,
43,I9xmnBFJTQy,POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection,['aclweb.org/ACL/ARR/2021/November/Paper2258/Authors'],['Anonymous'],"Ideology is at the core of political science. Yet, there still does not exist general-purpose tools that can characterize and predict ideology across different genres of text.  To this end, we study the training of PLMs using novel ideology-driven pretraining objectives that rely on the comparison of articles that are on the same stories but written by media of different ideologies. We further collect a large-scale dataset consisting of more than 3.6M political news articles for experiments.  Our model POLITICS and its variants outperform strong baselines on 10 out of the 11 ideology prediction and stance detection tasks. Our analysis further shows that POLITICS is especially good at understanding long or formally written texts, and is also robust in few-shot learning scenarios. ",/pdf/d35a9407ea00a227a254ddcc245e077fe1afcd31.pdf,/attachment/4fa1bcb7bac52379df521e7a1941106ac3cb7fe4.zip,,,,anonymous|politics_pretraining_with_samestory_article_comparison_for_ideology_prediction_and_stance_detection,,,,,,,,,
44,ObaBB7DvM4,Image Retrieval from Contextual Descriptions,['aclweb.org/ACL/ARR/2021/November/Paper1437/Authors'],['Anonymous'],"The ability to integrate context, including perceptual and temporal cues, plays a pivotal role in grounding the meaning of a linguistic utterance. In order to measure to what extent current vision-and-language models master this ability, we devise a new multimodal challenge, Image Retrieval from Contextual Descriptions (ImageCoDe). In particular, models are tasked with retrieving the correct image from a set of 10 minimally contrastive candidates based on a contextual description.
As such, each description contains only the details that help distinguish between images.
Because of this, descriptions tend to be complex in terms of syntax and discourse and require drawing pragmatic inferences. 
Images are sourced from both static pictures and video frames.
We benchmark several state-of-the-art models, including both cross-encoders such as ViLBERT and bi-encoders such as CLIP, on ImageCoDe.
Our results reveal that these models dramatically lag behind human performance: the best variant achieves an accuracy of 20.9 on video frames and 59.4 on static pictures, compared with 90.8 in humans.
Furthermore, we experiment with new model variants that are better equipped to incorporate visual and temporal context into their representations, which achieve modest gains. 
Our hope is that ImageCoDE will foster progress in grounded language understanding by encouraging models to focus on fine-grained visual differences.
",/pdf/357e65981bfca5b6356fc6157691abeac00e6448.pdf,,,,,anonymous|image_retrieval_from_contextual_descriptions,,,,,,,,,
45,NajekV9uBas,Tackling Situated Multi-Modal Task-Oriented Dialogs with a Single Transformer Model,['aclweb.org/ACL/ARR/2021/November/Paper798/Authors'],['Anonymous'],"The Situated Interactive Multi-Modal Conversations (SIMMC) 2.0 aims to create virtual shopping assistants that can accept complex multi-modal inputs, i.e. visual appearances of objects and user utterances. It consists of four subtasks, multi-modal disambiguation (MM-Disamb), multi-modal coreference resolution (MM-Coref), multi-modal dialog state tracking (MM-DST), and response retrieval and generation. While many task-oriented dialog systems usually tackle each subtask separately, we propose a jointly learned encoder-decoder that performs all four subtasks at once for efficiency. Moreover, we handle the multi-modality of the challenge by representing visual objects as special tokens whose joint embedding is learned via auxiliary tasks. This approach won the MM-Coref and response retrieval subtasks and nominated runner-up for the remaining subtasks using a single unified model. In particular, our model achieved 81.5\% MRR, 71.2\% R@1, 95.0\% R@5, 98.2\% R@10, and 1.9 mean rank in response retrieval task, setting a high bar for the state-of-the-art result in the SIMMC 2.0 track of the Dialog Systems Technology Challenge 10 (DSTC10). ",/pdf/7e0bd11c45f4b681a78eaa1d1a3c12064574b9db.pdf,,,,,anonymous|tackling_situated_multimodal_taskoriented_dialogs_with_a_single_transformer_model,,,,,,,,,
46,BcTg9ch2BWQ,Summ$^N$: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents,['aclweb.org/ACL/ARR/2021/November/Paper1672/Authors'],['Anonymous'],"Text summarization helps readers capture salient information from documents, news, interviews, and meetings. However, most state-of-the-art pretrained language models (LM) are unable to efficiently process long text for many summarization tasks. In this paper, we propose Summ$^N$, a simple, flexible, and effective multi-stage framework for input texts that are longer than the maximum context length of typical pretrained LMs. Summ$^N$ first splits the data samples and generates a coarse summary in multiple stages and then produces the final fine-grained summary based on it. Our framework can process input text of arbitrary length by adjusting the number of stages while keeping the LM input size fixed. Moreover, it can deal with both single-source documents and dialogues, and it can be used on top of different backbone abstractive summarization models. To the best of our knowledge, Summ$^N$ is the first multi-stage split-then-summarize framework for long input summarization. Our experiments demonstrate that Summ$^N$ outperforms previous state-of-the-art methods by improving ROUGE scores on three long meeting summarization datasets AMI, ICSI, and QMSum, two long TV series datasets from SummScreen, and a long document summarization dataset GovReport. Our data and code are available at https://github.com/ANONYMOUS/Summ-N. ",/pdf/8efb7412fdc793d034be925181c31fee82659d1f.pdf,,,,,anonymous|summ^n_a_multistage_summarization_framework_for_long_input_dialogues_and_documents,,,,,,,,,
47,M-A1d9yxSe,A Bit Bayesian Facilitates Efficient Training in Token Classification,['aclweb.org/ACL/ARR/2021/November/Paper1120/Authors'],['Anonymous'],"Token classification is a fundamental subject matter in computational linguistics. Token classification models, like other modern deep neural network models, are usually trained on the entire training set in each epoch, while research has found all of the training data may not be needed in late epochs of training. Inspired by human pedagogy, we propose a teacher-aware structure to accelerate the training of token classification models. After each epoch of training, the teacher samples data that it is uncertain to and data it predicts differently from the student, which are passed into the structure for training in the next epoch. As a proof of concept, we use a Bayesian linear classifier as the teacher, and use two commonly used backbone models as the student. Experiments show that our method reduces the number of training iterations, speeding up the training without affecting the model's performance.",/pdf/e0f11d8561427572a807b765b83de3aad857cd11.pdf,,,,,anonymous|a_bit_bayesian_facilitates_efficient_training_in_token_classification,,,,,,,,,
48,D_TuAZQZPEl,A Simple Unsupervised Approach for Coreference Resolution using Rule-based Weak Supervision,['aclweb.org/ACL/ARR/2021/November/Paper1398/Authors'],['Anonymous'],"Labeled data for the task of Coreference Resolution is a scarce resource, requiring significant human effort. While state-of-the-art coreference models rely on such data, we propose an approach that leverages an end-to-end neural model in settings where labeled data is unavailable. Specifically, using weak supervision, we transfer the linguistic knowledge encoded by Stanford’s rule-based coreference system to the end-to-end model, which jointly learns rich, contextualized span representations and coreference chains. Our experiments on the English OntoNotes corpus demonstrate that our approach effectively benefits from the noisy coreference supervision, producing an improvement over Stanford’s rule-based system (+3.7 F$_1$) and outperforming the previous best unsupervised model (+0.9 F$_1$). Additionally, we validate the efficacy of our method on two other datasets: PreCo and Litbank (+2.5 and +4 F$_1$ on Stanford's system, respectively).",/pdf/98a143e1af67b6287c49454fd8d22a5b7182e324.pdf,/attachment/9b7c6f8b25abcf5b29e47e594c27825309923258.zip,,,,anonymous|a_simple_unsupervised_approach_for_coreference_resolution_using_rulebased_weak_supervision,,,,,,,,,
49,JUrlIlxIEun,Seq2rel: A sequence-to-sequence-based approach for document-level relation extraction,['aclweb.org/ACL/ARR/2021/November/Paper1846/Authors'],['Anonymous'],"Motivated by the fact that many relations cross the sentence boundary, there has been increasing interest in document-level relation extraction (RE). Document-level RE requires integrating information within and across sentences, capturing complex interactions between mentions of interacting entities. Most document-level RE methods proposed to date are pipeline-based, requiring entities as input. However, previous work has demonstrated that jointly learning to extract entities and relations can improve performance and be more efficient due to shared parameters and training steps. In this paper, we develop a sequence-to-sequence-based approach that can learn the sub-tasks of document-level RE --- entity extraction, coreference resolution and relation extraction --- in an end-to-end fashion. We evaluate our approach on several datasets, in some cases exceeding the performance of existing methods. Finally, we demonstrate that, under our model, the end-to-end approach outperforms a pipeline-based approach. Our code and models will be made publicly available.",/pdf/1c338c3917d5cff480c443630c9086cdda446cdb.pdf,/attachment/a6f59f304c27a2f8db688e4ab0f760ed612df1d2.zip,,,,anonymous|seq2rel_a_sequencetosequencebased_approach_for_documentlevel_relation_extraction,,,,,,,,,
50,_0jeDIyBNu_,CINO: A Chinese Minority Pre-trained Language Model,['aclweb.org/ACL/ARR/2021/November/Paper736/Authors'],['Anonymous'],"Multilingual pre-trained language models have shown impressive performance on cross-lingual tasks. It greatly facilitates the applications of natural language processing on low-resource languages. However, there are still some languages that the existing multilingual model does not perform well on. In this paper, we propose CINO (Chinese Minority Pre-trained Language Model), a multilingual pre-trained language model for Chinese minority languages. It covers Standard Chinese, Cantonese, and six other Chinese minority languages. To evaluate the cross-lingual ability of the multilingual models on the minority languages, we collect documents from Wikipedia and build a text classification dataset WCM (Wiki-Chinese-Minority). We test CINO on WCM and two other text classification tasks. Experiments show that CINO outperforms the baselines notably. The CINO model and the WCM dataset will be made publicly available.
",/pdf/ef9573b9dfd0512f89f5ef0c767accee132ea192.pdf,,,,,anonymous|cino_a_chinese_minority_pretrained_language_model,,,,,,,,,
51,TSMRRUNJnZZ,A Model-agnostic Data Manipulation Method for Persona-based Dialogue Generation,['aclweb.org/ACL/ARR/2021/November/Paper2430/Authors'],['Anonymous'],"Towards building intelligent dialogue agents, there has been a growing interest in introducing explicit personas in generation models. However, with limited persona-based dialogue data at hand, it may be difficult to train a dialogue generation model well. We point out that the data challenges of this generation task lie in two aspects: first, it is expensive to scale up current persona-based dialogue datasets; second, each data sample in this task is more complex to learn with than conventional dialogue data. To alleviate the above data issues, we propose a data manipulation method, which is model-agnostic to be packed with any persona-based dialogue generation model to improve their performance. The original training samples will first be distilled and thus expected to be fitted more easily. Next, we show various effective ways that can diversify such easier distilled data. A given base model will then be trained via the constructed data curricula, i.e. first on augmented distilled samples and then on original ones. Experiments illustrate the superiority of our method with two strong base dialogue models (Transformer encoder-decoder and GPT2).",/pdf/9afc82201f6ee5ab39b51cb74edf7be8b6636032.pdf,/attachment/b31b5f16dcc4b2981513001e54362fee935d0987.zip,,,,anonymous|a_modelagnostic_data_manipulation_method_for_personabased_dialogue_generation,,,,,,,/attachment/cc8254db8966bdaba2f5c94560f90c7cdf742637.pdf,https://openreview.net/forum?id=yaU2ZfyVFgF,/attachment/12ac59ae4814ff36e04af044da8672873bf9c2e3.pdf
52,LRr5uSphqoQ,Combining static and contextualised multilingual embeddings,['aclweb.org/ACL/ARR/2021/November/Paper292/Authors'],['Anonymous'],"Static and contextual multilingual embeddings have complementary strengths. Static embeddings, while less expressive than contextual language models, can be more straightforwardly aligned across multiple languages. Contextual language models are more powerful. We combine the strengths of static and contextual models to improve multilingual representations. We extract static embeddings for 40 languages from XLM-R, validate those embeddings with cross-lingual word retrieval, and then align them using VecMap. This results in high-quality, highly multilingual static embeddings. Then we apply a novel continued pre-training approach to XLM-R, leveraging the high quality alignment of our static embeddings to better align the representation space of XLM-R. We show positive results for multiple complex semantic tasks. We will release the static embeddings and the continued pre-training code.",/pdf/797c81c29af35363396fa651f5605cfedb086c8c.pdf,/attachment/09cb96a52da0b3ea3664ca95231bcca79319791b.zip,,,,anonymous|combining_static_and_contextualised_multilingual_embeddings,,,,,,,,,
53,wXRPHXseNg3,WLASL-LEX: a Dataset for Recognising Phonological Properties in American Sign Language,['aclweb.org/ACL/ARR/2021/November/Paper2920/Authors'],['Anonymous'],"Signed Language Processing (SLP) concerns the automated processing of signed languages, the main means of communication of Deaf and hearing impaired individuals. SLP features many different tasks, ranging from sign recognition to translation and production of signed speech, but has been overlooked by the NLP community thus far.
In this paper, we bring to attention the task of modelling the phonology of sign languages. We leverage existing resources to construct a large-scale dataset of American Sign Language signs annotated with six different phonological properties. We then conduct an extensive empirical study to investigate whether data-driven end-to-end and feature-based approaches can be optimised to automatically recognise these properties. We find that, despite the inherent challenges of the task, graph-based neural networks that operate over skeleton features extracted from raw videos are able to succeed at the task to a varying degree. Most importantly, we show that this performance pertains even on signs unobserved during training. ",/pdf/84f387d8d36abb234007b73e6dd2b090acf0acd8.pdf,/attachment/b3b6ec68a1a061882cf06c75559cb9452a69b36e.zip,,,,anonymous|wlasllex_a_dataset_for_recognising_phonological_properties_in_american_sign_language,,,,,,/attachment/8d4dd93421607632eba0e8149e9208d3ea496411.zip,,,
54,qlYYH9VLVbq,A Graph Enhanced Label Attention Model for ICD Coding from Clinical Text,['aclweb.org/ACL/ARR/2021/November/Paper2691/Authors'],['Anonymous'],"Medical code assignment from clinical texts is a crucial task in the healthcare industry. Clinical texts are typically very long sequences and the number of possible labels are large, making this task quite challenging. Recent work applies deep neural network models to encode the medical notes and assign medical codes to clinical documents. Some works use effective attention mechanisms to construct label-specific document representations and show promising results. In this paper, we propose a new attention mechanism, GE-LAAT (graph enhanced label attention), which utilizes code graphs to learn robust representation vectors for medical codes and improve upon the state of the art models. Experiments on the MIMIC-III dataset are conducted to show the effectiveness of our proposed model.",/pdf/54d9c64bb9de5e66aaa062b4957fabf6a100914c.pdf,,,,,anonymous|a_graph_enhanced_label_attention_model_for_icd_coding_from_clinical_text,,,,,,,,,
55,vUNJM5__Yrw,Generating Diverse and High-Quality Abstractive Summaries with Variational Transformers,['aclweb.org/ACL/ARR/2021/November/Paper2621/Authors'],['Anonymous'],"Existing works on abstractive summarization mainly focus on boosting summarization's quality (informativeness, contextual similarity). To generate summaries of both high diversity and quality, we proposes the Transformer+CVAE model, which integrates the CVAE framework into the Transformer by introducing the prior/recognition networks that bridges the Transformer encoder and decoder. We utilize the latent variables generated in the global receptive field of the transformer by fusing them to the starting-of-sequence ([SOS]) of the decoder inputs. To better tune the weights of the latent variables in the sequence, we designed a gated unit to blend the latent representation and the [SOS] token.  Evaluated on the Gigaword dataset, our model outperforms the state-of-the-art seq-to-seq models and the base Transformer in diversity and quality metrics. After scrutinizing the pre-training and the gating mechanism we apply, we discover that both schemes help improve the quality of generated summaries in the CVAE framework. ",/pdf/bb77ba2fe6965ff094d1fa1902d43e2d3220e274.pdf,,,,,anonymous|generating_diverse_and_highquality_abstractive_summaries_with_variational_transformers,,,,,,,,,
56,-cs5MvTAppW,Unsupervised Open-Domain Question Answering with Higher Answerability,['aclweb.org/ACL/ARR/2021/November/Paper2163/Authors'],['Anonymous'],"Open-domain Question Answering (ODQA) has achieved significant results in terms of supervised learning manner. However, data annotation cannot also be irresistible for its huge demand in an open domain. Though unsupervised QA or unsupervised Machine Reading Comprehension (MRC) has been tried more or less, unsupervised ODQA has not been touched according to our best knowledge. This paper thus pioneers the work of unsupervised ODQA by formally introducing the task and proposing a series of key data construction methods. Our exploration in this work inspiringly shows unsupervised ODQA can reach up to 86% performance of supervised ones.",/pdf/848f3292f7564c02edfe5aa4d3583de5d6bab6e7.pdf,,,,,anonymous|unsupervised_opendomain_question_answering_with_higher_answerability,,,,,,,,,
57,H_LmmxjQrqw,Distill and Calibrate: Denoising Inconsistent Labeling Instances for Chinese Named Entity Recognition,['aclweb.org/ACL/ARR/2021/November/Paper2551/Authors'],['Anonymous'],"Data-driving supervised models for named entity recognition (NER) have made significant improvements on standard benchmarks. However, such models often have severe performance degradation on large-scale noisy data. Thus, a practical and challenging question arises: Can we leverage only a small amount of relatively clean data to guide the NER model learning from large-scale noisy data? To answer this question, we focus on the inconsistent labeling instances problem. We observe that inconsistent labeling instances can be classified into five types of noise, each of which will largely hinder the model performance in our experiments. Based on the above observation, we propose a simple yet effective denoising framework named Distillation and Calibration for Chinese NER (DCNER). DCNER consists: (1) a Dual-stream Label Distillation mechanism for distilling five types of inconsistent labeling instances from the noisy data; and (2) a Consistency-aware Label Calibration network for calibrating inconsistent labeling instances based on relatively clean data.  Additionally, we propose the first benchmark towards validating the ability of Chinese NER to resist inconsistent labeling instances. Finally, detailed experiments show that our method consistently and significantly outperforms previous methods on the proposed benchmark.",/pdf/eaf7cd470944eeab3a29db6a8124f19c0f3ecd68.pdf,,,,,anonymous|distill_and_calibrate_denoising_inconsistent_labeling_instances_for_chinese_named_entity_recognition,,,,,,,,,
58,BHUCb6_xBde,Translating Embeddings in Document for Modeling Multi-relational Graphs,['aclweb.org/ACL/ARR/2021/November/Paper2922/Authors'],['Anonymous'],"Document-level relation extraction (RE) aims at extracting heterogeneous relational graphs upon entities in document, which has been handled with graph neural networks (GNNs) and pre-trained language models (PLMs) effectively. 
However, a crucial problem is that most GNNs adopt a task-independent pseudo graph convoluation which cause the over-parameterization. 
Is this paper, we argue that excessive parameters are unnecessary, and further propose a novel light-weight model named \textbf{TransGCN}. Specifically, we obtain the representation of entities in a document through a PLM encoder and construct our transmission-based graph convolutional network (GCN) on them. Unlike the previous methods that require storing the parameters of GNNs, our transmission-based GCN is performed with message passing constrained with the transmitting scores, which can be calculated by knowledge graph embedding models. In this way, we reduce the number of parameters by about half compared to the SOTA model. 
We conduct experiments on DocRED, which is a large-scale human-annotated document RE dataset. The results show that we outperform the state-of-the-art model with only half amount of parameters. ",/pdf/f99ab40292eccfbe60010ffb9526f47d97c5fa74.pdf,,,,,anonymous|translating_embeddings_in_document_for_modeling_multirelational_graphs,,,,,,,,,
59,pIV0eeYD6E0,Uncertainty-Based Joint Training For Semi-Supervised Math Word Problem,['aclweb.org/ACL/ARR/2021/November/Paper1822/Authors'],['Anonymous'],"Math word problems (MWPs) convert natural math corpus into structured equation forms. Data sparsity is one of the main obstacles for math word understanding problem due to the high cost of human annotation efforts. However, existing work mainly start from the supervised learning perspective, making the low-resource scenario under explored. In this paper, we are the first to incorporate semi-supervised learning (SSL) framework into MWPs. We propose an uncertainty-aware unlabeled data selection strategies, which can access to reliable samples and increase the model capacity gradually. Besides, to improve the quality of pseudo equations, we incorporate two indirect supervision signals considering the semantic consistency property and grammar format constraints of generated equations. Experimental results on two benchmark MWPs datasets across different ratio of unlabeled data verify the effectiveness and generalization ability of our proposed method.",/pdf/0d4d65a5e5505f4a5a6625167d43478370f0a188.pdf,,,,,anonymous|uncertaintybased_joint_training_for_semisupervised_math_word_problem,,,,,,/attachment/e2d979e747467b27aae762d49ce7296d9dae51d7.zip,,,
60,zn-TaFtaFaK,FairLex: A Multilingual Benchmark for Evaluating Fairness in Legal Text Processing,['aclweb.org/ACL/ARR/2021/November/Paper1295/Authors'],['Anonymous'],"We present a benchmark suite of four datasets for evaluating the fairness of pre-trained legal language models and the techniques used to fine-tune them for downstream tasks. Our benchmarks cover four jurisdictions (European Council, USA, Swiss, and Chinese), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, nationality/region, language, and legal area). In our experiments, we evaluate pre-trained language models using several group-robust fine-tuning techniques and show that none of these combinations guarantee fairness, nor consistently mitigate group disparities. Furthermore, we analyze what causes performance differences across groups, and how group-robust fine-tuning techniques fail to mitigate group disparities under both representation inequality and temporal distribution swift. ",/pdf/813c8e579a5980c921b6b1e3b0f5fd511aadb4d3.pdf,/attachment/53dfdac6afcaa649c439bc407cb131ca6d799c58.zip,,,,anonymous|fairlex_a_multilingual_benchmark_for_evaluating_fairness_in_legal_text_processing,,,,,,,,,
61,0TReq1EztTt,Alleviating the Sparsity of Open Knowledge Graphs with Pretrained Contrastive Learning,['aclweb.org/ACL/ARR/2021/November/Paper2620/Authors'],['Anonymous'],"Due to the sparsity of formal knowledge and the roughness of non-ontological construction methods, relevant facts are often missing in Open Knowledge Graphs (OpenKGs). Although existing completion methods have achieved promising performance, they do not alleviate the sparsity problem of OpenKGs. Owing to fewer training chances caused by sparse links, many few-shot and zero-shot entities cannot fully learn high-dimensional features. In this paper, we propose a new OpenKG Contrastive Learning (OKGCL) model to alleviate the sparsity with contrastive entities and relations. OKGCL designs (a) negative entities to discriminate different entities with the same relation, (b) negative relations to discriminate different relations with the same entity-pair, and (c) \emph{self} positive samples to give zero-shot and few-shot entities chances to learn discriminative representations. Extensive experiments on benchmark datasets show the superiority of OKGCL over state-of-the-art models.",/pdf/1eb5f08175b1dcbea18b23c2bb0ae14b25a2738c.pdf,,,,,anonymous|alleviating_the_sparsity_of_open_knowledge_graphs_with_pretrained_contrastive_learning,,,,,,/attachment/ac92d834857ca53f8aceb1701c80e560ff61b857.zip,,,
62,nk_mwxAKbpB,Efficient Speech Translation with Pre-trained models,['aclweb.org/ACL/ARR/2021/November/Paper290/Authors'],['Anonymous'],"When building state-of-the-art speech translation models, the need for large computational resources is a significant obstacle due to the large training data size and complex models. The availability of pre-trained models is a promising opportunity to build strong speech translation systems efficiently. In a first step, we investigate efficient strategies to build cascaded and end-to-end speech translation systems based on pre-trained models. Using this strategy, we can train and apply the models on a single GPU. While the end-to-end models show superior translation performance to cascaded ones, the application of this technology has a limitation on the need for additional end-to-end training data. In a second step, we proposed an additional similarity loss to encourage the model to generate similar hidden representations for speech and transcript. Using this technique, we can increase the data efficiency and improve the translation quality by 6 BLEU points in scenarios with limited end-to-end training data.",/pdf/986e56bd82e427c7ebf8dc766710b2c7049b9b92.pdf,,,,,anonymous|efficient_speech_translation_with_pretrained_models,,,,,,,,,
63,IQv9ssIpU7K,Data Contamination: From Memorization to Exploitation,['aclweb.org/ACL/ARR/2021/November/Paper2071/Authors'],['Anonymous'],"It is common nowadays to train NLP models on massive web-based datasets. Previous works have shown that these datasets sometimes contain downstream test sets, a phenomenon typically referred to as ""data contamination"". It is not clear however to what extent models exploit the contaminated data for downstream tasks. In this paper we present a principled method to study this question. We pretrain BERT models on joint corpora of Wikipedia and labeled downstream datasets, and fine-tune them on the relevant task. 
Comparing performance between samples seen and unseen during pretraining enables us to define and quantify levels of memorization and exploitation.
Our experiments with two models and three downstream tasks indicate that exploitation exists in some cases, but in others the models  memorize the contaminated data, but do not exploit it. We show these two measures are affected by different factors such as contaminated data occurrences, model size, and random seeds. Our results highlight the importance of analyzing massive web-scale datasets to verify that progress in NLP is obtained by better language understanding and not better data exploitation.",/pdf/3abb1ea62599e85931a0e78585c4fd1996cef688.pdf,,,,,anonymous|data_contamination_from_memorization_to_exploitation,,,,,,,,,
64,z7KsNClgofB,Multi-Stage Framework with Refinement based Point Set Registration for Unsupervised Bi-Lingual Word Alignment,['aclweb.org/ACL/ARR/2021/November/Paper37/Authors'],['Anonymous'],"Cross-lingual alignment of word embeddings play an important role in knowledge transfer across languages, for improving machine translation and other multi-lingual applications. Current unsupervised approaches rely on learning structure preserving linear transformations using adversarial networks and refinement strategies. However, such techniques, tend to suffer from instability and convergence issues, requiring tedious fine-tuning of parameter setting. This paper proposes BioSpere, a novel multi-stage framework for unsupervised mapping of bi-lingual word embeddings onto a shared vector space, by combining adversarial initialization, refinement procedure and point set registration algorithm. We show that our framework alleviates the above shortcomings, and is robust against variable adversarial learning performance and parameter choices. Experiments for parallel dictionary induction, sentence translation and word similarity demonstrate state-of-the-art results for BioSpere on diverse language pairs.",/pdf/be735b6c0657c80c9c6f98b79c6c7d95ba5737be.pdf,,,,,anonymous|multistage_framework_with_refinement_based_point_set_registration_for_unsupervised_bilingual_word_alignment,,,,,,,,,
65,e3ujixkK9yS,Retrieval Data Augmentation Informed by Downstream Question Answering Performance,['aclweb.org/ACL/ARR/2021/November/Paper1841/Authors'],['Anonymous'],"Training retrieval models to fetch contexts for Question Answering (QA) over large corpora requires labeling relevant passages in those corpora. Since obtaining exhaustive manual annotations of all relevant passages is not feasible, prior work uses text overlap heuristics to find passages that are likely to contain the answer, but this is not feasible when the task requires deeper reasoning and answers are not extractable spans (e.g.: multi-hop, discrete reasoning). We address this issue by identifying relevant passages based on whether they are useful for a trained QA model to arrive at the correct answers, and develop a search process guided by the QA model's loss. Our experiments show that this approach enables identifying relevant context for  unseen data greater than 90% of the time on the IIRC dataset and generalizes better to the end QA task than those trained on just the gold retrieval data on IIRC and QASC datasets. ",/pdf/4e6007d6e0e53bb548eeff042030a57ca04dabc6.pdf,,,,,anonymous|retrieval_data_augmentation_informed_by_downstream_question_answering_performance,,,,,,,,,
66,eJi5Pvh08VY,Breaking Down Questions for Outside-Knowledge Visual Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper305/Authors'],['Anonymous'],"There is a recent trend towards Knowledge-Based VQA (KB-VQA) where different aspects of the question require different sources of knowledge including the image's visual content and external knowledge such as commonsense concepts and factual information. To address this issue, we propose a novel approach that passes knowledge from various sources between different pieces of semantic content in the question. Questions are first segmented into several chunks, and each segment is used to generate queries to retrieve knowledge from ConceptNet and Wikipedia. Then, a graph neural network, taking advantage of the question's syntactic structure, integrates the knowledge for different segments to jointly predict the answer. Our experiments on the OK-VQA dataset show that our approach achieves new state-of-the-art results. ",/pdf/7231eb662e2bacbeb46d2ea705b8acb4ef2fca67.pdf,,,,,anonymous|breaking_down_questions_for_outsideknowledge_visual_question_answering,,,,,,,,,
67,jHjDCY-fvSk,LOPS: Learning Order Inspired Pseudo-Label Selection for Weakly Supervised Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper2079/Authors'],['Anonymous'],"Iterative self-training is a popular framework in weakly supervised text classification that involves bootstrapping a deep neural classifier from heuristic pseudo-labels. The quality of pseudo-labels, especially the initial ones, is crucial to final performance but they are inevitably noisy due to their heuristic nature, so selecting the correct ones has a huge potential for performance boost. One straightforward solution is to select samples based on the softmax probability scores corresponding to their pseudo-labels. However, we show through our experiments that such methods are ineffective and unstable due to the erroneously high-confidence predictions from poorly calibrated models. Recent studies on the memorization effects of deep neural models suggest that these models first memorize training samples with clean labels and then those with noisy labels. Inspired by this observation, we propose a novel pseudo-label selection method LOPS that takes learning order of samples into consideration. We hypothesize that the learning order reflects the probability of wrong annotation in terms of ranking, and therefore, select the top samples that are learnt earlier. LOPS can be viewed as a strong performance-boost plug-in to most of existing weakly-supervised text classification methods, as confirmed in extensive experiments on six real-world datasets.",/pdf/1f406771cac55ae930950ab71e586ac0f74c32c9.pdf,,,,,anonymous|lops_learning_order_inspired_pseudolabel_selection_for_weakly_supervised_text_classification,,,,,,,,,
68,OJYPlFa4rmX,Ask Me Anything in Your Native Language,['aclweb.org/ACL/ARR/2021/November/Paper2842/Authors'],['Anonymous'],"Cross-lingual question answering is a thriving field in the modern world, helping people to search information on the web more efficiently. One of the important scenarios is to give an answer even there is no answer in the language a person asks a question with. We present a novel approach to achieving a new state of the art in both retrieval and end-to-end tasks on the XOR TyDi dataset outperforming the previous results up to 10\% on several languages. We find that our approach can be generalized to more than 100 languages in zero-shot approach and outperform all previous models by 8\%.",/pdf/9a5e557039efca0624165ee571b0dd6033050c58.pdf,,,,,anonymous|ask_me_anything_in_your_native_language,,,,,,/attachment/e5338cc3e699d40b3d3513d7df4fe2b28b6ef07f.zip,,,
69,9onUW-cjTl8,BERT got a Date: Introducing Transformers to Temporal Tagging,['aclweb.org/ACL/ARR/2021/November/Paper148/Authors'],['Anonymous'],"Temporal expressions in text play a significant role in language understanding, and correctly identifying them is fundamental to various retrieval and natural language processing systems.
Previous works have slowly shifted from rule-based to neural architectures, capable of tagging expressions with higher accuracy. However, neural models cannot yet distinguish between different expression types at the same level as their rule-based counterparts.
In this work, we aim to identify the most suitable transformer architecture for joint temporal tagging and type classification as well as investigating the effect of semi-supervised training on the performance of these systems.
Based on our study of token classification variants and encoder-decoder architectures, we present a transformer encoder-decoder model using  the RoBERTa language model as our best-performing system.
By supplementing training resources with weakly labeled data from rule-based systems, our model surpasses previous works in temporal tagging and type classification, especially on rare classes.
Our code and pre-trained experiments are available at: https://github.com/unknown_repo",/pdf/2a292c33afc0cb444862dc4a6c48944b5879ec77.pdf,/attachment/d453d5922b1a3db113f2ff4dc51e7f67046a4e54.zip,,,,anonymous|bert_got_a_date_introducing_transformers_to_temporal_tagging,,,,,,/attachment/7bc54b53e3dd1936effbc7a965bbf9c636b97663.zip,,,
70,Ij9UXxQGNmD,XLTime: A Cross-Lingual Knowledge Transfer Framework for Zero-Shot Low-Resource Language Temporal Expression Extraction,['aclweb.org/ACL/ARR/2021/November/Paper723/Authors'],['Anonymous'],"Temporal Expression Extraction (TEE) is essential for understanding time in natural language. It has applications in Natural Language Processing (NLP) tasks such as question answering, information retrieval, and causal inference.  To date, work in this area has mostly focused on English as TEE for low-resource languages is hindered by a scarcity of training data. We propose XLTime, a novel framework for zero-shot low-resource language TEE. XLTime works on top of pre-trained language models and leverages multi-task learning to prompt cross-language knowledge transfer both from English and within the low-resource languages. It alleviates the problems caused by the shortage in low-resource language training data. We apply XLTime with different language models and show that it outperforms the previous automatic SOTA methods on four low-resource languages, i.e., French, Spanish, Portuguese, and Basque, by large margins.  It also closes the gap considerably on the handcrafted HeidelTime tool. ",/pdf/d7707ebda05ba241a83406ab3837c541d556ff68.pdf,,,,,anonymous|xltime_a_crosslingual_knowledge_transfer_framework_for_zeroshot_lowresource_language_temporal_expression_extraction,,,,,,,,,
71,kT2Rnx1erjr,Improving the Faithfulness of Abstractive Summarization via Entity Coverage Control,['aclweb.org/ACL/ARR/2021/November/Paper219/Authors'],['Anonymous'],"Abstractive summarization systems leveraging pre-training language models have achieved superior results on benchmark datasets. However, such models have been shown to be more prone to hallucinate facts that are unfaithful to the input context.  In this paper, we propose a method to remedy entity-level extrinsic hallucinations with Entity Coverage Control (ECC).  We first compute entity coverage precision and prepend the corresponding control code for each training example, which implicitly guides the model to recognize faithfulness contents in the training phase. We further extend our method via intermediate fine-tuning on large but noisy data extracted from Wikipedia to unlock zero-shot summarization. We show that the proposed method leads to more faithful and salient abstractive summarization in supervised fine-tuning and zero-shot settings according to our experimental results on three benchmark datasets XSum, Pubmed, and SAMSum of very different domains and styles.",/pdf/5d2633c5761a1468d094c024ca73ccd148dd7b5e.pdf,,,,,anonymous|improving_the_faithfulness_of_abstractive_summarization_via_entity_coverage_control,,,,,,,,,
72,moQDm_ezXNA,Active Relation Discovery: Towards General and Label-aware OpenRE,['aclweb.org/ACL/ARR/2021/November/Paper2413/Authors'],['Anonymous'],"Open Relation Extraction (OpenRE) aims to discover and label novel relations from open domains. Previous methods mainly suffer from two problems: (1) Insufficient capacity to discriminate between known and novel relations. When extending conventional test settings to a more general setting where test data might also come from seen classes, existing OpenRE approaches have a significant performance decline. (2) Secondary labeling must be performed before practical application. Existing methods cannot label human-readable and meaningful types for novel relations, which is urgently required by the downstream tasks. To address these issues, we propose the Active Relation Discovery (ARD) framework, which utilizes relational outlier detection for discriminating known and novel relations and involves active learning for labeling novel relations. Extensive experiments\footnote{The source code will be available for reproducibility.} on three real-world datasets show that ARD significantly outperforms state-of-the-art methods on both conventional and our proposed general OpenRE settings. ",/pdf/96d4d7e2e787bddb9f0003f8433f32001fdf5df6.pdf,/attachment/c7e53baebac120531d2dcba8013f244d510351c4.zip,,,,anonymous|active_relation_discovery_towards_general_and_labelaware_openre,,,,,,/attachment/6544be272a5d41dd8faae7ab38dbf0e911110a3e.zip,,,
73,rm893aOESdu,Learning Disentangled Representations in Natural Language Definitions with Semantic Role Labeling Supervision,['aclweb.org/ACL/ARR/2021/November/Paper2282/Authors'],['Anonymous'],"Disentangling the encodings of neural models is a fundamental aspect for improving interpretability, semantic control and downstream task performance in Natural Language Processing. However, most disentanglement methods are unsupervised or rely on synthetic datasets with known generative factors. We argue that recurrent syntactic and semantic regularities in textual data can be used to provide the models with both structural biases and generative factors. We leverage the semantic structures present in a representative and semantically dense category of sentence types, definitional sentences, for training a Variational Autoencoder to learn disentangled representations. Our experimental results show that the proposed model outperforms unsupervised baselines on several qualitative and quantitative benchmarks for disentanglement, and it also improves the results in the downstream task of definition modeling.",/pdf/9c546d6df5147d51f3ce43b26bc3b713478c1346.pdf,/attachment/d10956b5d71fd75721ae02fb8bc4cda09195c81b.tgz,,,,anonymous|learning_disentangled_representations_in_natural_language_definitions_with_semantic_role_labeling_supervision,,,,,,,,,
74,SGgyIY2Xro,How does the pre-training objective affect what large language models learn about linguistic properties?,['aclweb.org/ACL/ARR/2021/November/Paper2606/Authors'],['Anonymous'],"Several pre-training objectives, such as masked language modeling (MLM), have been proposed to pre-train language models (e.g. BERT) with the aim of learning better language representations. However, to the best of our knowledge, no previous work so far has investigated how different pre-training objectives affect what BERT learns about linguistics properties. We hypothesize that linguistically motivated objectives (e.g. MLM) should help BERT to acquire better linguistic knowledge compared to using non-linguistically motivated objectives, i.e. hard for humans to guess the association between the input and the label to be predicted. To this end, we pre-train BERT with two linguistically motivated objectives and three non-linguistically motivated ones. We then probe for linguistic characteristics encoded in the representation of the resulting models. We find strong evidence that there is no actual differences in probing performance between the representations learned by the two different types of objectives. These surprising results question the dominant narrative of linguistically informed pre-training.",/pdf/8e18218c61818731ecd0ef1b13dd9056c6638ebd.pdf,,,,,anonymous|how_does_the_pretraining_objective_affect_what_large_language_models_learn_about_linguistic_properties,,,,,,,,,
75,eHVLwJiOlYi,Cross-cultural Emotion Classification: the Effect of Emotional Intensity and Acoustic Features,['aclweb.org/ACL/ARR/2021/November/Paper1862/Authors'],['Anonymous'],"Cross-cultural emotion recognition is attracting increasing research attention; robustness to such differences in emotional expression is important for speech modality emotion recognition. In this work we quantify the accuracy loss when classifying cross-culturally for multiple emotional intensities, and investigate the effect of feature sets, including feature importance. We find that different emotional intensities yield a similar decrease in cross-culture accuracy relative to within-culture, and different acoustic feature sets also yield similar relative cross-culture accuracy. The top 10 important eGeMAPS features for within-cultural and cross-cultural classification share only one common feature, which partially explains differences in accuracy.",/pdf/56acf177e57e21cd0c3356e4b81812864ca806ad.pdf,/attachment/53c1a332f144b40e2181e14583f9c350f9d6d94d.zip,,,,anonymous|crosscultural_emotion_classification_the_effect_of_emotional_intensity_and_acoustic_features,,,,,,,,,
76,WuVA5LBX5zf,DialogVED: A Pre-trained Latent Variable Encoder-Decoder Model for Dialog Response Generation,['aclweb.org/ACL/ARR/2021/November/Paper433/Authors'],['Anonymous'],"Dialog response generation in open domain is an important research topic where the main challenge is to generate relevant and diverse responses. In this paper, we propose a new dialog pre-training framework called DialogVED, which introduces continuous latent variables into the enhanced encoder-decoder pre-training framework to increase the relevance and diversity of responses. With the help of a large dialog corpus (Reddit), we pre-train the model using the following 4 tasks, used in training language models (LMs) and Variational Autoencoders (VAEs) literature: 1) masked language model; 2) response generation; 3) bag-of-words prediction; and 4) KL divergence reduction. We also add additional parameters to model the turn structure in dialogs to improve the performance of the pre-trained model. We conduct experiments on PersonaChat, DailyDialog, and DSTC7-AVSD benchmarks for response generation. Experimental results show that our model achieves the new state-of-the-art results on all these datasets. ",/pdf/a6a58bd6dd9625c6f96f121c567c29ee5bc605c6.pdf,,,,,anonymous|dialogved_a_pretrained_latent_variable_encoderdecoder_model_for_dialog_response_generation,,,,,,,,,
77,DsJO6wBxsF-,Probing the Robustness of Trained Metrics for Conversational Dialogue Systems,['aclweb.org/ACL/ARR/2021/November/Paper95/Authors'],['Anonymous'],"This paper introduces an adversarial method to stress-test trained metrics for the evaluation of conversational dialogue systems. The method leverages Reinforcement Learning to find response strategies that elicit optimal scores from the trained metrics. We apply our method to test recently proposed trained metrics. We find that they all are susceptible to giving high scores to responses generated by rather simple and obviously flawed strategies that our method converges on. For instance, simply copying parts of the conversation context to form a response yields competitive scores or even outperforms responses written by humans. ",/pdf/314c4fff187d0eb1b8b7137563ef562ae4ce8e7a.pdf,/attachment/6173be658a3880fde99ba3d7b47146c3ae44ad1f.zip,,,,anonymous|probing_the_robustness_of_trained_metrics_for_conversational_dialogue_systems,,,,,,/attachment/375a356886f05c0c0229d902b16868b6f54e9232.zip,,,
78,FAMbf9YpKc3,OneAligner: Zero-shot Cross-lingual Transfer with One Rich-Resource Language Pair for Low-Resource Sentence Retrieval,['aclweb.org/ACL/ARR/2021/November/Paper2528/Authors'],['Anonymous'],"Aligning parallel sentences in multilingual corpora is essential to curate data for downstream applications such as Machine Translation. In this work, we present OneAligner, an alignment model specially designed for sentence retrieval tasks. This model is able to train on only one language pair and transfers, in a cross-lingual fashion, to low-resource language pairs with negligible degradation in performance. When trained with all language pairs of a large-scale parallel multilingual corpus (OPUS-100), this model achieves the state-of-the-art result on the Tateoba dataset, outperforming an equally-sized previous model by $8.0$ points in accuracy while using less than $0.6\%$ of their parallel data. When finetuned on a single rich-resource language pair, be it English-centered or not, our model is able to match the performance of the ones finetuned on all language pairs under the same data budget with less than $2.0$ points decrease in accuracy. Furthermore, with the same setup, scaling up the number of rich-resource language pairs monotonically improves the performance, reaching a minimum of $0.4$ points discrepancy in accuracy, essentially obviating the need to collect any low-resource parallel data. Finally, we conclude through empirical results and analyses that the performance on the retrieval tasks depends mostly on the monolingual and parallel data size, up to a certain size threshold, rather than on what language pairs are used for training or evaluation.
",/pdf/eb8b842439856c0a63e5a7d6c3159ec3e2ba424e.pdf,,,,,anonymous|onealigner_zeroshot_crosslingual_transfer_with_one_richresource_language_pair_for_lowresource_sentence_retrieval,,,,,,,,,
79,YeFhaC1k5z2,"Interpreting character embeddings with perceptual representations: the case of shape, sound, and color",['aclweb.org/ACL/ARR/2021/November/Paper1336/Authors'],['Anonymous'],"Character-level information is included in many NLP models, but evaluating the information encoded in character representations is an open issue. We leverage perceptual representations in the form of shape, sound, and color embeddings to investigate their correlation to textual representations in five languages. This cross-lingual analysis shows that textual character representations correlate strongly with sound representations for languages using an alphabetic script, while shape correlates with featural scripts. We further develop a set of probing classifiers to intrinsically evaluate what phonological information is encoded in character embeddings. Our results suggest that information on features such as voiceness are embedded in both LSTM and transformer-based representations.",/pdf/578fbfb78fd139cd58b9236fb46cf0bb6088d9d5.pdf,/attachment/ba938cc94404a07d19d0ff89245a8e8dc0ace7d1.zip,,,,anonymous|interpreting_character_embeddings_with_perceptual_representations_the_case_of_shape_sound_and_color,,,,,,,,,
80,nZU8lffa5h,"When Does Translation Require Context? A Data-driven, Multilingual Exploration",['aclweb.org/ACL/ARR/2021/November/Paper1919/Authors'],['Anonymous'],"Although proper handling of discourse phenomena significantly contributes to the quality of machine translation (MT), improvements on these phenomena are not adequately measured in common translation quality metrics. Recent works in context-aware MT attempt to target a small set of these phenomena during evaluation. In this paper, we propose a methodology to identify translations that require context systematically, and use this methodology to both confirm the difficulty of previously studied phenomena as well as uncover new ones that have not been addressed in previous work. We then develop the \textbf{Mu}ltilingual \textbf{D}iscourse-\textbf{A}ware (MuDA) benchmark, a series of taggers for these phenomena in 14 different language pairs, which we use to evaluate context-aware MT. We find that state-of-the-art context-aware MT models make marginal improvements over context-agnostic models, which suggests current models do not handle these ambiguities effectively. We will release code and data to invite the MT research community to increase efforts on context-aware translation on discourse phenomena and languages that are currently overlooked.",/pdf/f71342ac3ea0770a93e05b262a19284db90c239b.pdf,/attachment/6a39e4f3541ccef02a96e82ac3c0c1cebe2a8703.zip,,,,anonymous|when_does_translation_require_context_a_datadriven_multilingual_exploration,,,,,,,,,
81,vuAX_4bv8A,CausalR: Causal Reasoning over Natural Language Rulebases,['aclweb.org/ACL/ARR/2021/November/Paper1630/Authors'],['Anonymous'],"Transformers have been shown to perform deductive reasoning on a logical rulebase containing rules and statements written in natural language. Recent works show that such models can also produce the reasoning steps (i.e., the proof graph) that emulate the model’s logical reasoning process. But these models behave as a black-box unit that emulates the reasoning process without any causal constraints in the reasoning steps, thus questioning the faithfulness. In this work, we frame the deductive logical reasoning task as a causal process by defining three modular components: rule selection, fact selection, and knowledge composition. The rule and fact selection steps select the candidate rule and facts to be used and then the knowledge composition combines them to generate new inferences. This ensures model faithfulness by assured causal relation from the proof step to the inference reasoning. To test our causal reasoning framework, we propose CausalR, where the above three components are independently modeled by transformers. We observe that CausalR is robust to novel language perturbations, and performs on par with previous works on existing reasoning datasets. Furthermore, the errors made by CausalR are more interpretable due to our multi-modular approach compared to black-box generative models.",/pdf/9a69856e82cde59b6a5faae2f9ce7bfed6347033.pdf,/attachment/80e4a8bdf1c185b9690e3cbf11c7e4ed1e46b580.zip,,,,anonymous|causalr_causal_reasoning_over_natural_language_rulebases,,,,,,,,,
82,nXEiMRv7Zyq,Gradient Sparsification For \emph{Masked Fine-Tuning} of Transformers,['aclweb.org/ACL/ARR/2021/November/Paper126/Authors'],['Anonymous'],"Fine-tuning masked language models is widely adopted for transfer learning to downstream tasks and can be achieved by (1) freezing gradients of the pretrained network or only updating gradients of a newly added classification layer or (2) performing gradient updates on all parameters. Gradual unfreezing trades off between the two by gradually unfreezing gradients of whole layers during training. We propose to extend this to {\em stochastic gradient masking} to regularize pretrained language models for improved fine-tuning performance. We introduce \emph{GradDrop} and variants thereof, a class of gradient sparsification methods that mask gradients prior to gradient descent. Unlike gradual unfreezing which is non-sparse and deterministic, GradDrop is sparse and stochastic. Experiments on the multilingual XGLUE benchmark with XLM-R$_{\text{Large}}$ show that \emph{GradDrop} outperforms standard fine-tuning and gradual unfreezing, while being competitive against methods that use additional translated data and intermediate pretraining. Lastly, we identify cases where largest zero-shot performance gains are on less resourced languages.",/pdf/08d348991e22bf043cf97ddb6d6813adea1e25e9.pdf,,,,,anonymous|gradient_sparsification_for_\emphmasked_finetuning_of_transformers,,,,,,,,,
83,3ou3-3tLTLk,Who Are We Talking About? Handling Person Names in Speech Translation,['aclweb.org/ACL/ARR/2021/November/Paper1606/Authors'],['Anonymous'],"Recent work has shown that systems for speech translation (ST) -- similarly to automatic speech recognition (ASR) -- poorly handle person names. This shortcoming does not only lead to errors that can seriously distort the meaning of the input, but also hinders the adoption of such systems in application scenarios (like computer-assisted interpreting) where the translation of named entities, like person names, is crucial. In this paper, we first analyse the outputs of ASR/ST systems to identify the reasons of failures in person name transcription/translation. Besides the frequency in the training data, we pinpoint the nationality of the referred person as a key factor. We then mitigate the problem by creating multilingual models, and further improve our ST systems by forcing them to jointly generate transcripts and translations, prioritising the former over the latter. Overall, our solutions result in a relative improvement in token-level person name accuracy by 47.8% on average for three language pairs (en$\rightarrow$es,fr,it).",/pdf/b142d0f5ee22e416392bd69f6b298aca4d623749.pdf,,,,,anonymous|who_are_we_talking_about_handling_person_names_in_speech_translation,,,,,,,,,
84,bg470UXkLqF,Improved grammatical error correction by ranking elementary edits,['aclweb.org/ACL/ARR/2021/November/Paper1380/Authors'],['Anonymous'],"We offer a rescoring method for grammatical error correction which is based on two-stage procedure: the first stage model extracts local edits and the second classiifies them as correct or false. We show how to use an encoder-decoder or sequence labeling approach as the first stage of our model. We achieve state-of-the-art quality on BEA 2019 English dataset even with a weak BERT-GEC basic model. When using a state-of-the-art GECToR edit generator and the combined scorer, our model beats GECToR on BEA 2019 by $2-3\%$. Our model also beats previous state-of-the-art on Russian, despite using smaller models and less data than the previous approaches.",/pdf/2e822657b761385680c9a6ed6dd27e51367884a2.pdf,/attachment/9b9c3774bda7ed2c0ecd8a1188d3253d5c757ef4.tgz,,,,anonymous|improved_grammatical_error_correction_by_ranking_elementary_edits,,,,,,,,,
85,hVhvWq5onI,A New Dataset for Summarizing Radiology Reports,['aclweb.org/ACL/ARR/2021/November/Paper409/Authors'],['Anonymous'],"The radiology report summary is an important technology in smart healthcare. Compared with medical image processing and disease recognition which have been comprehensively studied, the research on radiology report summary is much limited, which is mainly due to the lack of a high-quality benchmark dataset. In this paper, we present a dataset called CRRsum for radiology report summary, where it is constructed from over 10K real radiology reports that contain diagnostic findings and diagnostic opinions. We perform extensive evaluation with the current state-of-the-art methods for radiology report summary on the proposed dataset. An extensive evaluation is performed with the current state-of-the-art methods for radiology report summary on our proposed dataset. Our experiments reveal the challenges of radiology report summary and provide many opportunities for research going forward. We also show that the CRRsum can be used in medical classification to facilitate the research in this task.",/pdf/85f1adb7623beb3f3c1f8e917e0db258ad953beb.pdf,/attachment/408c80616dbd92e69f9f9d69eb64a8f75a433ce8.zip,,,,anonymous|a_new_dataset_for_summarizing_radiology_reports,,,,,,/attachment/1f6ba9151e188cfef3c9cc3687f5d217b84691f1.zip,,,
86,-FrhVMO65W,Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting,['aclweb.org/ACL/ARR/2021/November/Paper1217/Authors'],['Anonymous']," In document classification for, e.g., legal and biomedical text, we often deal with hundreds of classes, including very infrequent ones, as well as temporal concept drift caused by the influence of real-world events, e.g., policy changes, conflicts, or pandemics. Both class imbalance and drift are often approached by resampling the training data to simulate (or compensate for) a known target distribution, but what if the target distribution is determined by unknown future events? Instead of resampling uniformly to hedge our bets, we focus on the underlying optimization algorithms used to train such document classifiers and evaluate several group-robust optimization algorithms, initially proposed to mitigate group-level disparities. Reframing group-robust algorithms as adaptation algorithms under concept drift, we find that Invariant Risk Minimization and Spectral Decoupling outperform sampling-based approaches to class imbalance and concept drift, and lead to much better performance on minority classes. The effect is more pronounced the larger the label set. ",/pdf/d521efc96bb23208cf274a08975d3b52e052dc6e.pdf,/attachment/855a3ce4f8565cab3583146abeb0e343056b5d75.zip,,,,anonymous|improved_multilabel_classification_under_temporal_concept_drift_rethinking_grouprobust_algorithms_in_a_labelwise_setting,,,,,,/attachment/756627d5a42c375aa2eadb1f5072315d755a0373.zip,,,
87,Vc21sdEwCqa,Repo4QA: Answering Complex Coding Questions via Dense Retrieval on GitHub Repositories,['aclweb.org/ACL/ARR/2021/November/Paper2877/Authors'],['Anonymous'],"Open-source platforms such as Github and Stack Overflow both play important roles in our software ecosystem. It is crucial but time-consuming for programmers to raise their specific programming questions on coding forums such as Stack Overflow, which guides them to actual solutions on Github repositories. We show our interest in accelerating such a process and find that traditional Information Retrieval based methods fail to handle the long and complex questions in coding forums and thus cannot find the suitable coding repositories. In order to bridge the semantic gap between repositories and real-world coding questions effectively and efficiently, we introduce a specialized dataset named Repo4QA, which includes over 12,000 question-repository pairs constructed from Stack Overflow and Github. Furthermore, we propose QuReCL, a contrastive learning model based on CodeBERT, to jointly learn the representation of both questions and repositories. Experimental results demonstrate that our model can simultaneously capture the semantic features in both questions and repositories through jointly embedding, and outperforms existing state-of-art methods. ",/pdf/9b99cf2537fdbe76f989f4eb85883e8683791ba8.pdf,/attachment/1c917d0c8c40883074ae1b431849f362997ec322.zip,,,,anonymous|repo4qa_answering_complex_coding_questions_via_dense_retrieval_on_github_repositories,,,,,,/attachment/15afc3ce110610851fc8fa16bdf55f78cabdb518.zip,,,
88,CMXc3nK27q1,Bottom Up Parsing via Sequence Labeling,['aclweb.org/ACL/ARR/2021/November/Paper969/Authors'],['Anonymous'],"We translate the sequence labeling framework, first introduced for top-down discourse parsing by Koto et al. (2021), to bottom-up discourse parsing. We introduce a novel parser that is not constrained by parsing direction (left-to-right or otherwise), and is conditioned on previous parsing decisions. We describe the unique training requirements of a (directionally) unconstrained parser and explore two different training procedures. Additionally, we introduce a novel dynamic oracle for unconstrained bottom-up parsing. Our proposed parser achieves state-of-the-art performance amongst bottom-up RST parsers.",/pdf/4942eca67989357022bb8e5996a446809def232e.pdf,/attachment/79445ccf6567ee932daae97ade373f6d962f0901.zip,,,,anonymous|bottom_up_parsing_via_sequence_labeling,,,,,,,,,
89,fSc5SCkrI-B,On the Multilingual Capabilities of Very Large-Scale English Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2656/Authors'],['Anonymous'],"Generative Pre-trained Transformers (GPTs) have recently been scaled to unprecedented sizes in the history of machine learning. These models, solely trained on the language modeling objective, have been shown to exhibit outstanding zero, one, and few-shot learning capabilities in a number of different tasks. Nevertheless, aside from anecdotal experiences, little is known regarding their multilingual capabilities, given the fact that the pre-training corpus is almost entirely composed of English text. In this work, we investigate its potential and limits in three tasks: extractive question-answering, text summarization and natural language generation for five different languages, as well as the effect of scale in terms of model size. Our results show that GPT-3 can be almost as useful for many languages as it is for English, with room for improvement if optimization of the tokenization is addressed.",/pdf/8613b145b348f79b901e870a98b16998dc64f254.pdf,,,,,anonymous|on_the_multilingual_capabilities_of_very_largescale_english_language_models,,,,,,/attachment/c4fccc72f0f082ecad397314b10c67de673f2fe0.zip,,,
90,r_I1s2hkUHP,Discrete Wavelet Transform for Efficient Word Embeddings and Sentence Encoding,['aclweb.org/ACL/ARR/2021/November/Paper2254/Authors'],['Anonymous'],"Wavelets have emerged as a cutting edge technology in a number of fields. Concrete results of their application in image and signal processing suggest that wavelets can be effectively applied to Natural Language Processing (NLP) tasks to capture a variety of linguistic properties. In this paper, we leverage the power of applying Discrete Wavelet Transforms (DWT) to word and sentence embeddings. We evaluate, intrinsically and extrinsically, how wavelets can effectively be used to consolidate important information in a word vector while reducing its dimensionality. We demonstrate the effectiveness of using the DWT based embeddings, together with Discrete Cosine Transform (DCT), to compresses a sentence with a dense amount of information in a fixed size vector based on locally varying word features. 
We show the efficacy of the proposed paradigm on downstream applications yielding comparable and even superior (in some tasks) results to other state of the art spectral models.",/pdf/7c54fe29f9f858688726f7eb0a543b110b77ec32.pdf,,,,,anonymous|discrete_wavelet_transform_for_efficient_word_embeddings_and_sentence_encoding,,,,,,,,,
91,qc9O2EtrMI-,Overcoming a Theoretical Limitation of Self-Attention,['aclweb.org/ACL/ARR/2021/November/Paper330/Authors'],['Anonymous'],"Although transformers are remarkably effective for many tasks, there are some surprisingly easy-looking regular languages that they struggle with. Hahn shows that for languages where acceptance depends on a single input symbol, a transformer's classification decisions get closer and closer to random guessing (that is, a cross-entropy of 1) as input strings get longer and longer. We examine this limitation using two languages: PARITY, the language of bit strings with an odd number of 1s, and FIRST, the language of bit strings starting with a 1. We demonstrate three ways of overcoming the limitation implied by Hahn's lemma. First, we settle an open question by constructing a transformer that recognizes PARITY with perfect accuracy, and similarly for FIRST. Second, we use layer normalization to bring the cross-entropy of both models arbitrarily close to zero. Third, when transformers need to focus on a single position, as for FIRST, we find that they can fail to generalize to longer strings; we offer a simple remedy to this problem that also improves length generalization in machine translation.",/pdf/d25ac7062e7c203e57c8c678f9a619847f1c3afc.pdf,,,,,anonymous|overcoming_a_theoretical_limitation_of_selfattention,,,,,,,,,
92,nDqz4iCHWJq,Combating Spurious Features by Distribution Difference Regularization,['aclweb.org/ACL/ARR/2021/November/Paper1850/Authors'],['Anonymous'],"Prior studies show that spurious features are inevitable to avoid in the data collection process. These spurious features cause a shortcut for a model making bad prediction in real world test data due to ignoring the real features. In this work, we focus ondesigning a learning scheme to hinder the model from leveraging spurious features. To achieve this, prior studies usually make strong assumptions about the spurious features and identify them purely by manipulating the training data. In contrast, we make weaker assumptions and purpose a new framework for combating spurious features by observing the distribution shift between training and auxiliary data. In particular, with the help of unlabeled auxiliary data, we design a regularization technique based on the embedding distribution difference between training and auxiliary data to mitigate the effect of spurious features. Experimental results on NLI and coreference resolution tasks demonstrate that we improve the models on out-of-domain test data and reduce the contribution of spurious features in model predictions.",/pdf/ec327364973f3000ca9f0b86c74d10207d0fe8b7.pdf,,,,,anonymous|combating_spurious_features_by_distribution_difference_regularization,,,,,,,,,
93,lPx3fzsTTrK,Learning to Teach with Student Feedback,['aclweb.org/ACL/ARR/2021/November/Paper55/Authors'],['Anonymous'],"Knowledge distillation (KD) has gained much attention due to its effectiveness in compressing large-scale pre-trained models. In typical KD methods, the small student model is trained to match the soft targets generated by the big teacher model. However, the interaction between student and teacher is one-way. The teacher is usually fixed once trained, resulting in static soft targets to be distilled. This one-way interaction leads to the teacher's inability to perceive the characteristics of the student and its training progress. To address this issue, we propose Interactive Knowledge Distillation (IKD), which also allows the teacher to learn to teach from the feedback of the student. In particular, IKD trains the teacher model to generate specific soft target at each training step for a certain student. Joint optimization for both teacher and student is achieved by two iterative steps: a course step to optimize student with the soft target of teacher, and an exam step to optimize teacher with the feedback of student. IKD is a general framework that is orthogonal to most existing knowledge distillation methods. Experimental results show that IKD outperforms traditional KD methods on various NLP tasks.",/pdf/c25c8c171ffb84f9c577758bcd9a2e27e5ced84a.pdf,,,,,anonymous|learning_to_teach_with_student_feedback,,,,,,,,,
94,Nd1L1GfqOBS,HateBR: Large expert annotated corpus of Brazilian Instagram comments for abusive language detection,['aclweb.org/ACL/ARR/2021/November/Paper80/Authors'],['Anonymous'],"Due to the severity of the social media abusive comments in Brazil, and the lack of research in Portuguese, this paper provides the first large-scale annotated corpus of Brazilian Instagram comments for hate speech and offensive language detection on the web and social media. The HateBR corpus was collected from Brazilian Instagram comments of political personalities and manually annotated by specialists, being composed of 7,000 documents annotated according to three different layers: a binary classification (offensive versus non-offensive comments), offense-level classes (highly, moderately, and slightly offensive messages), as well as nine hate speech targets (xenophobia, racism, homophobia, sexism, religious intolerance, partyism, apology to the dictatorship, antisemitism, and fatphobia). Each comment was annotated by three different annotators and achieved high inter-annotator agreement.",/pdf/05e5e03c2dd471b0734678d271916e30126daf3f.pdf,,,,,anonymous|hatebr_large_expert_annotated_corpus_of_brazilian_instagram_comments_for_abusive_language_detection,,,,,,/attachment/15b22cf3cba887166dac91979d9d19dcc92a923f.zip,,,
95,4TMv3kdrhuc,Power Norm Based Lifelong Learning for Paraphrase Generations,['aclweb.org/ACL/ARR/2021/November/Paper1618/Authors'],['Anonymous'],"Seq2seq language generation models are trained with multiple domains in a continue learning manner, where the data from each domain being observed in an online fashion. However, continual learning studies usually suffer a lot from catastrophic forgetting, a persistent challenge for lifelong learning. To handle this problem, existing work has leveraged experience replay or dynamic architecture to consolidate the past knowledge, which however result in incremental memory space or high computational cost.  In this work, we propose an innovative framework PNLL that remedies the catastrophic forgetting issues with a power normalization on NLP transformer models. Specifically, PNLLL leverages power norm to achieve a better balance between past experience rehearsal and new knowledge acquisition. Our experiments on, paraphrase generation, show that PNLLL outperforms SOTA models by a considerable margin and remedy forgetting greatly.",/pdf/349181c0053665f28e74b9d2ec42d4c95a180b3c.pdf,,,,,anonymous|power_norm_based_lifelong_learning_for_paraphrase_generations,,,,,,,,,
96,8Gd6ZzHJG5C,Aligned Weight Regularizers for Pruning Pretrained Neural Networks,['Anonymous'],['Anonymous'],"Pruning aims to reduce the number of parameters while maintaining performance close to the original network. This work proposes a novel \emph{self-distillation} based pruning strategy, whereby the representational similarity between the pruned and unpruned versions of the same network is maximized. Unlike previous approaches that treat distillation and pruning separately, we use distillation to inform the pruning criteria, without requiring a separate student network as in knowledge distillation. We show that the proposed {\em cross-correlation objective for self-distilled pruning} implicitly encourages sparse solutions, naturally complementing magnitude-based pruning criteria. Experiments on the GLUE and XGLUE benchmarks show that self-distilled pruning increases mono- and cross-lingual language model performance. Self-distilled pruned models also outperform smaller Transformers with an equal number of parameters and are competitive against (6 times) larger distilled networks. We also observe that self-distillation (1) maximizes class separability, (2) increases the signal-to-noise ratio, and (3) converges faster after pruning steps, providing further insights into why self-distilled pruning improves generalization. ",/pdf/375eb502593bf3d0cb5614096eb196fd31d8f7cb.pdf,,,,,anonymous|aligned_weight_regularizers_for_pruning_pretrained_neural_networks,,,,,,,,,
97,8CRReJ4AgsG,NSP-NER: A Prompt-based Learner for Few-shot NER Driven by Next Sentence Prediction,['aclweb.org/ACL/ARR/2021/November/Paper2384/Authors'],['Anonymous'],"Recently, prompt-based learning has achieved great success in few-shot learning. This paradigm does better integrate pre-training and downstream tasks and mine the knowledge inherent in the pre-train language model itself. Most research on prompt-learning has been conducted, but the application of prompt-based learning in NER has not been fully explored. The main obstacles of prompt-based learning's application to NER are that, each unit to be predicted is a token or span instead of the whole input text, and the existing prompt-based methods are not sensitive to the boundaries of tokens or spans. To address these issues, we propose a prompt-based learner for few-shot NER driven by Next Sentence Prediction (NSP), reformulating NER as a NSP task with span boundary information enhancement. We conduct experiments on three NER datasets in true few-shot learning setting, which supposes that only a small training set and a small validation set are available. Experimental results show that our method outperforms previous state-of-the-art models and yields promising performance even in such a challenging scenario. ",/pdf/55a09f854f13f8957427e1fef505bde1d20bf292.pdf,,,,,anonymous|nspner_a_promptbased_learner_for_fewshot_ner_driven_by_next_sentence_prediction,,,,,,,,,
98,AfBuiCDtF_0,Improving Generalizability in Implicitly Abusive Language Detection with Concept Activation Vectors,['aclweb.org/ACL/ARR/2021/November/Paper327/Authors'],['Anonymous'],"Robustness of machine learning models on ever-changing real-world data is critical, especially for applications affecting human well-being such as content moderation. New kinds of abusive language continually emerge in online discussions in response to current events (e.g., COVID-19), and the deployed abuse detection systems should be updated regularly to remain accurate. In this paper, we show that general abusive language classifiers tend to be fairly reliable in detecting out-of-domain explicitly abusive utterances but fail to detect new types of more subtle, implicit abuse. Next, we propose an interpretability technique, based on the Testing Concept Activation Vector (TCAV) method from computer vision, to quantify the sensitivity of a trained model to the human-defined concepts of explicit and implicit abusive language, and use that to explain the generalizability of the model on new data, in this case, COVID-related anti-Asian hate speech. Extending this technique, we introduce a novel metric, Degree of Explicitness, for a single instance and show that the new metric is beneficial in suggesting out-of-domain unlabeled examples to effectively enrich the training data with informative, implicitly abusive texts.",/pdf/251e8210bb3436318de6a3e713c44fd864f95fab.pdf,/attachment/bfe5176c1206b07f3529258327107e7ac2bb97fc.zip,,,,anonymous|improving_generalizability_in_implicitly_abusive_language_detection_with_concept_activation_vectors,,,,,,/attachment/3c1c6bb7bbc2131dcd6ca95d395d7874c73c8381.zip,/attachment/bc2e3d3977f00f54bf2198b31233c25c8e8a3fb8.pdf,https://openreview.net/forum?id=eRRLIv7DrOX,/attachment/40e742b6c4a3ca1daf8a588d2c5aff4eeb4be46b.pdf
99,RE7ONmfTw7i,That Slepen Al the Nyght with Open Ye! Cross-era Sequence Segmentation with Switch-memory,['aclweb.org/ACL/ARR/2021/November/Paper97/Authors'],['Anonymous'],"Language evolution follows the rule of gradual change. Grammar, vocabulary, and lexical semantics shift took place over time, resulting in the diachronic linguistic gap. However, a considerable amount of texts are written in languages of different eras, which brings obstacles to natural language processing tasks, such as word segmentation and machine translation. Chinese is a language with a long history, but previous Chinese natural language processing works mainly focused on tasks in a specific era. Therefore, in this paper, we propose a cross-era learning framework for Chinese word segmentation (CWS), CROSSWISE, which uses the Switch-memory (SM) module to incorporate era-specific linguistic knowledge. Experiments on four corpora with different eras show that the performance of each corpus obtains a significant improvement. Further analyses also demonstrate that the SM can effectively integrate the knowledge of the eras into the neural network.",/pdf/3e88f8983018df2fb805d9704b310d17ececd6b7.pdf,,,,,anonymous|that_slepen_al_the_nyght_with_open_ye_crossera_sequence_segmentation_with_switchmemory,,,,,,,,,
100,AjLizwlktx,A Slot Is Not Built in One Utterance: Spoken Language Dialogs with Sub-Slots,['aclweb.org/ACL/ARR/2021/November/Paper2319/Authors'],['Anonymous'],"A slot value might be provided segment by segment over multiple-turn interactions in a dialog, especially for some important information such as phone numbers and names. It is a common phenomenon in daily life, but little attention has been paid to it in previous work. To fill the gap, this paper defines a new task named Sub-Slot based Task-Oriented Dialog (SSTOD) and builds a Chinese dialog dataset SSD for boosting research on SSTOD. The dataset includes total 40K dialogs and 500K utterances from four different domains: Chinese names, phone numbers, ID numbers and license plate numbers. The data is well annotated with sub-slot values, slot values, dialog states and actions. We find some new linguistic phenomena and interactive manners in SSTOD which raise some new challenges of building agents for the task. We test three state-of-the-art models on SSTOD and find they cannot handle the new task well on any of the four domains. We also investigate an improved model by involving slot knowledge in a plug-in manner. More work should be done to meet the new challenges raised from SSTOD which widely exists in real-life applications. ",/pdf/26fe758bb16400fbdd8cef88db27a3f4459531f5.pdf,,,,,anonymous|a_slot_is_not_built_in_one_utterance_spoken_language_dialogs_with_subslots,,,,,,,,,
101,2E1CRNtZP6t,On Isotropy Calibration of Transformer Models ,['aclweb.org/ACL/ARR/2021/November/Paper64/Authors'],['Anonymous'],"Different studies of the embedding space of transformer models suggest that the distribution of contextual representations is highly anisotropic - the embeddings are distributed in a narrow cone. Meanwhile, static word representations (e.g., Word2Vec or GloVe) have been shown to benefit from isotropic spaces. Therefore, previous work has developed methods to calibrate the embedding space of transformers in order to ensure isotropy. However, a recent study (Cai et al. 2021) shows that the embedding space of transformers is locally isotropic, which suggests that these models are already capable of exploiting the expressive capacity of their embedding space. In this work, we conduct an empirical evaluation of state-of-the-art methods for isotropy calibration on transformers and find that they do not provide consistent improvements across models and tasks. These results support the thesis that, given the local isotropy, transformers do not benefit from additional isotropy calibration.",/pdf/afe91364bbe2a409639863942eb860f876b3c431.pdf,,,,,anonymous|on_isotropy_calibration_of_transformer_models,,,,,,,,,
102,sFZPi0Dy6XV,Leveraging Uni-Modal Self-Supervised Learning for Multimodal Audio-visual Speech Recognition,['aclweb.org/ACL/ARR/2021/November/Paper2383/Authors'],['Anonymous'],"Training Transformer-based models demands a large amount of data, while obtaining parallel aligned and labelled data in multimodality is rather cost-demanding, especially for audio-visual speech recognition (AVSR). Thus it makes a lot of sense to make use of unlabelled uni-modal data. On the other side, although the effectiveness of large-scale self-supervised learning is well established in both audio and visual modalities, how to integrate those pre-trained models into a multimodal scenario remains underexplored. In this work, we successfully leverage uni-modal self-supervised learning to promote the multimodal AVSR. In particular, we first train audio and visual encoders on a large-scale uni-modal dataset, then we integrate components of both encoders into a larger multimodal framework which learns to recognize paired audio-visual data into characters through a combination of CTC and seq2seq decoding. We show that both components inherited from uni-modal self-supervised learning cooperate well, resulting in that the multimodal framework yields competitive results through fine-tuning. Our model is experimentally validated on both word-level and sentence-level AVSR tasks. Especially, even without an external language model, our proposed model raises the state-of-the-art performances on the widely accepted Lip Reading Sentences 2 (LRS2) dataset by a large margin, with a relative improvement of 30%.",/pdf/043294958e3ef70404152585da415bc190c7e82d.pdf,/attachment/d06712ab7f4a263414a41edf46a81be2339ac7ed.zip,,,,anonymous|leveraging_unimodal_selfsupervised_learning_for_multimodal_audiovisual_speech_recognition,,,,,,,,,
103,KxHD64st3JL,Lexical Gender Made Simple: A Scalable Methodology for Gender Detection with Online Lexical Databases,['aclweb.org/ACL/ARR/2021/November/Paper2923/Authors'],['Anonymous'],"The evaluation of gender bias in Natural Language Processing relies on the use of gendered expressions, such as pronouns and words with lexical gender. Up until this point, researchers have manually compiled lists that record lexical gender for individual words. However, manual compilation leads to static information if lists are not periodically updated and categorization requires value judgements by annotators and researchers. Moreover, words that are not covered by the list fall out of the range of analysis.
To address these issues, we devised a dictionary-based method to automatically detect lexical gender that can provide a dynamic, up-to-date analysis with high coverage. Our approach reaches 90 % accuracy in determining the lexical gender of words retrieved randomly from a Wikipedia sample, and when testing on a manually compiled list that the method aims to replace. ",/pdf/da39fe369a7be8cd22cb2921dfe39175f8cafccf.pdf,,,,,anonymous|lexical_gender_made_simple_a_scalable_methodology_for_gender_detection_with_online_lexical_databases,,,,,,/attachment/a5f882523501ce27828bd3473699d17959c37cea.zip,,,
104,RdQXgI1pXt1,Mixture-of-Graphs: Zero-shot Relational Learning for Knowledge Graph by Fusing Ontology and Textual Experts,['aclweb.org/ACL/ARR/2021/November/Paper1730/Authors'],['Anonymous'],"Knowledge Graph Embedding (KGE) have been proposed and succeed utilized to knowledge Graph Completion (KGC). But dominant KGE models often fail in zero-shot relational learning because they cannot learn effective representations for unseen relations. Previous studies mainly separately utilize the textual description of relation and its neighbor relations to represent unseen relations. In fact, the semantics of a relation can be expressed by three kinds of graphs: factual graph, ontology graph and textual description graph, and they can complement and enhance each other. Therefore, to obtain more accurate representation of relation in zero-shot learning, we propose the mixture-of-graphs (MoG) experts to improve the effect of current KGE for unseen relations. We build multi-aspect associations between seen and unseen relations which will be used directly to guide previous KGE methods such as TransE and RotatE on zero-shot relational learning. The experiments on multiple public datasets verify the effectiveness of the proposed method, which improves the state-of-the-art zero-shot relational learning method by 12.84% in Hits@10 on average.",/pdf/ffb379994a40d70f3da99f98e41f643fae7142a5.pdf,,,,,anonymous|mixtureofgraphs_zeroshot_relational_learning_for_knowledge_graph_by_fusing_ontology_and_textual_experts,,,,,,,,,
105,uNL0E5IuuG,Hansel: A Chinese Few-Shot and Zero-Shot Entity Linking Benchmark,['aclweb.org/ACL/ARR/2021/November/Paper2594/Authors'],['Anonymous'],"Modern Entity Linking (EL) systems entrench a popularity bias. However, there is no dataset focusing on tail and emerging entities in languages other than English. We present Hansel, a new benchmark in Chinese that fills the vacancy of non-English few-shot and zero-shot EL challenges. Hansel is human annotated and reviewed, with a novel method for collecting zero-shot EL datasets. It is a diverse dataset covering 8.2K documents in news, social media posts and other web articles, with Wikidata as its target Knowledge Base. We demonstrate that the existing state-of-the-art EL system performs poorly on Hansel (R@1 of 35.8% on Few-Shot). We then establish a strong baseline that scores a R@1 of 43.2% on Few-Shot and 76.6% on Zero-Shot on our dataset. We also show that our baseline achieves competitive results on TAC-KBP2015 Chinese Entity Linking task.",/pdf/8f4959985eb66242b6e972a5e914b4fa3e94fd54.pdf,,,,,anonymous|hansel_a_chinese_fewshot_and_zeroshot_entity_linking_benchmark,,,,,,/attachment/35f775794364f98776b3f23414a185348bf0cdf8.zip,/attachment/1b814dc45adf2c1c44b7f6e7a6749e39daacddf0.pdf,https://openreview.net/forum?id=kLXFm320Xit,/attachment/452fcf24ebbd982fe2804d6b289646946751a95f.pdf
106,hTAhTdgt0D4,What Makes The Story Forward? Inferring Commonsense Explanations as Prompts for Future Event Generation,['aclweb.org/ACL/ARR/2021/November/Paper2149/Authors'],['Anonymous'],"Future Event Generation (FEG) aims to generate fluent and reasonable future event descriptions given preceding events. It requires not only fluent text generation but also commonsense reasoning to maintain the coherence of the entire event story. However, existing FEG methods are easily trapped into repeated or general events without imposing any logical constraint to the generation process. In this paper, we propose a novel explainable FEG framework that consists of a commonsense inference model (\textsc{Im}) and an event generation model (\textsc{Gm}). The \textsc{Im}, which is pre-trained on a commonsense knowledge graph ATOMIC, learns to interpret the preceding events and conducts commonsense reasoning to reveal the character’s psychology such as intent, reaction and needs as latent variables. The \textsc{Gm} further takes the commonsense knowledge as prompts to guide and enforce the generation of logistically coherent future events. As a unique merit, the commonsense prompts can be further decoded into textual descriptions, yielding explanations for the future event. Automatic and human evaluation demonstrate that our approach can generate more coherent, specific, and logical future events than the strong baselines. All the programs and resources will be made public upon acceptance.",/pdf/e4c973e309a3b9651becfeebb2d472dca44b2acd.pdf,,,,,anonymous|what_makes_the_story_forward_inferring_commonsense_explanations_as_prompts_for_future_event_generation,,,,,,,,,
107,lrPUCUl7jgK,Diversifying Neural Dialogue Generation via Negative Distillation,['aclweb.org/ACL/ARR/2021/November/Paper2965/Authors'],['Anonymous'],"Generative dialogue models suffer from serious generic response problems, limiting their applications to a few toy scenarios.  Recently, an interesting approach, namely negative training, has been proposed to alleviate this problem by reminding the model not to generate high-frequency responses during training. However, its performance is hindered by two issues, ignoring low-frequency but generic responses and bringing low-frequency but meaningless responses. In this paper, we propose a novel negative training paradigm, called negative distillation, to keep the model away from the undesirable generic responses while avoiding the above problems.  First, we introduce a negative teacher model that can produce query-wise generic responses, and then the student model is required to maximize the distance with multi-level negative knowledge. Empirical results show that our method outperforms previous negative training methods significantly.",/pdf/dcdb0f771aab11a41d8ca27ac5d9c792b3ce4a9e.pdf,,,,,anonymous|diversifying_neural_dialogue_generation_via_negative_distillation,,,,,,,,,
108,0YD1VAUGZ-X,Packed Levitated Marker for Entity and Relation Extraction,['aclweb.org/ACL/ARR/2021/November/Paper2355/Authors'],['Anonymous'],"Recent entity and relation extraction works focus on investigating how to obtain a better span representation from the pre-trained encoder. However, a major limitation of existing works is that they ignore the interrelation between spans (pairs). In this work, we propose a novel span representation approach, named Packed Levitated Markers (PL-Marker),  to consider the interrelation between the spans (pairs) by strategically packing the markers in the encoder. In particular, we propose a neighborhood-oriented packing strategy, which  considers the neighbor spans integrally to better model the entity boundary information. Furthermore, for those more complicated span pair classification tasks, we  design a subject-oriented packing strategy, which packs each subject and all its objects to model the interrelation between the same-subject span pairs. The experimental results show that, with the enhanced marker feature, our model advances baselines on six NER benchmarks, and obtains a 3.5%-3.6% strict relation F1 improvement with higher speed over previous state-of-the-art models on ACE04 and ACE05. All the code and data of this paper will be made publicly available.",/pdf/ac4e0ef65a703692512e2ec726bdf35c0dc90f2b.pdf,/attachment/28fd9b2ccf4c54798f02ec6e1e496bc27eb83f25.zip,,,,anonymous|packed_levitated_marker_for_entity_and_relation_extraction,,,,,,,,,
109,Qu4RXfhYRKa,Predicting Attention Sparsity in Transformers,['aclweb.org/ACL/ARR/2021/November/Paper1555/Authors'],['Anonymous'],"Transformers' quadratic complexity with respect to the input sequence length has motivated a body of work on efficient sparse approximations to softmax. An alternative path, used by entmax transformers, consists of having built-in exact sparse attention; however this approach still requires quadratic computation. In this paper, we propose Sparsefinder, a simple model trained to identify the sparsity pattern of entmax attention before computing it. We experiment with three variants of our method, based on distances, quantization, and clustering, on two tasks: machine translation (attention in the decoder) and masked language modeling (encoder-only). Our work provides a new angle to study model efficiency by doing extensive analysis of the tradeoff between the sparsity and recall of the predicted attention graph. This allows for detailed comparison between different models along their Pareto curves, important to guide future benchmarks for sparse attention models.",/pdf/f7e8bb557de7cdc0a74cdf703f8e207c72262bf8.pdf,,,,,anonymous|predicting_attention_sparsity_in_transformers,,,,,,,,,
110,CAd8LOkxAb,First Bilingual Word Embeddings for te reo Māori and English: Towards Code-switching Detection in a Low-resourced setting,['aclweb.org/ACL/ARR/2021/November/Paper462/Authors'],['Anonymous'],"Māori speakers are bilingual, where  Māori is code-switched with English. With Māori being low-resourced for technology development, there are minimal resources available for Māori-English code-switch detection. This research collected the Māori-English Words corpus containing more than 71M words, and developed the first open-sourced Māori-English bilingual word embeddings model. We provide experimental evidence to show an improvement of atleast 5% in F1-scores when the bilingual embeddings we developed is used for code-switch detection compared to the already-available English-only embeddings trained on a relatively large database. This study is the first one providing resources and exploring deep learning for Māori-English code-switch detection.",/pdf/0898dc941f4da90fc1a171a5fb6410dc0894bd3a.pdf,,,,,anonymous|first_bilingual_word_embeddings_for_te_reo_mori_and_english_towards_codeswitching_detection_in_a_lowresourced_setting,,,,,,,,,
111,pqn1s7ARgYb,Stable Natural Language Understanding via Invariant Causal Constraint,['aclweb.org/ACL/ARR/2021/November/Paper287/Authors'],['Anonymous'],"Natural Language Understanding (NLU) task requires the model to understand the underlying semantics of input text. However, recent analyses demonstrate that NLU models tend to utilize dataset biases to achieve high dataset-specific performances, which always leads to performance degradation on out-of-distribution (OOD) samples. To
increase the performance stability, previous debiasing methods \emph{empirically} capture bias features from data to prevent model from corresponding biases. However, we argue that, the semantic information can form a \emph{causal} relationship with the target labels of the NLU task, while the biases information is only \emph{correlative} to the target labels. Such difference between the semantic information and dataset biases still remains not fully addressed, which limits the effectiveness of debiasing. To address this issue, we analyze the debiasing process under a \emph{causal perspective}, and present a causal invariance based stable NLU framework (CI-sNLU). 
",/pdf/3acf2cda206bad9738ee4ab98d4c3ed75576a35f.pdf,/attachment/bc502f603a661b0475d70dd5242f68085d41cfac.zip,,,,anonymous|stable_natural_language_understanding_via_invariant_causal_constraint,,,,,,,,,
112,VreTOiippg_,Sentence Selection Strategies for Distilling Word Embeddings from BERT,['aclweb.org/ACL/ARR/2021/November/Paper1425/Authors'],['Anonymous'],"Many applications crucially rely on the avail-ability of high-quality word vectors. To learn such representations, several strategies based on language models have been proposed in recent years. While effective, these methods typically rely on a large number of contextualised vectors for each word, which makes them impractical. In this paper, we investigate whether similar results can be obtained when only a few contextualised  representations  of  each  word can be used.  To this end, we analyze a range of strategies for selecting the most informative sentences.  Our results show that with a careful selection strategy, high-quality word vectors can be learned from as few as 5 to 10 sentences.",/pdf/f1b705ae945d27d85b7f1d035daff32de3346275.pdf,,,,,anonymous|sentence_selection_strategies_for_distilling_word_embeddings_from_bert,,,,,,,,,
113,Jj8UMGBF0RS,Spot the Difference: A Cooperative Object-Referring Game in Non-Perfectly Co-Observable Scene,['aclweb.org/ACL/ARR/2021/November/Paper741/Authors'],['Anonymous'],"Visual dialogue has witnessed great progress after introducing various vision-oriented goals into the conversation, especially such as GuessWhich and GuessWhat, where the only image is visible by either and both of the questioner and the answerer, respectively. Researchers explore more on visual dialogue tasks in such kind of single- or perfectly co-observable visual scene, while somewhat neglect the exploration on tasks of non-perfectly co-observable visual scene, where the images accessed by two agents may not be exactly the same, often occurred in practice. Although building common ground in non-perfectly co-observable visual scene through conversation is significant for advanced dialogue agents, the lack of such dialogue task and corresponding large-scale dataset makes it impossible to carry out in-depth research. To break this limitation, we propose an object-referring game in non-perfectly co-observable visual scene, where the goal is to spot the difference between the similar visual scenes through conversing in natural language. The task addresses challenges of the dialogue strategy in non-perfectly co-observable visual scene and the ability of categorizing objects. Correspondingly, we construct a large-scale multi-modal dataset, named \textit{SpotDiff}, which contains 49k Virtual Reality images and 97k dialogues generated by self-play. Finally, we give benchmark models for this task, and conduct extensive experiments to evaluate its performance as well as analyze its main challenges.",/pdf/5c9e8c0704927d34a98f3adc552e8b4dfef978d9.pdf,,,,,anonymous|spot_the_difference_a_cooperative_objectreferring_game_in_nonperfectly_coobservable_scene,,,,,,,,,
114,0sRxRtkzfd-,Generating Summaries for Scientific Paper Review,['aclweb.org/ACL/ARR/2021/November/Paper1472/Authors'],['Anonymous'],"The review process is essential to ensure the quality of publications.  Recently, the increase of  submissions  for  top  venues  in  machine learning  and  NLP  has  caused  a  problem  of excessive  burden  on  reviewers  and  has  often caused  concerns  regarding  how  this  may  not only  overload  reviewers,  but  also  may  affect the quality of the reviews.  An automatic system  for  assisting  with  the  reviewing  process could be a solution for ameliorating the problem.   In  this  paper,  we  explore  automatic  review summary generation for scientific papers. We posit that neural language models have the potential to be valuable candidates for this task. In  order  to  test  this hypothesis,  we release  a new  dataset  of  scientific  papers  and  their  reviews, collected from papers published in the NeurIPS conference from 2013 to 2020.  We evaluate state of the art neural summarization models, present initial results on the feasibility of automatic review summary generation, and propose directions for the future",/pdf/70318d7c287ae15889eaca39ed07e05a78e7bf29.pdf,,,,,anonymous|generating_summaries_for_scientific_paper_review,,,,,,,,,
115,5B-j_cnM7Oo,An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2639/Authors'],['Anonymous'],"Recent work has shown pre-trained language models capture social biases from the text corpora they are trained on. This has attracted attention to developing techniques that mitigate such biases. In this work, we perform an empirical survey of five recently proposed bias mitigation techniques: Counterfactual Data Augmentation (CDA), Dropout, Iterative Nullspace Projection, Self-Debias,  and SentenceDebias.
We quantify the effectiveness of each technique using three intrinsic bias benchmarks while also measuring the impact of these techniques on a model's language modeling ability, as well as its performance on downstream NLU tasks. We experimentally find that: (1) Self-Debias is the strongest debiasing technique, obtaining improved scores on all bias benchmarks; (2) Current debiasing techniques perform less consistently when mitigating non-gender biases; And (3) improvements on bias benchmarks such as StereoSet and CrowS-Pairs by using debiasing strategies are often accompanied by a decrease in language modeling ability, making it difficult to determine whether the bias mitigation was effective.",/pdf/29bc84863fd3404d3f2bd977f2f120563697cd90.pdf,/attachment/1ad67286aafad055bb603e24d959db2c609129ac.zip,,,,anonymous|an_empirical_survey_of_the_effectiveness_of_debiasing_techniques_for_pretrained_language_models,,,,,,,,,
116,t5rZf5Fvz0k,SlotGAN: Detecting Mentions in Text via Adversarial Distant Learning,['aclweb.org/ACL/ARR/2021/November/Paper2628/Authors'],['Anonymous'],"We present SlotGAN, a framework for training a mention detection model that only requires unlabeled text and a gazetteer. It consists of a generator trained to extract spans from an input sentence, and a discriminator trained to determine whether a span comes from the generator, or from the gazetteer.
We evaluate the method on English newswire data and compare it against supervised, weakly-supervised, and unsupervised methods. We find that the performance of the method is lower than these baselines, because it tends to generate more and longer spans, and in some cases it relies only on capitalization. In other cases, it generates spans that are valid but differ from the benchmark. When evaluated with metrics based on overlap, we find that SlotGAN performs within 95% of the precision of a supervised method, and 84% of its recall. Our results suggest that the model can generate spans that overlap well, but an additional filtering mechanism is required.",/pdf/8e3dbaa4b295c5b1608c30bdcfeaf7cc165d7f80.pdf,,,,,anonymous|slotgan_detecting_mentions_in_text_via_adversarial_distant_learning,,,,,,,,,
117,uPRJdUfb62q,Textomics: A Dataset for Genomics Data Summary Generation,['aclweb.org/ACL/ARR/2021/November/Paper1211/Authors'],['Anonymous'],"Summarizing biomedical discovery from genomics data using natural languages is an essential step in biomedical research but is mostly done manually. Here, we introduce Textomics, a novel dataset of genomics data description, which contains 22,273 pairs of genomics data matrix and its summary. Each summary is written by the researchers who generated the data and associated with a scientific paper. Based on this dataset, we study two novel tasks: generating textual summary from genomics data matrix and vice versa. Inspired by the successful applications of $k$ nearest neighbors in modeling genomics data, We propose a $k$NN-Vec2Text model to address these tasks and observe substantial improvement on our dataset. We further illustrate how Textomics can be used to advance other applications, including evaluating scientific paper embeddings and generating masked templates for scientific paper understanding. Textomics serves as the first benchmark for generating textual summary for genomics data and we envision it will be broadly applied to other biomedical and natural language processing applications.",/pdf/00e611e665523a66076d3fccee04ec7f2f51b625.pdf,/attachment/e5829faa1b06bc23b678d8a4e8fd581948379fad.zip,,,,anonymous|textomics_a_dataset_for_genomics_data_summary_generation,,,,,,/attachment/596dc58408292e98e0b6ef05d8460d5a2bedcbff.zip,,,
118,0qmlnLlafqv,The Case for a Single Model that can Both Generate Continuations and Fill-in-the-Blank,['aclweb.org/ACL/ARR/2021/November/Paper1690/Authors'],['Anonymous'],"The task of inserting text into a specified position in a passage, known as fill in the blank (FitB), is useful for a variety of applications where writers interact with a natural language generation (NLG) system to craft text. While previous work has tackled this problem with models trained specifically to do fill in the blank, a more useful model is one that can effectively perform _both_ FitB and continuation tasks.
In this work, we evaluate the feasibility of using a single model to do both tasks. We show that models pre-trained with a FitB-style objective are capable of both tasks, while models pre-trained for continuation are not. Finally, we show how these models can be easily finetuned to allow for fine-grained control over the length and word choice of the generation.",/pdf/31240984f5b9627c4942bfb770bbad5f00a1591b.pdf,,,,,anonymous|the_case_for_a_single_model_that_can_both_generate_continuations_and_fillintheblank,,,,,,,/attachment/0feb3fc421322d05825dc04bfcfda92cfd4be4ab.pdf,https://openreview.net/forum?id=wX4qY_TXKp8,/attachment/ebeccc1e7abbcd89bb3ad10d2ddedf9bd53c5a99.pdf
119,FY12Sx39srI,End-to-end Task-oriented Dialog Policy Learning based on Pre-trained Language Model,['aclweb.org/ACL/ARR/2021/November/Paper2539/Authors'],['Anonymous'],"This paper presents our approach to dialog policy learning (DPL), which aims to determine the next system’s action based on the current dialog state maintained by a dialog state tracking module. Different from previous stage-wise DPL, we propose an end-to-end DPL system to avoid error accumulation between the dialogue turns. The DPL system is deployed from two perspectives. Firstly, we consider turn-level DPL that selects the best dialog action from a predefined action set. Specifically, we proposed a dialog action-oriented BERT (DA-BERT), which integrates a new pre-training procedure named masked last action task (MLA) that encourages BERT to be dialog-aware and distill action-specific features. Secondly, we propose a word-level DPL that directly generates the dialog action. We creatively model DPL as a sequence generation model conditioned on the dialog action structure. Then GPT-2 equipped with an action structure parser module (termed as DA-GPT-2) is applied to learn the word level DPL. The effectiveness and different characteristics of the proposed models are demonstrated with the in-domain tasks and domain adaptation tasks on MultiWOZ with both simulator evaluation and human evaluation. ",/pdf/4a8f326d54e28a22816441a84819551d401416e8.pdf,,,,,anonymous|endtoend_taskoriented_dialog_policy_learning_based_on_pretrained_language_model,,,,,,,,,
120,EsQHxNYt0u,How to Translate Your Samples and Choose Your Shots? Analyzing Translate-train & Few-shot Cross-lingual Transfer,['aclweb.org/ACL/ARR/2021/November/Paper1000/Authors'],['Anonymous'],"Translate-train or few-shot cross-lingual transfer can be used to improve the zero-shot performance of multilingual pretrained language models. Few-shot utilizes high-quality low-quantity samples (often manually translated from the English corpus to the target language). Translate-train employs a machine translation of the English corpus, resulting in samples with lower quality that could be scaled to high quantity. Given the lower cost and higher availability of machine translation compared to manual professional translation, it is important to systematically compare few-shot and translate-train, understand when few-shot is beneficial, and whether choosing the shots to translate increases the few-shot gain. This work aims to fill this gap: we compare and quantify the performance gain of few-shot vs. translate-train using a varying number of samples for three tasks/datasets (XNLI, PAWS-X, XQuAD) spanning 17 languages. We show that scaling up the training data using machine translation gives a larger gain compared to using the small-scale (higher-quality) few-shot data. When few-shot is beneficial, we show that there are random sets of samples that perform better across languages and that the performance on English and on the machine-translation of the samples can both be used to choose the shots to manually translate for an increased few-shot gain.",/pdf/07d93d23049305423ef5d7259c17aa766a253dba.pdf,,,,,anonymous|how_to_translate_your_samples_and_choose_your_shots_analyzing_translatetrain_fewshot_crosslingual_transfer,,,,,,,,,
121,69pbZhLNcH,Rethinking Offensive Text Detection as a Multi-Hop Reasoning Problem,['aclweb.org/ACL/ARR/2021/November/Paper489/Authors'],['Anonymous'],"We introduce the task of implicit offensive text detection in dialogues, where a statement may have either an offensive or non-offensive interpretation, depending on the listener and context. We argue that reasoning is crucial for understanding this broader class of offensive utterances, and create Mh-RIOT ($\textbf{M}$ulti-hop $\textbf{R}$easoning $\textbf{I}$mplicitly $\textbf{O}$ffensive $\textbf{T}$ext Dataset), to support research on this task.  Experiments using the dataset show that state-of-the-art methods of offense detection perform poorly when asked to detect implicitly offensive statements, achieving only ${\sim} 0.11$ accuracy.

In contrast to existing offensive text detection datasets, Mh-RIOT features human-annotated chains of reasoning which describe the mental process by which an offensive interpretation can be reached from each ambiguous statement.
 We explore the potential for a multi-hop reasoning approach by utilizing existing entailment models to score the transitions of these chains, and show that even naive reasoning models can result in improved performance in most situations.  Analysis of the chains provides insight into the human interpretation process and emphasizes the importance of incorporating additional commonsense knowledge.",/pdf/1057e535dcf4de194d95c56dec60887a0ab5ba11.pdf,,,,,anonymous|rethinking_offensive_text_detection_as_a_multihop_reasoning_problem,,,,,,/attachment/06d7ce447a74f50e1206cfb8e342e574200c1a37.zip,/attachment/57db2aa701a5bcefa2c5029d25d695c4da3d9321.pdf,https://openreview.net/forum?id=CCAvbuPYKC,/attachment/0b3e5b832e061649f5e280f19d27c9ff06dd2b87.pdf
122,TnX3iwX_6Iu,A Comprehensive and Large-Scale Dataset for Integrated Argument Mining Tasks,['aclweb.org/ACL/ARR/2021/November/Paper1089/Authors'],['Anonymous'],"Traditionally, a debate usually requires a manual preparation process, including reading plenty of articles, selecting the claims, identifying the stances of the claims, seeking the evidences for the claims, etc. As the AI debate attracts more attention these years, it is worth exploring the methods to automate the tedious process involved in the debating system. In this work, we introduce a comprehensive and large dataset, which can be applied to a series of argument mining tasks, including claim extraction, stance classification, evidence extraction, etc. Our dataset is collected from over 1k articles related to 123 topics. Near 70k sentences in the dataset are fully annotated based on their argument properties (e.g., claims, stances, evidences, etc.). We further propose two new integrated argument mining tasks associated with the debate preparation process: (1) claim extraction with stance classification (CESC) and (2) claim-evidence pair extraction (CEPE). We adopt a pipeline approach and an end-to-end method for each integrated task separately. Promising experimental results are reported to show the values and challenges of our proposed tasks, and motivate future research on argument mining.",/pdf/c796cd9e610c846bee134288b91e6c96a280ce36.pdf,/attachment/731c9793ce39c2c73f9ce7d2f29f7daea32d49e2.zip,,,,anonymous|a_comprehensive_and_largescale_dataset_for_integrated_argument_mining_tasks,,,,,,/attachment/f24c7d4f21f1269318c64c12f993d36c0c4d8d49.zip,,,
123,fv41yKtPzcl,Towards Computationally Feasible Deep Active Learning,['aclweb.org/ACL/ARR/2021/November/Paper2220/Authors'],['Anonymous'],"Active learning (AL) is a prominent technique for reducing the annotation effort required for training machine learning models. Deep learning offers a solution for several essential obstacles to deploying AL in practice but introduces many others. One of such problems is the excessive computational resources required to train an acquisition model and estimate its uncertainty on instances in the unlabeled pool. We propose two techniques that tackle this issue for text classification and tagging tasks, offering a substantial reduction of AL iteration duration and the computational overhead introduced by deep acquisition models in AL. We also demonstrate that our algorithm that leverages pseudolabeling and distilled models overcomes one of the essential obstacles revealed previously in the literature. Namely, it was shown that due to differences between an acquisition model used to select instances during AL and a successor model trained on the labeled data, the benefits of AL can diminish. We show that our algorithm, despite using a smaller and faster acquisition model, is capable of training a more expressive successor model with higher performance.",/pdf/fe1be50f233a9363efeea594ed971e9f64549382.pdf,,,,,anonymous|towards_computationally_feasible_deep_active_learning,,,,,,,/attachment/e81ef1f570d8e1abadef15cf8250282272b3f1dd.pdf,https://openreview.net/pdf?id=Ch1K-07jfmy,/attachment/2579ff8e912cd0a01a52de4c3a28aef588608af1.pdf
124,fXPJ6aC5dQo,Data-Driven Adaptive Simultaneous Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper2194/Authors'],['Anonymous'],"In simultaneous translation (SimulMT), the most widely used strategy is the \waitk policy thanks to its simplicity and effectiveness in balancing translation quality and latency. However, \waitk suffers from two major limitations: (a) it is a fixed policy that can not adaptively adjust  latency given context, and (b) its training is much slower than full-sentence translation. To alleviate these issues, we propose a novel and efficient training scheme for adaptive SimulMT by augmenting the training corpus with adaptive prefix-to-prefix pairs, while the training complexity remains the same as that of training full-sentence translation models. Experiments on two language pairs show that our method outperforms all strong baselines in terms of translation quality and latency.",/pdf/7886a401f3be7bed14e2073a61819516a9b4b66c.pdf,,,,,anonymous|datadriven_adaptive_simultaneous_machine_translation,,,,,,,,,
125,hROSL4xfNpH,BERT Learns to Teach: Knowledge Distillation with Meta Learning,['aclweb.org/ACL/ARR/2021/November/Paper2286/Authors'],['Anonymous'],"We present Knowledge Distillation with Meta Learning (MetaDistil), a simple yet effective alternative to traditional knowledge distillation (KD) methods where the teacher model is fixed during training. We show the teacher network can learn to better transfer knowledge to the student network (i.e., \textit{learning to teach}) with the feedback from the performance of the distilled student network in a meta learning framework. Moreover, we introduce a pilot update mechanism to improve the alignment between the inner-learner and meta-learner in meta learning algorithms that focus on an improved inner-learner. Experiments on various benchmarks show that MetaDistil can yield significant improvements compared with traditional KD algorithms and is less sensitive to the choice of different student capacity and hyperparameters, facilitating the use of KD on different tasks and models.",/pdf/36b72008db775155169a848242d68a0a22f4fb52.pdf,,,,,anonymous|bert_learns_to_teach_knowledge_distillation_with_meta_learning,,,,,,,/attachment/d3bd3e2dbd19974ce69205794ba28518bdbd59ef.pdf,https://openreview.net/forum?id=_giVW90_UAV,/attachment/735f51980df29e1ad0b569583e62363ce4ae7c35.pdf
126,I52u5Z4KDy0,A  Relation-Attentive 3D Matrix Framework for Relational Triple Extraction,['aclweb.org/ACL/ARR/2021/November/Paper2369/Authors'],['Anonymous'],"Extracting relational triples from unstructured text is crucial for information extraction. Recent methods achieve considerable performance, but due to the insufficient consideration of triple global information, there is an obvious performance gap between triple (E1, R, E2) and E1/R/E2, that is, some extracted entities or relations fail to form a valid relational triple. To break this bottleneck,  we propose a relation-attentive 3D matrix  framework (RA3D)  composed of an encoder module, a fusion module, and a 3D matrix module. Instead of using a 2D table to align the subject and object, we integrate clearly encoded relation information to convert the 2D table into a 3D matrix, so that the entries of the 3D matrix can capture the interaction in subjects, objects, and relations completely. To extract relation and entity information required for the 3D matrix reasonably,  we design a transformer-decoder-based fusion module that updates the representation of relations and entities iteratively. Our model achieves state-of-the-art performance with F1 score up to 93.5\% and 94.3\% on two public datasets and delivers consistent performance gain on complex scenarios of overlapping triples.  ",/pdf/409a782cde5a84b92b237f65001b78dfccdab99f.pdf,/attachment/6a5164c42a7d937234dfe0f9d28c555816b4cec4.zip,,,,anonymous|a_relationattentive_3d_matrix_framework_for_relational_triple_extraction,,,,,,/attachment/51ccff584ebc6de1b6fea606b9140b956969425a.zip,,,
127,NiUPI5OLS0o,AutoLEX: An Automatic Framework for Linguistic Exploration,['aclweb.org/ACL/ARR/2021/November/Paper1669/Authors'],['Anonymous'],"Each language has its own complex systems of word, phrase, and sentence construction, the guiding principles of which are often summarized in grammatical descriptions for the consumption of linguists or language learners.  However, manual creation of such descriptions across many languages is a fraught process, as creating language descriptions which describe the language in ""its own terms"" without bias or error requires both a deep understanding of the language at hand and linguistics as a whole. We propose an automatic framework AutoLEX that aims to ease linguists' discovery and extraction of concise descriptions of linguistic phenomena.  Specifically, we apply this framework to extract descriptions for three linguistic phenomena: morphological agreement, case marking, and word order, across several languages. We evaluate the extracted descriptions with the help of language experts and propose a method for automated evaluation when human evaluation is infeasible.",/pdf/1002f2d7651e5352520520fefb45a8c3edf78d41.pdf,,,,,anonymous|autolex_an_automatic_framework_for_linguistic_exploration,,,,,,,,,
128,MVcv5KxTqu_,Answering Open-Domain Multi-Answer Questions via a Recall-then-Verify Framework,['aclweb.org/ACL/ARR/2021/November/Paper2481/Authors'],['Anonymous'],"Open-domain questions are likely to be open-ended and ambiguous, leading to multiple valid answers. Existing approaches typically adopt the rerank-then-read framework, where a reader reads top-ranking evidence to predict answers. According to our empirical analysis, this framework faces three problems: first, to leverage a large reader under a memory constraint, the reranker should select only a few relevant passages to cover diverse answers, while balancing relevance and diversity is non-trivial; second, the small reading budget prevents the reader from accessing valuable retrieved evidence filtered out by the reranker; third, when using a generative reader to predict answers all at once based on all selected evidence, whether a valid answer will be predicted also pathologically depends on evidence of some other valid answer(s). To address these issues, we propose to answer open-domain multi-answer questions with a recall-then-verify framework, which separates the reasoning process of each answer so that we can make better use of retrieved evidence while also leveraging large models under the same memory constraint. Our framework achieves state-of-the-art results on two multi-answer datasets, and predicts significantly more gold answers than a rerank-then-read system that uses an oracle reranker.",/pdf/a19cbab97ee6a3f6f07964f509c116d49553bcde.pdf,,,,,anonymous|answering_opendomain_multianswer_questions_via_a_recallthenverify_framework,,,,,,,,,
129,lMDrXdhP2P,Automatic Song Translation for Tonal Languages,['aclweb.org/ACL/ARR/2021/November/Paper1966/Authors'],['Anonymous'],"This paper addresses automatic song translation (AST) for tonal languages and the unique challenge of aligning words' tones with the melody of a song in addition to conveying the original meaning. We propose three criteria for effective AST---preserving semantics, singability and intelligibility---and develop objectives for these criteria. We develop a new benchmark for English--Mandarin song translation and develop an unsupervised AST system, the Guided AliGnment for Automatic Song Translation (GagaST), which combines pre-training with three decoding constraints. Both automatic and human evaluations show GagaST successfully balances semantics and singability.",/pdf/f2747d7a2365d0ef45da3131ad141353e73feb8e.pdf,,,,,anonymous|automatic_song_translation_for_tonal_languages,,,,,,,,,
130,HG_3q4oywyc,Counselling Summarization using Mental Health Knowledge guided Utterance Filtering,['aclweb.org/ACL/ARR/2021/November/Paper2417/Authors'],['Anonymous'],"The psychotherapy intervention technique is a multifaceted conversation between a therapist and a patient. Unlike general clinical discussions, psychotherapy's core components (viz. symptoms) are hard to diagnose and become a complex problem to summarize later. A structured counselling conversation may contain discussions on symptoms or reasons for mental health issues, the discovery of the patient's behaviour and habits, and the rest of the conversation is generally chit-chat. We call these psychotherapy ingredients to be counselling components. We aim for the task of mental health counselling summarization exploiting domain knowledge. We curated a new dataset, MEMO, where we annotate 12.9K utterances for counselling components and reference summaries for each dialogue. Further, we propose ConSum: a novel counselling-component guided summarization model. The model works in three independent modules. First, it uses mental health domain knowledge to filter utterances by utilising the Patient Health Questionnaire (PHQ-9), while, the second and third modules work on the classification of counselling components. At last, we propose a problem specific Mental Health Information Capture (MHIC) evaluation metric for counselling summaries. Our extensive ablation study shows that we improve on the scores and better language semantics. We comprehensively analyse the generated summaries to investigate the capturing of core components of psychotherapy. In last, we discuss the uniqueness in mental health counselling summarization in contrast with medical conversation.",/pdf/fabfd76315177f4177c228d914b3013071739b64.pdf,,,,,anonymous|counselling_summarization_using_mental_health_knowledge_guided_utterance_filtering,,,,,,/attachment/1bd3e7f6b68a66c498ac1419aefb2475002e3576.zip,,,
131,HBYJawngw5,DrugEHRQA: A Question Answering Dataset on Structured and Unstructured Electronic Health Records For Medicine Related Queries,['aclweb.org/ACL/ARR/2021/November/Paper2640/Authors'],['Anonymous'],"This paper develops the first question answering dataset (DrugEHRQA) containing question-answer pairs from both structured tables and unstructured notes from a publicly available Electronic Health Record (EHR). EHRs contain patient records, stored in structured tables as well as unstructured clinical notes. The information in structured and unstructured EHR records is not strictly disjoint: information may be duplicated, contradictory, or provide additional context between these sources. This presents a rich opportunity to study question answering (QA) models that combine reasoning over both structured and unstructured data. Additionally, we propose a novel methodology that automatically generates a large QA dataset by retrieving answers from both structured and unstructured EHR records. The automatically-generated dataset has medication-related queries, containing over 70,000 question-answer pairs.  Our dataset is validated for both individual modalities using state-of-the-art QA models. In order to address the problem arising from complex, nested queries, this is the first time Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers (RAT-SQL) has been used for EHR data. Finally, we introduce a rule-based method to obtain multi-modal answers, combining the answers from the different modalities. Our goal is to provide a benchmark dataset for multi-modal QA systems, and to open up new avenues of research in improving question answering over EHR structured data by using context from unstructured clinical data.",/pdf/1ba73e7db3bcff7a99233d6ca3b61d08fd06be0e.pdf,/attachment/071cbd50adac5ef44ef56b0548f85dc1294dadc4.zip,,,,anonymous|drugehrqa_a_question_answering_dataset_on_structured_and_unstructured_electronic_health_records_for_medicine_related_queries,,,,,,/attachment/605d62c8df250f717be70345f064fbd3dd443865.zip,,,
132,FvVma0bSUMu,DAML-ST5: Low Resource Style Transfer via Domain Adaptive Meta Learning,['aclweb.org/ACL/ARR/2021/November/Paper2573/Authors'],['Anonymous'],"Text style transfer (TST) without parallel data has achieved some practical success. However, most of the existing unsupervised text style transfer methods suffer from (i) requiring massive amounts of nonparallel data to guide the transferring of different text styles. (ii) huge performance degradation when fine-tuning the model in new domains. In this work, we propose DAML-ST5, which consists of two parts, DAML and ST5. DAML is a domain adaptive meta-learning approach to refine  general knowledge in multi-heterogeneous source domains, which is capable of adapting to new unseen domains with a small amount data. Moreover, we propose a new  unsupervised TST model Style-T5 (ST5), which is composed of a sequence-to-sequence pre-trained language model T5 and uses style adversarial training for better content preservation and style transfer. Results on multi-domain datasets demonstrate that  our  approach  generalize well on unseen low-resource domains, achieving state of the art results against ten strong baselines.",/pdf/94729b15cb141aab28f2600cb78c6ffea59e60a0.pdf,,,,,anonymous|damlst5_low_resource_style_transfer_via_domain_adaptive_meta_learning,,,,,,,,,
133,1R5ZctTSwX-,Relation Extraction from Tables using Artificially Generated Metadata,['aclweb.org/ACL/ARR/2021/November/Paper46/Authors'],['Anonymous'],"Relation Extraction (RE) from tables is the task of identifying relations between pairs of columns of a table. Generally, RE models for this task require labelled tables for training. These labelled tables can also be generated artificially from a Knowledge Graph (KG), which makes the cost to acquire them much lower in comparison to manual annotations. However, unlike real tables, these synthetic tables lack associated metadata, such as, column-headers, captions, etc; this is because synthetic tables are created out of KGs that do not store such metadata. Meanwhile, previous works have shown that metadata is important for accurate RE from tables. To address this issue, we propose methods to artificially create some of this metadata for synthetic tables. Afterward, we experiment with a BERT-based model, in line with recently published works, that takes as input a combination of proposed artificial metadata and table content. Our empirical results show that this leads to improvements of 9\%-45\% in F1 score, in absolute terms, over 2 tabular datasets. ",/pdf/4562c9578704668dd9b73223abbb2caf02d4384a.pdf,,,,,anonymous|relation_extraction_from_tables_using_artificially_generated_metadata,,,,,,,,,
134,FzJk5alRVP,Do Current Natural Language Inference Models Truly Understand Sentences? Insights from Simple Sentences,['aclweb.org/ACL/ARR/2021/November/Paper1932/Authors'],['Anonymous'],"Natural language inference (NLI) is a task to infer the relationship between a premise and a hypothesis (e.g. entailment, neutral, or contradiction), and transformer-based models perform well on current NLI datasets such as MNLI and SNLI. Nevertheless, given the complexity of the task, especially the complexity of the sentences used for model evaluations, it remains controversial whether these models can truly infer the meaning of sentences or they simply guess the answer via non-humanlike heuristics. Here, we reduce the complexity of the task using two approaches. The first approach simplifies the relationship between the premise and hypothesis by making them unrelated. A test set, referred to as Random Pair, is constructed by randomly pairing premises and hypotheses in MNLI/SNLI. Models fine-tuned on MNLI/SNLI identify a large proportion (up to 77.6%) of these unrelated statements as being contradictory. Models fine-tuned on SICK, a dataset that included unrelated premise-hypothesis pairs, perform well on Random Pair. The second approach simplifies the task by constraining the premises/hypotheses to be syntactically/semantically simple sentences. A new test set, referred to as Simple Pair, is constructed using simple sentences, such as short SVO sentences, and basic conjunction sentences. We find that models fine-tuned on MNLI/SNLI generally fail to understand these simple sentences, but their performance can be boosted by re-fine-tuning the models using only a few hundreds of samples from SICK. All models tested here, however, fail to understand the fundamental compositional binding relation between a subject and a predicate (up to ~100% error rate) for basic conjunction sentences. Taken together, the results show that models achieving high accuracy on mainstream datasets can still lack basic sentence comprehension capacity, and datasets discouraging non-humanlike heuristics are required to build more robust NLI models.",/pdf/6097b705087b852f5a93b2291cf8afdee6cbba30.pdf,/attachment/888752de0afde57b44003e993c6ae615908d1cd0.zip,,,,anonymous|do_current_natural_language_inference_models_truly_understand_sentences_insights_from_simple_sentences,,,,,,/attachment/fd7b59d6668c7a1701668b14fefa2b88c1028696.zip,,,
135,BFPN7IxqXRv,Analyzing Gender Representation in Multilingual Models,['aclweb.org/ACL/ARR/2021/November/Paper2222/Authors'],['Anonymous'],"Multilingual language models were shown to allow for nontrivial transfer across scripts and languages. In this work, we study the structure of the internal representations that enable this transfer. We focus on the representations of gender distinctions as a practical case study, and examine the extent to which the gender concept is encoded in shared subspaces across different languages. Our analysis shows that gender representations consist of several prominent components that are shared across languages, alongside language-specific components. The existence of language-independent and language-specific components provides an explanation for an intriguing empirical observation we make: while gender classification transfers well across languages, bias mitigation interventions trained on a single language do not transfer easily to others. ",/pdf/12bf4447b0694248526f48da08fce1f47501e23d.pdf,,,,,anonymous|analyzing_gender_representation_in_multilingual_models,,,,,,,,,
136,WpQ4b4b_ENy,Improving Unsupervised Sentence Simplification Using Fine-Tuned Masked Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2493/Authors'],['Anonymous'],"Simple word suggestion in unsupervised sentence simplification (SS) methods is mostly done independently of the context. The idea of adapting and fine-tuning a context-aware model on simple data for improving performance has been discussed but not practiced. In this paper, we propose a framework involving fine-tuning a pre-trained BERT masked language model on simple English corpora to aid SS. Our analysis of public test data shows that fine-tuning on any set of simple sentences do not necessarily yield better simplifications but generally makes improvements. To tackle this issue, we propose a self-supervised framework which is composed of a labeling method that conducts an estimate about the \textit{usefulness} of each training sample, paired with a simple linear classifier that decides the inclusion of a given sentence in the fine-tuning process. The fine-tuned BERT will be used in an iterative edit-based unsupervised SS model to provide contextual word suggestions. The results show that our data selection approach can improve simplifications as much as having a simple-to-complex parallel corpus.",/pdf/a1d3d56fb363216a12fb546d899a9f0c7f1db72e.pdf,,,,,anonymous|improving_unsupervised_sentence_simplification_using_finetuned_masked_language_models,,,,,,,,,
137,Cr23m4deFPF,Towards Asking Clarification Questions in Task-Oriented Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper2934/Authors'],['Anonymous'],"Task-oriented dialogues aim at providing users with task-specific services. To provide satisfactory services, two major challenges exist: 1) users are not able to fully describe their complex needs due to lack of task knowledge, and; 2) systems need to personalize the service to their users since different users have different profiles and preferences. In order to solve these challenges, systems need to be able to ask questions so as to clarify the user's profile and needs. However, existing task-oriented dialogue systems ignore this aspect. In this paper, we formulate the problem of asking clarification questions in task-oriented dialogue systems. To this end, we propose a dialogue-based user simulator to collect a dataset, called TaskClariQ\footnote{To foster research in this area, the dataset and code will be made public upon paper’s acceptance.}. We further propose a new System Ask paradigm and a Multi-Attention Seq2Seq Networks (MAS2S) that implements it. Experimental results on TaskClariQ show that MAS2S outperforms competitive baselines. 
",/pdf/3648869beee502cd3672112dd45a009aa5b8c566.pdf,,,,,anonymous|towards_asking_clarification_questions_in_taskoriented_dialogue,,,,,,,,,
138,1mnGR8UW-7OO,Interpretability on clinical analysis from Pattern Disentanglement Insight,['aclweb.org/ACL/ARR/2021/November/Paper1843/Authors'],['Anonymous'],"Diagnosis of a clinical condition can help medical professionals save time in making a clinical diagnosis and prevent overlooking risks. Therefore we explore the problem using free-text medical notes recorded in electronic health records (EHR). MIMIC III is a de-identified EHR database containing observations from over 40,000 patients in critical care units. Since the text corpus is unstructured in the non-database table format, existing machine learning models may be ineffective at interpreting the results, which is often desirable for clinical diagnosis. Hence, in this paper, we proposed a text mining and pattern discovery solution to discover strong association patterns from patient discharge summaries and the code of international classification of diseases (ICD9-code). The proposed approach offers a straightforward interpretation of the underlying relation of patient characteristics in an unsupervised machine learning setting. The clustering results outperform the baseline clustering algorithm and are comparable to baseline supervised methods.",/pdf/fe3424fa86312d1ed93023b9f60cfd70985ff57b.pdf,,,,,anonymous|interpretability_on_clinical_analysis_from_pattern_disentanglement_insight,,,,,,,,,
139,qFV4ATfOE2C,Can Pre-trained Models Really Generate Single-Step Textual Entailment?,['aclweb.org/ACL/ARR/2021/November/Paper2896/Authors'],['Anonymous'],"We investigate the task of generating textual entailment (GTE). Different from prior works on recognizing textual entailment, also known as NLI, GTE requires the models with deeper reasoning capabilities - generating entailment from premises rather than making prediction on given premises and the entailment. We argue that existing adapted datasets are limited and inadequate to train and evaluate human-like reasoning in the GTE. In this paper, we propose a new large-scale benchmark, named \mydataset, targeted for learning and evaluating models' capabilities towards RTE. \mydataset consists of 15k instances with each containing a pair of premise statements and a human-annotated entailment. It is constructed by first retrieving instances from a knowledge base, and then augmenting each instance with several complementary instances by 7 manually crafted  transformations. We demonstrate that even extensively fine-tuned pre-trained
models perform poorly on \mydataset. The best generator models can only generate valid textual entailment 59.1\% of times. Further, to motivate future advances, we provide detailed analysis to show significant gaps between baselines and human performance.",/pdf/48dc5af73807589af1871e9c4e6df307ac58d0b0.pdf,,,,,anonymous|can_pretrained_models_really_generate_singlestep_textual_entailment,,,,,,,,,
140,ZKzFyhMUT8-,Adversarial multi-task learning to solve holistic semantic polishing problem of Chinese text,['aclweb.org/ACL/ARR/2021/November/Paper910/Authors'],['Anonymous'],"For the core obstacles faced by Chinese proofreading, we think that the effective holistic semantic feature representation of a sentence and its characteristics is a key. Here, we propose a novel adversarial multi-task learning framework to realize above point. Wherein, sentence scoring and word prediction tasks are considered as not only a group of multi-tasks, but also a couple of generative adversarial relationship. Moreover, a policy network is introduced to achieve text polishing based on above adversarial multi-task model and Monte Carlo search training strategy. The ablation experiment results on Xuexi and CLUE corpus show that, for text scoring and prediction tasks, adversarial multi-task learning achieves a 10-20% improvement in accuracy and F1-score compared to the baseline. And, in text correction task, our method is significantly better than the baselines.",/pdf/8b7ef6e6da772643474a998a5ddcc3366e386016.pdf,,,,,anonymous|adversarial_multitask_learning_to_solve_holistic_semantic_polishing_problem_of_chinese_text,,,,,,/attachment/a703c657464e6f7d4d6f9c6c1007c22a30f5ced0.zip,,,
141,Qb6XuSBODsW,Zero-shot Cross-lingual Conversational Semantic Role Labeling,['aclweb.org/ACL/ARR/2021/November/Paper457/Authors'],['Anonymous'],"While conversational semantic role labeling (CSRL) has shown its usefulness on Chinese conversational tasks, it is still under-explored in non-Chinese languages due to the lack of multilingual CSRL annotations for the parser training. To avoid expensive data collection and error-propagation of translation-based methods, we present a simple but effective approach to perform zero-shot cross-lingual CSRL. Our model implicitly learns language-agnostic, conversational structure-aware and semantically rich representations with the hierarchical encoders and elaborately designed pre-training objectives. Experimental results show that our cross-lingual model not only outperforms baselines by large margins but it is also robust to low-resource scenarios. More importantly, we confirm the usefulness of CSRL to English conversational tasks such as question-in-context rewriting and multi-turn dialogue response generation by incorporating the CSRL information into the downstream conversation-based models. We believe this finding is significant and will facilitate the research of English dialogue tasks which suffer the problems of ellipsis and anaphora.",/pdf/07ac5312f12ea514cbd69ff55a4bd0f2d53bf27f.pdf,,,,,anonymous|zeroshot_crosslingual_conversational_semantic_role_labeling,,,,,,,,,
142,ZaM7EsLb5X,SumHiS: Extractive Summarization Exploiting Hidden Sctructure,['aclweb.org/ACL/ARR/2021/November/Paper2828/Authors'],['Anonymous'],"Extractive summarization is a task of highlighting the most important parts of the text. We introduce a new approach to extractive summarization task using hidden clustering structure of the text. Experimental results on CNN/DailyMail demonstrate that our approach generates more accurate summaries than both extractive and abstractive methods, achieving state-of-the-art results in terms of ROUGE-2 metric exceeding the previous approaches by 10\%. Additionally, we show that hidden structure of the text could be interpreted as aspects.",/pdf/92f77957bc5b796cf352d5526f38caa3e8c1f824.pdf,,,,,anonymous|sumhis_extractive_summarization_exploiting_hidden_sctructure,,,,,,,,https://openreview.net/forum?id=dTwZya8uNnS,
143,_qM-i0O9A2_,"All in One: A Multi-Task Learning for Emoji, Sentiment and Emotion Analysis in Code-Mixed Text",['aclweb.org/ACL/ARR/2021/November/Paper2134/Authors'],['Anonymous'],"Code mixed language and emojis are being extensively used in social media to express opinions. In this paper, we propose a novel task that focuses on suggesting appropriate emojis in English-Hindi code-mixed sentences. We aim to exploit the dependency between emotion, sentiment, and emojis for building an end-to-end framework that can simultaneously identify the emotion, sentiment and emojis in code-mixed sentences. We introduce the Code-Mixed Emoji, Emotion and Sentiment aware Dataset (CMEESD) which is an extension of the SemEval 2020 Task 9. We establish strong baselines to predict the correct emojis by simultaneously identifying the emotion and sentiment of a given tweet. The sentiment and emotion prediction in turn helps for the appropriate emoji classification. Empirical results on the CMEESD dataset demonstrate that the proposed multi-task framework yields better performance over the single-task framework.",/pdf/d39eb6edcad75e59cd95a1bce2c975d803c7f64a.pdf,/attachment/57c69e4eef3b7e8a97976fce69785687efd50463.zip,,,,anonymous|all_in_one_a_multitask_learning_for_emoji_sentiment_and_emotion_analysis_in_codemixed_text,,,,,,/attachment/9f6ccc1dc862b923d0265a73007fe818552d388e.zip,,,
144,d0ECgzUIS3T,Towards Community-Driven NLP: Measuring Geographic Performance Disparities of Offensive Language Classifiers,['aclweb.org/ACL/ARR/2021/November/Paper1831/Authors'],['Anonymous'],"Text classifiers are applied at scale in the form of one-size-fits-all solutions. Nevertheless, many studies show that many classifiers are biased regarding different languages and dialects. Both language style and content change depending on the location that it is posted. For example, states that border Mexico may be more likely to discuss issues regarding immigration from Latin America. However, several questions remain, such as ``Do changes in the style and content of text across geographic regions impact model performance?''. We introduce a novel dataset called GeoOLID with more than 13 thousand examples across 15 geographically and demographically diverse cites to address this question. Furthermore, we perform a comprehensive analysis of geographical content and stylistic differences and their interaction in causing performance disparities of Offensive Language Detection models. Overall, we find that current models do not generalize across. Likewise, we show that understanding broad dialects (e.g., African American English) is not the only predictive factor of model performance when applied to cities with large minority populations. Hence, community-specific evaluation is vital for real-world applications. Warning: This paper contains offensive language.",/pdf/34e4169f8a5a6ac1205e4897b980218ad3eecd9f.pdf,,,,,anonymous|towards_communitydriven_nlp_measuring_geographic_performance_disparities_of_offensive_language_classifiers,,,,,,/attachment/442713f50bb208934076ce0bdc94b7e64ce5e6c7.zip,,,
145,Exljjx1lfcH,"HighIE: High-Order Inference for Entity Recognition, Relation Extraction, and Event Extraction",['aclweb.org/ACL/ARR/2021/November/Paper2824/Authors'],['Anonymous'],"Most prior work on Information Extraction typically predicts labels of individual instances (e.g., event triggers, relations, entities) independently regardless of their interactions. We propose a novel framework, HighIE, that aims to integrate high-order cross-subtask and cross-instance dependencies in both learning and inference. High-order inference on label variables is an NP-hard problem. To address it, we propose a high-order decoder that is unfolded from an approximate inference algorithm. The experimental results show that our approach achieves consistent improvement compared with prior work.",/pdf/cdd1b14e95ec64952099fd83e6559aa268b8893c.pdf,,,,,anonymous|highie_highorder_inference_for_entity_recognition_relation_extraction_and_event_extraction,,,,,,,,,
146,2pXdLthNwh2,An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels,['aclweb.org/ACL/ARR/2021/November/Paper1938/Authors'],['Anonymous'],"Pre-trained language models derive substantial linguistic and factual knowledge from the massive corpora on which they are trained, and prompt engineering seeks to align these models to specific tasks. Unfortunately, existing prompt engineering methods require significant amounts of labeled data, access to model parameters, or both. We introduce a new method for selecting prompt templates \textit{without labeled examples} and \textit{without direct access to the model}. Specifically, over a set of candidate templates, we choose the template that maximizes the mutual information between the input and the corresponding model output. Across 8 datasets representing 7 distinct NLP tasks, we show that when a template has high mutual information, it also has high accuracy on the task. On the largest model, selecting prompts with our method gets 90\% of the way from the average prompt accuracy to the best prompt accuracy and requires no ground truth labels.",/pdf/114dfa2ed22c82b1a41cb85164988d59064de6e1.pdf,/attachment/5ee8f2fb3da23a34b6ac4b2da88a290827c4db68.zip,,,,anonymous|an_informationtheoretic_approach_to_prompt_engineering_without_ground_truth_labels,,,,,,,,,
147,uELLijm1osF,"What Works and Doesn't Work, A Deep Decoder for Neural Machine Translation",['aclweb.org/ACL/ARR/2021/November/Paper1845/Authors'],['Anonymous'],"Deep learning has demonstrated performance advantages in a wide range of natural language processing tasks, including neural machine translation (NMT). Transformer NMT models are typically strengthened by deeper encoder layers, but deepening their decoder layers usually results in failure. In this paper, we first identify the cause of the failure of the deep decoder in the Transformer model. Inspired by this discovery, we then propose approaches to improving it, with respect to model structure and model training, to make the deep decoder practical in NMT. Specifically, with respect to model structure, we propose a cross-attention drop mechanism to allow the decoder layers to perform their own different roles, to reduce the difficulty of deep-decoder learning. For model training, we propose a collapse reducing training approach to improve the stability and effectiveness of deep-decoder training. We experimentally evaluated our proposed Transformer NMT model structure modification and novel training methods on several popular machine translation benchmarks. The results showed that deepening the NMT model by increasing the number of decoder layers successfully prevented the deepened decoder from degrading to an unconditional language model. In contrast to prior work on deepening an NMT model on the encoder, our method can deepen the model on both the encoder and decoder at the same time, resulting in a deeper model and improved performance.",/pdf/7720a3f36b18f8ae476d7addb9b4170c28ab5047.pdf,,,,,anonymous|what_works_and_doesnt_work_a_deep_decoder_for_neural_machine_translation,,,,,,,,,
148,vVoxEasyToY,More Informative Dialogue Generation via Multiple Knowledge Selection,['aclweb.org/ACL/ARR/2021/November/Paper943/Authors'],['Anonymous'],"Knowledge-grounded dialogue generation is a task of generating a fluent and informative response based on both dialogue context and a collection of external knowledge. There is a lot of noise in the knowledge pool, and appropriate knowledge selection plays an important role. Existing methods can only select one piece of knowledge to participate in the generation of the response, which inevitably loses some useful clues contained in the discarded candidates. In this work, we propose MSEL, a novel knowledge selector which could select multiple useful knowledge. MSEL takes the dialog context and knowledge pool as inputs and predicts a subset of knowledge pool in sequence-to-sequence manner. MSEL is easy to implement and can benefits from the generative pre-trained language models. Empirical results on the Wizard-of-Wikipedia dataset indicate that our model can significantly outperforms state-of-the-art approaches in both automatic and human evaluation.",/pdf/8606f60b1b7f5fba6c0c07e454e21d5d64812162.pdf,/attachment/2eac8ac7fd35c885f339b54f7f46325f65e461a1.zip,,,,anonymous|more_informative_dialogue_generation_via_multiple_knowledge_selection,,,,,,,,,
149,BgUXvB7hn1t,Unsupervised Domain Adaptation for Event Detection via Meta Self-Paced Learning,['aclweb.org/ACL/ARR/2021/November/Paper2106/Authors'],['Anonymous'],"As important events in textual data are usually highly specific in terms of tasks and domains, a change in data distribution would have a significant impact on detection performance. Recent methods addressing unsupervised domain adaptation for event detection task typically extracted domain-invariant representations through combining and balancing various objectives to align the feature space between source and target domains. While effective, these methods are impractical as large-scale language models are drastically growing bigger to achieve optimal performance. To this end, we propose Meta Self-Paced Domain Adaption framework (MSP-DA) that effectively and efficiently alleviates the need for domain-specific hyperparameter tuning. By imitating the train-test dataset split based on the difficulties of source domain's samples, the model is trained through a meta-learning process that learns to weigh the importance of each labeled instance and to balance every alignment objective, simultaneously. Extensive experiments demonstrate our framework substantially improves performance on target domains, surpassing state-of-the-art approaches. Furthermore, we present detailed analyses to validate our method and provide insight into how each domain affects the learned hyperparameters.",/pdf/9aa89b578da1a791e2690fafdcf09efe66008b27.pdf,,,,,anonymous|unsupervised_domain_adaptation_for_event_detection_via_meta_selfpaced_learning,,,,,,,,,
150,CPdvNQGrOr0,ST-SQL: Semi-Supervised Self-Training for Text-to-SQL via Column Specificity Meta-Learning,['aclweb.org/ACL/ARR/2021/November/Paper2733/Authors'],['Anonymous'],"The few-shot problem is an urgent challenge for the generalization capability of the single-table text-to-SQL task. Current few-shot methods neglect the potential information of unlabeled data and have a domain bias due to the same weight of samples. Motivated by this, this paper proposes a Self-Training text-to-SQL (ST-SQL) method which handles the problem from both views of data and algorithms. At the data level, ST-SQL performs data expansion by using an iterative framework to attach pseudo-labels to unlabeled data. The expanded data are sampled to reversely train the model. At the algorithm level, ST-SQL defines a column specificity to perform a more fine-grained gradient update during meta-training. The common samples are attached more weight to eliminate the domain bias. ST-SQL achieves state-of-the-art results on both open-domain and domain-specific benchmarks and brings more significant improvements on few-shot tests.",/pdf/7690015f02c9c7292e76587d98c792893f21f158.pdf,,,,,anonymous|stsql_semisupervised_selftraining_for_texttosql_via_column_specificity_metalearning,,,,,,,,,
151,1FvpjR6pZug,Continual Prompt Tuning for Dialog State Tracking,['aclweb.org/ACL/ARR/2021/November/Paper2121/Authors'],['Anonymous'],"A desirable dialog system should be able to continually learn new skills without forgetting old ones, and thereby adapt to new domains or tasks in its life cycle. However, continually training a model often leads to a well-known catastrophic forgetting issue. In this paper, we present Continual Prompt Tuning, a parameter-efficient framework that not only avoids forgetting but also enables knowledge transfer between tasks. To avoid forgetting, we only learn and store a few prompt tokens' embeddings for each task while freezing the backbone pre-trained model. To achieve bi-directional knowledge transfer among tasks, we propose several techniques (continual prompt initialization, query fusion, and memory replay) to transfer knowledge from preceding tasks and a memory-guided technique to transfer knowledge from subsequent tasks. Extensive experiments demonstrate the effectiveness and efficiency of our proposed method on continual learning for dialog state tracking, compared with state-of-the-art baselines.",/pdf/1542aca0b87da0e75a08d20296c7c836c114fc20.pdf,/attachment/c822ac39370ba310508ea76b3d1c5036748d9ef6.zip,,,,anonymous|continual_prompt_tuning_for_dialog_state_tracking,,,,,,,,,
152,_TLu-3ucBI,ARCNN: A Semantic Enhanced Relation Detection Model for Knowledge Base Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper454/Authors'],['Anonymous'],"Relation detection plays an important role in knowledge base question answering (KBQA), and it is critical for the final performance of KBQA systems. The previous works mainly focused on enriching the information representations of questions and relations, and neglected the interaction information of questions and relations and different tokens within the relation. In this paper, we propose a semantic enhanced relation detection model called ARCNN, which is carefully designed by combining BiGRU, multi-scale semantic extracted CNN, and different attention mechanisms in a seamless way. Moreover, we combine four levels of relation abstractions to ensure the integrity of relation information and hence to enrich the relation representation. The experimental results on two benchmarks show that our ARCNN model achieves new state-of-the-art accuracies of 96.42% for SimpleQuestions and 90.4% for WebQuestions. Moreover, it helps our KBQA system to yield the accuracy of 81.5% and the F1 score of 72.0% on two benchmarks, respectively. ",/pdf/ad23a9cbcb94d24bc44a12c7a62206ce68d95dea.pdf,/attachment/79969c84e1b799dde5621a1230a8cbda3c0de00e.zip,,,,anonymous|arcnn_a_semantic_enhanced_relation_detection_model_for_knowledge_base_question_answering,,,,,,/attachment/5cc8971cbb3d660bb13914bf692a665cdbb55d51.zip,,,
153,BaXUNv8-g9G,One-to-Many and Many-to-One Dialogue Learning via Sentence Semantic Segmentation Guided Conditional Variational Auto-Encoder,['aclweb.org/ACL/ARR/2021/November/Paper689/Authors'],['Anonymous'],"Due to the complex mapping relations, one-to-many and many-to-one phenomena are huge challenges for open-domain dialogue generation task, which tend to make dialogue models generate irrelevant, incoherent or non-diverse responses. Most existing methods avoid learning such phenomena through introducing the external information, reconstructing the optimization function or manipulating data samples. However, avoiding confronting such challenges ignores valuable information in these responses, and the dialogue models cannot learn the nature of such phenomena. In this paper, we propose a Sentence Semantic Segmentation guided Conditional Variational Auto-Encoder (SegCVAE) to directly learn one-to-many and many-to-one responses. SegCVAE uses prominent semantics to replace the original semantics to learn the distribution of latent variables, which avoids the gap between latent variables and the context, thus ensuring the relevance and coherence of the generated responses. Furthermore, SegCVAE can segment multiple prominent semantics to ensure the diversity of generated responses. To evaluate the model, we first define two new tasks named one-to-many dialogue learning task and many-to-one dialogue learning task. And then provide two new dialogue datasets named One-to-Many and Many-to-One, which are extracted from the well-established dataset. Finally, we also propose the evaluation strategies based on some commonly-used metrics. The experiment results show that our model achieve better performance than the baseline models in addressing these two new tasks.",/pdf/6001b9765ec2c8774a203847e1755c7187a73dd3.pdf,,,,,anonymous|onetomany_and_manytoone_dialogue_learning_via_sentence_semantic_segmentation_guided_conditional_variational_autoencoder,,,,,,,,,
154,R6wAUSO2fSr,Improving End-to-end Speech Translation by Leveraging Auxiliary Speech and Text Data,['aclweb.org/ACL/ARR/2021/November/Paper2272/Authors'],['Anonymous'],"We present a method for introducing a text encoder into pre-training end-to-end speech translation systems. It enhances the ability of adapting one modality (i.e., source-language speech) to another (i.e., source-language text). Thus, the speech translation model can learn from both unlabeled and labeled data, especially when the source-language text data is abundant. Beyond this, we present a denoising method for a robust text encoder that can deal with both normal and noisy text data. Our system sets new state-of-the-art on the MuST-C En-De, En-Fr, and LibriSpeech En-Fr tasks.",/pdf/75bfce70e8bb114d065f283789c3b10cf06a7d0c.pdf,/attachment/32cb84bf85b0238fd62a2a6d0f22c7662b86e0f2.zip,,,,anonymous|improving_endtoend_speech_translation_by_leveraging_auxiliary_speech_and_text_data,,,,,,,,,
155,QXlUtiZIARH,Improving Controllable Text Generation with Position-Aware Weighted Decoding,['aclweb.org/ACL/ARR/2021/November/Paper1794/Authors'],['Anonymous'],"Weighted decoding methods composed of the pretrained language model (LM) and the controller have achieved promising results for controllable text generation. However, these models often suffer from a control strength/fluency trade-off problem as higher control strength is more likely to generate incoherent and repetitive text. In this paper, we illustrate this trade-off is arisen by the controller imposing the target attribute on the LM at improper positions. And we propose a novel framework based on existing weighted decoding methods called CAT-PAW, which introduces a lightweight regulator to adjust bias signals from the controller at different decoding positions. Experiments on positive sentiment control, topic control, and language detoxification show the effectiveness of our CAT-PAW upon 4 SOTA models.",/pdf/cde2c2ed66e289818819b6e24b18ec49f075cfdb.pdf,,,,,anonymous|improving_controllable_text_generation_with_positionaware_weighted_decoding,,,,,,,,,
156,83XIAPSB_pj,Learning Functional Distributional Semantics with Visual Data,['aclweb.org/ACL/ARR/2021/November/Paper2614/Authors'],['Anonymous'],"Functional Distributional Semantics is a recently proposed framework for learning distributional semantics that provides linguistic interpretability. It models the meaning of a word as a binary classifier rather than a numerical vector. In this work, we propose a method to train a Functional Distributional Semantics model with grounded visual data. We train it on the Visual Genome dataset, which is closer to the kind of data encountered in human language acquisition than a large text corpus. On four external evaluation datasets, our model outperforms previous work on learning semantics from Visual Genome.",/pdf/a4c4e23d37ba1d2da850642260248eecb6828666.pdf,,,,,anonymous|learning_functional_distributional_semantics_with_visual_data,,,,,,,/attachment/a969795fe7473f0ed1a4b59b906bea11f0446e29.pdf,https://openreview.net/forum?id=HJSSYU3swSj,/attachment/e4916cd73671e31041f813f887cce6c6ebc21248.pdf
157,_jpxhquKzO9,Roles of Words: What Should (n’t) Be Augmented in Text Augmentation on Text Classification Tasks?,['aclweb.org/ACL/ARR/2021/November/Paper536/Authors'],['Anonymous'],"Text augmentation techniques are widely used in text classification problems to improve the performance of classifiers, especially in low-resource scenarios. Previous text-editing-based methods augment the text in a non-selective manner: the words in the text are treated without difference during augmentation, which may result in unsatisfactory augmented samples. In this work, we present four kinds of roles of words (ROWs) which have different functions in text classification tasks, and design effective methods to automatically extract these ROWs based on statistical and semantic perspectives. Systematic experiments are conducted on what ROWs should (n't) be augmented during augmentation for classification tasks. Based on these experiments, we discover some interesting and instructive potential patterns that certain ROWs are especially suitable or unsuitable for certain augmentation operations. Guided by these patterns, we propose a set of Selective Text Augmentation (STA) operations, which significantly outperform traditional methods and show outstanding generalization performance. ",/pdf/04e5d984ba091bdefb5d7556d11234ad1bb8b5e5.pdf,/attachment/2bbb885788962347fd6166328cc0875cd67546f4.zip,,,,anonymous|roles_of_words_what_should_nt_be_augmented_in_text_augmentation_on_text_classification_tasks,,,,,,/attachment/6643283e96e74665bed0ac5da39439b582a6aa5a.zip,,,
158,mZ_MHVvOwry,Comprehensive Multi-Modal Interactions for Referring Image Segmentation,['aclweb.org/ACL/ARR/2021/November/Paper364/Authors'],['Anonymous'],"We investigate Referring Image Segmentation (RIS), which outputs a segmentation map corresponding to the natural language description. Addressing RIS efficiently requires considering the interactions happening across visual and linguistic modalities and the interactions within each modality. Existing methods are limited because they either compute different forms of interactions sequentially (leading to error propagation) or ignore intra-modal interactions. We address this limitation by performing all three interactions simultaneously through a Synchronous Multi-Modal Fusion Module (SFM). Moreover, to produce refined segmentation masks, we propose a novel Hierarchical Cross-Modal Aggregation Module (HCAM), where linguistic features facilitate the exchange of contextual information across the visual hierarchy. We present thorough ablation studies and validate our approach's performance on four benchmark datasets, showing considerable performance gains over the existing state-of-the-art (SOTA) methods.",/pdf/76d44312ce5672bc2d2dad421c2c250beac3ff04.pdf,/attachment/3b79302e0bdc3513342471c79a92afcbc9a0a566.zip,,,,anonymous|comprehensive_multimodal_interactions_for_referring_image_segmentation,,,,,,,,,
159,AYXloseLOi,AdapLeR: Speeding up Inference by Adaptive Length Reduction,['aclweb.org/ACL/ARR/2021/November/Paper2874/Authors'],['Anonymous'],"Pre-trained language models have shown stellar performance in various downstream tasks. But, this usually comes at the cost of high latency and computation, hindering their usage in resource-limited settings. In this work, we propose a novel approach for reducing the computational cost of BERT with minimal loss in downstream performance. Our model dynamically eliminates less contributing tokens through layers, resulting in shorter lengths and consequently lower computational cost. To determine the importance of each token representation, we train a Contribution Predictor for each layer using a gradient-based saliency method. Our experiments on several diverse classification tasks show speedups up to 17x during inference time. We also validate the quality of the selected tokens in our method using human annotations in the ERASER benchmark. In comparison to other widely used strategies for selecting important tokens, such as saliency and attention, our proposed method has significantly less false positive rate in generating rationales.",/pdf/7c8657980deacf447a4a44639d77a43da5083fda.pdf,/attachment/42db9997449cda1f2ccad0b8438aa31194ce1066.zip,,,,anonymous|adapler_speeding_up_inference_by_adaptive_length_reduction,,,,,,,,,
160,UqO_3RE6E7x,Toward More Meaningful Resources for Lower-resourced Languages,['aclweb.org/ACL/ARR/2021/November/Paper2924/Authors'],['Anonymous'],"In this paper, we describe our perspective on how meaningful resources for lower-resourced languages can be developed in connection with the speakers of those languages. We examine two massively multilingual resources in detail. We explore the contents of the names stored in Wikidata for a few lower-resourced languages and find that many of them are not in fact in the languages they claim to be and require non-trivial effort to correct. We discuss quality issues present in WikiAnn and evaluate whether it is a useful supplement to hand annotated data. We then discuss the importance of creating annotation for lower-resourced languages in a thoughtful and ethical way that includes the languages' speakers as part of the development process. We conclude with recommended guidelines for resource development.",/pdf/9dda32ba40fd2dab32f543a65cb1a4c338c4ac8f.pdf,,,,,anonymous|toward_more_meaningful_resources_for_lowerresourced_languages,,,,,,,,,
161,NOTubDYTfjQ,End-To-End Sign Language Translation via Multitask Learning,['aclweb.org/ACL/ARR/2021/November/Paper2056/Authors'],['Anonymous'],"Sign language translation (SLT) is usually seen as a two-step process of continuous sign language recognition (CSLR) and gloss-to-text translation. We propose a novel, Transformer-based architecture to jointly perform CSLR and sign-translation in an end-to-end fashion. We extend the ordinary Transformer decoder with two channels to support multitasking, where each channel is devoted to solve a particular problem. To control the memory footprint of our model, channels are designed to share most of their parameters among each other. However, each channel still has a dedicated set of parameters which is fine-tuned with respect to the channel's task. In order to evaluate the proposed architecture, we focus on translating German signs into English sequences and use the RWTH-PHOENIX-Weather 2014 T corpus in our experiments. Evaluation results indicate that the mixture of information provided by the multitask decoder was successful and enabled us to achieve superior performance in comparison to other SLT models. ",/pdf/56f17da25910bb4ae03fe395fbbde1e1aa646761.pdf,/attachment/fa3f81c1d57c5b5c1401a132ab611f1995ccbae3.zip,,,,anonymous|endtoend_sign_language_translation_via_multitask_learning,,,,,,,,,
162,Fx7vTiX9Wae,Rethinking and Refining the Distinct Metric,['aclweb.org/ACL/ARR/2021/November/Paper2269/Authors'],['Anonymous'],"Distinct is a widely used automatic metric for evaluating the diversity of language generation tasks.
However, we observe that the original approach to calculating distinct scores has evident biases that tend to add higher penalties to longer sequences. In this paper, we refine the calculation of distinct scores by re-scaling the number of distinct tokens based on its expectation. We provide both empirical and theoretical evidence to show that our method effectively removes the biases exhibited in the original distinct score. Further analyses also demonstrate that the refined score correlates better with human evaluations.",/pdf/2e102cd44ba76918234b1229c31be26a28aff7a9.pdf,,,,,anonymous|rethinking_and_refining_the_distinct_metric,,,,,,,,,
163,nu1dPURGSOi,Tracking Satisfaction States for Customer Satisfaction Prediction in E-commerce Service Chatbots,['aclweb.org/ACL/ARR/2021/November/Paper1899/Authors'],['Anonymous'],"Due to the increasing use of service chatbots in E-commerce platforms in recent years, customer satisfaction prediction (CSP) is gaining more and more attention. CSP is dedicated to evaluating subjective customer satisfaction in conversational service and thus helps improve customer service experience. However, previous methods focus on modeling customer-chatbot interaction at different single turns, neglecting the important dynamic satisfaction states throughout the customer journey. In this work, we investigate the problem of satisfaction states tracking and its effects on CSP in E-commerce service chatbots. To this end, we propose a dialogue-level classification model named DialogueCSP to track satisfaction states for CSP. In particular, we explore a novel two-step interaction module to represent the dynamic satisfaction states at each turn. In order to capture dialogue-level satisfaction states for CSP, we further introduce dialogue-aware attentions to integrate historical informative cues into the interaction module. To evaluate the proposed approach, we also build a Chinese E-commerce dataset for CSP. Experiment results demonstrate that our model significantly outperforms multiple baselines, illustrating the benefits of satisfaction states tracking on CSP.",/pdf/6f892ba924fc07c72743200ef608da4901f245ad.pdf,,,,,anonymous|tracking_satisfaction_states_for_customer_satisfaction_prediction_in_ecommerce_service_chatbots,,,,,,,,,
164,t0YZGag-6fe,A Zero-Resource Approach to Cross-Lingual Query-Focused Abstractive Summarization,['aclweb.org/ACL/ARR/2021/November/Paper1859/Authors'],['Anonymous'],"We present a novel approach for cross-lingual query-focused abstractive summarization (QFAS) that leverages the translate-then-summarize paradigm. We approach cross-lingual QFAS as a zero-resource problem and introduce a framework to create a synthetic QFAS corpus from a standard summarization corpus using a novel query-generation strategy. Our model summarizes documents in foreign languages for which translation quality is poor. It learns not only to identify and condense salient information relevant to a query, but also to appropriately rephrase grammatical errors and disfluencies that may occur in the noisy translations. Our technique enhances a pre-trained encoder-decoder transformer by introducing query focus to the encoder.  We show that our method for creating synthetic QFAS data leads to more robust models that not only achieve state-of-the-art performance on our corpus, but also perform better on out-of-distribution data as compared to prior work.",/pdf/ac0f753d180fc6bf0f73e4031d062efdb7b967a9.pdf,,,,,anonymous|a_zeroresource_approach_to_crosslingual_queryfocused_abstractive_summarization,,,,,,,,,
165,z8yUOveEGqa,Situated Dialogue Learning through Procedural Environment Generation,['aclweb.org/ACL/ARR/2021/November/Paper735/Authors'],['Anonymous'],"We teach goal-driven agents to interactively act and speak in situated environments by training on generated curriculums. Our agents operate in LIGHT (Urbanek et al. 2019)---a large-scale crowd-sourced fantasy text adventure game wherein an agent perceives and interacts with the world through textual natural language. Goals in this environment take the form of character-based quests, consisting of personas and motivations. We augment LIGHT by learning to procedurally generate additional novel textual worlds and quests to create a curriculum of steadily increasing difficulty for training agents to achieve such goals. In particular, we measure curriculum difficulty in terms of the rarity of the quest in the original training distribution---an easier environment is one that is more likely to have been found in the unaugmented dataset. An ablation study shows that this method of learning from the tail of a distribution results in significantly higher generalization abilities as measured by zero-shot performance on never-before-seen quests.",/pdf/cea59ea6083a2f72371642e5a07946de65648e61.pdf,,,,,anonymous|situated_dialogue_learning_through_procedural_environment_generation,,,,,,,,,
166,5eHlYiVukG,Get the Point! Graph Enhanced Candidate Retrieval for Zero-shot Entity Linking,['aclweb.org/ACL/ARR/2021/November/Paper2787/Authors'],['Anonymous'],"For the retrieval phase of the zero-shot entity linking task, BERT has been widely used to represent the mentions and entities with the sentence embeddings. However, the sentence embeddings obtained by BERT are dominated by the high-frequency words in the pre-training corpus, thus performing poorly especially when the mention/entity is a low-frequency word. To solve this issue, we propose a Graph enhanced Entity Retrieval (GER) framework, fusing word-level embedding with the sentence embedding from BERT.
Specifically, we construct a mention/entity centralized graph and design a Hierarchical Graph Neural Network (HGNN) to capture the word-level information. Experimental results on the ZESHEL dataset demonstrate that our proposal achieves a recall@64 of 84.72\%, a 2.66 points improvement compared to previous best results.",/pdf/6e3a72e51e469701d33952a903cd5e14f7bbe1b4.pdf,,,,,anonymous|get_the_point_graph_enhanced_candidate_retrieval_for_zeroshot_entity_linking,,,,,,/attachment/3f4b2033d8b3b86dad4b47eada4023f0719148f9.zip,,,
167,nXyXgrVOk8k,Stock Movement Prediction Based on Bi-typed and Hybrid-relational Market Knowledge Graph via Dual Attention Networks,['aclweb.org/ACL/ARR/2021/November/Paper562/Authors'],['Anonymous'],"Stock Movement Prediction (SMP) aims at predicting listed company's stock future price trend, which is a challenging task due to the volatile nature of financial markets. Recent financial studies show that the momentum spillover effect plays a significant role in stock fluctuation. However, previous studies typically only learn the simple connection information among related companies, which inevitably fail to model complex relations of listed companies in real financial market. To address this issue, we first construct a more comprehensive Market Knowledge Graph (MKG) which contains bi-typed entities including listed companies and their associated executives, and hybrid-relations including the explicit relations and implicit relation. Afterward, we propose \textsc{DanSmp}, a novel Dual Attention Networks to learn the momentum spillover signals based upon the constructed MKG for stock prediction. The empirical experiments on our constructed datasets against nine SOTA baselines demonstrate that the proposed \textsc{DanSmp} is capable of improving stock prediction with the constructed MKG. ",/pdf/74b94a18d5e5fd0e78ee7d9d5e003a6d3f052905.pdf,/attachment/e71b902decbec18b10d7fc37be29195084261a93.zip,,,,anonymous|stock_movement_prediction_based_on_bityped_and_hybridrelational_market_knowledge_graph_via_dual_attention_networks,,,,,,/attachment/192a7fc1269bc1a20be261b04b6b130595f3ee8c.zip,,,
168,8njdjhMeRJY,Understanding Multimodal Procedural Knowledge by Sequencing Multimodal Instructional Manuals,['aclweb.org/ACL/ARR/2021/November/Paper1055/Authors'],['Anonymous'],"The ability to sequence unordered events is evidence of comprehension and reasoning about real world tasks/procedures, and is essential for applications such as task planning and multi-source instruction summarization.
It often requires thorough understanding of temporal common sense and multimodal information, since these procedures are often conveyed by a combination of texts and images.
While humans are capable of reasoning about and sequencing unordered procedural instructions, the extent to which the current machine learning methods possess such a capability is still an open question.
In this work, we benchmark models' capability of reasoning over and sequencing unordered multimodal instructions by curating datasets from online instructional manuals and collecting comprehensive human annotations.
We find current state-of-the-art models not only perform significantly worse than humans but also seem incapable of efficiently utilizing  multimodal information.
To improve machines' performance on multimodal event sequencing, we propose sequence-aware pretraining techniques exploiting the sequential alignment properties of both texts and images, resulting in > 5% improvements on perfect match ratio.",/pdf/b9248a5f8864bea65773ff9af051b5c41e491802.pdf,/attachment/be355b35194bf921400324c763273d50a8329f2f.zip,,,,anonymous|understanding_multimodal_procedural_knowledge_by_sequencing_multimodal_instructional_manuals,,,,,,,,,
169,3VsqNuliPR,Learning Tokenization in Private Federated Learning with Sub-Word Model Sampling,['aclweb.org/ACL/ARR/2021/November/Paper1520/Authors'],['Anonymous'],"Federated learning with differential privacy, i.e. private federated learning (PFL), makes it possible to train models on private data distributed across users' devices without harming privacy.  However, it is only known how to do this for models, such as neural networks, that have a fixed number of parameters, and thus a fixed-dimensional gradient vector. Such models include neural-net language models, but not n-gram language models or, indeed, tokenizers, the topic of this work. Training a tokenizer normally requires access to the training data. An alternative is to train the tokenizer on publicly available data, but this, we show, degrades accuracy for a next-word prediction task by 10-20% across different datasets and models. We propose to take a tokenizer built on public data, use it to train a language model with PFL, and sample from the language model to find a new tokenizer. Retraining with the new tokenizer brings performance to within 2\,\% of the oracle tokenizer, without expending additional privacy budget. Finally, we build a new federated pipeline to update the tokenizer during model training by modifying affected model embeddings.",/pdf/f2cbbeb5639d558216a71003edc79a93f7a988ff.pdf,,,,,anonymous|learning_tokenization_in_private_federated_learning_with_subword_model_sampling,,,,,,,,,
170,t4RMD0mI_k,Sentence-aware Contrastive Learning for Open-Domain Passage Retrieval,['aclweb.org/ACL/ARR/2021/November/Paper564/Authors'],['Anonymous'],"Training dense passage representations via contrastive learning has been shown effective for Open-Domain Passage Retrieval (ODPR). Existing studies focus on further optimizing by improving negative sampling strategy or extra pretraining. However, these studies keep unknown in capturing passage with internal representation conflicts from improper modeling granularity. This work thus presents a refined model on the basis of a smaller granularity, contextual sentences, to alleviate the concerned conflicts. In detail, we introduce an in-passage negative sampling strategy to encourage a diverse generation of sentence representations within the same passage. Experiments on three benchmark datasets verify the efficacy of our method, especially on datasets where conflicts are severe. Extensive experiments further present good transferability of our method across datasets.",/pdf/0628a9eb5562ab4611e217853272eea908492179.pdf,,,,,anonymous|sentenceaware_contrastive_learning_for_opendomain_passage_retrieval,,,,,,,,,
171,DW8WNS97jP5,The Past Mistake is the Future Wisdom: Error-driven Contrastive Probability Optimization for Chinese Spell Checking,['aclweb.org/ACL/ARR/2021/November/Paper2375/Authors'],['Anonymous'],"Chinese Spell Checking (CSC) aims to detect and correct Chinese spelling errors, which are mainly caused by the phonological or visual similarity. Recently, pre-trained language models (PLMs) promote the progress of CSC task. However, there exists a gap between the learned knowledge of PLMs and the goal of CSC task. PLMs focus on the semantics in text and tend to correct the erroneous characters to semantically proper or commonly used ones, but these aren't the ground-truth corrections. To address this issue, we propose an Error-driven COntrastive Probability Optimization (ECOPO) framework for CSC task. ECOPO refines the knowledge representations of PLMs, and guides the model to avoid predicting these common characters through an error-driven way. Particularly, ECOPO is model-agnostic and it can be combined with existing CSC methods to achieve better performance. Extensive experiments and detailed analyses on SIGHAN datasets demonstrate that ECOPO is simple yet effective.",/pdf/c1b57abdcc654d93a2addd4a8df666986855bef4.pdf,/attachment/c88c65194e4a6d052db74ee2b8062ba46abd9fa6.zip,,,,anonymous|the_past_mistake_is_the_future_wisdom_errordriven_contrastive_probability_optimization_for_chinese_spell_checking,,,,,,/attachment/81b8d3ac7573ae8548687b9907c75d4e4d36fc58.zip,/attachment/38fc48d013e40dcf9e17e91c74008120d49392d9.pdf,https://openreview.net/forum?id=cEA-p49sP8x,/attachment/b61c1965f53c48b98ec96229b54fa22389f7a4df.pdf
172,poQNS7GAgBJ,Fine-Grained Controllable Text Generation Using Non-Residual Prompting,['aclweb.org/ACL/ARR/2021/November/Paper1415/Authors'],['Anonymous'],"The introduction of immensely large Causal Language Models (CLMs) has rejuvenated the interest in open-ended text generation. However, controlling the generative process for these Transformer-based models is at large an unsolved problem. Earlier work has explored either plug-and-play decoding strategies, or more powerful but blunt approaches such as prompting. There hence currently exists a trade-off between fine-grained control, and the capability for more expressive high-level instructions. To alleviate this trade-off, we propose an encoder-decoder architecture that enables intermediate text prompts at arbitrary time steps. We propose a resource-efficient method for converting a pre-trained CLM into this architecture, and demonstrate its potential on various experiments, including the novel task of contextualized word inclusion. Our method provides strong results on multiple experimental settings, proving itself to be both expressive and versatile.",/pdf/4d50b6ddd014d2c7f62359526a400646af2b2702.pdf,,,,,anonymous|finegrained_controllable_text_generation_using_nonresidual_prompting,,,,,,,,,
173,csNgXsD1tx,,,,,,,,,,,,,,,,,,,
174,avbPntXOwCW,Building Chinese Biomedical Language Models via Multi-Level Text Discrimination,['aclweb.org/ACL/ARR/2021/November/Paper1182/Authors'],['Anonymous'],"Pre-trained language models (PLMs), such as BERT and GPT, have revolutionized the field of NLP, not only in the general domain but also in the biomedical domain. Most prior efforts in building biomedical PLMs have resorted simply to domain adaptation and focused mainly on English. In this work we introduce eHealth, a Chinese biomedical PLM built from scratch with a new pre-training framework. This new framework pre-trains eHealth as a discriminator through both token- and sequence-level discrimination. The former is to detect input tokens corrupted by a generator and recover their original identities from plausible candidates, while the latter is to further distinguish corruptions of a same original sequence from those of others. As such, eHealth can learn language semantics at both token and sequence levels. Extensive experiments on 11 Chinese biomedical language understanding tasks of various forms verify the effectiveness and superiority of our approach. We release the pre-trained model to the public,\footnote{\url{Anonymous URL}} and will also release the code later.",/pdf/c305df6be6085df028f72afc8c241523956fb865.pdf,,,,,anonymous|building_chinese_biomedical_language_models_via_multilevel_text_discrimination,,,,,,,,,
175,IvllkwwgKc4,SiSP: Japanese Situation-dependent Sentiment Polarity Dictionary,['aclweb.org/ACL/ARR/2021/November/Paper1713/Authors'],['Anonymous'],"In order to deal with the variety of meanings and contexts of words, we created a Japanese Situation-dependent Sentiment Polarity Dictionary (SiSP) of sentiment values labeled for 20 different situations. This dictionary was annotated by crowdworkers with 25,520 Japanese words, and consists of 10 responses for each situation of each word. Using our SiSP, we predicted the polarity of each word in the dictionary and that of dictionary words in sentences considering the context. In both experiments, situation-dependent prediction showed superior results in determining emotional polarity.",/pdf/ff19cf41cfd392fb004544b8f762bfd063de63b6.pdf,,,,,anonymous|sisp_japanese_situationdependent_sentiment_polarity_dictionary,,,,,,,,,
176,NtU4muk0bvd,Automatic Mining of Salient Events from Multiple Documents,['aclweb.org/ACL/ARR/2021/November/Paper2887/Authors'],['Anonymous'],"This paper studies a new event knowledge extraction task, Event Chain Mining. Given multiple documents on a super event, it aims to mine a series of salient events in a temporal order. For example, the event chain of super event Mexico Earthquake in 2017 is {earthquake hit Mexico, destroy houses, kill people, block roads}. This task can help readers capture the gist of texts quickly, thereby improving reading efficiency and deepening text comprehension. To address this task, we regard an event as a cluster of different mentions of similar meanings. In this way, we can identify the different expressions of events, enrich their semantic knowledge and enhance order information among them. Taking events as the basic unit, we propose a novel and flexible unsupervised framework, EMiner. Specifically, we extract event mentions from texts and merge those of similar meanings into a cluster as an event. Then, essential events are selected and arranged into a chain in the order of their occurrences. We then develop a testbed for the proposed task, including a human-annotated benchmark and comprehensive evaluation metrics. Extensive experiments are conducted to verify the effectiveness of EMiner in terms of both automatic and human evaluations.",/pdf/b6f86e48ed2e8f3e162cdae98739ba9b05c6d82b.pdf,,,,,anonymous|automatic_mining_of_salient_events_from_multiple_documents,,,,,,,,,
177,oyCPRgwkf5w,Do We Need to Differentiate Negative Candidates Before Training a Neural Ranker?,['aclweb.org/ACL/ARR/2021/November/Paper1621/Authors'],['Anonymous'],"Retrieval-based Question Answering (ReQA) requires a system to find candidates (e.g., sentences or short passages) containing the answer to a given question from a large corpus. A promising way to solve this task is a two-stage pipeline, where the first stage retrieves a set of candidates, and the second stage uses a neural network to rank the retrieved candidates. There are three standard methods to train neural rankers, Binary Cross-Entropy loss, Mean Square Error loss, and Hinge loss. While all these training strategies assign the same label for all the negative candidates, we argue that negativeness is not binary but exists as a spectrum, i.e., some candidates may be more negative than the others, and thus should be treated differently. We present SCONER---scoring negative candidates before training neural ranker---a model trained to differentiate negative candidates. Our approach includes 1) semantic textual similarity-based scoring together with data augmentation for score generation of negative candidates, and 2) a neural ranker trained on data using generated scores as labels. Together, we systematically compare three standard training methods and our proposed method on a range of ReQA datasets under multiple settings (i.e., single-domain and multi-domain). Our finding suggests that using more negative candidates to train neural rankers are better than less in both single- and multi-domain settings, where SCONER is the best in the single-domain settings and Hinge loss is the best in multi-domain settings. ",/pdf/7e798c12ea301b2cdd63dbbfc6b746bce42ffa8c.pdf,,,,,anonymous|do_we_need_to_differentiate_negative_candidates_before_training_a_neural_ranker,,,,,,,,,
178,i-lLDEfPRnG,A Self-Adaptive Learning Rate and Curriculum Learning Based Framework for Few-Shot Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper2177/Authors'],['Anonymous'],"Due to the lack of labeled data in many realistic scenarios, a number of few-shot learning methods for text classification have been proposed, among which the meta learning based ones have recently attracted much attention. Such methods usually consist of a learner as the classifier and a meta learner for specializing the learner to tasks. For the learner, learning rate is crucial to its performance. However, existing methods treat it as a hyper parameter and adjust it manually, which is time-consuming and laborious. Intuitively, for different tasks and neural network layers, the learning rates should be different and self-adaptive. For the meta learner, it requires a good generalization ability so as to quickly adapt to new tasks. Therefore, we propose a novel meta learning framework, called MetaCLSLR, for few-shot text classification. Specifically, we present a novel meta learning mechanism to obtain different learning rates for different tasks and neural network layers so as to enable the learner to quickly adapt to new training data. Moreover, we propose a task-oriented curriculum learning mechanism to help the meta learner achieve a better generalization ability by learning from different tasks with increasing difficulties. Extensive experiments on three benchmark datasets demonstrate the effectiveness of MetaCLSLR.",/pdf/233be95fe60fe8057aa85a5b8d660871c5e154bf.pdf,,,,,anonymous|a_selfadaptive_learning_rate_and_curriculum_learning_based_framework_for_fewshot_text_classification,,,,,,,,,
179,9AWwcpDj9fV,An asynchronous distributed training algorithm based on Gossip,['aclweb.org/ACL/ARR/2021/November/Paper185/Authors'],['Anonymous'],"Distributed training is widely used in deep learning, and distributed method is divided into centralized and decentralized. Centralized distributed clusters, such as Parameter Server (PS), have been widely used nowadays. The main problems of PS are the communication bottleneck and the security problem of the central node. For example, Horovod framework based on Ring AllReduce algorithm, one of the existing decentralized distributed clusters, can reduce the bottleneck of the central node communication. However, the framework is not completely decentralized, and the communication algorithm is synchronous, which will lead to longer communication waiting time inter-node in the cluster. Combined the Gossip protocol with Stochastic Gradient Descent (SGD), this paper proposes a communication framework Gossip Ring SGD (GR-SGD) for deep learning. GR-SGD is decentralized and asynchronous, and solves the problem of long communication waiting time. This paper uses the ImageNet data set and the ResNet model to verify the feasibility of the algorithm and compares it with Ring AllReduce and D-PSGD. Moreover, this paper also indicates that some data redundancy can reduce communication overhead and increase system fault tolerance.",/pdf/8df361424bfd3d66a82b294dcbe9a5e6803daa4a.pdf,,,,,anonymous|an_asynchronous_distributed_training_algorithm_based_on_gossip,,,,,,,,,
180,QTSlG9lWk8,Improving Compositional Generalization with Self-Training for Data-to-Text Generation,['aclweb.org/ACL/ARR/2021/November/Paper1944/Authors'],['Anonymous'],"Data-to-text generation focuses on generating fluent natural language responses from structured meaning representations (MRs). Such representations are compositional and it is costly to collect responses for all possible combinations of atomic meaning schemata, thereby necessitating few-shot generalization to novel MRs. In this work, we systematically study the compositional generalization of the state-of-the-art T5 models in few-shot data-to-text tasks. We show that T5 models fail to generalize to unseen MRs, and we propose a template-based input representation that considerably improves the model's generalization capability. To further improve the model's performance, we propose an approach based on self-training using fine-tuned BLEURT for pseudo-response selection. On the commonly-used SGD and Weather benchmarks, the proposed self-training approach improves tree accuracy by $46\%+$ and reduces the slot error rates by $73\%+$ over the strong T5 baselines in few-shot settings.",/pdf/a14c0d46ee2d99ad8428d45d009e605d1ef66610.pdf,,,,,anonymous|improving_compositional_generalization_with_selftraining_for_datatotext_generation,,,,,,,,,
181,OKvn1-qwsWA,Computational historical linguistics and language diversity in South Asia,['aclweb.org/ACL/ARR/2021/November/Paper1991/Authors'],['Anonymous'],"South Asia is home to a plethora of languages, most of which are severely lacking access to language technologies that have been developed with the maturity of NLP/CL. This linguistic diversity, however, also results in a research environment conducive to the study of comparative, contact, and historical linguistics---fields which necessitate the gathering of extensive data from many languages. We claim that data scatteredness (rather than scarcity) is the primary obstacle in the development of South Asian language technology, and suggest that the study of language history is uniquely aligned with surmounting this obstacle. We review recent developments in, and the intersection of, South Asian NLP and historical--comparative linguistics, explaining our current efforts in this area while also offering new paths towards breaking the data barrier.",/pdf/eae784086e6adc1199ecfdf30809d3634c51e0e2.pdf,,,,,anonymous|computational_historical_linguistics_and_language_diversity_in_south_asia,,,,,,,,,
182,RmFZIQVG4XN,Models can use keywords to answer questions that human cannot,['aclweb.org/ACL/ARR/2021/November/Paper2615/Authors'],['Anonymous'],"Recent studies raised that reading comprehension (RC) models learn to exploit biases and annotation artifacts in current Machine Reading Comprehension (MRC) datasets to achieve impressive performance. This hinders the community from measuring sophisticated understanding of RC systems. MRC questions whose answers can be rightly predicted without understanding their contexts are defined as biased ones. Previous researches aimed to split unintended biases and determine their influence have some limitations. Some methods using partial test data to extract biases lack holistic consideration with question-context-option tuple. Others relied on artificial statistical features are limited by question types. 
In this paper, we employ two simple heuristics to identify biased questions in current MRC datasets through human-annotated keywords. We implement three neural networks on the biased data and find that they have outstanding abilities to capture the biases, and further study the superficial features of the biased data exploited by models as shortcuts in views of lexical choice and paragraphs. Experiments show that (i) models can answer some questions merely using several keywords which are unanswerable or difficulty for human. (ii) lexical choice preference in options creates biases utilized by models. (iii) fewer paragraphs are more likely to introduce biases in MRC datasets.
",/pdf/6774b7d67ba273c9bf8fe7560520721008da0c93.pdf,,,,,anonymous|models_can_use_keywords_to_answer_questions_that_human_cannot,,,,,,/attachment/4c0cee93dee820cc446488f9aa94a784239bb286.zip,,,
183,dTE4YtueHaD,LINDA: Unsupervised Learning to Interpolate in Natural Language Processing,['aclweb.org/ACL/ARR/2021/November/Paper2263/Authors'],['Anonymous'],"Despite the success of mixup in data augmentation, its applicability to natural language processing (NLP) tasks has been limited due to the discrete and variable-length nature of natural languages. Recent studies have thus relied on domain-specific heuristics and manually crafted resources, such as dictionaries, in order to apply mixup in NLP. In this paper, we instead propose an unsupervised learning approach to text interpolation for the purpose of data augmentation, to which we refer as 'Learning to INterpolate for Data Augmentation' (LINDA), that does not require any heuristics nor manually crafted resources but learns to interpolate between any pair of natural language sentences over a natural language manifold. After empirically demonstrating the LINDA's interpolation capability, we show that LINDA indeed allows us to seamlessly apply mixup in NLP and leads to better generalization in text classification both in-domain and out-of-domain.",/pdf/98ccf7bd66a341d552785da9e18ba87af1442eb7.pdf,,,,,anonymous|linda_unsupervised_learning_to_interpolate_in_natural_language_processing,,,,,,,,,
184,6q-mLPJICaa,BigFive: A Dataset of Coarse- and Fine-Grained Personality Characteristics,['aclweb.org/ACL/ARR/2021/November/Paper1158/Authors'],['Anonymous'],"Obtaining the personalities of users conveyed by their published short texts has a wide and important range of applications, from detecting abnormal behavior of online users to accurately customization recommendation. Advancement in this area can be improved using large-scale datasets with coarse- and fine-grained typologies, adaptable to multiple downstream tasks. Therefore, this paper introduces $BigFive$, a large, high quality dataset manually annotated by experts. $BigFive$ contains 13,478 Chinese phrases that belong to five categories (coarse-grained) and 30 categories (fine-grained). The reliability of five categories grouped by personality level and 30 categories grouped by dimension level is demonstrated via a detailed data analysis. In addition,  a strong baseline is build based on fine-tuning a BERT model. Our BERT-based model achieves an average F1-score of .33 (std=.24) in terms of 30 categories and an average F1-score of .66 (std=.05) in terms of five categories. The experimental results suggest that there is much room for improvement.",/pdf/ec3ac170583ffef0e7eb1783d23172c5e306d701.pdf,,,,,anonymous|bigfive_a_dataset_of_coarse_and_finegrained_personality_characteristics,,,,,,,,,
185,GO9vQ8BrJtk,Detection of Adversarial Examples in NLP: Benchmark and Baseline via Robust Density Estimation,['aclweb.org/ACL/ARR/2021/November/Paper74/Authors'],['Anonymous'],"Word-level adversarial attacks have shown success in NLP models, drastically decreasing the performance of transformer-based models in recent years. As a counter measure, adversarial defense has been explored, but relatively little efforts have been made to detect adversarial examples. However, detecting adversarial examples in NLP may be crucial for automated task (e.g. review sentiment analysis) that wishes to amass information about a certain population and additionally be a step towards a robust defense system. To this end, we release a dataset for four popular attack methods on three datasets and four NLP models to encourage further research in this field. Along with it, we propose a competitive baseline based on density estimation that has the highest \textsc{auc} on 21 out of 22 dataset-attack-model combinations.\footnote{https://github.com/anoymous92874838/text-adv-detection}",/pdf/877942c3c07e20a2b98f25102a8981ae3313a9e7.pdf,/attachment/13e981c7203e7fe40e7736500c0c0e63947fa5de.zip,,,,anonymous|detection_of_adversarial_examples_in_nlp_benchmark_and_baseline_via_robust_density_estimation,,,,,,,,,
186,LgRe_HPmQyv,Measuring HLT Research Equality of European Languages,['aclweb.org/ACL/ARR/2021/November/Paper891/Authors'],['Anonymous'],"This work explores quantitatively the equality of the languages of the European Union in the field of HLT. Our ultimate goal is to investigate European language diversity and identify low-resource and endangered languages taking into account the research papers of the main HLT conferences. This framework has been selected with the goal to identify potential inequalities among theoretically similarly capable languages in terms of available social and economical resources as well as political status. We have identified several groups of EU languages in terms of HLT research equality, each group comprising languages of very varying number of speakers. We have discovered a relative equality among surprisingly different languages in terms of speaker base and also relevant inequalities within the most spoken languages. All data and code will be released upon acceptance.",/pdf/294d8e00e2a68446e583e9fa016dd858e9096dfb.pdf,,,,,anonymous|measuring_hlt_research_equality_of_european_languages,,,,,,,,,
187,HT9x1moobfz,SummaReranker: A Multi-Task Mixture-of-Experts Re-ranking Framework for Abstractive Summarization,['aclweb.org/ACL/ARR/2021/November/Paper1123/Authors'],['Anonymous'],"Sequence-to-sequence neural networks have recently achieved great success in abstractive summarization, especially with the trend of fine-tuning large pre-trained language models on the downstream dataset. These models are typically decoded with beam search to generate a unique summary. However, the search space is very large, and due to exposure bias, such decoding is not optimal. In this paper, we show that it is possible to directly train a second-stage model performing re-ranking on a set of summary candidates. Our mixture-of-experts SummaReranker learns to select a better candidate and systematically improves the performance of the base model. With a base PEGASUS, we push ROUGE scores by 5.44% on CNN-DailyMail (47.16 ROUGE-1), 1.31% on XSum (48.12 ROUGE-1) and 9.34% on Reddit TIFU (29.83 ROUGE-1), reaching a new state-of-the-art.",/pdf/89fc14fef11fcd6dc6747b827d5cceb7edeb5f67.pdf,/attachment/a09bb634a78f3a28a65c111a770bb553212c4ed2.zip,,,,anonymous|summareranker_a_multitask_mixtureofexperts_reranking_framework_for_abstractive_summarization,,,,,,,,,
188,j6PUcXtiy75,FLAP: Table-to-Text Generation with Feature Indication and Numerical Reasoning Pretraining,['aclweb.org/ACL/ARR/2021/November/Paper1693/Authors'],['Anonymous'],"Recent neural models have shown success in table-to-text generation. However, the performance of content selection and content planning is still unsatisfactory. In this paper, we propose an effective framework with Feature indication and numericaL reAsoning Pretraining (FLAP) to help the neural generation model on content selection and planning. First, rather than treating the table as a sequence of token embeddings, we map each table into a numerical vector to utilize the real number information. We further propose a feature indication mechanism that introduces combination invariant bias to reduce the exposure bias problem in our generation system. Second, we propose a numerical reasoning pretraining task to help model do numerical reasoning upon the selected subset of tables. Experiments show that our framework outperforms the strong baselines on metrics of both content selection and planning on ROTOWIRE and RW-FG.",/pdf/a4f75f9066543f823a93ba6a362723cca621494c.pdf,,,,,anonymous|flap_tabletotext_generation_with_feature_indication_and_numerical_reasoning_pretraining,,,,,,,,,
189,EmJCjwPiH_i,TextMosaic: A New Data Augmentation Method for Named Entity Recognition Using Document-Level Contexts,['aclweb.org/ACL/ARR/2021/November/Paper2289/Authors'],['Anonymous'],"Named Entity Recognition (NER) often faces the problem of lacking massive and diverse annotation data, recent advances of pre-training techniques have shown great power on such low-resource tasks.  However, the robustness of NER models is still insufficient which motivates us for efficient text enhancement method.  Inspired by the mosaic augmentation method for object detection, this paper puts forward a novel data augmentation method named TextMosaic for NER through span sampling,over-sampling, and random sampling, which takes full consideration of the context-sensitive relevance. Meanwhile, sliding window is leveraged in the sampling to effectively capture rich document-level information and solve the problem of label imbalance. Our proposed method won the Top 1 in the robustness evaluation of CCIR Cup 2021.  We also conduct extensive experiments on OntoNote 4.0 dataset, on which our method achieves higher accuracy and robustness for NER simultaneously.  Besides, it consumes less computing resources and makes the model capable of running in 1080ti GPU efficiently. The code will be open-sourced on Github.",/pdf/799acbc84e71f95243e65d77023d4f2b53911c05.pdf,,,,,anonymous|textmosaic_a_new_data_augmentation_method_for_named_entity_recognition_using_documentlevel_contexts,,,,,,/attachment/1ba186305978334dd8fb730de6af8e0f89ded27b.zip,,,
190,PQl2HPBGRvW,Language Level Classification on German Texts using a Neural Approach,['aclweb.org/ACL/ARR/2021/November/Paper1284/Authors'],['Anonymous'],"Studies on language level classification (LLC) for German are scarce. Of the few existing, most use a feature-engineered approach. To the best of our knowledge, there is no deep learning approach on German texts yet. This paper shows that LLC can also be successfully applied to German texts by exploiting different pre-existing neural network architectures. Seven diverse corpora represent the data basis for training the networks: a web-scraped corpus, a corpus  created  from  newspaper  articles, three second language learner corpora, a corpus created by a company that translates complex texts into incremental simplified versions, and a corpus  created  from  a collection of  written  examinations  covering  the whole CEFR  spectrum  (A1-C2). An approach based on the BERT architecture yielded the best results. The highest F1 score achieved was 1.0 and 0.83 on a document  and sentence level, respectively.",/pdf/2fc9fc38f9bd88f8751f9271c3fe195ad97d618f.pdf,,,,,anonymous|language_level_classification_on_german_texts_using_a_neural_approach,,,,,,,,,
191,YeaNQgfFwlQ,A New Search Paradigm for Natural Language Code Search,['aclweb.org/ACL/ARR/2021/November/Paper885/Authors'],['Anonymous'],"Code search can accelerate the efficiency of software development by finding code snippets for the given query. The dominant code search paradigm is to learn the semantic matching between code snippets and queries by neural networks. However, this search paradigm causes the gap transferring and expansion between code snippets and queries because researchers utilize pairs of code snippets and code descriptions (e.g., comments and documentation) to train their models and evaluate the trained models on the query which is different from the code description in writing style and application scenario. To remedy the issue, we propose a new simple but effective search paradigm, Query2Desc, which entirely depends on natural language and conducts code search by performing the semantic matching between code descriptions and queries. Experimental results on dataset CoSQA show that the state-of-the-art model CodeBERT gets improvement of 17.48\% in terms of the average MRR when applying it on Query2Desc. Moreover, baseline models on Query2Desc can return the right results in top-$10$ search results for at least 95\% of queries in the test set of CoSQA.",/pdf/f9d8ad1842ca1309ba3194ff549b59f6e5c02380.pdf,,,,,anonymous|a_new_search_paradigm_for_natural_language_code_search,,,,,,,,,
192,MS79LypM_jA,Domain-aware Self-supervised Pre-training for Weakly-supervised Meme Analysis,['aclweb.org/ACL/ARR/2021/November/Paper2634/Authors'],['Anonymous'],"Existing self-supervised learning strategies are constrained to a limited set of trivial and generic downstream tasks that predominantly target uni-modal applications. This has isolated progress for imperative multi-modal applications that are diverse in terms of complexity and domain-affinity such as meme analysis.  Here, we introduce two self-supervised pre-training strategies, namely Ext-PIE-Net and MM-SimCLR that (i) employ multi-modal hate-speech data during pre-training,  and (ii) extend existing self-supervision learning approaches by incorporating multiple specialized pretext tasks; effectively catering to the required complex multi-modal representation learning for meme analysis. 
We experiment with different self-supervision strategies, including potential variants that could help learn rich cross-modality representations and evaluate using popular linear probing on the Hateful Memes task. The proposed solutions strongly compete with the fully-supervised baseline in a weakly-supervised setting, while distinctly outperforming them on all three tasks of the Memotion challenge with 0.18\%, 23.64\%, and 0.93\% performance gain, respectively. Further we demonstrate generalizability of the proposed solutions by reporting competitive performance on the HarMeme task. Finally, we empirically establish efficient convergence of the proposed solutions during fine-tuning, in a weak-supervision setup by arguing that the complexity of the self-supervision strategy and downstream task at hand are correlated. Our efforts highlight the requirement of better self-supervision strategies involving specialised pretext tasks for efficient fine-tuning and generalizable performance.",/pdf/b7e94962b9420c8ef9dcd4a27838289be34165d2.pdf,/attachment/c65274eb7b0f1a961ca34e7f41a1ca20bfb410dd.zip,,,,anonymous|domainaware_selfsupervised_pretraining_for_weaklysupervised_meme_analysis,,,,,,,,,
193,Xp_pRGHM6F0,E-MMAD: Multimodal Advertising Caption Generation Based on Structured Information,['aclweb.org/ACL/ARR/2021/November/Paper1351/Authors'],['Anonymous'],"With multimodal tasks increasingly getting popular in recent years, datasets with large scale and reliable authenticity are in urgent demand. Therefore, we present an e-commercial multimodal advertising dataset, E-MMAD, which contains 120 thousand valid data elaborately picked out from 1.3 million real product examples in both Chinese and English. Noticeably, it is one of the largest  video captioning datasets in this field, in which each example has its product video (around 30 seconds), title, caption and structured information table that is observed to play a vital role in practice. We also introduce a fresh task for vision-language research based on E-MMAD: e-commercial multimodal advertising generation, which requires to use aforementioned product multimodal information to generate textual advertisement. Accordingly, we propose a baseline method on the strength of structured information reasoning to solve the demand in reality on this dataset.",/pdf/3e5ccc5b51f4d9bde4aca02224fc20163150db25.pdf,,,,,anonymous|emmad_multimodal_advertising_caption_generation_based_on_structured_information,,,,,,,,,
194,o-LWIbKagke,Fantastic Questions and Where to Find Them: FairytaleQA--An Authentic Dataset for Narrative Comprehension,['aclweb.org/ACL/ARR/2021/November/Paper2026/Authors'],['Anonymous'],"Question answering (QA) is a fundamental means to facilitate assessment and training of narrative comprehension skills for both machines and young children, yet there is scarcity of high-quality QA datasets carefully designed to serve this purpose. In particular, existing datasets rarely distinguish fine-grained reading skills, such as the understanding of varying narrative elements. Drawing from education domains where QA is also used to train children's narrative comprehension, we introduce FairytaleQA, a dataset focusing on narrative comprehension of kindergarten to eighth grade students. Generated by educational experts based on an evidence-based theoretical framework, FairytaleQA  consists of 10,580 explicit and implicit questions derived from 278 children-friendly stories, covering seven types of narrative elements/relations.
Our dataset is valuable in two folds: First, with annotations on particular reading skills required for answering each question, FairytaleQA decomposes the otherwise scarce performance into multiple analysis dimensions that are consistent to human-language-learning assessment. We ran existing QA models on our dataset, and confirmed that this annotation helps assess models' fine-grained learning skills. Second, the dataset supports generating questions (QG) in the education domain. Through benchmarking with QG models, we show that the QG model trained on FairytaleQA is capable of asking high-quality and more diverse questions. ",/pdf/b5c8fb3f8386ced11dd1db0346039991b76f40b8.pdf,,,,,anonymous|fantastic_questions_and_where_to_find_them_fairytaleqaan_authentic_dataset_for_narrative_comprehension,,,,,,,,,
195,4X-nUzszhp,Question-Led Semantic Structure Enhanced Attentions for VQA,['aclweb.org/ACL/ARR/2021/November/Paper476/Authors'],['Anonymous'],"The exploit of the semantic structure in the visual question answering (VQA) task is a trending topic where researchers are interested in leveraging internal semantics and bringing in external knowledge to tackle more complex questions. The prevailing approaches either encode the external knowledge separately from the local context, which magnificently increases the complexity of the ensemble system, or use graph neural networks to model the semantic structure in the context, which suffers from the limited reasoning capability due to the relatively shallow network. In this work, we propose a question-led structure extraction scheme using external knowledge and explore multiple training methods, including direct attention supervision, SGHMC-EM Bayesian multitask learning, and masking strategies, to aggregate the structural knowledge into deep models without changing the architectures.  We conduct extensive experiments on two domain-specific but challenging sub-tasks of VrR-VG dataset and demonstrate that our proposed methods achieve significant improvements over strong baselines, showing the promising potentials of applicability.",/pdf/39948d654f0797dccd72e9968a0a006b7f3e991c.pdf,,,,,anonymous|questionled_semantic_structure_enhanced_attentions_for_vqa,,,,,,,,,
196,GnDf8RijEfl,Towards a Fine-Grained Multi-Domain Neural Machine Translation Using Inter-Domain Relationships,['aclweb.org/ACL/ARR/2021/November/Paper1697/Authors'],['Anonymous'],"While research on the domain adaptation task in neural machine translation has become popular recently, there exists no agreement on what constituents a domain, and most previous studies only focus on coarse-grained domain adaptation and their methods cannot be generalized if the domain size is large. In this work, we argue the necessity to study a fine-grained domain adaptation problem. We build a new multilingual dataset from web sources that focus on fine-grained domains and inter-domain attributes and relationships. We also propose a simple but effective adaptation method to incorporate domain knowledge leveraging models in information networks. ",/pdf/56fc3bd14760755c200d305f81b251df082e7c5c.pdf,/attachment/5ebc45fcf50732b2ffcf7e3572e2524f13595b61.zip,,,,anonymous|towards_a_finegrained_multidomain_neural_machine_translation_using_interdomain_relationships,,,,,,/attachment/bac07702426a6943baae32bd53b2a1ad5fb7b9a3.zip,,,
197,tSgisvw--5B,The Sensitivity of Annotator Bias to Task Definitions,['aclweb.org/ACL/ARR/2021/November/Paper1456/Authors'],['Anonymous'],"NLP models are biased by the data they are trained on, including how it is annotated, but NLP research increasingly examines the em social biases of models, often in the light of their training data. This paper is first to examine to what extent social bias is sensitive to how data is annotated. We do so by collecting annotations of arguments in the same documents following four different guidelines and from four different demographic annotator backgrounds. We show that annotations exhibit widely different levels of group disparity depending on which guidelines annotators follow. The differences are not explained by task complexity, but rather by characteristics of these groups, as previously identified by sociological studies.",/pdf/a4b03e523228f42a1789115ba6893035c84b06dc.pdf,,,,,anonymous|the_sensitivity_of_annotator_bias_to_task_definitions,,,,,,,,,
198,syvKAodJ-Gj,A Novel Framework Based on Medical Concept Driven Attention for Explainable Medical Code Prediction via External Knowledge,['aclweb.org/ACL/ARR/2021/November/Paper1196/Authors'],['Anonymous'],"Medical code prediction from clinical notes aims at automatically associating medical codes with the clinical notes. Rare code problem, the medical codes with low occurrences, is prominent in medical code prediction. Recent studies employ deep neural networks and the external knowledge to tackle it. However, such approaches lack interpretability which is a vital issue in medical application. Moreover, due to the lengthy and noisy clinical notes, such approaches fail to achieve satisfactory results. Therefore, in this paper, we propose a novel framework based on medical concept driven attention to incorporate external knowledge for explainable medical code prediction. In specific, both the clinical notes and Wikipedia documents are aligned into topic space to extract medical concepts using topic modeling. Then, the medical concept-driven attention mechanism is applied to uncover the medical code related concepts which provide explanations for medical code prediction. Experimental results on the benchmark dataset show the superiority of the proposed framework over several state-of-the-art baselines. ",/pdf/ee86e7f3b500e4b9f6f0f61d925d537b67465879.pdf,,,,,anonymous|a_novel_framework_based_on_medical_concept_driven_attention_for_explainable_medical_code_prediction_via_external_knowledge,,,,,,,,,
199,Dwqav13klH3,Identifying Moments of Change from Longitudinal User Text,['aclweb.org/ACL/ARR/2021/November/Paper1394/Authors'],['Anonymous'],"Identifying changes in individuals' behaviour and mood, as observed via content shared on online platforms, is increasingly gaining importance. Most research to-date on this topic focuses on either: (a) identifying individuals at risk or with a certain mental health condition given a batch of posts or (b) providing equivalent labels at the post level. A disadvantage of such work is the lack of a strong temporal component and the inability to make longitudinal assessments following an individual's trajectory and allowing timely interventions. Here we define a new task, that of identifying moments of change in individuals on the basis of their shared content online. The changes we consider are sudden shifts in mood (switches) or gradual mood progression (escalations). We have created detailed guidelines for capturing moments of change and a corpus of 500 manually annotated user timelines (18.7K posts). We have developed a variety of baseline models drawing inspiration from related tasks and show that the best performance is obtained through context aware sequential modelling. We also introduce new metrics for capturing rare events in temporal windows.",/pdf/008373596fcac3e62e746f9e5f85a1950b9ddc05.pdf,,,,,anonymous|identifying_moments_of_change_from_longitudinal_user_text,,,,,,,,,
200,nUcR4c0hg5q,CONJR: Conjunctive Sentence Splitter without Parsing,['aclweb.org/ACL/ARR/2021/November/Paper1814/Authors'],['Anonymous'],"In this paper, we observe and address the challenges of splitting conjunctive sentences around each group of conjuncts. Most existing methods rely on parsers to identify the conjuncts in a sentence and detect the coordination boundaries. However, state-of-the-art syntactic parsers are slow and suffer from errors, especially for long and complicated sentences. In order to better solve the problems, we formulate coordination boundary detection as a sequence tagging task and propose a specialized model CONJR without using syntactic parsers. We introduce both semantic and syntactic features and a specially designed attention mechanism to capture the symmetry among the potential conjuncts. The experimental results on datasets from various domains demonstrate the effectiveness of our proposed methods.",/pdf/ca3bbeb70ccf7d47b914997e2a8828ed98931a44.pdf,/attachment/1d3ee86b636980330a2dbfa41b6253330cac60b8.zip,,,,anonymous|conjr_conjunctive_sentence_splitter_without_parsing,,,,,,/attachment/7d3e9c9fa71d4c5edeb11eb3d5abdd5f73f97c66.zip,,,
201,3u6rOiXR9RA,Teaching Models new APIs: Domain-Agnostic Simulators for Task Oriented Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper609/Authors'],['Anonymous'],"We demonstrate that large language models are able to simulate Task Oriented Dialogues in novel domains, provided only with an API implementation and a list of goals. We show these simulations can formulate online, automatic metrics that correlate well with human evaluations. Furthermore, by filtering for dialogues where goals are met, we can use simulation to repeatedly generate training data and improve the quality of the dialogues themselves. With no human intervention or domain-specific training data, our simulations bootstrap end-to-end models which achieve a 37\% error reduction over baseline in previously unseen domains. By including as few as 32 domain-specific conversations, bootstrapped models can match the performance of a fully-supervised model with $10\times$ more data.",/pdf/2489fd4441c69c6ce7e49f3835760f63c90b2a54.pdf,,,,,anonymous|teaching_models_new_apis_domainagnostic_simulators_for_task_oriented_dialogue,,,,,,,,,
202,whBQ1c5Chd5,Modeling Intensification for Signed Language Generation: A Computational Approach,['aclweb.org/ACL/ARR/2021/November/Paper1982/Authors'],['Anonymous'],"End-to-end sign language generation models do not accurately represent the prosody of the languages. This lack of temporal and spatial variation in generated signs leads to poor quality and lower human perception. In this paper, we seek to improve prosody in generated sign languages by modeling intensification in a data-driven manner with strategies grounded in the linguistics of sign language by enhancing the representation of intensifiers in the gloss annotations. To employ our strategies, we first annotate a subset of the benchmark PHOENIX14T dataset with different levels of intensification. We then use a supervised intensity tagger to extend the tagging to the whole dataset. This enhanced dataset is then used to train state-of-the-art transformer models for sign language generation. We find that our efforts in intensifier modeling yield better results evaluated with automated metrics. Human evaluation also indicates a significantly higher preference of the videos generated using our strategies in the presence of intensity modifiers.",/pdf/f0cad74ba2328e7798336aca46d18e0ce27280bb.pdf,/attachment/648aa66931a97d11ce53f0d8dbaf88c9c8fc5f0c.zip,,,,anonymous|modeling_intensification_for_signed_language_generation_a_computational_approach,,,,,,/attachment/baf2cdefefc01988e6d8106c74a29a7887efcf45.zip,,,
203,P008p9qTbyO,A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models,['aclweb.org/ACL/ARR/2021/November/Paper1509/Authors'],['Anonymous'],"Large pre-trained vision-language (VL) models can learn a new task with a handful of examples and generalize to a new task without fine-tuning. However, these VL models are hard to deploy for real-world applications due to their impractically huge sizes and slow inference speed. To solve this limitation, we study prompt-based low-resource learning of VL tasks with our proposed method, FewVLM, relatively smaller than recent few-shot learners. For FewVLM, we pre-train a sequence-to-sequence transformer model with prefix language modeling (PrefixLM) and masked language modeling (MaskedLM). Furthermore, we analyze the effect of diverse prompts for few-shot tasks. Experimental results on VQA show that FewVLM with prompt-based learning outperforms Frozen which is 31x larger than FewVLM by 18.2\% point on zero-shot VQAv2 and achieves comparable results to a 246x larger model, PICa.
In our analysis, we observe that (1) prompts significantly affect zero-shot performance but marginally affect few-shot performance, (2) models with noisy prompts learn as quickly as hand-crafted prompts given larger training data, and (3) MaskedLM helps VQA tasks while PrefixLM boosts captioning performance. ",/pdf/f1cce00a24bb2f2dc2506d2ab55915f5eb33cbdb.pdf,,,,,anonymous|a_good_prompt_is_worth_millions_of_parameters_lowresource_promptbased_learning_for_visionlanguage_models,,,,,,,,,
204,7lJpG58T5qy,Revisiting the Compositional Generalization Abilities of Neural Sequence Models,['aclweb.org/ACL/ARR/2021/November/Paper1494/Authors'],['Anonymous'],"Compositional generalization is a fundamental trait in humans, allowing us to effortlessly combine known phrases to form novel sentences. Recent works have claimed that standard seq-to-seq models severely lack the ability to compositionally generalize. In this paper, we focus on one-shot primitive generalization as introduced by the popular SCAN benchmark. We demonstrate that modifying the training distribution in simple and intuitive ways enables standard seq-to-seq models to achieve near-perfect generalization performance, thereby showing that their compositional generalization abilities were previously underestimated. We perform detailed empirical analysis of this phenomenon. Our results indicate that the generalization performance of models is highly sensitive to the characteristics of the training data which should be carefully considered while designing such benchmarks in future.",/pdf/f11f8541c90004eba976de809048dae8408bea9c.pdf,/attachment/ae94483ca2cbc7ee2657e53ea33e9f309f847d9f.zip,,,,anonymous|revisiting_the_compositional_generalization_abilities_of_neural_sequence_models,,,,,,,,,
205,_9QcfD3L0z,Retrieval-guided Counterfactual Generation for QA,['aclweb.org/ACL/ARR/2021/November/Paper1953/Authors'],['Anonymous'],"Deep NLP models have been shown to be brittle to input perturbations. Recent work has shown that data augmentation using counterfactuals --- i.e. minimally perturbed inputs --- can help ameliorate this weakness. We focus on the task of creating counterfactuals for question answering, which presents unique challenges related to world knowledge, semantic diversity, and answerability. To address these challenges, we develop a Retrieve-Generate-Filter(RGF) technique to create counterfactual evaluation and training data with minimal human supervision. Using an open-domain QA framework and question generation model trained on original task data, we create counterfactuals that are fluent, semantically diverse, and automatically labeled. Data augmentation with RGF counterfactuals improves performance on out-of-domain and challenging evaluation sets over and above existing methods, in both the reading comprehension and open-domain QA settings. Moreover, we find that RGF data leads to significant improvements in a model's robustness to local perturbations.",/pdf/7d24dfc2b5eb14fbf77f8ed1eaa5ca5d8db4f454.pdf,,,,,anonymous|retrievalguided_counterfactual_generation_for_qa,,,,,,,,,
206,WSxxdJdByLS,Data Augmentation with Sentence Recombination Method for Semi-supervised Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper1989/Authors'],['Anonymous'],"As the need of large amount of time and expertise to obtain enough labeled data, semi-supervised learning has received much attention to utilize both labeled and unlabeled data. In this paper, we present SeRe: a Sentence Recombination method to augment training data for semi-supervised text classification. SeRe makes full use of the similarities between sentences in different samples through the grouping and recombining process to form rich and varied training data. SeRe generates data from three combinations, including labeled, unlabeled, and mixed data. Meanwhile, SeRe combines the self-training framework to improve the quality of augmented training data iteratively. We apply SeRe to text classification tasks and conduct extensive experiments on four publicly available benchmarks. Experimental results show that SeRe achieves new state-of-the-art performances on all of them.",/pdf/4a0b280083aae7a771f4ffc90102ec34c4a612b0.pdf,,,,,anonymous|data_augmentation_with_sentence_recombination_method_for_semisupervised_text_classification,,,,,,,,,
207,Bqm_vhc-d6Y,More Than Words: Collocation Retokenization for Latent Dirichlet Allocation Models,['aclweb.org/ACL/ARR/2021/November/Paper884/Authors'],['Anonymous'],"Traditionally, Latent Dirichlet Allocation (LDA) ingests words in a collection of documents to discover their latent topics using word-document co-occurrences. Previous studies show that representing bigrams collocations in the input can improve topic coherence in English. However, it is unclear how to achieve the best results for languages without marked word boundaries such as Chinese and Thai. Here, we explore the use of retokenization based on chi-squared measures, $t$-statistics, and raw frequency to merge frequent token ngrams into collocations when preparing input to the LDA model. Based on the goodness of fit and the coherence metric, we show that topics trained with merged tokens result in topic keys that are clearer, more coherent, and more effective at distinguishing topics than those of unmerged models.",/pdf/9331b65cc96f75d7572d6962176b8bc41ba5948b.pdf,,,,,anonymous|more_than_words_collocation_retokenization_for_latent_dirichlet_allocation_models,,,,,,,,,
208,KsvzWG8G2kv,Blackbird's language matrices (BLMs): a new benchmark to investigate disentangled generalisation in neural networks,['aclweb.org/ACL/ARR/2021/November/Paper1150/Authors'],['Anonymous'],"Current successes of machine learning architectures are based on computationally expensive algorithms and prohibitively large amounts of data. We need to develop tasks and data to train networks to reach more complex and more compositional skills. In this paper, we illustrate Blackbird's language matrices (BLMs), a novel grammatical dataset developed to test a linguistic variant of Raven's progressive matrices, an intelligence test usually based on visual stimuli. The dataset consists of roughly 48000 sentences, generatively constructed to support investigations of current models' linguistic mastery of grammatical rules and their ability to generalize them. We present the logic of the dataset, the method to automatically construct data on a large scale, and the architecture to learn them. Through error analysis and several experiments on variations of the dataset, we demonstrate that this language task and the data that instantiate it provide a new challenging testbed to understand generalization and abstraction.
  ",/pdf/6b0e05912020031cb0da2298dc0e7ea5023578cd.pdf,/attachment/a7e7a7a35a1a52e3da9d1762e7ca33b0f43898fa.zip,,,,anonymous|blackbirds_language_matrices_blms_a_new_benchmark_to_investigate_disentangled_generalisation_in_neural_networks,,,,,,/attachment/0ab7661cadeaaee7db46f8219cfd8f074816b404.zip,,,
209,2NOSFKxicWQ,Learn to Adapt for Generalized Zero-Shot Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper1781/Authors'],['Anonymous'],"Generalized zero-shot text classification aims to classify textual instances from both previously seen classes and incrementally emerging unseen classes. Most existing methods generalize poorly since the learned parameters are only optimal for seen classes rather than for both classes, and the parameters keep stationary in predicting procedures. To address these challenges, we propose a novel Learn to Adapt (LTA) network using a variant meta-learning framework. Specifically, LTA trains multiple meta-learners by using both seen classes and virtual unseen classes to simulate a generalized zero-shot learning (GZSL) scenario in accordance with the test time, and simultaneously learns to calibrate the class prototypes and sample representations to make the learned parameters adaptive to incoming unseen classes. We claim that the proposed model is capable of representing all prototypes and samples from both classes to a more consistent distribution in the global space. Extensive experiments on five text classification datasets show that our model outperforms several competitive previous approaches by large margins. The code and the whole datasets will be available after paper publication.",/pdf/26723a42796ccb5dda6c1d0bec18214be1a1c3f6.pdf,/attachment/23f87933d290b6df26db70ee908e84c28fae58ab.zip,,,,anonymous|learn_to_adapt_for_generalized_zeroshot_text_classification,,,,,,/attachment/53e2fc10d470802662fc90f1953b61fa1115f662.zip,,,
210,ZvJdOe_VUXB,Language Model-Guided Knowledge Subgraphs for Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper145/Authors'],['Anonymous'],"Knowledge graphs for question answering can provide  subgraphs  based  on  different  combinations of questions and answers for multiple reasoning chains, in which humans often find the answer for a question.   In this paper,  we introduce extracting multiple subgraphs fromKGs to model the reasoning process.  We propose a new model to leverage language model-guided knowledge subgraphs, which explicitly provide  potential  multiple  reasoning  chains from  different  perspectives  and  are  encoded with language models for joint reasoning.  We evaluate our model in two datasets: Common-senseQA and OpenBookQA. The results show that the proposed approach outperforms state-of-the-art methods.",/pdf/1bd61d79cd4429a839b982a4ed4e7ea729427b14.pdf,,,,,anonymous|language_modelguided_knowledge_subgraphs_for_question_answering,,,,,,,,,
211,IbqvTfZZR7X,Extreme Multi-label Text Classification with Pseudo Label Descriptions,['aclweb.org/ACL/ARR/2021/November/Paper1960/Authors'],['Anonymous'],"Extreme multi-label text classification (XMTC) is the task of tagging each document with the relevant labels in a large predefined label space, where the label frequency distribution is often highly skewed.  That is, a large portion of labels (namely the tail labels) have very few positive instances, posing a hard optimization problem for training the classification models.  The severe data sparse issue with tail labels is more announced in recent neural classifiers, where the embeddings of both the input documents and the output labels need to be jointly learned, and the success of such learning relies on the availability of sufficient training instances. This paper addresses this tough challenge in XMTC by proposing a novel approach that combines the strengths of both traditional bag-of-words (BoW) classifiers and recent neural embedding based classifiers.  Specifically, we use a trained BoW model to generate a pseudo description for each label, and apply a neural model to establish the mapping between input documents and target labels in the latent embedding spaces. Our experiments show significant improvements of the proposed approach over other strong baseline methods on benchmark datasets, especially on tail label prediction. We also provide a theoretical analysis for relating BoW and neural models w.r.t. performance lower bound.",/pdf/f5b7db6d1ba26b1b8ad5a07d9d4b9ca7c66da035.pdf,,,,,anonymous|extreme_multilabel_text_classification_with_pseudo_label_descriptions,,,,,,,,,
212,AhOTf_-zq0I,S$^2$SQL: Injecting Syntax to Question-Schema Interaction Graph Encoder for Text-to-SQL Parsers,['aclweb.org/ACL/ARR/2021/November/Paper1696/Authors'],['Anonymous'],"The task of converting a natural language question into an executable SQL query, known as text-to-SQL, is an important branch of semantic parsing. The state-of-the-art graph-based encoder has been successfully used in this task but does not model the question syntax well. In this paper, we propose S$^2$SQL, injecting Syntax to question-Schema graph encoder for Text-to-SQL parsers, which effectively leverages the syntactic dependency information of questions in text-to-SQL to improve the performance. We also employ the decoupling constraint to induce diverse relational edge embedding, which further improves the network's performance. Experiments on the Spider and robustness setting Spider-Syn demonstrate that the proposed approach outperforms all existing methods when pre-training models are used, resulting in a performance ranks first on the Spider leaderboard.",/pdf/2c6d6e43bf971aa52a103d5c0f50e60a8b20168c.pdf,/attachment/e6e223cf0c6b96991da8755223e7acc67b6f1274.zip,,,,anonymous|s^2sql_injecting_syntax_to_questionschema_interaction_graph_encoder_for_texttosql_parsers,,,,,,,,,
213,8JHTdpDdzue,Chinese Word Attention based on Valid Division of Sentence,['aclweb.org/ACL/ARR/2021/November/Paper796/Authors'],['Anonymous'],"Chinese word attention (CWA) with word-level information is very important for natural language processing. The purpose is how to attention words in a sentence. We first explore the valid divisions of a sentence by splitting word tools. We use BERT for character and word pre-training. Each character embedding with its word in one division is encoded in block local attention. We use attention with prior to assign attention weights to each splitting result, and finally combine the global attention mechanism to get the optimal recognition result in Chinese NER.",/pdf/9ab051f3428706186bf6d796823ec88dff1e9c2b.pdf,,,,,anonymous|chinese_word_attention_based_on_valid_division_of_sentence,,,,,,,,,
214,NkOTih-TP7T,Assessing the Coherence Modeling Capabilities of Pretrained Transformer-based Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2310/Authors'],['Anonymous'],"The task of ordering a shuffled set of sentences into a coherent text is used to evaluate the capacity of a model to understand causal and temporal relations between entities and events. Recent approaches rely on pretrained Transformer-based models, but it remains unknown whether the differences between them, such as size, pretraining data and objectives, affect their coherence modeling capacity. We present a simple architecture for sentence ordering that relies exclusively on pretrained Transformer-based encoder-only models. This allows us to compare the coherence modeling capabilities of the monolingual and multilingual versions of BERT, RoBERTa, and DistilBERT. We show that RoBERTa-based models outperform BERT-based models and are more robust when ordering longer documents with more than 10 sentences. Thus, the intuitive advantage offered by sentence-based objectives such as Next Sentence Prediction used in BERT is effectively compensated by the higher amount and diversity of the training data used in RoBERTa. However, the difference between multilingual versions of BERT and RoBERTa is narrower. This suggests that exposure to  different languages partially makes up for the benefits of larger and more diverse training data.",/pdf/69eed733a72b26d9d67539408b7636ba77871e60.pdf,,,,,anonymous|assessing_the_coherence_modeling_capabilities_of_pretrained_transformerbased_language_models,,,,,,,,,
215,84ELWXcppZC,Break it - Message it - Fix it : Learning to Repair Python Programs using Error Messages without Labelled Data,['aclweb.org/ACL/ARR/2021/November/Paper2482/Authors'],['Anonymous'],"In recent years there is an increasing demand to reduce the gap in development to deployment. It has been estimated that developers spend almost 20\% of their time in fixed problems with their code. Therefore tools which can automatically repair code can help accelerate the DevOps cycles. In this work we build upon recent success of deploying neuro-symbolic approaches for automatic code repair. In our approach, we use a dataset of python code, viz, CodeNet, which represents data distribution for human generated code. We train two neural modules a breaker and a fixer, which are trained iteratively, along with a symbolic module Pylint. The breaker learns to introduce errors in the code, the symbolic module acts as a Critic and is able to fragment the error by identifying the line, as well provide the error type with a specific exception message. The Fixer utilizes the exception message to repair the erroneous line in the code. We are able to cover 32 different syntax errors, and iterative training based on back translation actually helps improve the performance of the Fixer. ",/pdf/0d5b5582e11ad4679e425a0c38fbab704d0e7ea1.pdf,,,,,anonymous|break_it_message_it_fix_it_learning_to_repair_python_programs_using_error_messages_without_labelled_data,,,,,,,,,
216,hbXoXCc7_8,Uncertainty in the Social World and its Interdependence,['aclweb.org/ACL/ARR/2021/November/Paper2768/Authors'],['Anonymous'],"This research investigates the variety of social behaviours that we engage in on a daily basis. There are several unknown factors in each scenario, reflecting the many sources of uncertainty inherent in social judgement. We illustrate how uncertainty emerges in social situations (the thoughts and intentions of others are generally hidden, making predicting a person's behaviour difficult) and why people are driven to reduce the aversive feelings created by uncertainty. We propose a model in which social uncertainty is mitigated first through automatic modes of inference (such as impression generation), before more control-demanding modes of inference (such as perspective-taking) are used to narrow one's expectations even further. Finally, social uncertainty is reduced further by allocating resources to update these predictions based on newer inputs. We propose a novel quantitative framework to provide an account of the mechanisms underlying social cognition and action, by integrating studies from multiple disciplines. ",/pdf/ef61d329ac3bd97a213f2fca7448c117bc3e1114.pdf,,,,,anonymous|uncertainty_in_the_social_world_and_its_interdependence,,,,,,,,,
217,PMh4S5-FEC,How to be Helpful on Online Support Forums?,['aclweb.org/ACL/ARR/2021/November/Paper393/Authors'],['Anonymous'],"Internet forums such as Reddit offer people a platform to ask for advice when they encounter various issues at work, school or in relationships. Telling helpful comments apart from unhelpful comments to these advice-seeking posts can help people and dialogue agents to become more helpful in offering advice. We propose a dataset that contains both helpful and unhelpful comments in response to such requests. We then relate helpfulness to the closely related construct of empathy. Finally, we are the first study to analyze the language features that are associated with helpful and unhelpful comments.",/pdf/3519659d8315011abafea4065e4729ac8ad1e373.pdf,/attachment/2568bf6a061edb8cd0f7a5aed1347f515325fa7e.tgz,,,,anonymous|how_to_be_helpful_on_online_support_forums,,,,,,/attachment/cba61d80ba78edcc2329de8ee14f06b7acc0a84d.tgz,,,
218,R--glT8acxR,Challenges for Open-domain Targeted Sentiment Analysis,['aclweb.org/ACL/ARR/2021/November/Paper1253/Authors'],['Anonymous'],"Since previous studies on open-domain targeted sentiment analysis are limited in dataset domain variety and sentence level,  we propose a novel dataset consisting of 6,013 human-labeled data to extend the data domains in topics of interest and document level. Furthermore, we offer a nested target annotation schema to extract the complete sentiment information in documents, boosting the practicality and effectiveness of open-domain targeted sentiment analysis. Moreover, we leverage the pre-trained model BART in a sequence-to-sequence generation method for the task. Benchmark results show that there exists large room for improvement of open-domain targeted sentiment analysis. Meanwhile, experiments have shown that challenges remain in the effective use of open-domain data, long documents, the complexity of target structure, and domain gaps.",/pdf/3409574a25880a2708f1d8a10c2f89e806c84102.pdf,,,,,anonymous|challenges_for_opendomain_targeted_sentiment_analysis,,,,,,/attachment/e7ed17b5e2e61102ed8acd6452d09d643423a193.zip,,,
219,VbtRUvpzht,VQN: Variable Quantization Noise for Neural Network Compression,['aclweb.org/ACL/ARR/2021/November/Paper973/Authors'],['Anonymous'],"Quantization refers to a set of methods that compress a neural network by representing its parameters with fewer bits. However, applying quantization to a neural network after training often leads to severe performance regressions. Quantization Aware Training (QAT) addresses this problem by applying simulated training-time quantization for the model to learn robustness to inference-time quantization. One key drawback of this approach is that quantization functions induce biased gradient flow through the network during backpropagation, thus preventing the network from best-fitting to the learning task. Fan et al. addressed this issue by proposing Quant-Noise, in which simulated quantization is applied to a fixed proportion, called the quantization noise rate, of parameters during training. Our study, Variable Quantization Noise (VQN), builds upon their technique by exploring a variable quantization noise rate instead of a fixed one. We craft three candidate functions to vary noise rate during training and evaluate the variants with 3 datasets and 3 quantization schemes for each dataset. First, we report negative results on our hand-crafted candidate functions. Second, we observe somewhat positive results on a method, originally intended as an ablation study, of randomly varying the noise rate during training. This method outperforms Quant-Noise on two out of three quantization schemes for all three tested datasets. Moreover, on two of the datasets, this method at 4x compression matches or exceeds performance of even the uncompressed model. Future work should determine whether these unexpected results hold for more datasets and quantization schemes, as well as investigating other schemes for varying the noise rate during training.",/pdf/3a0f5acd8e81a4e60fd39aa8de7f6a3648cbbe5c.pdf,,,,,anonymous|vqn_variable_quantization_noise_for_neural_network_compression,,,,,,,,,
220,0a6du8Ebbcm,A Cueing Strategy for Prompt Tuning in Relation Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1183/Authors'],['Anonymous'],"Traditional relation extraction models predict confidence scores for each relation type based on a condensed sentence representation. In prompt tuning, prompt templates is used to tune pretrained language models (PLMs), which outputs relation types as verbalized type tokens. This strategy shows great potential to support relation extraction because it is effective to take full use of rich knowledge in PLMs. However, current prompt tuning models are directly implemented on a raw input. It is weak to encode contextual features and semantic dependencies of a relation instance. In this paper, we designed a cueing strategy which implants task specific cues into the input. It controls the attention of prompt tuning, which enable PLMs to learn task specific contextual features and semantic dependencies of a relation instance. We evaluated our method on two public datasets. Experiments show great improvement. It exceeds state-of-the-art performance by more than 4.8% and 1.4% in terms of F1-score on the SemEval corpus and the ReTACRED corpus.",/pdf/ca2bc4c4a7412bb68d524a32c174470bc023d137.pdf,,,,,anonymous|a_cueing_strategy_for_prompt_tuning_in_relation_extraction,,,,,,,,,
221,vJc9FszTpC3,Skill Induction and Planning with Latent Language,['aclweb.org/ACL/ARR/2021/November/Paper99/Authors'],['Anonymous'],"We present a framework for learning hierarchical policies from demonstrations, using sparse natural language annotations to guide the discovery of reusable skills for autonomous decision-making. We formulate a generative model of action sequences in which goals generate sequences of high-level subtask descriptions, and these descriptions generate sequences of low-level actions. We describe how to train this model using primarily unannotated demonstrations by parsing demonstrations into sequences of named high-level subtasks, using only a small number of seed annotations to ground language in action. In trained models, the space of natural language commands indexes a combinatorial library of skills; agents can use these skills to plan by generating high-level instruction sequences tailored to novel goals. We evaluate this approach in the ALFRED household simulation environment, providing natural language annotations for only 10% of demonstrations. It completes more than twice as many tasks as a standard approach to learning from demonstrations, matching the performance of instruction following models with access to ground-truth plans during both training and evaluation.",/pdf/ee8d5e8be337676b6b4efa060735245f4c59d775.pdf,,,,,anonymous|skill_induction_and_planning_with_latent_language,,,,,,,,,
222,DP1CWR2fN72,RoMe: A Robust Metric for Evaluating Natural Language Generation,['aclweb.org/ACL/ARR/2021/November/Paper1503/Authors'],['Anonymous'],"Evaluating Natural Language Generation (NLG) systems is a challenging task. Firstly, the metric should ensure that the generated hypothesis reflects the reference's semantics. Secondly, it should consider the grammatical quality of the generated sentence. Thirdly, it should be robust enough to handle various surface forms of the generated sentence. Thus, an effective evaluation metric has to be multifaceted. In this paper, we propose an automatic evaluation metric incorporating several core aspects of natural language understanding (language competence, syntactic and semantic variation). Our proposed metric, RoMe, is trained on language features such as semantic similarity combined with tree edit distance and grammatical acceptability, using a self-supervised neural network to assess the overall quality of the generated sentence. Moreover, we perform an extensive robustness analysis of the state-of-the-art methods and RoMe. Empirical results suggest that RoMe has a stronger correlation to human judgment over state-of-the-art metrics in evaluating system-generated sentences across several NLG tasks.",/pdf/dd705c6ebb93884be53daee0dfb4f780d3cb4e91.pdf,,,,,anonymous|rome_a_robust_metric_for_evaluating_natural_language_generation,,,,,,,,,
223,vIsNdxqCaoa,ElitePLM: An Empirical Study on General Language Ability Evaluation of Pretrained Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2653/Authors'],['Anonymous'],"Pretrained language models (PLMs), such as BERT and GPT-3, have dominated the majority of NLP tasks. However, relatively little work has been conducted on systematically evaluating the language abilities of PLMs. In this paper, we present a large-scale empirical study on gen\underline{E}ral \underline{l}anguage ab\underline{i}li\underline{t}y \underline{e}valuation of PLMs (ElitePLM). We first design four evaluation dimensions in ElitePLM, including memory, comprehension, reasoning, and composition, and further measure ten widely-used PLMs within five categories. Our empirical results demonstrate that: (1) the pretraining objectives and strategies have significant impacts on PLMs performance in downstream tasks; (2) fine-tuning PLMs in downstream tasks is usually sensitive to the data size and distribution; (3) PLMs have excellent transferability between similar tasks. Our experimental results summarize several important findings, which can guide the future work to choose, apply, and design  PLMs for specific tasks. We have made all the details of experiments publicly available at https://anonymous.4open.science/r/Paper-for-ACL-4FD1.",/pdf/1ead755f7f4b168e2d00b93fe7819fb46735007b.pdf,,,,,anonymous|eliteplm_an_empirical_study_on_general_language_ability_evaluation_of_pretrained_language_models,,,,,,,/attachment/2a8d86ad6a034d7b65a6432a5f7279aff8b6cc1d.pdf,https://openreview.net/forum?id=vjwdO75bWI0,/attachment/0d4c9d2bb0877a01ed26294e7b93640a52e3cbfa.pdf
224,qoGNaYWzdcw,Distilling Causal Metaknowledge from Massive Knowledge Graph,['aclweb.org/ACL/ARR/2021/November/Paper1078/Authors'],['Anonymous'],"In recent years, the growing information overload facilitates the access to billions  of  relational  facts in the world, which are usually integrated in all manner of knowledge graphs. The metaknowledge, defined as the knowledge about knowledge, reveals the inner principle of arising these factual knowledge, and hence is of vital importance to be discovered for the understanding, exploiting and completion of knowledge. In this paper, we focus on capturing the causal component of metaknowledge, that is a metarule with causal semantic.
For the propose, we devise an efficient causal rule discovery algorithm called CaRules that distills the causal rules between two knowledge graph schemata abstracted from instances from massive knowledge graphs. Extensive experiments demonstrate that the quality and interpretability of the causation-based rules outperform the correlation-based rules, especially in the out-of-distribution tasks.
",/pdf/2e265678dfbf7bba8a3485c7a9ef4338b9f1fc68.pdf,,,,,anonymous|distilling_causal_metaknowledge_from_massive_knowledge_graph,,,,,,,,,
225,-PQISG-m88j,Cross-Task Generalization via Natural Language Crowdsourcing Instructions,['aclweb.org/ACL/ARR/2021/November/Paper1985/Authors'],['Anonymous'],"Humans (e.g., crowdworkers) have a remarkable ability in solving different tasks, by simply reading textual instructions that define them and looking at a few examples. Despite the success of the conventional supervised learning on individual datasets, such models often struggle with generalization across tasks (e.g., a question-answering system cannot solve  classification tasks). A long-standing challenge in AI is to build a model that learns a new task by understanding the human-readable instructions that define it. To study this, we introduce NATURAL INSTRUCTIONS, a dataset of 61  distinct tasks, their human-authored instructions, and 193k task instances (input-output pairs). The instructions are obtained from crowdsourcing instructions used to create  existing NLP datasets and mapped to a unified schema. Using this meta-dataset, we measure cross-task generalization by training models on seen tasks and measuring generalization to the remaining unseen ones. We adopt generative pre-trained language models to encode task-specific instructions along with input and generate task output. Our results indicate that models benefit from instructions when evaluated in terms of generalization to unseen tasks (19% better for models utilizing instructions). These models, however, are far behind an estimated performance upperbound indicating significant room for more progress in this direction.",/pdf/1d5a2bf57f85107e851fe5a72d739bffde3099e8.pdf,,,,,anonymous|crosstask_generalization_via_natural_language_crowdsourcing_instructions,,,,,,,,,
226,539xGPKXgH8,A Well-Composed Text is Half Done! Semantic Composition Sampling for Diverse Conditional Generation,['aclweb.org/ACL/ARR/2021/November/Paper2508/Authors'],['Anonymous'],"We propose Composition Sampling, a simple but effective method to generate higher quality diverse outputs for conditional generation tasks, compared to previous stochastic decoding strategies. It builds on recently proposed planning-based neural generation models that are trained to first create a composition of the output using an entity chain and then continue to generate conditioned on the entity chain and the input \cite{frost}. Our approach avoids text degeneration by first sampling a composition in the form of an entity chain and then using beam search to generate the best possible text grounded to the entity chain. Experiments  on CNN/DailyMail and XSum  using a variety of automatic metrics and human-based evaluation demonstrate that Composition Sampling is currently the best available decoding strategy for generating diverse meaningful summaries. We further outperform state-of-the-art approaches for question generation in terms of BLEU.",/pdf/6688abf58c4a85c6325f3053b55e16f9ff91c565.pdf,,,,,anonymous|a_wellcomposed_text_is_half_done_semantic_composition_sampling_for_diverse_conditional_generation,,,,,,,,,
227,Ku8v46wIwL,ShrinkNAS : Single-Path One-Shot Operator Exploratory Training for Transformer with Dynamic Space Shrinking,['aclweb.org/ACL/ARR/2021/November/Paper2484/Authors'],['Anonymous'],"Neural Architecture Search (NAS) for Transformer has shown its growing capabilities in exploiting the benefits of various Transformer architecture configurations. Recent studies envision the diverse potential of introducing unprecedented Transformer operators (OPs, such as Convolution) to its structure, yet the existing methods of doing so are all time-consuming. Traditionally, Single-Path One-Shot (SPOS) models enable efficient search over a vast set of OPs. However, existing SPOS methods on Transformer focus only on dimensional configurations of the vanilla Transformer OP (e.g., Multi-head Attention), and did not consider introducing other OPs. This paper explores the possibility of including OPs in the Transformer-based SPOS architecture search to discover better Transformer structures with the high efficiency facilitated in the SPOS category. To achieve that, we propose Dynamic Space Shrinking  (DSS), a novel method that resolves problems brought from newly added OPs by dynamically keeping the current sample space containing subnets with good configurations and performance. 
We implemented DSS in ShrinkNAS, the first SPOS one-shot inter-OP model for Transformer. Our evaluation shows that ShrinkNAS is of much higher elasticity by finding a better structure beating the human-designed ones under tight constraint (<10M parameters), while existing intra-OP SPOS methods are not even close.",/pdf/f8d6f014290f07af05b7826f6ea9a83d476728c8.pdf,,,,,anonymous|shrinknas_singlepath_oneshot_operator_exploratory_training_for_transformer_with_dynamic_space_shrinking,,,,,,,,,
228,GvuDmpDf9Em,Heterogeneous Language Model Optimization in Automatic Speech Recognition,['aclweb.org/ACL/ARR/2021/November/Paper371/Authors'],['Anonymous'],"The rising data privacy risks make it difficult for automatic speech recognition (ASR) systems to acquire complete training data in practical application. Recently, the merge paradigm for acoustic model has been proposed to solve the issue. However, ASR still suffers from another salient issue on language model. Current efforts mainly focus on isomorphic neural network models, while language model optimization is characterized by merging and matching heterogeneous models including $n$-gram and neural network models. In this paper, we propose a novel Match-and-Merge paradigm to fill up the vacuum for the language model optimization. Based on different training datasets, we train multiple language model pairs. In order to merge them into a target pair with the best performance, we first propose a Genetic Match-and-Merge (GMM) method that can be specifically adopted to optimize heterogeneous models. To improve the algorithm efficiency, we further propose a Reinforced Match-and-Merge (RMM) method, which maintains superior recognition accuracy while reducing convergence time. Extensive experiments demonstrate the effectiveness and generalization of our proposed methods, which significantly establishes the new state-of-the-art.",/pdf/0c3fb22a3dc25197caf0e0bef82afe7ea80af009.pdf,,,,,anonymous|heterogeneous_language_model_optimization_in_automatic_speech_recognition,,,,,,,,,
229,-4-movxUMNV,Detecting Unassimilated Borrowings in Spanish: An Annotated Corpus and Approaches to Modeling,['aclweb.org/ACL/ARR/2021/November/Paper1098/Authors'],['Anonymous'],"This work presents a new resource for borrowing identification and analyzes the performance and errors of several models on this task.
We introduce a new annotated corpus of Spanish newswire rich in unassimilated lexical borrowings---words from one language that are introduced into another without orthographic adaptation---and use it to evaluate how several sequence labeling models (CRF, BiLSTM-CRF, and Transformer-based models) perform. The corpus contains 370,000 tokens and is larger, more borrowing-dense, OOV-rich, and topic-varied than previous corpora available for this task. Our results show that a BiLSTM-CRF model fed with either Transformer-based embeddings pretrained on codeswitched data or a combination of contextualized word embeddings (along with character embeddings and Spanish and English subword embeddings) outperforms results obtained by a multilingual BERT-based model.",/pdf/f0d9bb1f21160ff081e1cad33de81f1b50fbc259.pdf,/attachment/7e5effd73d2a7b00fefa2676cec70a6a2333eaf0.zip,,,,anonymous|detecting_unassimilated_borrowings_in_spanish_an_annotated_corpus_and_approaches_to_modeling,,,,,,/attachment/ebe3fcb54a3a7a03865ba08cda4d6b8c5ee85767.zip,,,
230,P3ziO-8tFU,GFDC: Graph Function Dependence for Logically Consistent Dialogue Response Beyond Persona Data,['aclweb.org/ACL/ARR/2021/November/Paper2859/Authors'],['Anonymous'],"The rigorous logical consistency between current and historical responses during dialogue is the basis of an excellent human speaker, and it is also essential for dialogue agents. Although maintaining consistent personas has made tremendous advancements, they are still limited to the scale of persona data. Then it is necessary to study further how to lead to generate consistent responses when there are beyond personas or even without personas. In this work, we show how the problems can be tackled by consistent dialogue generation turn into Graph Functional Dependencies of a consistent graph schema representation and utilized, called GFDC. Specifically, the model consists of an XLNet-based consistency module and a Transformer-based generation module. The consistency module is for learning the representation of the consistent graph schema. The generation module is for generating responses using consistent graph schema representations. In particular, to learn a consistent graph schema in the dialogue data, we construct the dialogue data as a graph. Then introduce the graph of general knowledge for constructing the consistent graph schema. Both automatic and human evaluations show that our model outperforms strong baselines in response quality and consistency under fewer persona data settings.",/pdf/da02d53924edca0e3625ebdd67e29c2cd3170c9a.pdf,/attachment/40414553c957e2368ed26105b12a32c207736c99.zip,,,,anonymous|gfdc_graph_function_dependence_for_logically_consistent_dialogue_response_beyond_persona_data,,,,,,,,,
231,0AzDYJ0ydie,,,,,,,,,,,,,,,,,,,
232,vI0FX7RY9UH,Make the Best of Cross-lingual Transfer: Evidence from POS Tagging with over 100 Languages,['aclweb.org/ACL/ARR/2021/November/Paper1365/Authors'],['Anonymous'],"Cross-lingual transfer learning with large multilingual pre-trained models can be an effective approach for low-resource languages with no labeled training data. Existing evaluations of cross-lingual generalisability of large pre-trained models use datasets with English training data, and test data in a selection of target languages. We explore a more extensive transfer learning setup with 65 different source languages and 105 target languages for  part-of-speech tagging. Through our analysis, we show that pre-training of both source and target language, as well as matching language families, writing systems, word order systems, and lexical-phonetic distance significantly impact cross-lingual performance.",/pdf/c475291dd301844be3a83b1235c92fa38a416740.pdf,,,,,anonymous|make_the_best_of_crosslingual_transfer_evidence_from_pos_tagging_with_over_100_languages,,,,,,,,,
233,3kKspQxVa38,Direct parsing to sentiment graphs,['aclweb.org/ACL/ARR/2021/November/Paper1753/Authors'],['Anonymous'],"This paper demonstrates how a graph-based semantic parser can be applied to the task of structured sentiment analysis, directly predicting sentiment graphs from text. We advance the state of the art on 4 out of 5 standard benchmark sets. We release the source code, models and predictions with the camera-ready version.",/pdf/013a4634950087d8297b6834393292fc417ea185.pdf,/attachment/2e3daecb23619f3f65d13eb88f3d4a3862a2c69c.zip,,,,anonymous|direct_parsing_to_sentiment_graphs,,,,,,,,,
234,uMF63VjD7FF,Neighbour Contrastive Learning with Heterogeneous Graph Attention Networks on Short Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper2752/Authors'],['Anonymous'],"Graph neural networks (GNNs) have attracted extensive research interests in text classification tasks, due to their superiority in representation learning. However, most existing studies adopt the same semi-supervised learning setting as the vanilla Graph Convolution Network (GCN), which require a large amount of labelled data during training and thus are less robust when dealing with large-scale graph data with few labels. Additionally, graph structure information is normally captured by direct information aggregation via network schema and missing adjacency knowledge may hinder the performance. Addressing those problems, this paper proposes a novel method to learn graph structure, by using simple neighbour contrastive learning for an existing self-supervised heterogeneous graph neural network model (NC-HGAT). It considers the graph structure information from heterogeneous graphs with a multi-layer perceptrons (MLPs) and delivers consistent results, despite the corrupted neighbouring connections. Extensive experiments have been implemented on four benchmark short-text datasets, and demonstrate that our proposed model NC-HGAT outperforms the state-of-the-art methods on three datasets and achieves a competitive result on the remaining dataset.",/pdf/a4761556dfa148ba5e9988faf26eac20127bb960.pdf,,,,,anonymous|neighbour_contrastive_learning_with_heterogeneous_graph_attention_networks_on_short_text_classification,,,,,,,,,
235,usdBGTkuuEp,Enhancing Neural Machine Translation with Syntactic Ambiguities,['aclweb.org/ACL/ARR/2021/November/Paper1798/Authors'],['Anonymous'],"Benefiting from the data-driven end-to-end model architecture, neural machine translation has obvious performance advantages over statistical machine translation, but its demand for data is also significantly greater, including monolingual and parallel corpus. Most of the past studies have focused on reducing the demand for parallel corpus or making more effective use of limited parallel corpus. In this work, we have studied a method of using ambiguity of syntactic structure to achieve more effective use of monolingual corpus. Experiments conducted on multiple benchmarks for various languages show that our method has a greater improvement than the method using back-translation only, demonstrating the effectiveness of our proposed method.",/pdf/a46a84a1b10ed8bb2e637eba1da4548b0c1cbc87.pdf,,,,,anonymous|enhancing_neural_machine_translation_with_syntactic_ambiguities,,,,,,,,,
236,1-tfgu3G3Ga,Modeling Multidimensional Language Matrices to Learn Predictive Text,['aclweb.org/ACL/ARR/2021/November/Paper1373/Authors'],['Anonymous'],"The predictive text in the tray bed of the Chinese typewriter presents “Radiating style” and other important patterns, which reflect the main properties of the Chinese language. For a robot to understand these patterns like human’s “once glanced, never forgotten”, we construct multidimensional language matrices (MLM) to present the characters and/or words of predictive text for Chinese Natural Language Processing (NLP). Using 2D LM, our approach identified the core character as the prefix of radiating outward words, and as the suffix of radiating inward words to show the best distribution of the characters in a nine-grid. Using 3D LM, our approach, for robots doing as human, recognized the meaning and location of the words in a nine-grid by “Once learning mechanism”. Even though these approaches are proposed for the Chinese language, their methods are extendable to other languages.",/pdf/ac7cd2dbf3d1a6c3b1ba7adf5aae572bd8f9a820.pdf,/attachment/dbd39ab7972b34bcfc27a1e0bef5bb8fe195ad40.zip,,,,anonymous|modeling_multidimensional_language_matrices_to_learn_predictive_text,,,,,,,,,
237,kt6-xydKjf,A Comparison of the Validity of Measurement Methods for the General English Proficiency through Dictation and Read-Aloud Performances,['aclweb.org/ACL/ARR/2021/November/Paper952/Authors'],['Anonymous'],"This paper compares three measurement methods for the general proficiency of learners of English as a second language (GEP). If students’ GEP can be measured on course materials frequently, for instance, at the beginning and end of a semester, English teachers can confirm students’ levels of learning achievement. So far, English teachers have two options for GEP measurement: calculating scores for read-aloud or those of dictation performance. This study expands an option to measure GEP using both dictation and read-aloud performances. When comparing the three types of measurement methods, the experimental results suggest that GEP should be measured by calculating dictation and read-aloud performances.",/pdf/0c53379985e04721b908712d718f9fec08b328b7.pdf,,,,,anonymous|a_comparison_of_the_validity_of_measurement_methods_for_the_general_english_proficiency_through_dictation_and_readaloud_performances,,,,,,,,,
238,xOHDWpBSxfp,Vec2Node: Self-training with Tensor Augmentation for Text Classification with Few Labels,['aclweb.org/ACL/ARR/2021/November/Paper1366/Authors'],['Anonymous'],"Recent  advances  in  state-of-the-art  machine learning  models  like  deep  neural  networks heavily rely on large amounts of labeled training data which is difficult to obtain for many applications.  To address label scarcity, recent work has focused on data augmentation techniques  to  create  synthetic  training  data.    In this  work,  we  propose  a  novel  approach  of data augmentation leveraging tensor decomposition to generate synthetic samples by exploiting local and global information in text and reducing concept drift. We develop Vec2Node that leverages self-training from in-domain un-labeled data augmented with tensorized word embeddings  that  significantly  improves  over state-of-the-art  models,   particularly  in  low-resource settings.  For instance, with only 1% of labeled training data,Vec2Node obtains a 21.5% improvement over the base model with augmentation.  Furthermore,Vec2Node generates  interpretable  explanations  for  the  augmented data leveraging tensor embeddings",/pdf/88a14eb031ec9ec66929e5d6afed2a8ceb5ba627.pdf,/attachment/93fd03ca537aa52bd27e2255d2be53980b9698d4.zip,,,,anonymous|vec2node_selftraining_with_tensor_augmentation_for_text_classification_with_few_labels,,,,,,,,,
239,u-BLrzX2UnV,DS-TOD: Efficient Domain Specialization for Task-Oriented Dialog,['aclweb.org/ACL/ARR/2021/November/Paper2663/Authors'],['Anonymous'],"Recent work has shown that self-supervised dialog-specific pretraining on large conversational datasets yields substantial gains over traditional language modeling (LM) pretraining in downstream task-oriented dialog (TOD). These approaches, however, exploit general dialogic corpora (e.g., Reddit) and thus presumably fail to reliably embed domain-specific knowledge useful for concrete downstream TOD domains. In this work, we investigate the effects of domain specialization of pretrained language models (PLMs) for TOD. Within our DS-TOD framework, we first automatically extract salient domain-specific terms, and then use them to construct DomainCC and DomainReddit -- resources that we leverage for domain-specific pretraining, based on (i) masked language modeling (MLM) and (ii) response selection (RS) objectives, respectively. We further propose a resource-efficient and modular domain specialization by means of domain adapters -- additional parameter-light layers in which we encode the domain knowledge. Our experiments with prominent TOD tasks -- dialog state tracking (DST) and response retrieval (RR) -- encompassing five domains from the MultiWOZ benchmark demonstrate the effectiveness of DS-TOD. Moreover, we show that the light-weight adapter-based specialization (1) performs comparably to full fine-tuning in single domain setups and (2) is particularly suitable for multi-domain specialization, where besides advantageous computational footprint, it can offer better downstream performance.",/pdf/565cecbe7f72e42f453c2664aaabd0cf8e60e9ec.pdf,/attachment/bbb4bc865ba6d64abb8684bb2b9a8f6397a83710.zip,,,,anonymous|dstod_efficient_domain_specialization_for_taskoriented_dialog,,,,,,/attachment/7a56a07d67b068d3522265d8fa3b25cebf568025.zip,,,
240,TLDSZl0aq9X,Speaking Rationally by Gestures: Information Theoretic Insights from Multi-Modal Language Models,['aclweb.org/ACL/ARR/2021/November/Paper339/Authors'],['Anonymous'],"The multi-modality nature of human communication can be utilized to enhance the performance of computational language models. However, few studies have explored the non-verbal channels with finer theoretical lens. We use multi-modal language models trained against monologue video data to study how the non-verbal expression contributes to communication, by examining two aspects: first, whether incorporating gesture representations can improve the language model's performance (perplexity), and second, whether the gesture channel demonstrates the similar pattern of entropy rate constancy (ERC) found in verbal language, which is governed by Information Theory. We have positive results to support both assumptions. The conclusion is that speakers indeed use simple gestures to convey information that enhances verbal communication, and how this information is organized is a rational process. ",/pdf/242bbb11c2895e6cb39c11fe7fe66f3313403ccc.pdf,,,,,anonymous|speaking_rationally_by_gestures_information_theoretic_insights_from_multimodal_language_models,,,,,,,,,
241,OB-d5avJcBz,TABi: Type-Aware Bi-encoders for End-to-End Entity Retrieval,['aclweb.org/ACL/ARR/2021/November/Paper1540/Authors'],['Anonymous'],"Entity retrieval---retrieving information about entities in a query---is a core step in open-domain tasks, such as question answering or fact checking. However, state-of-the-art entity retrievers struggle to retrieve rare entities in queries.  There are two key challenges: (1) most retrievers are trained on unstructured text about entities and ignore structured data about entities that can be challenging to learn from text, such as entity types, and (2) methods that leverage structured types are not designed for end-to-end retrieval, which is necessary for open-domain tasks.  In this work, we introduce a method, TABi, to jointly train bi-encoders on unstructured text and structured types for end-to-end retrieval. TABi uses a type-enforced contrastive loss to encode type information in the embedding space and trains over datasets from multiple open-domain tasks to learn to retrieve entities. We demonstrate that this simple method can improve retrieval of rare entities on the AmbER sets, while maintaining strong overall performance on retrieval for open-domain tasks when compared to state-of-the-art retrievers. We also find that TABi produces embeddings that better capture types on a nearest neighbor type classification and an entity similarity task.",/pdf/8a7545e2627e8ed33c2dd1d7c200b54d3c06d5fd.pdf,,,,,anonymous|tabi_typeaware_biencoders_for_endtoend_entity_retrieval,,,,,,,,,
242,npVogfg9Vuw,What Makes Machine Reading Comprehension Questions Difficult? Investigating Variation in Passage Sources and Question Types,['aclweb.org/ACL/ARR/2021/November/Paper2318/Authors'],['Anonymous'],"For a natural language understanding benchmark to be useful in research, it has to consist of examples that are diverse and difficult enough to discriminate among current and near-future state-of-the-art systems.
However, we do not yet know how best to select passages to collect a variety of challenging examples.
In this study, we crowdsource multiple-choice reading comprehension questions for passages taken from seven qualitatively distinct sources, analyzing what attributes of passages contribute to the difficulty and question types of the collected examples.
To our surprise, we find that passage source, length, and readability measures do not significantly affect question difficulty.
Through our manual annotation of seven reasoning types, we observe several trends between passage sources and reasoning types, e.g., logical reasoning is more often required in questions written for technical passages.
These results suggest that when creating a new benchmark dataset, selecting a diverse set of passages can help ensure a diverse range of question types, but that passage difficulty need not be a priority.",/pdf/2dee32f5bc303e67bff5bc33e05ea3b132a3152f.pdf,,,,,anonymous|what_makes_machine_reading_comprehension_questions_difficult_investigating_variation_in_passage_sources_and_question_types,,,,,,,/attachment/d5fd78bc2b4f417ba4fb4b0df4d112597305518b.pdf,https://openreview.net/forum?id=kJob69ydIj-,/attachment/a1f49635b647373741d8cb2869d796f9abbcd05e.pdf
243,GEBVwhJbvsj,Discontinuous Constituency and BERT: A Case Study of Dutch,['aclweb.org/ACL/ARR/2021/November/Paper297/Authors'],['Anonymous'],"In this paper, we set out to quantify the syntactic capacity of BERT in the evaluation regime of non-context free patterns, as occurring in Dutch. We devise a test suite based on a mildly context-sensitive formalism, from which we derive grammars that capture the linguistic phenomena of control verb nesting and verb raising. The grammars, paired with a small lexicon, provide us with a large collection of naturalistic utterances, annotated with verb-subject pairings, that serve as the evaluation test bed for an attention-based span selection probe. Our results, backed by extensive analysis, suggest that the models investigated fail in the implicit acquisition of the dependencies examined.",/pdf/57c80f54aadfbda40a68838763c6154ee0cda14f.pdf,/attachment/f44f15365b144c6390cbf697d916596744413b8e.zip,,,,anonymous|discontinuous_constituency_and_bert_a_case_study_of_dutch,,,,,,/attachment/975b0ac7b678eb8f55e82f5b908176f718e4575a.zip,,,
244,T4q0_LdnUbX,A Graph-to-Sequence Model for Joint Intent Detection and Slot Filling in Task-Oriented Dialogue Systems,['aclweb.org/ACL/ARR/2021/November/Paper785/Authors'],['Anonymous'],"Effectively decoding semantic frames in task-oriented dialogue systems remains a challenge, which typically includes intent detection and slot filling. Although RNN-based neural models show promising results by jointly learning of these two tasks, dominant RNNs are primarily focusing on modeling sequential dependencies. Rich graph structure information hidden in the dialogue context is seldomly explored. In this paper, we propose a novel Graph-to-Sequence model to tackle the spoken language understanding problem by modeling both temporal dependencies and structural information in a conversation. We introduce a new Graph Convolutional LSTM (GC-LSTM) encoder to learn the semantics contained in the dialogue dependency graph by incorporating a powerful graph convolutional operator. Our proposed GC-LSTM can not only capture the spatio-temporal semantic features in a dialogue, but also learn the co-occurrence relationship between intent detection and slot filling. Furthermore, a LSTM decoder is utilized to perform final decoding of both slot filling and intent detection, which mutually improves both tasks through global optimization. Experiments on benchmark ATIS and Snips datasets show that our model achieves state-of-the-art performance and outperforms existing models.",/pdf/cb11554116e3993711535470c3305da86f5fa67b.pdf,,,,,anonymous|a_graphtosequence_model_for_joint_intent_detection_and_slot_filling_in_taskoriented_dialogue_systems,,,,,,,,,
245,u-g1ga9F6e-,SUPERB-SG: Enhanced Speech processing Universal PERformance Benchmark for Semantic and Generative Capabilities,['aclweb.org/ACL/ARR/2021/November/Paper1185/Authors'],['Anonymous'],"Transfer learning has proven to be crucial in advancing the state of speech and natural language processing research in recent years. In speech, a model pre-trained by self-supervised learning transfers remarkably well on multiple tasks. However, the lack of a consistent evaluation methodology is limiting towards a holistic understanding of the efficacy of such models. SUPERB was a step towards introducing a common benchmark to evaluate pre-trained models across various speech tasks. In this paper, we introduce SUPERB-SG, a new benchmark focusing on evaluating the semantic and generative capabilities of pre-trained models by increasing task diversity and difficulty over SUPERB. We use a lightweight methodology to test the robustness of representations learned by pre-trained models under shifts in data domain and quality across different types of tasks. It entails freezing pre-trained model parameters, only using simple task-specific trainable heads. The goal is to be inclusive of all researchers, and encourage efficient use of computational resources. We also show that the task diversity of SUPERB-SG coupled with limited task supervision is an effective recipe for evaluating the generalizability of model representation.",/pdf/917779dd930de7fef59eb355cf55032b495518e8.pdf,,,,,anonymous|superbsg_enhanced_speech_processing_universal_performance_benchmark_for_semantic_and_generative_capabilities,,,,,,,,,
246,rmjhxGnih0E,Pair-Based Joint Learning with Relational Graph Convolutional Networks for Emotion-Cause Pair Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1816/Authors'],['Anonymous'],"Emotion-cause pair extraction (ECPE) aims to extract the emotion clauses and the corresponding cause clauses, which have recently received more attention. Previous methods sequentially encode features with a specified order, which first encode the emotion and cause features for clause extraction and then combine them for pair extraction, leading to an imbalance in inter-task feature interaction where features extracted later have no direct contact with the former. To this end, we propose a novel joint encoding network, which generates pairs and clauses features simultaneously in a joint feature learning manner to model the causal relationship from clauses. Specifically, from a multi-relational perspective, we construct a heterogeneous undirected graph and apply the Relational Graph Convolutional Network (RGCN) to capture the complex relationship between clauses and the relationship between pairs and clauses. Experimental results show that our model achieves state-of-the-art performance on the Chinese benchmark corpus.",/pdf/e2ca0c16db686aec2809b432064467d47375134c.pdf,,,,,anonymous|pairbased_joint_learning_with_relational_graph_convolutional_networks_for_emotioncause_pair_extraction,,,,,,,,,
247,Vh1wS3tPa0a,A Primer in NMTology: What we have understood about NMT,['aclweb.org/ACL/ARR/2021/November/Paper319/Authors'],['Anonymous'],"Neural Machine Translation (NMT) has been through great revolutions in recent years. Accompanied with improvements in translation quality are works that attempted to understand the working mechanism of various aspects of the NMT framework. In our paper, we survey those efforts on unveiling the \textit{black box} of the standard NMT framework. To begin with, we briefly introduce the three critical components of the holistic NNT framework; nextly, we deliver a clear \textit{component-centric} categorization and clean summary of these specific works \textit{guided} by \textit{frequently-asked} questions (FAQs) that aim at making up \textit{lack} of understanding; finally, we discuss several limitations, future directions and inspirations. We believe this paper could facilitate the community to weave a holistic and clear picture of our current understandings of the standard NMT framework and shed light on its future improvements and developments. Please check this website https://nmtology.github.io/ for a visual guidance of the FAQs.",/pdf/29988cb6aa81cdde1a42fdb6cc27e5f2a9afa009.pdf,,,,,anonymous|a_primer_in_nmtology_what_we_have_understood_about_nmt,,,,,,,,,
248,5mD_WKOwu2,BufferSearch: Generating Black-Box Adversarial Texts With Lower Queries,['aclweb.org/ACL/ARR/2021/November/Paper471/Authors'],['Anonymous'],"Machine learning security has recently become a prominent topic in the natural language processing (NLP) area. The existing black-box adversarial attack suffers prohibitively from the high model querying complexity, resulting in easily being captured by anti-attack monitors. Meanwhile, how to eliminate redundant model queries is rarely explored. In this paper, we propose a query-efficient approach BufferSearch to effectively attack general intelligent NLP systems with the minimal number of querying requests. In general, BufferSearch makes use of historical information and conducts statistical test to avoid incurring model queries frequently. Numerically, we demonstrate the effectiveness of BufferSearch on various benchmark text-classification experiments by achieving the competitive attacking performance but with a significant reduction of query quantity. Furthermore,BufferSearch performs multiple times better than competitors within restricted query budget. Our work establishes a strong benchmark for the future study of query-efficiency in NLP  adversarial attacks. The source code is available at \url{https://tinyurl.com/buffersearch}.",/pdf/465c61f2aea3606617c037ecfadf30b1aabc6f89.pdf,,,,,anonymous|buffersearch_generating_blackbox_adversarial_texts_with_lower_queries,,,,,,/attachment/37701ea25d824074f57df5c390b91d99fe5f7fb0.zip,,,
249,_wHAe6eoT8,Do Pre-trained Models Benefit Knowledge Graph Completion? A Reliable Evaluation and a Reasonable Approach,['aclweb.org/ACL/ARR/2021/November/Paper2083/Authors'],['Anonymous'],"In recent years, pre-trained language models (PLMs) have been shown to capture factual knowledge from massive texts, which encourages the proposal of PLM-based knowledge graph completion (KGC) models. However, these models are still quite behind the SOTA KGC models in terms of performance. In this work, we find two main reasons for the weak performance: (1) Inaccurate evaluation setting. The evaluation setting under the closed-world assumption (CWA) may underestimate the PLM-based KGC models since they introduce more external knowledge; (2) Inappropriate utilization of PLMs. Most PLM-based KGC models simply splice the labels of entities and relations as inputs, leading to incoherent sentences that do not take full advantage of the implicit knowledge in PLMs. To alleviate these problems, we highlight a more accurate evaluation setting under the open-world assumption (OWA), which manual checks the correctness of knowledge that is not in KGs. Moreover, motivated by prompt tuning, we propose a novel PLM-based KGC model named PKGC. The basic idea is to convert each triple and its support information into natural prompt sentences, which is further fed into PLMs for classification. Experiment results on two KGC datasets demonstrate OWA is more reliable for evaluating KGC, especially on the link prediction, and the effectiveness of our PKCG model on both CWA and OWA settings.",/pdf/41db0fd66da8aeb8cecfe5cfa3882575dfc0c93d.pdf,,,,,anonymous|do_pretrained_models_benefit_knowledge_graph_completion_a_reliable_evaluation_and_a_reasonable_approach,,,,,,,,,
250,nfyLt7dQNJc,SuMe: A Dataset Towards Summarizing Biomedical Mechanisms,['aclweb.org/ACL/ARR/2021/November/Paper2624/Authors'],['Anonymous'],"Can language models read biomedical texts and explain the biomedical mechanisms discussed? In this work we introduce a biomedical mechanism summarization task. Biomedical studies often investigate the mechanisms behind how one entity (e.g., a protein or a chemical) affects another in a biological context. The abstracts of these publications often include a focused set of sentences that present relevant supporting statements regarding such relationships, associated experimental evidence, and a concluding sentence that summarizes the mechanism underlying the relationship. We leverage this structure and create a summarization task, where the input is a collection of sentences in an abstract and the output includes the main relationships and a natural language sentence that summarizes the mechanism. Using a small amount of manually labeled mechanism sentences, we train a mechanism sentence classifier to filter a large biomedical abstract collection and create a summarization dataset with 22k instances. We also introduce a pretraining conclusion generation task with 611k samples. Our benchmarking experiments with large language models show that the pretraining is helpful for the original task, but the model performance isn't still satisfactory and this task presents significant challenges in biomedical language understanding and summarization.",/pdf/68ead41b9d044646b260e62f84b321ee87076474.pdf,,,,,anonymous|sume_a_dataset_towards_summarizing_biomedical_mechanisms,,,,,,,,,
251,8FsctOOUuh7,Divide-and-Conquer Text Simplification by Scalable Data Enhancement,['aclweb.org/ACL/ARR/2021/November/Paper757/Authors'],['Anonymous'],"Text simplification, whose aim is to reduce reading difficulty, can be decomposed into four discrete rewriting operations: substitution, deletion, reordering, and splitting. However, due to a large distribution discrepancy between existing training data and human-annotated data, models may learn improper operations, thus lead to poor generalization capabilities. In order to bridge this gap, we propose a novel data enhancement method, Simsim, that generates training pairs by simulating specific simplification operations. Experiments show that the models trained with Simsim outperform multiple strong baselines and achieve the better SARI on the Turk and Asset datasets. The newly constructed dataset Simsim is available at *.",/pdf/00dd6ac4adaf032f05de666b7cd9fefee385fc0b.pdf,/attachment/c50e930843a4cb3576ce6a0c1f719d2df39667a7.zip,,,,anonymous|divideandconquer_text_simplification_by_scalable_data_enhancement,,,,,,/attachment/d83ae5ad8ac8a136b0406c4d513d6542425e9ceb.zip,,,
252,XhS7RljJqaN,A Legal Approach to Hate Speech – Operationalizing the EU’s Legal Framework against the Expression of Hatred as an NLP Task,['aclweb.org/ACL/ARR/2021/November/Paper246/Authors'],['Anonymous'],"We propose a ’legal approach’ to hate speech detection by operationalization of the decision as to whether a post is subject to criminal law into an NLP task. Comparing existing regulatory regimes for hate speech, we base our investigation on the European Union’s framework as it provides a widely applicable legal minimum standard. Accurately judging whether a post is punishable or not usually requires legal training. We show that, by breaking the legal assessment down into a series of simpler sub-decisions, even laypersons can annotate consistently. Based on a newly annotated dataset, our experiments show that directly learning an automated model of punishable content is challenging. However, learning the two sub-tasks of ‘target group’ and ‘targeting conduct’ instead of an end-to-end approach to punishability yields better results. Overall, our method also provides decisions that are more transparent than those of end-to-end models, which is a crucial point in legal decision-making.",/pdf/b002a7308b2f7edc02e22377b3d8cda6320ec886.pdf,,,,,anonymous|a_legal_approach_to_hate_speech_operationalizing_the_eus_legal_framework_against_the_expression_of_hatred_as_an_nlp_task,,,,,,/attachment/5194b14aea5d4274fade516f16770163acc30f61.zip,,https://openreview.net/forum?id=44kC8ypzww8,
253,lXczoncSyt0,On the Robustness of Reading Comprehension Models to Entity Renaming,['aclweb.org/ACL/ARR/2021/November/Paper2636/Authors'],['Anonymous'],"We study the robustness of machine reading comprehension (MRC) models to entity renaming---do models make more wrong predictions when answer entities have different names? Such failures imply that models overly rely on entity information to answer questions, and thus may generalize poorly when facts about the world change or questions are asked about novel entities. To systematically audit this issue, we present a general and scalable pipeline to replace entity names with names from a variety of sources, ranging from common English names to names from other languages to arbitrary strings. Across five datasets and three pretrained model architectures, MRC models consistently perform worse when entities are renamed, with particularly large accuracy drops on datasets constructed via distant supervision. We also find large differences between models: SpanBERT, which is pretrained with span-level masking, is more robust than RoBERTa, despite having similar accuracy on unperturbed test data. We further experiment with different masking strategies as the continual pretraining objective and find that entity-based masking can improve the robustness of MRC models.",/pdf/903f7312f470aba502b3516aae52ab185290b1fd.pdf,,,,,anonymous|on_the_robustness_of_reading_comprehension_models_to_entity_renaming,,,,,,/attachment/c004e41740a993cde45ea734c4352a06e864f852.zip,,,
254,LbSfoYEGQJW,The AI Doctor Is In: A Survey of Task-Oriented Dialogue Systems for Healthcare Applications,['aclweb.org/ACL/ARR/2021/November/Paper2171/Authors'],['Anonymous'],"Task-oriented dialogue systems in healthcare are increasingly common and have been characterized by diverse architectures and objectives. Although they have been surveyed in the medical community from a non-technical perspective, a systematic review from a rigorous computational perspective remains noticeably absent. This has resulted in limited knowledge of important implementation and replicability details, slowing the pace of innovation.  To fill this gap, we investigated an initial pool of 4070 papers from well-known computer science, natural language processing, and artificial intelligence venues, identifying 70 papers discussing the system-level implementation of task-oriented dialogue systems for healthcare applications. We comprehensively reviewed these papers, and present our key findings including identified gaps and corresponding recommendations.",/pdf/fa6edc272ede40c22eb0730974413ebb75f69e61.pdf,,,,,anonymous|the_ai_doctor_is_in_a_survey_of_taskoriented_dialogue_systems_for_healthcare_applications,,,,,,,/attachment/783fc37427395969c7e4e3be6fee8906ae56feb5.pdf,https://openreview.net/pdf?id=byOHhLq9Qn,/attachment/04646384fee52defbabbf8a95fb5edc94998d555.pdf
255,XDmaWzv2xFO,Simulating Bandit Learning from User Feedback for Extractive Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper1767/Authors'],['Anonymous'],"We study learning from user feedback for extractive question answering by simulating feedback using supervised data. We cast the problem as contextual bandit learning, and analyze the characteristics of several learning scenarios with focus on reducing data annotation. We show that systems initially trained on few examples can dramatically improve given feedback from users on model-predicted answers, and that one can use existing datasets to deploy systems in new domains without any annotation effort, but instead improving the system on-the-fly via user feedback.",/pdf/507b0ae356f7d5458555788774a0cc540fa54935.pdf,,,,,anonymous|simulating_bandit_learning_from_user_feedback_for_extractive_question_answering,,,,,,,,,
256,L4NfVyTwjhv,Good Night at 4 pm?! Time Expressions in Different Cultures,['aclweb.org/ACL/ARR/2021/November/Paper1564/Authors'],['Anonymous'],"We propose the task of culture-specific time expression grounding, i.e. mapping from expressions such as ""morning"" in English or ""Manhã"" in Portuguese to specific hours in the day. We propose 3 language-agnostic methods, one of which achieves promising results on gold standard annotations that we collected for a small number of languages. We then apply this method to 28 languages and analyze the similarities across languages in the grounding of time expressions. ",/pdf/645e33e61b2850cb3f3bcd9dd4451bc02a262c08.pdf,,,,,anonymous|good_night_at_4_pm_time_expressions_in_different_cultures,,,,,,,,,
257,bn3T-UIxrb7,Prompt-Guided Few-Shot Event Detection,['aclweb.org/ACL/ARR/2021/November/Paper1716/Authors'],['Anonymous'],"Practical applications of event extraction systems have long been hindered by their need for heavy human annotation. In order to scale up to new domains and event types, models must learn to cope with limited supervision, as in few-shot learning settings. To this end, the major challenge is to let the model master the semantic of event types, without requiring abundant event mention annotations. In our study, we employ cloze prompts to elicit event-related knowledge from pre-trained language models and further use event definitions and keywords to pinpoint the trigger word. By formulating the event detection task as an ""identify-then-localize"" procedure, we minimize the number of type-specific parameters, enabling our model to quickly adapt to event detection tasks for new types. Experiments on three event detection benchmark datasets (ACE, FewEvent, MAVEN) show that our proposed method performs favorably under fully supervised settings and surpasses existing few-shot methods by 16% F1 on the FewEvent dataset and 23% on the MAVEN dataset when only 5 examples are provided for each event type. ",/pdf/9ce3a17b4211813934f9bf9fc25a0c73463aed8f.pdf,,,,,anonymous|promptguided_fewshot_event_detection,,,,,,,,,
258,G6iaQp2d2S,Sense Embeddings are also Biased -- Evaluating Social Biases in Static and Contextualised Sense Embeddings,['aclweb.org/ACL/ARR/2021/November/Paper939/Authors'],['Anonymous'],"Sense embedding learning methods learn different embeddings for the different senses of an ambiguous word.
One sense of an ambiguous word might be socially biased while its other senses remain unbiased.
In comparison to the numerous prior work evaluating the social biases in pretrained word embeddings, the biases in sense embeddings have been relatively under studied.
In this paper, we create a benchmark dataset for evaluating the social biases in sense embeddings and propose novel sense-specific bias evaluation measures.
We conduct an extensive evaluation of multiple static and contextualised sense embeddings for various types of social biases using the proposed measures.
Our experimental results show that even in cases where no biases are found at word-level, there still exist worrying levels of social biases at sense-level, which are often ignored by the word-level bias evaluation measures.",/pdf/9215e853da2953770cb931bb0ef9241986a26d48.pdf,/attachment/87202fdf9fa4c9237d28b033cb3015699dd0f7d5.zip,,,,anonymous|sense_embeddings_are_also_biased_evaluating_social_biases_in_static_and_contextualised_sense_embeddings,,,,,,/attachment/6bde259aaea0f54cc20f30503c7f461a6145d128.zip,,None,
259,4zfWLKLrehI,Impact of Tokenization on Language Models: An Analysis for Turkish,['aclweb.org/ACL/ARR/2021/November/Paper312/Authors'],['Anonymous'],"Tokenization is an important text preprocessing step to prepare input tokens for language models. WordPiece and BPE are de-facto methods employed by large language models, such as BERT and GPT. However, the impact of tokenization can be different for the agglutinative languages having words with prefixes and suffixes, such as Turkic languages. We compare five tokenization methods, including a morphological-level tokenization that takes agglutinative language structure into account. We train tokenizers, and pre-train mini language models using RoBERTa pre-training procedure on Turkish OSCAR corpus. We then fine-tune our models on six downstream tasks. There are two main outcomes: (i) Morphological and word-level tokenizers outperform de-facto tokenizers in particular cases. (ii) Mini models can be competitive to larger state-of-the-art models, such that a 14-times smaller model can recover 94\% of the performance of a larger model.",/pdf/3ab4ae3517f4bb365428ee48d87231b1c45c59ba.pdf,,,,,anonymous|impact_of_tokenization_on_language_models_an_analysis_for_turkish,,,,,,,,,
260,5ah6h68B7pD,Clause Attention based on Signal Words Division,['aclweb.org/ACL/ARR/2021/November/Paper799/Authors'],['Anonymous'],"Clause Attention (CA) is very important for long sentences processing. We build and label datasets for signal word training. According to the position of signal word, the long sentences are divided into clauses which are assigned to additional block attention. The original sentence is mapped and fed into the shared encoder to learn the extraneous representation of words in its clause sentences. We use attention with prior to balance global attention with local attention. It improves the quality of long sentence processing in NER and NMT task.",/pdf/f17633e148f79ed5d1c3f5f8738427b0b377ed93.pdf,,,,,anonymous|clause_attention_based_on_signal_words_division,,,,,,,,,
261,n5NQ9GX-QPo,Are All the Datasets in Benchmark Necessary? A Pilot Study of Dataset Evaluation for Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper2154/Authors'],['Anonymous'],"In this paper, we ask the research question if all the datasets in the benchmark are necessary. We approach this by first characterizing the distinguishability of datasets when comparing different systems. Experiments on 9 datasets and 36 systems show that several existing benchmark datasets contribute little to discriminating top-scoring systems, while those less used datasets exhibit impressive discriminative power. We further, taking the text classification task as a case study, investigate the possibility of predicting dataset discrimination based on its properties (e.g., average sentence length). Our preliminary experiments promisingly show that given a sufficient number of training experimental records, a meaningful predictor can be learned to estimate dataset discrimination over unseen datasets. We released all related code at Github \url{https://github.com/annonnlp-demo/acl-V2} and a new benchmark dataset for text classification based on our observations.
",/pdf/04a2d6cf9050c7730e14a4f85fcffbcaec065736.pdf,/attachment/80ce0f7d6c32154c77e5a2232edc559ccf76031d.zip,,,,anonymous|are_all_the_datasets_in_benchmark_necessary_a_pilot_study_of_dataset_evaluation_for_text_classification,,,,,,/attachment/d066755c6a587b12bab5c94fb6913bd7f25c338f.zip,,,
262,1aP4JMLtay,The impact of lexical and grammatical processing on generating code from natural language,['aclweb.org/ACL/ARR/2021/November/Paper392/Authors'],['Anonymous'],"Considering the seq2seq architecture of Yin and Neubig (2018) for natural language to code translation, we identify four key components of importance: grammatical constraints, lexical preprocessing, input representations, and copy mechanisms. To study the impact of these components, we use a state-of-the-art architecture that relies on BERT encoder and a grammar-based decoder for which a formalization is provided. The paper highlights the importance of the lexical substitution component in the current natural language to code systems.",/pdf/95eb83b4410bbd52764b1ea7dd8389212d581031.pdf,,,,,anonymous|the_impact_of_lexical_and_grammatical_processing_on_generating_code_from_natural_language,,,,,,,,,
263,cL4tgY1ZxS,Simple yet Powerful: An Overlooked Architecture for Nested Named Entity Recognition,['aclweb.org/ACL/ARR/2021/November/Paper426/Authors'],['Anonymous'],"Named Entity Recognition (NER) is an important task in Natural Language Processing that aims to identify text spans belonging to predefined categories. Traditional NER research ignores nested entities, which are entities contained in other entity mentions. Although several methods have been proposed to address this case, most of them rely on complex task-specific structures and ignore potentially useful baselines for the task. We argue that this creates an overly optimistic impression of their performance. This paper revisits the Multiple LSTM-CRF (MLC) model, a simple, overlooked, yet powerful approach based on training independent sequence labeling models for each entity type. Extensive experiments with three nested NER corpora show that, regardless of the simplicity of this model, its performance is better or at least as well as more sophisticated methods. Furthermore, we show that the MLC architecture achieves state-of-the-art results in the Chilean Waiting List corpus by including pre-trained language models. In addition, we propose new task-specific metrics that adequately measure the ability of models to detect nestings. The results show that standard NER metrics do not measure well the ability of a model to detect nested entities, while our task-specific metrics provide new evidence on how existing approaches handle the task.",/pdf/2cfc2529ad7c991de9d1eca2d117ff3095928f5e.pdf,/attachment/9fceaa0e8999d3426c94866b083067f8567add76.zip,,,,anonymous|simple_yet_powerful_an_overlooked_architecture_for_nested_named_entity_recognition,,,,,,/attachment/adc20fcee5339482fd3dee5da94793970a1d534c.zip,,,
264,O2BGw7qupHl,ASSIST: Towards Label Noise-Robust Dialogue State Tracking,['aclweb.org/ACL/ARR/2021/November/Paper555/Authors'],['Anonymous'],"The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state tracking (DST). However, substantial noise has been discovered in its state annotations. Such noise brings about huge challenges for training DST models robustly. Although several refined versions, including MultiWOZ 2.1-2.4, have been published recently, there are still lots of noisy labels, especially in the training set. Besides, it is costly to rectify all the problematic annotations. In this paper, instead of improving the annotation quality further, we propose a general framework, named ASSIST (lAbel noiSe-robuSt dIalogue State Tracking), to train DST models robustly from noisy labels. ASSIST first generates pseudo labels for each sample in the training set by using an auxiliary model trained on a small clean dataset, then puts the generated pseudo labels and vanilla noisy labels together to train the primary model. We show the validity of ASSIST theoretically. Experimental results also demonstrate that ASSIST improves the joint goal accuracy of DST by up to $28.16\%$ on the initial version MultiWOZ 2.0 and $8.41\%$ on the latest version MultiWOZ 2.4, respectively. ",/pdf/d42b15ec3d122e8d7e7d873093c0c02872573f36.pdf,/attachment/2ddee80a0533f03e364e5317b05bccf0413a9070.zip,,,,anonymous|assist_towards_label_noiserobust_dialogue_state_tracking,,,,,,/attachment/4610a96fbb1224861ffd2bb3ec4e608bc0df0b54.zip,/attachment/b37734fef48983db7c9357267637769b29beea94.pdf,https://openreview.net/forum?id=sgmCcvG-3xH,/attachment/42b43334602ff8e16bbc941f8cd2317cd5398074.pdf
265,yfQLm836KC2,Detection and Mitigation of Political Bias in Natural Language Processing: A Survey,['aclweb.org/ACL/ARR/2021/November/Paper82/Authors'],['Anonymous'],"With the increasing importance of Natural Language Processing (NLP) tools, their implications on the propagation of societal biases become more and more relevant. In this context, the analysis of political bias in manually written and automatically generated text is a relatively understudied field. Political bias refers to the preference or prejudice towards one political ideology over another. To increase the discourse in this subject area, we analyse contemporary studies on detecting and mitigating political bias in this literature review. We further discuss benefits and potential drawbacks of the considered methods and look at the ethical considerations involved with political bias in NLP, before we give suggestions for future studies.",/pdf/7673fe763e3931e13d145087b026c5e8868a5427.pdf,,,,,anonymous|detection_and_mitigation_of_political_bias_in_natural_language_processing_a_survey,,,,,,,,,
266,dgdf3Wqz_HE,Continual Pre-training of Language Models for Math Problem Understanding with Syntax-Aware Memory Network,['aclweb.org/ACL/ARR/2021/November/Paper2252/Authors'],['Anonymous'],"Recently, pre-trained language models (PLMs) have shown effectiveness in domain transfer and task adaption. However, two major challenges limit the effectiveness of transferring PLMs into math problem understanding tasks. First, a math problem usually contains a textual description and formulas. The two types of information have a natural semantic gap. Second, textual and formula information is essential to each other, it is hard but necessary to deeply fuse the two types of information. To address these issues, we enrich the formula information by combining the syntax semantics of the text to construct the math syntax graph, and design the syntax-aware memory networks to deeply fuse the characteristics from the graph and text.  With the help of syntax relations, the token from the text can trace its semantic-related nodes within the formulas, which is able to capture the fine-grained correlations between text and formulas. Besides, we also devise three continual pre-training tasks to further align and fuse the representations of the text and graph. Experimental results on four tasks in the math domain demonstrate the effectiveness of our approach.",/pdf/ed34f55eefd1bb474fb67152fd66ecab8f16420b.pdf,,,,,anonymous|continual_pretraining_of_language_models_for_math_problem_understanding_with_syntaxaware_memory_network,,,,,,,,,
267,QVgQFjcOzaP,Learning to Learn Recognising Biomedical Entities from Multiple Domains with Task Hardness,['aclweb.org/ACL/ARR/2021/November/Paper2041/Authors'],['Anonymous'],"Few-shot learning has been a big challenge for many classification tasks, where the final classifier is trained only with a few examples. This problem amplifies when we apply the few-shot setup to recognising named entity from different domains, i.e., few-shot domain adaption for NER. In this paper, we present a simple yet effective MAML-based NER model that can effectively leverage the task hardness information to improve the adaptability of the learnt model in the few-shot setting. Experimental results on biomedical datasets show that our model can achieve significant performance improvement over the recently published MetaNER model.",/pdf/c8707ad9e07a6ad6398704a9b4b42773fb47ac21.pdf,,,,,anonymous|learning_to_learn_recognising_biomedical_entities_from_multiple_domains_with_task_hardness,,,,,,,,,
268,JorkR6sWwM,A Structured Semantic Reinforcement method for Task-Oriented Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper979/Authors'],['Anonymous'],"Recently, many BERT based approachs have been proposed for task-oriented dialogue (TOD) task. Despite their impressive performance, the insufficient utilization of deep semantic information and long-distance context understanding makes it difficult for these methods to digest complex dialogue scenarios for they cannot obtain sufficient evidence from dialogue data to support dialogue decision-making.
In this work, we propose a novel structured semantics reinforcement (SSR) method to handle these issues.
SSR reorganized the end-to-end TOD structure, which mainly includes two key components:
  1. The dialogue symbolic memory, which cache the objects mentioned in the dialogue and the structure under the semantic relationship.
  2. semantic projection module,  understanding module, based on the previous structured results, determines the source of the slot extraction required for the current task.
And our approach achieves state-of-the-art results on dataset MultiWOZ 2.1, where we acquire a joint goal accuracy beyond 60\% and also gains a significant effect on dataset DSTC8.",/pdf/30b09e33dc81782366c5f2a2f04d4d5f72075e81.pdf,,,,,anonymous|a_structured_semantic_reinforcement_method_for_taskoriented_dialogue,,,,,,,,,
269,cMso6FXqCi5,OrderSum: Reading Order-Aware Unsupervised Opinion Summarization,['aclweb.org/ACL/ARR/2021/November/Paper1110/Authors'],['Anonymous'],"Opinion summarization aims to create a concise summary reflecting subjective information conveyed by multiple user reviews about the same product. To avoid the high expense of curating golden summaries for training, many unsupervised methods have been recently developed. Most state-of-the-art methods utilize the extracted segments following their salience ranking as pseudo labels to train a summary generator. However, the extracted salient segments can be verbose and their reading order has been long overlooked. In this paper, we propose a reading order-aware framework, OrderSum, aiming to generate concise and logical summaries. Specifically, we first formulate the segment ordering problem in pseudo labels as path-choosing and solve it using reinforcement learning. Moreover, to generate a more concise summary, we propose to encourage the generative model to skip useless words based on the token link information derived from concise sentences, which can be collected easily from massive raw reviews by considering the ratio of sentiment/aspect words. Extensive experiments demonstrate that OrderSum benefits from the awareness of reading order and the conciseness modeling, thus being more effective than existing unsupervised methods and achieving the state-of-the-art performance.

",/pdf/91678144200b8b9639dc64c237fb3cce3c435e12.pdf,,,,,anonymous|ordersum_reading_orderaware_unsupervised_opinion_summarization,,,,,,,,,
270,W4ZeajjH2u9,Good Examples Make A Faster Learner: Simple Demonstration-based Learning for Low-resource NER,['aclweb.org/ACL/ARR/2021/November/Paper1439/Authors'],['Anonymous'],"Recent advances in prompt-based learning have shown strong results on few-shot text classification by using cloze-style templates.
Similar attempts have been made on named entity recognition (NER) which manually design templates to predict entity types for every text span in a sentence. However, such methods may suffer from error propagation induced by entity span detection, high cost due to enumeration of all possible text spans, and omission of inter-dependencies among token labels in a sentence. Here we present a simple demonstration-based learning method for NER, which lets the input be prefaced by task demonstrations for in-context learning. We perform a systematic study on demonstration strategy regarding what to include (entity examples, with or without surrounding context), how to select the examples, and what templates to use. Results on in-domain learning and domain adaptation show that the model's performance in low-resource settings can be largely improved with a suitable demonstration strategy (e.g., a 4-17% improvement on 25 train instances). We also find that good demonstration can save many labeled examples and consistency in demonstration contributes to better performance.",/pdf/f536c96dcfa8305a383ceac98966adf697bef183.pdf,/attachment/dcda9ca1a021386c705b18e339b763df1e7df38f.zip,,,,anonymous|good_examples_make_a_faster_learner_simple_demonstrationbased_learning_for_lowresource_ner,,,,,,/attachment/923e9aeb45242ab83fcf6885c30894a4b919578a.zip,,,
271,H3Fp5M4M8fO,Towards Collaborative Neural-Symbolic Graph Semantic Parsing via Uncertainty,['aclweb.org/ACL/ARR/2021/November/Paper813/Authors'],['Anonymous'],"Recent work in task-independent graph semantic parsing has shifted from grammar-based symbolic approaches to data-intensive neural approaches, and has shown strong performance on different types of meaning representations.  However, it is still unclear that what are the limitations of these neural parsers, and whether these limitations can be compensated by collaborating with symbolic parsers. In this paper, we attempt to answer these questions by taking English Resource Grammar (ERG) parsing as a case study. Specifically, we first develop a state-of-the-art neural ERG parser, and then conduct detailed analyses on fine-grained linguistic phenomena. The results suggest that the neural parser's performance degrades significantly on long-tail examples, while the symbolic parser performs more robustly. To address this, we further propose a collaborative neural-symbolic semantic parsing framework. Specifically, we improve the beam search strategy by designing a decision criterion that incorporates both the model uncertainty about the testing data distribution and the prior knowledge from a symbolic parser. Experimental results show that this collaborative parsing framework can outperform the single neural parser and concretely improve the model's performance on long-tail examples.",/pdf/edcb42859e802c12fcaced77507eb51e3a631663.pdf,,,,,anonymous|towards_collaborative_neuralsymbolic_graph_semantic_parsing_via_uncertainty,,,,,,,,,
272,NEo5KgVezju,Entailment Graph Learning with Textual Entailment and Soft Transitivity,['aclweb.org/ACL/ARR/2021/November/Paper805/Authors'],['Anonymous'],"Typed entailment graphs try to learn the entailment relations between predicates from text and model them as edges between predicate nodes. The construction of entailment graphs usually suffers from severe sparsity and unreliability of distributional similarity. We propose a two-stage method, Entailment Graph with Textual Entailment and Transitivity (EGT2). EGT2 learns the local entailment relations by recognizing the textual entailment between template sentences formed by typed CCG-parsed predicates. Based on the generated local graph, EGT2 then uses three novel soft transitivity constraints to consider the logical transitivity in entailment structures. Experiments on benchmark datasets show that EGT2 can well model the transitivity in entailment graph to alleviate the sparsity, and leads to signifcant improvement over current state-of-the-art methods.",/pdf/e36a1ef76ed5204ec20f6709c17167ec58702497.pdf,,,,,anonymous|entailment_graph_learning_with_textual_entailment_and_soft_transitivity,,,,,,,,,
273,dPyE06n12yX,Fair comparison of knowledge graphs for question answering,['aclweb.org/ACL/ARR/2021/November/Paper2972/Authors'],['Anonymous'],"Knowledge graphs are commonly used as sources of information in question answering. Models often combine pre-trained text encoders with a graph encoder to use this information to increase accuracy. However, the way that these two types of model interact is not clear. Here we show that, when provided with graph information for a random question, two recent models exhibit no significant change in performance. These models cannot therefore be used to obtain graph-structured explanations, or to compare the relevance of a particular knowledge graph to a dataset. We perform two model ablations and show that the resulting model is more responsive to variation in graph input, and so can be used for gathering explanations and measuring KG-dataset fit. We also show that uncontrollable nondeterminism can cause significant changes in results, and highlight the importance of statistical testing of these models.",/pdf/7439bea746d46227ce30d2b04b5d812dda1990ca.pdf,,,,,anonymous|fair_comparison_of_knowledge_graphs_for_question_answering,,,,,,,,,
274,bRVvxrjkLM,How do people talk about images? A study on open-domain conversation on images.,['aclweb.org/ACL/ARR/2021/November/Paper2788/Authors'],['Anonymous'],"Open-domain conversation on images requires the model to consider the relation and balance between utterances and images in order to generate proper responses. This paper explore how human conduct conversation on images by investigating a well-constructed open-domain image conversation dataset, ImageChat. We examine the conversations on images from three perspectives: $\textit{image relevancy}$, $\textit{image information}$ and $\textit{utterance style}$. We show that objects in the image are indeed the most important element for conversations on image, which could be directly discussed or be a bait to other off-image conversations. Thus, being able to accurately detect objects in the image and knowing their attributes are essential to chat on image. Understanding the scenarios of the image, except extracting the image objects, is also a key factor to the conversation on images. Based on our analysis, we propose to enriching the image information with image caption and object tags, increasing the diversity and image-relevancy of generated responses. We believe that our analysis provides useful insights and directions that facilitate future research on open-domain conversation on images.",/pdf/7e84d19cc805e3849fffb8cbd0c2adbbe9ae1941.pdf,,,,,anonymous|how_do_people_talk_about_images_a_study_on_opendomain_conversation_on_images,,,,,,,,,
275,EiosI2K6lU,Empirical Analysis of Training Strategies of Transformer-based Japanese Chit-chat Systems,['aclweb.org/ACL/ARR/2021/November/Paper2622/Authors'],['Anonymous'],"In recent years, several high-performance conversational systems have been proposed based on the Transformer encoder-decoder model.
Although previous studies analyzed the effects of the model parameters and the decoding method on subjective dialogue evaluations with overall metrics, they did not analyze how the differences of fine-tuning datasets affect on user's detailed impression. 
In addition, the Transformer-based approach has only been verified for English, not for such languages with large inter-language distances as Japanese.
In this study, we develop large-scale Transformer-based Japanese dialogue models and Japanese chit-chat datasets to examine the effectiveness of the Transformer-based approach for building chit-chat dialogue systems.
We evaluated and analyzed the impressions of human dialogues in different fine-tuning datasets, model parameters, and the use of additional information.",/pdf/4b643270e496aaac0d2e923e9f63519f15ee6d47.pdf,,,,,anonymous|empirical_analysis_of_training_strategies_of_transformerbased_japanese_chitchat_systems,,,,,,/attachment/b5671d4b4b1fb6e32c6b1fa35497c57b3e8343ab.zip,,,
276,6sMWYnBUWYR,CSL: A Large-scale Chinese Scientific Literature Dataset for Cross-task Evaluation,['aclweb.org/ACL/ARR/2021/November/Paper1011/Authors'],['Anonymous'],"Scientific literature serves as a high-quality corpus, which could provide natural annotated data for many natural language processing (NLP) research. In this work, we introduce a Chinese Scientific Literature dataset – CSL, which contains the titles, abstracts, keywords and academic fields of 400,000 papers. The rich semantic information in these scientific literature creates extensive NLP tasks and provides a natural cross-task scenario. Based on this, we present a cross-task few-shot benchmark. To evaluate the cross-task transferability of the model, we design scenarios with different aspects and difficulties. Compared with previous cross-task benchmarks, these tasks are constructed from homogeneous corpus, allowing researchers to investigate the relationships between tasks, without being disturbed by heterogeneous data sources, annotation, and other factors. We analyze the behavior of existing text-to-text models on the proposed benchmark, and reveal the challenges for cross-task generalization, which provides a valuable reference for future research. Code and data are publicly available at https://github.com/CSL-Dataset/CSL_Dataset.",/pdf/4ac021fa61f364d6cf73a14944b837bbd9782f10.pdf,/attachment/2bd55b1ab48b2a99258af4b2efa8b326b139de73.zip,,,,anonymous|csl_a_largescale_chinese_scientific_literature_dataset_for_crosstask_evaluation,,,,,,/attachment/3a6f001ac5fb2dde67516414d794f489442ea491.zip,,,
277,lMQ2TTkQo51,Sparsity Regularization for Chinese Spelling Check,['aclweb.org/ACL/ARR/2021/November/Paper6/Authors'],['Anonymous'],"The Chinese Spelling Check (CSC) research objective is to detect and correct the spelling errors in the input. Generally, the number of incorrect characters in the input is far less than the correct, so the error probability sequence of input sentence predicted by the detection module should be sparse and sharp. However, all existing work has ignored this problem. In this paper, we add a sparsity regularization item to the objective function to make the output of the detection module close to sparse and sharp. We study two kinds of regularization: L1  regularization and minimum entropy regularization. Extensive experiments on the SIGHAN show that the sparsity regularization proposed in this paper can effectively improve the performance of the CSC model while without increasing the computational complexity. In addition, the robustness experiment results show that our method is robust.",/pdf/d5a3c25695436e7f3c5e4feae79566653fdcafc1.pdf,,,,,anonymous|sparsity_regularization_for_chinese_spelling_check,,,,,,,,,
278,IbG4UNbtY_,Calibration of Machine Reading Systems at Scale,['aclweb.org/ACL/ARR/2021/November/Paper2816/Authors'],['Anonymous'],"
In typical machine learning systems, an estimate of the probability of the prediction is used to assess the system's confidence in the prediction.
This confidence measure is usually uncalibrated; i.e.\ the system's confidence in the prediction does not match the true probability of the predicted output.
In this paper, we present an investigation into calibrating open setting machine reading systems
such as open-domain question answering and claim verification systems.
We show that calibrating such complex systems which contain discrete retrieval and deep reading components is challenging and current calibration techniques fail to scale to these settings. 
We propose simple extensions to existing calibration approaches that allows us to adapt them to these settings.
Our experimental results reveal that the approach works well, and can be useful to selectively predict answers when question answering systems are posed with unanswerable or out-of-the-training distribution questions.",/pdf/7636f8d4be548dd6a4de911459ee87627389cb8f.pdf,,,,,anonymous|calibration_of_machine_reading_systems_at_scale,,,,,,,,,
279,DkbUnKnnKVk,"Contextualized Sensorimotor Norms: multi-dimensional measures of sensorimotor strength for ambiguous English words, in context",['aclweb.org/ACL/ARR/2021/November/Paper1311/Authors'],['Anonymous'],"Most large language models are trained on linguistic input alone, yet humans appear to ground their understanding of words in sensorimotor experience. A natural solution is to augment LM representations with human judgments of a word's sensorimotor associations (e.g., the Lancaster Sensorimotor Norms), but this raises another challenge: most words are ambiguous, and judgments of words in isolation fail to account for this multiplicity of meaning (e.g., ""wooden table"" vs. ""data table"". We attempted to address this problem by building a new lexical resource of contextualized sensorimotor judgments for 112 English words, each rated in four different contexts (448 sentences total). We show that these ratings encode overlapping but distinct information from the Lancaster Sensorimotor Norms, and that they also predict other measures of interest (e.g., relatedness), above and beyond measures derived from BERT. ",/pdf/28f3b9d139a254d535b3a4b6dffd59e72064069a.pdf,,,,,anonymous|contextualized_sensorimotor_norms_multidimensional_measures_of_sensorimotor_strength_for_ambiguous_english_words_in_context,,,,,,/attachment/3890d109efe0e9bef6b2009d39bf172755066ad0.zip,,,
280,0gYkM3fk9Bb,Distantly Supervised Named Entity Recognition via Confidence-Based Multi-Class Positive and Unlabeled Learning,['aclweb.org/ACL/ARR/2021/November/Paper430/Authors'],['Anonymous'],"In this paper, we study the named entity recognition (NER) problem under distant supervision. Due to the incompleteness of the external dictionaries and/or knowledge bases, such distantly annotated training data usually suffer from a high false negative rate. To this end, we formulate the Distantly Supervised NER (DS-NER) problem via Multi-class Positive and Unlabeled (MPU) learning and propose a theoretically and practically novel CONFidence-based MPU (Conf-MPU) approach. To handle the incomplete annotations, Conf-MPU consists of two steps. First, a confidence score is estimated for each token of being an entity token. Then, the proposed Conf-MPU risk estimation is applied to train a multi-class classifier for the NER task. Thorough experiments on two benchmark datasets labeled by various external knowledge demonstrate the superiority of the proposed Conf-MPU over existing DS-NER methods.",/pdf/da915954d539186a5b2fb7d935631ba51a1ca7e8.pdf,/attachment/84604dc001283a993c8b31cc49c94f0aa7b9f045.zip,,,,anonymous|distantly_supervised_named_entity_recognition_via_confidencebased_multiclass_positive_and_unlabeled_learning,,,,,,/attachment/5bab13aa15812fb6a12ab08b20e6c99a9eaca831.zip,,,
281,mwqdoc4kCp-,Compositional Data Augmentation for Abstractive Conversation Summarization,['aclweb.org/ACL/ARR/2021/November/Paper1367/Authors'],['Anonymous'],"Recent abstractive conversation summarization systems generally rely on large-scale annotated summaries. However, collecting conversations and annotating their corresponding summaries can be time-consuming and labor-intensive. To alleviate the data scarcity issue, in this work, we present a simple yet effective compositional data augmentation method, Compo, for generating diverse and high-quality pairs of conversations and summaries. Specifically, we generate novel conversation and summary pairs through first extracting conversation snippets and summary sentences based on conversation stages and then randomly composing them constrained by the temporal relation and semantic similarities. To deal with the noises in the augmented data, we further utilize knowledge distillation to learn concise representation from a teacher model trained on high-quality data. Extensive experiments on benchmark datasets demonstrate that Compo significantly outperforms prior state-of-the-art baselines in terms of both quantitative and qualitative evaluation, and exhibits a reasonable level of interpretability.",/pdf/d7f2cceac9ef0a42f44a7fcaf23f6ad603d14498.pdf,/attachment/3bf92d91f525df08f089c63c8a1ace92fae7e655.zip,,,,anonymous|compositional_data_augmentation_for_abstractive_conversation_summarization,,,,,,,,,
282,1BTmXDgdEVp,Mental Health Assessment for the Chatbots,['aclweb.org/ACL/ARR/2021/November/Paper1600/Authors'],['Anonymous'],"Previous researches on dialogue system assessment usually focus on the quality evaluation (e.g. fluency, relevance, etc) of responses generated by the chatbots, which are local and technical metrics. For a chatbot which responds to millions of online users including minors, we argue that it should have a healthy mental tendency in order to avoid the negative psychological impact on them. In this paper, we establish several mental health assessment dimensions for chatbots (depression, anxiety, alcohol addiction, empathy) and introduce the questionnaire-based mental health assessment methods. We conduct assessments on some well-known open-domain chatbots and find that there are severe mental health issues for all these chatbots. We consider that it is due to the neglect of the mental health risks during the dataset building and the model training procedures. We expect to attract researchers' attention to the serious mental health problems of chatbots and improve the chatbots' ability in positive emotional interaction.",/pdf/6747cf0e84f0795d5deeb0dfb71ab7c5ea9b0dc2.pdf,,,,,anonymous|mental_health_assessment_for_the_chatbots,,,,,,,,,
283,FEg_0BrW4Ks,CQARE: Contrastive Question-Answering for Few-shot Relation Extraction with Prompt Tuning,['aclweb.org/ACL/ARR/2021/November/Paper2695/Authors'],['Anonymous'],"Prompt tuning with pre-trained language models (PLM) has exhibited outstanding performance by closing the gap between pre-training tasks and various downstream applications, without the need for uninitialized parameters to be introduced. However, prompt tuning requires vast amounts of prompt engineering and predefined label word mapping, which obstructs its implements in practice. Besides, the ample label space makes prompt tuning more arduous and challenging when it comes to relation extraction (RE). To tackle these issues, we propose a Contrastive Question-Answering method with prompt tuning for few-shot RE (CQARE). CQARE carries out a RE task-specific pre-training with four entity-relation-aware pre-training objects, including a prompt pre-training to automatically generate continuous prompts. The proposed pre-training can provide more robust initialization with prompt tuning while maintaining semantic consistency with the proposed PLM. Furthermore, CQARE can effectively avoid label words mapping by reformulating RE as contrastive question answering. The results indicate CQARE raising averaged accuracy of 5.11\% on a cross-domain few-shot dataset, demonstrating that robust initialization is crucial for prompt tuning and effective contrastive question answering.",/pdf/b2a74c585069ed0301a50f4c7111bb866a57d826.pdf,,,,,anonymous|cqare_contrastive_questionanswering_for_fewshot_relation_extraction_with_prompt_tuning,,,,,,,,,
284,i6sPAdxEnZ,A Multilingual Corpus for Socio-political Event Coreference Resolution,['aclweb.org/ACL/ARR/2021/November/Paper2781/Authors'],['Anonymous'],"We propose a dataset for event coreference resolution, which is based on random samples drawn from multiple sources, languages, and countries. Early scholarship on event information collection has not quantified the contribution of event coreference resolution. We prepared and analyzed a representative multilingual corpus and measured the performance and contribution of the state-of-the-art event coreference resolution approaches. We found that almost half of the event mentions in documents co-occur with other event mentions and this makes it inevitable to obtain erroneous or partial event information. We showed that event coreference resolution could help improving this situation. Our contribution sheds light on a challenge that has been overlooked or hard to study to date. Future event information collection studies can be designed based on the results we present in this report.",/pdf/06f05fc321b2c0022879e05d76c64163d2c5154d.pdf,/attachment/b6efa6f66033195355b29ece2474fc0444f89dee.zip,,,,anonymous|a_multilingual_corpus_for_sociopolitical_event_coreference_resolution,,,,,,/attachment/61c8764e03908a02eba86ec085af3a3785b3bf7c.zip,,,
285,p1MGE4DZi0d,Sharper Reasons: Argument Mining Leveraged with Confluent Knowledge,['aclweb.org/ACL/ARR/2021/November/Paper285/Authors'],['Anonymous'],"Relevant to all application domains where it is important to get at the reasons underlying decisions and sentiments, argument mining seeks to obtain structured arguments from unstructured text and has been addressed recently by approaches typically involving some feature and/or neural architecture engineering.

By embracing a transfer learning viewpoint, the aim of this paper is to empirically assess the potential of transferring knowledge learned with confluent tasks to argument mining by means of a systematic study with a wide range of sources of related knowledge possibly suitable to leverage argument mining.

This permitted to gain new empirically based insights into the argument mining task while establishing also new state of the art levels of performance for the three main sub-tasks in argument mining, viz. identification of argument components, classification of the components, and determination of the relation among them, with a leaner approach that dispenses with heavier feature and model engineering.",/pdf/3bf1a86020b37280b1883dfa208655122b41a479.pdf,,,,,anonymous|sharper_reasons_argument_mining_leveraged_with_confluent_knowledge,,,,,,,,,
286,Ee9nZGl2MQ,Eye Gaze and Self-attention: How Humans and Transformers Attend Words in Sentences,['aclweb.org/ACL/ARR/2021/November/Paper437/Authors'],['Anonymous'],"Attention mechanisms are used to describe human reading processes and natural language processing by transformer neural networks. On the surface, attention appears to be very different under these two contexts. However, this paper presents evidence that there are links between the two during reading tasks.

During reading, the dwell times of human eye movements were strongly correlated with the attention patterns occurring in the early layers of pre-trained transformers such as BERT. Furthermore, we explored what factors lead to variations in these correlations and observed that data were more correlated when humans read for comprehension than when they were searching for specific information. Additionally, the strength of a correlation was not related to number of parameters within a transformer.",/pdf/e7ab6eadea65d8ca722084f1ee34525d68d5909d.pdf,,,,,anonymous|eye_gaze_and_selfattention_how_humans_and_transformers_attend_words_in_sentences,,,,,,/attachment/d84ab9610bde93620c05b438fd9107908d4e5270.zip,,,
287,DXbxULpbXZ4,Unsupervised Chinese Word Segmentation with BERT Oriented Probing and Transformation,['aclweb.org/ACL/ARR/2021/November/Paper173/Authors'],['Anonymous'],"Word Segmentation is a fundamental step for understanding Chinese language. Previous neural approaches for unsupervised Chinese Word Segmentation (CWS) only exploits shallow semantic information, which can miss important context. Large scale Pre-trained language models (PLM) have achieved great success in many areas because of its ability to capture the deep contextual semantic relation. In this paper, we propose to take advantage of the deep semantic information embedded in PLM (e.g., BERT) with a self-training manner,  which iteratively probes and transforms the semantic information in PLM into explicit word segmentation ability. Extensive experiment results show that our proposed approach achieves state-of-the-art F1 score on  two CWS benchmark datasets. ",/pdf/218b01dd611a7cd6fd24bd6d0808129a2815daf4.pdf,/attachment/eaae0df187ef3f1af89385c2b71e0192195816dd.zip,,,,anonymous|unsupervised_chinese_word_segmentation_with_bert_oriented_probing_and_transformation,,,,,,/attachment/84f0e1a1c59770492ff6ef447069048fd4714a56.zip,,,
288,IDGRssQIu6X,Bidirectional Modeling for Simultaneous Neural Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper2460/Authors'],['Anonymous'],"Simultaneous Neural Machine Translation (SimulNMT) generates the output before the entire input sentence is available and only uses the unidirectional attention from left-to-right so that its decoding highly relies on future forecast according to word ordering rules. However, it is utopian that the word order strictly obeys the grammar rules in a language, especially in oral. To address the mismatch between SimulNMT expecting strict word order and free word order in real scenario, we propose a bidirectional modeling. In detail, we train another backward model where the input sentence is from right-to-left and keep the target sentence from left-to-right. Then we join this backward model into the standard forward SimulNMT model during decoding. This strategy enhances the robustness of SimulNMT and empowers the model to be more adaptable for the inconstant word ordering phenomenon. Experiments show that our method brings improvement over the strong baselines.",/pdf/5556c877452412ec431bd930f03dde92b5ebbec5.pdf,,,,,anonymous|bidirectional_modeling_for_simultaneous_neural_machine_translation,,,,,,,,,
289,HLw5GosG4fb,S$^4$-Tuning: A Simple Cross-lingual Sub-network Tuning Method,['aclweb.org/ACL/ARR/2021/November/Paper768/Authors'],['Anonymous'],"The emergence of multilingual pre-trained language models makes it possible to adapt to target languages with only few labeled examples.
However, vanilla fine-tuning tends to achieve degenerated and unstable results, owing to the  Language Interference among different languages, and Parameter Overload under the few-sample transfer learning scenarios.
To address two problems elegantly, we propose S$^4$-Tuning, a Simple Cross-lingual Sub-network Tuning method. 
S$^4$-Tuning first detects the most essential sub-network for each target language, and only updates it during fine-tuning.
In this way, the language sub-networks lower the scale of trainable parameters, and hence better suit the low-resource scenarios.
Meanwhile, the commonality and characteristics across languages are modeled by the overlapping and non-overlapping parts to ease the interference among languages.
Simple but effective, S$^4$-Tuning gains consistent improvements over vanilla fine-tuning on three multi-lingual tasks involving 37 different languages in total (XNLI, PAWS-X, and Tatoeba).",/pdf/d70532a73921c5b6863d7b838312fb15ccfd7d47.pdf,,,,,anonymous|s^4tuning_a_simple_crosslingual_subnetwork_tuning_method,,,,,,,,,
290,GHB9zPiVfOk,Robust and Effective Grammatical Error Correction with Simple Cycle Self-Augmenting,['aclweb.org/ACL/ARR/2021/November/Paper3006/Authors'],['Anonymous'],"Recent studies have revealed that grammatical error correction methods in the sequence-to-sequence paradigm are vulnerable to adversarial attack, and simply utilizing adversarial examples in the pre-training or post-training process can significantly enhance the robustness of GEC models to certain types of attack without suffering too much performance loss on clean data. In this paper, we further conduct a thorough robustness evaluation of cutting-edge GEC methods to four different types of adversarial attacks and propose a simple yet very effective Cycle Self-Augmenting (CSA) method accordingly. By leveraging the augmenting data from the GEC models themselves in the post-training process and introducing regularization data for cycle training, our proposed method can effectively improve model robustness of well-trained GEC models with only a few more training epochs as the extra cost. Experiments on four benchmark datasets and seven strong models indicate that our proposed training method can significantly enhance the robustness to four types of attacks without using purposely built adversarial examples in training. Evaluation results on clean data further confirm that our proposed CSA method significantly improves the performance of four baselines and yields nearly comparable results with other state-of-the-art models. Our code is available in the supplementary .zip file, which will be released after the anonymous period.",/pdf/ba93f52ab5829fa29f55f25c213f13056b3f629f.pdf,/attachment/3a84599b72d7751f4fe09578425a3307ed0e2bc0.zip,,,,anonymous|robust_and_effective_grammatical_error_correction_with_simple_cycle_selfaugmenting,,,,,,,,,
291,cSYOakZR4m-,SOS: Systematic Offensive Stereotyping Bias in Word Embeddings,['aclweb.org/ACL/ARR/2021/November/Paper1340/Authors'],['Anonymous'],"Hate speech detection models aim to provide a safe environment for marginalised social groups to express themselves. However, the bias in these models could lead to silencing those groups. In this paper, we introduce the systematic offensive stereotyping (SOS) bias. We propose a method to measure the SOS bias in different word embeddings and also investigate its influence on the downstream task of hate speech detection. Our results show that SOS bias against various groups exists in widely used word embeddings and that our SOS bias metric correlates positively with the statistics of published surveys on online abuse and \added[id=fa]{extremism}. However, we found that it is not easy to prove that bias in word embeddings influences downstream task performance. Finally, we show that SOS bias is more indicative of sexism and racism in the inspected word embeddings when used for sexism and racism detection than social biases.",/pdf/0067f3c2b3b6e0fec9e8124a5ca743e7364f6411.pdf,,,,,anonymous|sos_systematic_offensive_stereotyping_bias_in_word_embeddings,,,,,,,/attachment/3742648041996e454240a5e6967ec79206b6fb8a.pdf,https://openreview.net/forum?id=i7DhBQrfi-e,/attachment/ba90b2152e5c9745bd2c79f0a05e1bab3f45698f.pdf
292,Qgc_nVbdnFr,Schema-Free Dependency Parsing via Sequence Generation,['aclweb.org/ACL/ARR/2021/November/Paper2040/Authors'],['Anonymous'],"Dependency parsing aims to extract syntactic dependency structure or semantic dependency structure for sentences. Existing methods suffer the drawbacks of lacking universality or highly relying on the auxiliary decoder. To remedy these drawbacks, we propose to achieve universal and schema-free Dependency Parsing (DP) via Sequence Generation (SG) DPSG by utilizing only the pre-trained language model (PLM) without any auxiliary structures or parsing algorithms. We first explore different serialization designing strategies for converting parsing structures into sequences. Then we design dependency units and concatenate these units into the sequence for DPSG. Thanks to the high flexibility of the sequence generation, our DPSG can achieve both syntactic DP and semantic DP using a single model. By concatenating the prefix to indicate the specific schema with the sequence, our DPSG can even accomplish the multi-schemata parsing. The effectiveness of our DPSG is demonstrated by the experiments on widely used DP benchmarks, i.e., PTB, CODT, SDP15, and SemEval16. DPSG achieves comparable results with the first-tier methods on all the benchmarks and even the state-of-the-art (SOTA) performance in CODT and SemEval16. This paper demonstrates our DPSG has the potential to be a new parsing paradigm. We will release our codes upon acceptance.",/pdf/c35f42802f6adf86e7dbe01a8ffa019ecd7bfc09.pdf,/attachment/b278f351585176411485acc8026248333257a8b5.zip,,,,anonymous|schemafree_dependency_parsing_via_sequence_generation,,,,,,/attachment/3bde209aa2751309e8ffed540e3b72c3a26f36d6.zip,,,
293,FijPbZc7RUa,Greek Forced Alignment: Assessing the Accuracy of the Montreal Forced Aligner,['aclweb.org/ACL/ARR/2021/November/Paper1609/Authors'],['Anonymous'],Forced alignment has allowed for the rapid creation and annotation of corpora. In this study we examine the Montreal Foreced Aligner and its accuracy of aligning Greek data. Using a conversational Greek corpus we train a small grapheme-to-phoneme model and use this model to align the entire corpus. We compare our results to various previous studies of the MFA and other forced alignment software and conclude that forced alignment greatly increases the ability to create new corpora for low-resource and understudied languages.,/pdf/2069d2ba9f44af7061ff4ee9818a4af7b9b36483.pdf,/attachment/c5af29f39515f53cdef6ca873bf387759703a8c0.zip,,,,anonymous|greek_forced_alignment_assessing_the_accuracy_of_the_montreal_forced_aligner,,,,,,/attachment/055b4c995f12e32eecfac289ef44b9bfb46348d5.zip,,,
294,8u9t73N5_K,Using Structured Content Plans for Fine-grained Syntactic Control in Pretrained Language Model Generation,['aclweb.org/ACL/ARR/2021/November/Paper2686/Authors'],['Anonymous'],"Large pretrained language models offer powerful generation capabilities, but suffer from a lack of interpretability and fine-grained control. We propose an approach to fine-grained control in generating  text directly from a semantic representation, Abstract Meaning Representation (AMR) by augmenting the nodes with syntactic tags. We experiment with English-language generation of three modes of syntax relevant to the framing of a sentence - verb voice (active or passive), verb tense, and realization of human entities - and demonstrate that they can be reliably controlled. Controlling how information is framed is important for applications such as summarization, which aim to highlight salient information.",/pdf/35120b87ba39cf5ab1e30a82b6e7bc1f9fdf2b7f.pdf,,,,,anonymous|using_structured_content_plans_for_finegrained_syntactic_control_in_pretrained_language_model_generation,,,,,,,,,
295,7-oqq8EX6fn,Can Neural Networks Understand Programs like Humans?,['aclweb.org/ACL/ARR/2021/November/Paper876/Authors'],['Anonymous'],"Program understanding is a fundamental task in program language processing. Despite the success, existing works fail to take human minds as reference in understanding programs. In this paper, we incorporate human minds and propose the PGNN-EK model that consists of two main components. On the one hand, inspired by the “divide-and-conquer” reading behaviours of humans, we present a partitioning-based graph neural network model PGNN on the upgraded AST of codes. On the other hand, to characterize human minds of resorting to other resources to help code comprehension, we transform raw codes with external knowledge and apply pre-training techniques for information extraction. Finally, we combine the two embeddings generated from the two components to output code embeddings. We conduct extensive experiments to show the superior performance of PGNN-EK on the code summarization and code clone detection tasks. In particular, to show the generalization ability of our model, we release a new dataset that is more challenging for code clone detection and could advance the development of the community. Our codes and data are publicly available at https://github.com/anonymousforpaper1997/PGNN-EK.",/pdf/953404692e583f992db02ca02ea514010dddc84b.pdf,/attachment/3e90aa6d2769c3de40620e5fc280f30dcf60caee.zip,,,,anonymous|can_neural_networks_understand_programs_like_humans,,,,,,,,,
296,XwXnMY4djH0,Self-supervised Schema Induction for Task-oriented Dialog,['aclweb.org/ACL/ARR/2021/November/Paper1592/Authors'],['Anonymous'],"Hand-crafted schemas describing how to collect and annotate dialog corpora are a prerequisite towards building task-oriented dialog systems. In practical applications, manually designing schemas can be error-prone, laborious, iterative, and slow, especially when the schema is complicated. To automate this process, we propose a self-supervised approach for schema induction from unlabeled dialog corpora. Our approach utilizes representations provided by in-domain language models constrained on unsupervised structures, followed by multi-step coarse-to-fine clustering. We compare our method against several strong supervised baselines, and show significant performance improvement in schema induction on MultiWoz and SGD datasets. We also demonstrate the effectiveness of induced schemas on downstream tasks including dialog state tracking and response generation.",/pdf/00be20204c344fc3a03a6fe30f962e9eef7bdc28.pdf,/attachment/d1615f0c6960b42e183222802158fec615149327.zip,,,,anonymous|selfsupervised_schema_induction_for_taskoriented_dialog,,,,,,,,,
297,DIoZjaguhLj,"""You might think about slightly revising the title"": identifying hedges in peer-tutoring interactions",['aclweb.org/ACL/ARR/2021/November/Paper2720/Authors'],['Anonymous'],"Hedges have an important role in the management of rapport. In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.
Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.",/pdf/90303ff97465ee52268300fbbac7542ec55323b5.pdf,,,,,anonymous|you_might_think_about_slightly_revising_the_title_identifying_hedges_in_peertutoring_interactions,,,,,,,,,
298,6DFjJLNtXCx,Looking Into the Black Box - How Are Idioms Processed in BERT?,['aclweb.org/ACL/ARR/2021/November/Paper1549/Authors'],['Anonymous'],"Idioms such as ``call it a day'' and ``piece of cake'' are frequent in natural language. How are they processed by language models such as BERT? This study investigates this question with two experiments: (1) an analysis of embedding similarities of idiomatic sentences and their literal Spelled-out counterparts across all layers, and (2) an analysis of the word embeddings when the word appears in an idiomatic versus literal context across all layers. Experiment 1 shows that the embeddings of an Idiom sentence and its Spelled-out counterpart become more similar across the layers. When compared to random controls, layer 8 is where the Spelled-out counterpart is ranked highest in embedding similarity. Experiment 2 shows that the embedding of single words in idiomatic versus literal contexts diverge and become the most different in layer 8. Overall, the study suggests that BERT ``understands'' idiomatic expressions even without context, and that it processes them more akin to a syntactic feature than purely a semantic one.",/pdf/998fd51bcf6461b515114671f9ad3b5afdbc3894.pdf,,,,,anonymous|looking_into_the_black_box_how_are_idioms_processed_in_bert,,,,,,,,,
299,qp5bKE07P8,DialogConv: A Lightweight Fully Convolutional Network for Multi-view Response Selection,['aclweb.org/ACL/ARR/2021/November/Paper2315/Authors'],['Anonymous'],"Current end-to-end retrieval-based dialogue systems are primarily based on Recurrent Neural Networks or Transformers with attention mechanisms. Despite promising results have been achieved, these models usually suffer from slow inference speed or an enormous amount of parameters. In this paper, we propose a novel lightweight fully convolutional architecture called DialogConv for the response selection. DialogConv is built exclusively on convolutions for distilling the matching features of context and response. The dialogue is modeled in a 3D view, where DialogConv conducts convolution operations on embedding dimension, word dimension and utterance dimension iteratively to capture richer semantic information from a multi-view of context. On four benchmark datasets, DialogConv is approximately 4.0x smaller and up to 27x faster in inference compared with strong baselines. Moreover, DialogConv can achieve competitive performance results on four public datasets.",/pdf/da036ea773b6fee6303c847f591585ffccb48c6a.pdf,/attachment/a41b8fe46abfac9fad165f6d1be6f6471260704d.zip,,,,anonymous|dialogconv_a_lightweight_fully_convolutional_network_for_multiview_response_selection,,,,,,,,,
300,4CwYXIpRYe0,CCQA: A New Web-Scale Question Answering Dataset for Model Pre-Training,['aclweb.org/ACL/ARR/2021/November/Paper67/Authors'],['Anonymous'],"We propose a novel open-domain question-answering dataset based on the Common Crawl project. With a previously unseen number of around 130 million multilingual question-answer pairs (including about 60 million English data-points), we use our large-scale, natural, diverse and high-quality corpus to in-domain pre-train popular language models for the task of question-answering. In our experiments, we find that our Common Crawl Question Answering dataset (CCQA) achieves promising results in zero-shot, low resource and fine-tuned settings across multiple tasks, models and benchmarks.",/pdf/b8254597efc173b9f4e229d81ecf6c21f2764445.pdf,,,,,anonymous|ccqa_a_new_webscale_question_answering_dataset_for_model_pretraining,,,,,,,,,
301,7rU9g7qlwLC,Entity-based Neural Local Coherence Modeling,['aclweb.org/ACL/ARR/2021/November/Paper164/Authors'],['Anonymous'],"In this paper, we propose an entity-based neural local coherence model which is linguistically more sound than previously proposed neural coherence models. Recent neural coherence models encode the input document using large-scale pretrained language models. Hence their basis for computing local coherence are words and even sub-words. The analysis of their output shows that these models frequently compute coherence on the basis of connections between (sub-)words which, from a linguistic perspective, should not play a role. Still, these models achieve state-of-the-art performance in several end applications. In contrast to these models, we compute coherence on the basis of entities by constraining the input to noun phrases and proper names. This provides us with an explicit representation of the most important items in sentences leading to the notion of focus. This brings our model linguistically in line with pre-neural models of computing coherence. It also gives us better insight into the behaviour of the model thus leading to better explainability. Our approach is also in accord with a recent study (O’Connor and Andreas, 2021), which shows that most usable information is captured by nouns and verbs in transformer-based language models. We evaluate our model on three downstream tasks showing that it is not only linguistically more sound than previous models but also that it outperforms them in end applications.",/pdf/91b484fa874bd0ba502706b3313724057b3f7112.pdf,,,,,anonymous|entitybased_neural_local_coherence_modeling,,,,,,,,,
302,wGiQqaBB9Rz,Enhancing the Nonlinear Mutual Dependencies in Transformers with Mutual Information,['aclweb.org/ACL/ARR/2021/November/Paper137/Authors'],['Anonymous'],"The Predictive Uncertainty problem exists in Transformers. We present that pre-trained Transformers can be further regularized by mutual information to alleviate such issue in Neural Machine Translation (NMT). In this paper, we explicitly capture the nonlinear mutual dependencies existing in two types of attentions in decoder to reduce the model uncertainty concerning token-token interactions. Specifically, we adopt an unsupervised objective of mutual information maximization on self-attentions with the contrastive learning methodology and construct the estimation of mutual information by using InfoNCE. Experimental results on WMT'14 En$\rightarrow$De, WMT'14 En$\rightarrow$Fr demonstrate the consistent effectiveness and evident improvements of our model over the strong baselines. Quantifying the model uncertainty again verifies our hypothesis.  The proposed plug-and-play approach can be easily incorporated and deployed into pre-trained Transformer models. Code will be released soon.",/pdf/4ee38a66b6c64e19c6bf16ac4f3674f4c63f79d3.pdf,,,,,anonymous|enhancing_the_nonlinear_mutual_dependencies_in_transformers_with_mutual_information,,,,,,,/attachment/b11efe7d1467263c656752decbae759cc88ff6c4.pdf,https://openreview.net/forum?id=Dys8zbWqW3C,/attachment/1d1906d1baa0f6974dfd055501a65c8939212a3c.pdf
303,m2BaZXL9wLB,UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning,['aclweb.org/ACL/ARR/2021/November/Paper217/Authors'],['Anonymous'],"Recent parameter-efficient language model tuning (PELT) methods manage to match the performance of fine-tuning with much fewer trainable parameters and perform especially well when training data is limited. However, different PELT methods may perform rather differently on the same task, making it nontrivial to select the most appropriate method for a specific task, especially considering the fast-growing number of new PELT methods and tasks. In light of model diversity and the difficulty of model selection, we propose a unified framework, UniPELT, which incorporates different PELT methods as submodules and learns to activate the ones that best suit the current data or task setup via gating mechanism. On the GLUE benchmark, UniPELT consistently achieves 1~4% gains compared to the best individual PELT method that it incorporates and even outperforms fine-tuning under different setups. Moreover, UniPELT generally surpasses the upper bound that takes the best performance of all its submodules used individually on each task, indicating that a mixture of multiple PELT methods may be inherently more effective than single methods.",/pdf/136cf4603f053c24aa209a9272dde41cb09e0272.pdf,,,,,anonymous|unipelt_a_unified_framework_for_parameterefficient_language_model_tuning,,,,,,,,,
304,JcxhaCjSlGz,Zero-Shot Visual Grounding of Referring Utterances in Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper1519/Authors'],['Anonymous'],"This work explores whether current pretrained multimodal models, which are optimized to align images and captions, can be applied to the rather different domain of referring expressions. In particular, we test whether one such model, CLIP, is effective in capturing two main trends observed for referential chains uttered within a multimodal dialogue, i.e., that utterances become less descriptive over time while their discriminativeness remains unchanged. We show that CLIP captures both, which opens up the possibility to use these models for reference resolution and generation. Moreover, our analysis indicates a possible role for these architectures toward discovering the mechanisms employed by humans when referring to visual entities.",/pdf/0467b59c86c04076a742c30fce3eaf58f2a3bc93.pdf,,,,,anonymous|zeroshot_visual_grounding_of_referring_utterances_in_dialogue,,,,,,,,,
305,-lMM2Yb9mzT,Are You Really Okay? A Transfer Learning-based Approach for Identification of Underlying Mental Illnesses,['aclweb.org/ACL/ARR/2021/November/Paper2055/Authors'],['Anonymous'],"Evidence has demonstrated that there are similarities in language use across mental illnesses, and oftentimes underlying mental illnesses are also identified by healthcare providers following initial diagnosis. We review literature to identify semantic correlations and similarities among mental illnesses. We also present a novel transfer learning-based approach that learns from data associated with known mental illnesses and predicts the presence of those previously unknown by the model.  Our model achieves a predictive accuracy of 85%, providing promising evidence that language models can harness learned patterns from known mental illnesses to aid in their prediction of others that may lie latent.",/pdf/f4b151abdeb81c7c1929d0d39e5be0158322d477.pdf,,,,,anonymous|are_you_really_okay_a_transfer_learningbased_approach_for_identification_of_underlying_mental_illnesses,,,,,,,,,
306,KNqKOUnl_3F,MILLIE: Modular & Iterative Multilingual Open Information Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1363/Authors'],['Anonymous'],"Open Information Extraction (OpenIE) is the task of extracting $(subject, predicate, object)$ triples from natural language sentences. Current OpenIE systems extract all triple slots independently. In contrast, we investigate the hypothesis that it may be beneficial to extract triple slots iteratively: first extract easy slots, followed by the difficult ones by conditioning on the easy slots, and therefore achieve a better overall extraction. Based on this hypothesis, we propose a neural OpenIE system, MILLIE, that operates in an iterative fashion.  Due to the iterative nature, the system is also modular: it is possible to seamlessly integrate rule based extraction systems with a neural end-to-end system, thereby allowing rule based systems to supply extraction slots which MILLIE can leverage for extracting the remaining slots. We confirm our hypothesis empirically: MILLIE outperforms SOTA systems on multiple languages ranging from Chinese to Arabic. Additionally, we are the first to provide an OpenIE test dataset for Arabic. ",/pdf/c9fa19f64e2ce3a13e70e86c806a24df3400f177.pdf,/attachment/875a3f4ca2763208870c1c1ec00a02cb36042c9c.zip,,,,anonymous|millie_modular_iterative_multilingual_open_information_extraction,,,,,,/attachment/46987df8e1ef4cb5cb8dedd5e5d87566c2b84077.zip,,,
307,7jn4Z8Lef_x,Zero-shot Learning for Grapheme to Phoneme Conversion with Language Ensemble,['aclweb.org/ACL/ARR/2021/November/Paper1760/Authors'],['Anonymous'],"Grapheme-to-Phoneme (G2P) has many applications in NLP and speech fields. Most existing work focuses heavily on languages with abundant training datasets, which limit the scope of target languages to less than 100 languages. This work attempts to apply zero-shot learning to propose G2P models for all low-resource and endangered languages in Glottolog (about 8k languages). For any unseen target language, we first build the phylogenetic tree (i.e. language family tree) to identify top-$k$ nearest languages for which we have training sets. Then we run models of those languages to obtain a hypothesis set, which we combine into a confusion network to propose a most likely hypothesis as an approximation to the target language. We test our approach on over 600 unseen languages and demonstrate it significantly outperforms baselines.",/pdf/2b49367a541627353a9d036219d27b52b346bfc0.pdf,,,,,anonymous|zeroshot_learning_for_grapheme_to_phoneme_conversion_with_language_ensemble,,,,,,,,,
308,qZEAjNzBHv,Context-Aware Language Modeling for Goal-Oriented Dialogue Systems,['aclweb.org/ACL/ARR/2021/November/Paper1928/Authors'],['Anonymous'],"Goal-oriented dialogue systems has long faced the trade-off between fluent language generation and task-specific control. While supervised learning with large language models are capable of producing realistic responses, how to steer such responses towards completing a specific task without sacrificing language quality remains an open question. In this work, by viewing a goal-oriented dialogue system as a reinforcement learning (RL) problem, we turn a supervised language model into a dynamics model and a behavioral cloning policy in a partially observable Markov decision process. This view allows RL techniques such as task relabeling and goal-conditioned policy to be naturally adopted as a form of data augmentation and task-specific fintuning of language models. We evaluate our method, Context-Aware Language Models (\method), on a practical flight-booking task using AirDialogue. Empirically, \method outperforms the previous state-of-the-art method by more than 10\% in terms of task success, achieving human-level task performance on this dataset.",/pdf/01a8aa1fb8b91683b440ecca1452b824254ce704.pdf,,,,,anonymous|contextaware_language_modeling_for_goaloriented_dialogue_systems,,,,,,,,,
309,z51ngO9O_cE,,,,,,,,,,,,,,,,,,,
310,5zmfwLi_mzB,Exploring Topic-Metadata Relationships with the STM: A Bayesian Approach,['aclweb.org/ACL/ARR/2021/November/Paper2587/Authors'],['Anonymous'],"The initial purpose of topic models was to identify latent topical clusters within unstructured text. Meanwhile, the focus of advanced studies  has changed primarily to estimating the relationship between the discovered topical structure and theoretically relevant metadata. Methods used to estimate such relationships must take into account that the topical structure is not directly observed, but instead being estimated itself in an unsupervised fashion. In the Structural Topic Model (STM;Roberts et al., 2016), for instance, multiple repeated linear regressions of sampled topic proportions on metadata covariates are performed. This is done by using a Monte Carlo sampling technique known as the \textit{method of composition}. In this paper, we propose two modifications of this approach: First, we implement a substantial correction to the model by replacing linear regression with the more appropriate Beta regression. Second, we provide a fundamental enhancement of the entire estimation framework by substituting the current blending of frequentist and Bayesian methods with a fully Bayesian approach instead. This allows for a more appropriate quantification of uncertainty. We illustrate our improved methodology by investigating relationships between Twitter posts by German parliamentarians and different metadata covariates related to their electoral districts.",/pdf/a8cd54dfe69a95ea38bf3613fbec4b629287319b.pdf,/attachment/bf3a773551dde1bb43f745bfae763263005dd1f2.zip,,,,anonymous|exploring_topicmetadata_relationships_with_the_stm_a_bayesian_approach,,,,,,,,,
311,B1cgyz67D9E,CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions,['aclweb.org/ACL/ARR/2021/November/Paper81/Authors'],['Anonymous'],"Humans are able to perceive, understand and reason about causal events. Developing models with similar physical and causal understanding capabilities is a long-standing goal of artificial intelligence. As a step towards this direction, we introduce CRAFT, a new video question answering dataset that requires causal reasoning about physical forces and object interactions. It contains 58K video and question pairs that are generated from 10K videos from 20 different virtual environments, containing various objects in motion that interact with each other and the scene. Two question categories in CRAFT include previously studied descriptive and counterfactual questions. Additionally, inspired by the Force Dynamics Theory in cognitive linguistics, we introduce a new causal question category that involves understanding the causal interactions between objects through notions like cause, enable, and prevent. Our results show that even though the questions in CRAFT are easy for humans, the tested baseline models, including existing state-of-the-art methods, do not yet deal with the challenges posed in our benchmark.",/pdf/148b931d0fd312de59d1b7c701d6ac05617e1932.pdf,,,,,anonymous|craft_a_benchmark_for_causal_reasoning_about_forces_and_interactions,,,,,,,,,
312,l1xUIpGuuAK,Post-processing Networks: A Method for Optimizing Pipeline Task-oriented Dialogue Systems using Reinforcement Learning,['aclweb.org/ACL/ARR/2021/November/Paper2557/Authors'],['Anonymous'],"Many studies have proposed methods for optimizing the dialogue performance of an entire pipeline system by jointly training modules in the system using reinforcement learning. However, these methods are limited in that they can only be applied to modules implemented using trainable neural-based methods. To address this problem, we propose a method for optimizing a pipeline system composed of modules implemented with arbitrary methods for dialogue performance. In our method, neural-based components called post-processing networks (PPNs) are installed inside the system to post-process the output of each module. All PPNs are updated to improve the overall dialogue performance of the system by using reinforcement learning, not necessitating each module to be updated. Through dialogue simulation experiments on the MultiWOZ dataset, we show that PPNs can improve the dialogue performance of pipeline systems consisting of various modules.",/pdf/80f5c55e4bb98b5805b0030f42b1b8e7ec06d00a.pdf,,,,,anonymous|postprocessing_networks_a_method_for_optimizing_pipeline_taskoriented_dialogue_systems_using_reinforcement_learning,,,,,,,,,
313,0bntqrz16gU,Can Language Models Be Specific? How?,['aclweb.org/ACL/ARR/2021/November/Paper1708/Authors'],['Anonymous'],"A good speaker needs not only to be correct but also to be specific, and so are language models. In this paper, we propose to measure how specific the language of pre-trained language models (PLMs) is. To achieve this, we introduce a novel approach to build a benchmark for specificity testing by forming masked token prediction tasks with prompts. For instance, given ``J. K. Rowling was born in [MASK].'', we want to test whether a more specific answer will be better filled in by PLMs, e.g., Yate instead of England.
From our evaluations, we show that existing PLMs have only a slight preference for more specific answers, indicating that PLMs are weak in specificity. We identify underlying factors affecting the specificity and design two prompt-based methods to improve the specificity. Results show that the specificity of the models can be improved by the proposed methods without additional training. We believe this work can provide a new insight for language modeling and encourage the research community to further explore this important but understudied problem.",/pdf/a83aecc36c248fce46953658458a1dfe3593d5b0.pdf,/attachment/3818265cfe02196d5e4aace8fa1c830ecbcdef0c.zip,,,,anonymous|can_language_models_be_specific_how,,,,,,/attachment/3e70cddce108f762f158a7d7dabd53ab687d5819.zip,,,
314,sgD9UjLFcuH,A Survey on Geocoding: Algorithms and Datasets for Toponym Resolution,['aclweb.org/ACL/ARR/2021/November/Paper176/Authors'],['Anonymous'],"Geocoding, the task of converting unstructured text to structured spatial data, has recently seen progress thanks to a variety of new datasets, evaluation metrics, and machine-learning algorithms. We provide a survey to review, organize and analyze recent work on geocoding (also known as toponym resolution) where the text is matched to geospatial coordinates and/or ontologies. We summarize the findings of this research and suggest some promising directions for future work.",/pdf/f94eeb7a9d14098f457d11c12cc17007f7acbdcb.pdf,,,,,anonymous|a_survey_on_geocoding_algorithms_and_datasets_for_toponym_resolution,,,,,,,/attachment/5d9c79106ce755c9cdeb896509f67c3c814e7cf9.pdf,https://openreview.net/forum?id=NVhMSb0UM0x,/attachment/3473bdde420bb422b10b7be572babd9f286dc276.pdf
315,kO0y8t9PMEf,Towards Coherent Visual Storytelling with Ordered Image Attention,['aclweb.org/ACL/ARR/2021/November/Paper575/Authors'],['Anonymous'],"We address the problem of visual storytelling, i.e., generating a story for a given sequence of images. While each story sentence should describe a corresponding image, a coherent story also needs to be consistent and relate to both future and past images. Current approaches encode images independently, disregarding relations between images.  Our approach learns to encode images with different interactions based on the story position (i.e., past image or future image). To this end,  we develop a novel message-passing-like algorithm for ordered image attention (OIA) that collects interactions across all the images in the sequence. Finally, to generate the story's sentences, a second attention mechanism picks the important image attention vectors with an Image-Sentence Attention (ISA). The obtained results improve the METEOR score on the VIST dataset by 1%. Furthermore, a thorough human study confirms improvements and demonstrates that order-based Interactions significantly improve coherency (64.20% vs. 28.70%). 
",/pdf/b29089833c1688261e6fb42e2a1c87516e876dec.pdf,,,,,anonymous|towards_coherent_visual_storytelling_with_ordered_image_attention,,,,,,,,,
316,fUahDQidjl_,Probing Difficulty and Discrimination of Natural Language Questions With Item Response Theory,['aclweb.org/ACL/ARR/2021/November/Paper1829/Authors'],['Anonymous'],"Item Response Theory (IRT) has been extensively used to characterize question difficulty for human subjects in domains including cognitive psychology and education (Primi et al.,2014; Downing, 2003). In this work, we explore IRT to characterize the difficulty and discrimination of natural language questions in Question-Answering datasets. We use HotPotQA for illustration. Our analysis reveals significant variations along these traits, as well as interdependence between them. Additionally, we explore predictive models for directly estimating these traits from the text of the questions and answers. Our experiments show that it is possible to predict both difficulty and discrimination parameters for new questions, and these traits are correlated with features of questions, answers, and associated contexts. Our findings can have significant implications for the creation of new datasets and tests on the one hand and strategies such as active learning and curriculum learning on the other.",/pdf/8a381f4a343ca48758879bac9e2be779b152c18c.pdf,/attachment/8780ff621bb44d466621e3856998c4da7a7e7a2e.zip,,,,anonymous|probing_difficulty_and_discrimination_of_natural_language_questions_with_item_response_theory,,,,,,,,,
317,r11rAKtW5QU,"Investigating Selective Prediction Approaches Across Several Tasks in IID, OOD, and Adversarial Settings",['aclweb.org/ACL/ARR/2021/November/Paper1495/Authors'],['Anonymous'],"Humans usually choose not to answer questions on which they are likely to be incorrect. In order to equip NLP systems with this selective answering capability, several task-specific approaches have been proposed. However, which approaches work best across tasks or even if they consistently outperform the simplest baseline `MaxProb' remains to be explored. To this end, we systematically study `selective prediction' in a large-scale setup of 17 datasets across several NLP tasks. Through comprehensive experiments under in-domain (IID), out-of-domain (OOD), and adversarial (ADV) settings, we show that despite leveraging additional resources (held-out data/computation), none of the existing approaches consistently and considerably outperforms MaxProb in all three settings. Furthermore, their performance does not translate well across tasks. For instance, 'Monte-Carlo Dropout' outperforms all other approaches on Duplicate Detection datasets but does not fare well on NLI datasets, especially in the OOD setting. Thus, we recommend that future selective prediction approaches should be evaluated across tasks and settings for reliable estimation of their capabilities.",/pdf/2fbbb47ae2a9615e03f15c0b95886c18ba45b875.pdf,/attachment/a550bf811eb2f9c71fdb2d08a1e1a4e45f1299c8.zip,,,,anonymous|investigating_selective_prediction_approaches_across_several_tasks_in_iid_ood_and_adversarial_settings,,,,,,,,,
318,CD1eiFUWNxp,,,,,,,,,,,,,,,,,,,
319,4lVCrmuqkDI,Probing BERT’s priors with serial reproduction chains,['aclweb.org/ACL/ARR/2021/November/Paper931/Authors'],['Anonymous'],"We can learn as much about language models from what they say as we learn from their performance on targeted benchmarks. Sampling is a promising bottom-up method for probing, but generating samples from successful models like BERT remains challenging. Taking inspiration from theories of iterated learning in cognitive science, we explore the use of serial reproduction chains to probe BERT's priors. Although the masked language modeling objective does not guarantee a consistent joint distribution, we observe that a unique and consistent estimator of the ground-truth joint distribution may be obtained by a GSN sampler, which randomly selects which word to mask and reconstruct on each step. We compare the lexical and syntactic statistics of sentences from the resulting prior distribution against those of the ground-truth corpus distribution and elicit a large empirical sample of naturalness judgments to investigate how, exactly, the model deviates from human speakers.  Our findings suggest the need to move beyond top-down evaluation methods toward bottom-up probing to capture the full richness of what has been learned about language.",/pdf/0c58bac5fb5895ad47a66a0bdd54b5e8210d8608.pdf,,,,,anonymous|probing_berts_priors_with_serial_reproduction_chains,,,,,,,,,
320,lfz6pM0shv,WeaNF: Weak Supervision with Normalizing Flows,['aclweb.org/ACL/ARR/2021/November/Paper1497/Authors'],['Anonymous'],"A popular approach to decrease the need for costly manual annotation of large data sets is weak supervision, which introduces problems of noisy labels, coverage and bias. Methods for overcoming these problems have either relied on discriminative models, trained with cost functions specific to weak supervision, and more recently, generative models, trying to  model the output of the automatic annotation process. In this work, we explore a novel direction of generative modeling for weak supervision: Instead of modeling the output of the annotation process (the labeling function matches), we generatively model the input-side data distributions (the feature space) covered by labeling functions. Specifically, we estimate a density for each weak labeling source, or labeling function, by using normalizing flows. An integral part of our method is the flow-based modeling of multiple simultaneously matching labeling functions, and therefore phenomena such as labeling function overlap and correlations are captured. We analyze the effectiveness and modeling capabilities on various commonly used weak supervision data sets, and show that weakly supervised normalizing flows compare favorably to standard weak supervision baselines. ",/pdf/ab79294a31cdfdf357c531b0c587435a5550ef48.pdf,,,,,anonymous|weanf_weak_supervision_with_normalizing_flows,,,,,,,,,
321,f_zJvXNd4e,Pretraining over Interactions for Learning Grounded Object Representations,['aclweb.org/ACL/ARR/2021/November/Paper1961/Authors'],['Anonymous'],"Large language models have been criticized for their limited ability to reason about \textit{affordances} - the actions that can be performed on an object. It has been argued that to accomplish this, models need some form of grounding, i.e., connection, to objects and how they interact in the physical world. Inspired by the way humans learn about the world through interaction, we develop an approach to learning physical properties directly. We introduce a dataset of 200k object interactions in a 3D virtual environment and a self-supervised pretraining objective for learning representations of these objects. We show with probing and clustering experiments that even in the zero-shot setting, derived models learn robust representations of objects and their affordances in an unsupervised manner. Our model outperforms pretrained language and vision models on an affordance prediction baseline, suggesting that pretraining on observed interactions encodes grounded information that is not readily learned in conventional text or vision models.",/pdf/69089fbcf659a64fc399cc44540f40c94cbfbda2.pdf,,,,,anonymous|pretraining_over_interactions_for_learning_grounded_object_representations,,,,,,,,,
322,JFTy3wvySO0,Strategies in subword tokenization: humans vs. algorithms,['aclweb.org/ACL/ARR/2021/November/Paper1473/Authors'],['Anonymous'],"The output of subword tokenization can be very different depending on what algorithm is used. It is typically judged as more or less plausible, depending on how much it corresponds to human intuition. A subword vocabulary overlap between manual and automatic segmentation is an indicator of plausibility, but it does not reveal much on how the process of segmentation compares with human analysis. In this study, we propose a new method to analyze subword segmentation strategies relying on a spatial analysis of the distribution of subwords' lengths. Our experiments on English, Finnish and Turkish show that humans tend to balance creativity and consistency, while algorithms tend to be either strongly biased or inconsistent. To imitate humans better, algorithms need to produce subword segments of moderately uneven length, which can be achieved by combining complementary strategies.  ",/pdf/884d0229577158f9b620bfa84b2b4316aca24f2e.pdf,,,,,anonymous|strategies_in_subword_tokenization_humans_vs_algorithms,,,,,,,,,
323,v5F2vaqlISQ,Inducing Global and Local Knowledge Attention in Multi-turn Dialog Understanding,['aclweb.org/ACL/ARR/2021/November/Paper1178/Authors'],['Anonymous'],"In multi-turn dialog understanding, semantic frames are constructed by detecting intents and slots within each user utterance. However, recent works lack the capability of modeling multi-turn dynamics within a dialog where the contexts are mostly adopted for updating dialog states instead of capturing overall intent semantic flows in spoken language understanding (SLU). Moreover, external knowledge related to dialogs may be beneficial in exploring deep semantic information across dialog turns, which many works only considered for end-to-end response generation. In this paper, we propose to equip a BERT-based joint framework with a context attention module and a knowledge attention module to introduce knowledge attention with contexts between two SLU tasks. We propose three attention mechanisms to induce both global and local attention on knowledge triples. Experimental results in two complicated multi-turn dialog datasets have demonstrated significant improvements of our proposed framework by mutually modeling two SLU tasks with filtered knowledge and dialog contexts. Attention visualization also provides nice interpretability of how our modules leverage knowledge across the utterance.",/pdf/9162642e9913955808b00e24a1e76ea33d571ff3.pdf,,,,,anonymous|inducing_global_and_local_knowledge_attention_in_multiturn_dialog_understanding,,,,,,,,,
324,roJqgF-OqWE,Learn More from Less: Improving Conversational Recommender Systems via Contextual and Time-Aware Modeling,['aclweb.org/ACL/ARR/2021/November/Paper2029/Authors'],['Anonymous'],"Conversational Recommender Systems (CRS) aims to perform recommendations through interactive conversations. Prior work on CRS tends to incorporate more external knowledge to enhance performance. Given the fact that too much extra knowledge introduces the difficulty to balance among them and degenerates the generalizability, we propose to fully discover and extract the internal knowledge from the context. We capture both entity-level and contextual-level representations to jointly model user preferences for the recommendation, where a time-aware attention is designed to emphasize the recently appeared items in entity-level representations. We further use the pre-trained BART to initialize the generation module to alleviate the data scarcity and enhance the context modeling. Experiments on two public CRS datasets show that our model achieves comparable performance with less external knowledge and generalizes well to other domains. Further analyses demonstrate the effectiveness of our model in different scenarios.",/pdf/c59a161364549ca5e695bdb5adeeefc9fda55f35.pdf,/attachment/59e00244eae2423f43e923a55140e254862f0667.zip,,,,anonymous|learn_more_from_less_improving_conversational_recommender_systems_via_contextual_and_timeaware_modeling,,,,,,,,,
325,4bSHVDT698M,Learning Methods for Solving Astronomy Course Problems,['aclweb.org/ACL/ARR/2021/November/Paper1298/Authors'],['Anonymous'],"This work trains a specialized machine learning model to solve university undergraduate level Introduction to Astronomy course problems. We use Transformers and graph neural networks to predict arithmetic expression trees with three key contributions: (i) a new dataset of formatted Introduction to Astrophysics course questions; (ii) support of new mathematical operators; and (iii) inclusion of tabular data consisting of known physical constants and units. Perhaps most importantly, this work introduces the concept of turning questions into programming tasks and using a Transformer trained on both text and code, namely OpenAI Codex, to solve these quantitative questions. Comparing our specialized model trained only on Astrophysics with the generic Codex model, across all topics taught in the course, we find a classical trade-off between accuracy on a specific course and the ability to scale to many courses. Our specialized model achieves 92% though does not scale to any other course; whereas the generic Codex achieves 67% on Astrophysics and is able to scale to many different courses.",/pdf/e1ceec4f6ec34c299c879f038aa3b333242a9d52.pdf,,,,,anonymous|learning_methods_for_solving_astronomy_course_problems,,,,,,,,,
326,EjqWzuK41L_,ReadE: Learning Relation-Dependent Entity Representation for Knowledge Graph Completion,['aclweb.org/ACL/ARR/2021/November/Paper2629/Authors'],['Anonymous'],"Conventional knowledge graph embedding methods learn semantic representations for entities considering their intrinsic interactions through powerful graph neural networks. However, previous methods represent each node solely with a coarse-grained unique representation, regardless of the variance of emphasis of entity semantics by different relations. To tackle this problem, we propose ReadE, a method to learn relation-dependent entity representations of which the semantic information is emphasized by varied relations types. First, we propose a relation-controlled gating mechanism targeting on utilizing the relation to control the information flow in the aggregation step of the graph neural network. Second, we propose a contrastive learning method with mixing both relation-level and entity-level negative samples to enhance semantics preserved in relation-dependent entity representations. Experiments on three benchmarks show that our proposed model outperforms all strong baselines. The code will be made open-sourced on Github.",/pdf/63a4f661615ab21a60476ead0b3b1368f67bf81e.pdf,,,,,anonymous|reade_learning_relationdependent_entity_representation_for_knowledge_graph_completion,,,,,,,,,
327,GY9WLLsW2M5,Feature Structure Distillation for BERT Transferring,['aclweb.org/ACL/ARR/2021/November/Paper136/Authors'],['Anonymous'],"Knowledge distillation is an approach to transfer information on feature representations from a teacher to a student by reducing their difference. A challenge of this approach is to reduce the flexibility of the student's representations inducing inaccurate learning of the teacher's knowledge. To resolve it in BERT transferring, we investigate distillation of structures of representations specified to three types: intra-feature, local inter-feature, global inter-feature structures. To transfer them, we introduce \textit{feature structure distillation} methods based on the Centered Kernel Alignment, which assigns a consistent value to similar distributions of representations and reveals more informative relations. In particular, a memory-augmented transfer method with clustering is implemented for the global structures. In the experiments on the nine tasks for language understanding of the GLUE dataset, the proposed methods effectively transfer the three types of structures and improve performance compared to state-of-the-art distillation methods.",/pdf/530f6002b2c932e0358ff40a95a83f426cb662d0.pdf,/attachment/b38e9041d0d74cfdfa26bfa60e66ed11283f3ca0.zip,,,,anonymous|feature_structure_distillation_for_bert_transferring,,,,,,/attachment/f46143e8f8a49fafb46cab18bec12e504ffdd150.zip,,,
328,4YFTlwJIht7,Rethinking Negative Sampling for Handling Missing Entity Annotations,['aclweb.org/ACL/ARR/2021/November/Paper1305/Authors'],['Anonymous'],"Negative sampling is highly effective in handling missing annotations for named entity recognition (NER). One of our contributions is an analysis on how it makes sense through introducing two insightful concepts: missampling and uncertainty. Empirical studies show low missampling rate and high uncertainty are both essential for achieving promising performances with negative sampling. Based on the sparsity of named entities, we also theoretically derive a lower bound for the probability of zero missampling rate, which is only relevant to sentence length. The other contribution is an adaptive and weighted sampling distribution that further improves negative sampling via our former analysis. Experiments on synthetic datasets and well-annotated datasets (e.g., CoNLL-2003) show that our proposed approach benefits negative sampling in terms of F1 score and loss convergence. Besides, models with improved negative sampling have achieved new state-of-the-art results on real-world datasets (e.g., EC).",/pdf/a2c3658e0a3c479fb7aea5e7287a6ccf0f87a2d5.pdf,,,,,anonymous|rethinking_negative_sampling_for_handling_missing_entity_annotations,,,,,,,,,
329,BDztRV6KLTe,Uncertainty-based Visual Question Answering: Estimating Semantic Inconsistency between Image and Knowledge Base,['aclweb.org/ACL/ARR/2021/November/Paper2518/Authors'],['Anonymous'],"Knowledge-based visual question answering (KVQA) task aims to answer questions that require additional external knowledge as well as an understanding of images and questions. Recent studies on KVQA inject an external knowledge in a multi-modal form, and as more knowledge is used, irrelevant information may be added and can confuse the question answering. In order to properly use the knowledge, this study proposes the following: 1) We introduce a novel semantic inconsistency measure using caption uncertainty and semantic similarity. 2) We suggest a new external knowledge assimilation method based on the semantic inconsistency measure and apply it to integrate explicit knowledge and implicit knowledge for KVQA. 3) The proposed method is evaluated on the OK-VQA dataset and achieves the state-of-the-art performance.",/pdf/160d2d36377b2b1d0ff31d07a8fc2445cf6a58df.pdf,,,,,anonymous|uncertaintybased_visual_question_answering_estimating_semantic_inconsistency_between_image_and_knowledge_base,,,,,,,,,
330,35V2c0WUkuZ,k-Rater Reliability: The Correct Unit of Reliability for Aggregated Human Annotations,['aclweb.org/ACL/ARR/2021/November/Paper2281/Authors'],['Anonymous'],"Since the inception of crowdsourcing, aggregation has been a common strategy for dealing with unreliable data. Aggregate ratings are more reliable than individual ones. However, many NLP datasets that rely on aggregate ratings only report the reliability of individual ones, which is the incorrect unit of analysis. In these instances, the data reliability is being under-reported. We present empirical, analytical, and bootstrap-based methods for measuring the reliability of aggregate ratings. We call this k-rater reliability (kRR), a multi-rater extension of inter-rater reliability (IRR). We apply these methods to the widely used word similarity benchmark dataset, WordSim. We conducted two replications of the WordSim dataset to obtain an empirical reference point. We hope this discussion will nudge researchers to report kRR, the correct unit of reliability for aggregate ratings, in addition to IRR.",/pdf/b98c8addf03fcd9b6233ea335b94727c2e18bbbc.pdf,,,,,anonymous|krater_reliability_the_correct_unit_of_reliability_for_aggregated_human_annotations,,,,,,,,,
331,AunN5vQYjsB,KinyaBERT: a Morphology-aware Kinyarwanda Language Model,['aclweb.org/ACL/ARR/2021/November/Paper417/Authors'],['Anonymous'],"Pre-trained language models such as BERT have been successful at tackling many natural language processing tasks. However, the unsupervised sub-word tokenization methods commonly used in these models (e.g., byte-pair encoding - BPE) are sub-optimal at handling morphologically rich languages. Even given a morphological analyzer, naive sequencing of morphemes into a standard BERT architecture is inefficient at capturing morphological compositionality and expressing word-relative syntactic regularities. We address these challenges by proposing a simple two-tier BERT architecture that leverages a morphological analyzer and explicitly represents morphological compositionality. Despite the success of BERT, most of its evaluations have been conducted on high-resource languages, obscuring its applicability on low-resource languages. We evaluate our proposed method on the low-resource morphologically rich Kinyarwanda language, naming the proposed model architecture KinyaBERT. A robust set of experimental results reveal that KinyaBERT outperforms solid baselines by 2% F1 score on a named entity recognition task and by 4.3% average score of a machine-translated GLUE benchmark. KinyaBERT fine-tuning has better convergence and achieves more robust results on multiple tasks even in the presence of translation noise.",/pdf/a438e6125ddd09a69df9db003773e984f746056f.pdf,,,,,anonymous|kinyabert_a_morphologyaware_kinyarwanda_language_model,,,,,,,,,
332,XTJnzzrgsDN,Reasoning over Hybrid Chain for Table-and-Text Open Domain Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper153/Authors'],['Anonymous'],"Tabular and textual question answering requires systems to perform reasoning over heterogeneous information, considering table structure, and the connections among table and text. In this paper, we propose a ChAin-centric Reasoning and Pre-training framework (CARP). CARP utilizes hybrid chain to model the explicit intermediate reasoning process across table and text for question answering. We also propose a novel chain-centric pre-training method, to enhance the pre-trained model in identifying the cross-modality reasoning process and alleviating the data sparsity problem. This method constructs the large-scale reasoning corpus by synthesizing pseudo heterogeneous reasoning paths from Wikipedia and generating corresponding questions. We evaluate our system on OTT-QA, a large-scale table-and-text open-domain question answering benchmark, and our system achieves the state-of-the-art performance. Further analyses illustrate that the explicit hybrid chain offers substantial performance improvement and interpretablity of the intermediate reasoning process, and the chain-centric pre-training boosts the performance on the chain extraction.",/pdf/e9065264b090694cce065ae089832fccb03a6687.pdf,,,,,anonymous|reasoning_over_hybrid_chain_for_tableandtext_open_domain_question_answering,,,,,,,,,
333,DjU0lWdsAzn,"Two Front-Ends, One Model : Fusing Heterogeneous Speech Features for Low Resource ASR with Multilingual Pre-Training",['aclweb.org/ACL/ARR/2021/November/Paper2504/Authors'],['Anonymous'],"Transfer learning is widely applied in various deep learning-based speech tasks, especially for tasks with a limited amount of data. Recent studies in transfer learning mainly focused on either supervised or self-supervised perspectives. This work, however, seeks to incorporate the two schemes together towards low-resource automatic speech recognition (ASR) for minor and endangered language (EL) communities. We propose a general framework to use learned transformations to resolve time resolution differences between any speech features, allowing for fusion of any self-supervised representations or spectral features used in multilingual pre-training. Our experiments over two low-resource languages and three ELs demonstrate that the proposed framework can significantly improve the absolute average word error rate from 45.4% to 35.5%.",/pdf/802d45fe2d77e28859fccfae0de093d8de52fd17.pdf,,,,,anonymous|two_frontends_one_model_fusing_heterogeneous_speech_features_for_low_resource_asr_with_multilingual_pretraining,,,,,,,,,
334,jGSSvp8KOex,Rare Tokens Degenerate All Tokens: Improving Neural Text Generation via Adaptive Gradient Gating for Rare Token Embeddings,['aclweb.org/ACL/ARR/2021/November/Paper2901/Authors'],['Anonymous'],"Recent studies have determined that the learned token embeddings of large-scale neural language models are degenerated to be anisotropic with a narrow-cone shape. This phenomenon, called the representation degeneration problem, facilitates an increase in the overall similarity between token embeddings that negatively affect the performance of the models. Although the existing methods that address the degeneration problem based on observations of the phenomenon triggered by the problem improves the performance of the text generation, the training dynamics of token embeddings behind the degeneration problem are still not explored. In this study, we analyze the training dynamics of the token embeddings focusing on rare token embedding. We demonstrate that the specific part of the gradient for rare token embeddings is the key cause of the degeneration problem for all tokens during training stage. Based on the analysis, we propose a novel method called, adaptive gradient gating(AGG). AGG addresses the degeneration problem by gating the specific part of the gradient for rare token embeddings. Experimental results from language modeling, word similarity, and machine translation tasks quantitatively and qualitatively verify the effectiveness of AGG.",/pdf/848a75292909e30251bee3d63e38dffee0a1abd0.pdf,,,,,anonymous|rare_tokens_degenerate_all_tokens_improving_neural_text_generation_via_adaptive_gradient_gating_for_rare_token_embeddings,,,,,,,,,
335,1wAxnkbl-1O,Towards Robust Passage Re-Ranking Model by Mitigating Lexical Match Bias,['aclweb.org/ACL/ARR/2021/November/Paper1251/Authors'],['Anonymous'],"While deep learning models can overcome the limitations of traditional machine learning algorithms that use hand-crafted features, recent studies have shown that these models often achieve high dataset-specific accuracy by exploiting several bias without understanding deeper semantics of intended task. In this paper, we show that neural re-ranking models in information retrieval field are easily deceived by passage and query which exist some lexical match but are semantically irrelevant or less relevant. Then we create a challenging evaluation dataset to expose model's inability in fully capturing contextual semantic information to learn sequence representation for relevance match. After that in order to encourage model to focus on semantic match between passage and query, we explore adversarial removal method to mitigate model's tendency in learning shortcut of lexical match bias in training corpus. Experiments on two benchmarks show that our debiased models can both achieve certain gains on original and challenging test sets compared with baseline models.",/pdf/0e0e1858a00e1b03e2416be1b041d6a2dd9ac0ce.pdf,,,,,anonymous|towards_robust_passage_reranking_model_by_mitigating_lexical_match_bias,,,,,,,/attachment/bffc42a38d88c31af89294f88dade66ecf4fee33.pdf,,
336,MzT29q_1ez8,Sentence-Level Discourse Parsing as Text-to-Text Generation,['aclweb.org/ACL/ARR/2021/November/Paper2661/Authors'],['Anonymous'],"Previous studies have made great advances in RST discourse parsing through neural frameworks or efficient features, but they split the parsing process into two subtasks and heavily depended on gold segmentation. In this paper, we introduce an end-to-end method for sentence-level RST discourse parsing via transforming it into a text-to-text generation task. Our method unifies the traditional two-stage parsing and generates the parsing tree directly from the input text without requiring a complicated model. Moreover, the EDU segmentation can be simultaneously generated and extracted from the parsing tree. Experimental results on the RST Discourse Treebank demonstrate that our proposed method outperforms existing methods in both tasks of sentence-level RST parsing and discourse segmentation. Considering the lack of annotated data in RST parsing, we also create high-quality augmented data based on several filtering strategies, which further improves the performance.",/pdf/c98f0e50a4eeed155a9c860023c5b1b326b492bb.pdf,,,,,anonymous|sentencelevel_discourse_parsing_as_texttotext_generation,,,,,,,,,
337,41mP2ocAXOR,A Simple Hash-Based Early Exiting Approach For Language Understanding and Generation,['aclweb.org/ACL/ARR/2021/November/Paper2342/Authors'],['Anonymous'],"Early exiting allows instances to exit at different layers according to the estimation of difficulty.
Previous works usually adopt heuristic metrics such as the entropy of internal outputs to measure instance difficulty, which suffers from generalization and threshold-tuning. In contrast, learning to exit, or learning to predict instance difficulty is a more appealing way. Though some effort has been devoted to employing such ""learn-to-exit"" modules, it is still unknown whether and how well the instance difficulty can be learned. As a response, we first conduct experiments on the learnability of instance difficulty, which demonstrates that modern neural models perform poorly on predicting instance difficulty. Based on this observation, we propose a simple-yet-effective Hash-based Early Exiting approach HashEE) that replaces the learn-to-exit modules with hash functions to assign each token to a fixed exiting layer. Different from previous methods, HashEE requires no internal classifiers nor extra parameters, and therefore is more efficient.HashEE can be used in various tasks (including language understanding and generation) and model architectures such as seq2seq models. Experimental results on classification, regression, and generation tasks demonstrate that HashEE can achieve higher performance with fewer FLOPs and inference time compared with previous state-of-the-art early exiting methods.",/pdf/9895063413c488a1e3f25221978233c29a20f6e6.pdf,,,,,anonymous|a_simple_hashbased_early_exiting_approach_for_language_understanding_and_generation,,,,,,,,,
338,FEEUqSmmrtZ,Text-to-Table: A New Way of Information Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1711/Authors'],['Anonymous'],"We study a new problem setting of information extraction (IE), referred to as text-to-table. In text-to-table, given a text, one creates a table or several tables expressing the main content of the text, while the model is learned from text-table pair data. The problem setting differs from those of the existing methods for IE. First, the extraction can be carried out from long texts to large tables with complex structures. Second, the extraction is entirely data-driven, and there is no need to explicitly define the schemas.  As far as we know, there has been no previous work that studies the problem. In this work, we formalize text-to-table as a sequence-to-sequence (seq2seq) problem.  We first employ a seq2seq model fine-tuned from a pre-trained language model to perform the task.  We also develop a new method within the seq2seq approach, exploiting two additional techniques in table generation: table constraint and table relation embeddings. We consider text-to-table as an inverse problem of the well-studied table-to-text, and make use of four existing table-to-text datasets in our experiments on text-to-table. Experimental results show that the vanilla seq2seq model can outperform the baseline methods of using relation extraction and named entity extraction. The results also show that our method can further boost the performances of the vanilla seq2seq model. We further discuss the main challenges of the proposed task. The code and data will be made publicly available.",/pdf/ba24b16c542bb9ec958940b8f0768abce6ef569f.pdf,,,,,anonymous|texttotable_a_new_way_of_information_extraction,,,,,,,,,
339,oAAtk-e1ccP,"STaR: Knowledge Graph Embedding by Scaling, Translation and Rotation",['aclweb.org/ACL/ARR/2021/November/Paper1168/Authors'],['Anonymous'],"The bilinear method is mainstream in Knowledge Graph Embedding (KGE), aiming to learn low-dimensional representations for entities and relations in Knowledge Graph (KG) and complete missing links. Most of the existing works are to find patterns between relationships and effectively model them to accomplish this task. Previous works have mainly discovered 6 important patterns like non-commutativity.  Although some bilinear methods succeed in modeling these patterns, they neglect to handle 1-to-N, N-to-1, and N-to-N relations (or complex relations) concurrently, which hurts their expressiveness. To this end, we integrate scaling, the combination of translation and rotation that can solve complex relations and patterns, respectively, where scaling is a simplification of projection. Therefore, we propose a corresponding bilinear model Scaling Translation and Rotation (STaR) consisting of the above two parts. Besides, since translation can not be incorporated into the bilinear model directly, we introduce translation matrix as the equivalent. Theoretical analysis proves that STaR is capable of modeling all patterns and handling complex relations simultaneously, and experiments demonstrate its effectiveness on commonly used benchmarks for link prediction. ",/pdf/3c3aebcfe3a131e7b58e66b71e9ed7084f0f3e7d.pdf,/attachment/5b83d6797360abb0c8c9ad6401b39f0188054f4e.zip,,,,anonymous|star_knowledge_graph_embedding_by_scaling_translation_and_rotation,,,,,,/attachment/348a64716971abf62d6bfa882cc9b7513a7b6784.zip,,,
340,6BBmgbDaOYB,Meta-learning via Language Model In-context Tuning,['aclweb.org/ACL/ARR/2021/November/Paper2058/Authors'],['Anonymous'],"The goal of meta-learning is to learn to adapt to a new task with only a few labeled examples. Inspired by the recent progress in large language models, we propose $\textit{in-context tuning}$ (ICT), which recasts task adaptation and prediction as a simple sequence prediction problem: to form the input sequence, we concatenate the task instruction, labeled in-context examples, and the target input to predict; to meta-train the model to learn from in-context examples, we fine-tune a pre-trained language model (LM) to predict the target label given the input sequence on a collection of tasks.
We benchmark our method on two collections of text classification tasks: LAMA and BinaryClfs. Compared to MAML which adapts the model through gradient descent, our method leverages the inductive bias of pre-trained LMs to perform pattern matching, and outperforms MAML by an absolute $6\%$ average AUC-ROC score on BinaryClfs, gaining more advantage with increasing model size. Compared to non-fine-tuned in-context learning (i.e. prompting a raw LM), in-context tuning meta-trains the model to learn from in-context examples. On BinaryClfs, ICT improves the average AUC-ROC score by an absolute $10\%$, and reduces the variance due to example ordering by 6x and example choices by 2x.",/pdf/2cce5359ef87410e06a76bbba1b55390c42aae5a.pdf,,,,,anonymous|metalearning_via_language_model_incontext_tuning,,,,,,,,,
341,J6ov_5Uww16,The Case of Imperfect Negation Cues: A Two-Step Approach for Automatic Negation Scope Resolution,['aclweb.org/ACL/ARR/2021/November/Paper1370/Authors'],['Anonymous'],"Neural network-based methods are the state of the art in negation scope resolution.  However, they often use the unrealistic assumption that cue information is completely accurate.  Even if  this  assumption  holds,  there  remains  a  de-pendency  on  engineered  features  from  state-of-the-art machine learning methods. The cur-rent study adopted a two-step negation resolving approach to assess whether a bidirectional long short-term memory-based method can be used for cue detection as well, and how inaccurate cue predictions would affect the scope resolution performance.   Results suggest that the  scope  resolution  performance  is  most  robust against inaccurate information for models with  a  recurrent  layer  only,  compared  to  ex-tensions with a conditional random field layer or a post-processing algorithm.  We advocate for  more  research  into  the  application  of  automated deep learning on negation cue detection and the effect of imperfect information on scope resolution.",/pdf/7eeda77a54719175ff2fba4f8898cd1243f0197e.pdf,,,,,anonymous|the_case_of_imperfect_negation_cues_a_twostep_approach_for_automatic_negation_scope_resolution,,,,,,,,,
342,TS3flrd9wWY,Language-Family Adapters for Multilingual Neural Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper1562/Authors'],['Anonymous'],"Massively multilingual pretrained models yield state-of-the-art results in a wide range of cross-lingual natural language processing tasks. For machine translation, the de facto way to leverage knowledge of pretrained models is fine-tuning on parallel data from one or multiple language pairs. Multilingual fine-tuning improves performance on medium- and low-resource languages but requires modifying the entire model and can be prohibitively expensive. Training either language-pair specific or language-agnostic adapters while keeping most of the pretrained model's parameters frozen has been proposed as a lightweight alternative. However, the former do not learn useful cross-lingual representations for multiple language pairs, while the latter share parameters for all languages and potentially have to deal with negative interference. In this paper, we propose training language-family adapters on top of a pretrained multilingual model to facilitate cross-lingual transfer. Using language families, our model consistently outperforms other adapter-based approaches and is on par with multilingual fine-tuning, while being more efficient. We also demonstrate that language-family adapters provide an effective method to translate to languages unseen during pretraining and substantially outperform the baselines.",/pdf/a231c15618989c1b40b5de797e79f3fb0301d8f2.pdf,/attachment/a6dc50c1a625a21e9007fba5d54fe8c24168e957.zip,,,,anonymous|languagefamily_adapters_for_multilingual_neural_machine_translation,,,,,,,,,
343,F_D9FRmAZ2A,Towards Faithful Response Generation for Chinese Table Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper1945/Authors'],['Anonymous'],"The response generation for TableQA aims to automatically generate a response to end-users from a SQL query and its corresponding execution result (in the form of table). It is an essential and practical task. However, there has been little work on it in recent years. We consider this may be blamed on the lack of large-scale and high-quality datasets in this area. In this paper, we present ResponseNLG, a large-scale and high-quality Chinese dataset for TableQA response generation, to advance the field in both academic and industrial communities. Further, to bridge the structural gap between the input SQL and table and establish better semantic alignments, we propose a Heterogeneous Graph Transformation approach. In this way, we establish a joint encoding space for the two heterogeneous input data and convert this task to a Graph-to-Text problem. We further introduce the Node Segment Embedding to better preserve the original graph structure upon PLMs based models.",/pdf/f684b9e8d93f7cabab0705007fdb205694ec9aea.pdf,/attachment/ca32533d8c9f633f87e2926218b9e6f9d4460d76.zip,,,,anonymous|towards_faithful_response_generation_for_chinese_table_question_answering,,,,,,/attachment/f18b7610a9161db01ef1cddc40b1947610904f8a.zip,,,
344,UBk6b94uH7,Is Neural Topic Modelling Better than Clustering? An Empirical Study on Clustering with Contextual Embeddings for Topics,['aclweb.org/ACL/ARR/2021/November/Paper928/Authors'],['Anonymous'],"Recent work incorporates pre-trained word embeddings such as BERT embeddings into Neural Topic Models (NTMs), generating highly coherent topics. However, with high-quality contextualized document representations, do we really need sophisticated neural models to obtain coherent and interpretable topics? In this paper, we conduct thorough experiments showing that directly clustering high-quality sentence embeddings with an appropriate word selecting method can generate more coherent and diverse topics than NTMs, achieving also higher efficiency and simplicity.",/pdf/dd4a1cfb96059299d9ca19f325e1a31eff94f2bf.pdf,,,,,anonymous|is_neural_topic_modelling_better_than_clustering_an_empirical_study_on_clustering_with_contextual_embeddings_for_topics,,,,,,,,,
345,mX96PUnWBTW,Global Mixup: Eliminating Ambiguity with Clustering Relationships,['aclweb.org/ACL/ARR/2021/November/Paper1189/Authors'],['Anonymous'],"Data augmentation with Mixup has been proven an effective method to regularize the current deep neural networks. Mixup generates virtual samples and corresponding labels by linear interpolation. However, the linear interpolation needed for mixup causes two problems: (1) Only relying on linear relationships will generate ambiguous samples, confusing the model in the training phase. (2) The linear combination greatly limits the distribution space of the generated samples. To tackle these problems, We propose a simple but effective augmentation method based on global relationships called \textbf{Global Mixup}, which assigns credible and unambiguous labels to generated samples depending on the global relationship between virtual and actual samples. Extensive experiments using \textbf{CNN}, \textbf{LSTM}, and \textbf{BERT} on five tasks show that Global Mixup significantly outperforms previous state-of-the-art baselines. Further experiments also demonstrate the advantage of Global Mixup in low-resource scenarios.",/pdf/cf979e9a295edd450d3c10d77689b4eb9b2d46c4.pdf,/attachment/bfa90c8c4e3638af2ba8aa85ac24f3a18208d52b.zip,,,,anonymous|global_mixup_eliminating_ambiguity_with_clustering_relationships,,,,,,,,,
346,wQxlUlyWrm,A Unified and Efficient Contrastive Learning Framework for Text Summarization,['aclweb.org/ACL/ARR/2021/November/Paper2668/Authors'],['Anonymous'],"Both extractive and abstractive summarization systems share a common problem, i.e., there is a  mismatch between the training object and evaluation metrics. To bridge this gap, we introduce a unified and efficient contrastive learning framework called UniCLS for both extractive and abstractive methods. In this framework, the summarization model not only learns how to write summaries but also is required to evaluate the generated summary. Without any additional parameters, our contrastive learning approach can be effortlessly applied to any extractive and abstractive summarization systems. Extensive experiments show that our framework brings substantial improvements on a wide range of datasets and clearly outperforms previous state-of-the-art end-to-end systems by a large margin on CNN/DailyMail benchmark. In Particular,  UniCLS achieves an improvement of 1.75 ROUGE-1 score over the BART-large model without sacrificing inference efficiency.",/pdf/f0fee64c4894f56a90fd09397b38da97af9916d4.pdf,/attachment/681552d0c32a5422f3387e86167e123aecfbeb39.zip,,,,anonymous|a_unified_and_efficient_contrastive_learning_framework_for_text_summarization,,,,,,/attachment/77310110d967e7ae049f882ab886019554d693e0.zip,,,
347,D2RrkfGsKTQ,Temporal Knowledge Graph Embedding based on Multivariate Gaussian Process,['aclweb.org/ACL/ARR/2021/November/Paper932/Authors'],['Anonymous'],"Recently, reasoning over Temporal Knowledge Graph (TKG), such as link prediction, has become an attractive research topic. 
Numerous Temporal Knowledge Graph Embedding (TKGE) methods have been proposed to map the entities and relations in TKG to the high-dimensional representations for further reasoning tasks. However, most existing TKGE methods \lh{which mainly based on deterministic vector embeddings, still} have two drawbacks. On the one hand, they mainly model temporal evolution of entities and relations by a deterministic function of time, which captures the global trends but fails at the surging local fluctuations. On the other hand, they mainly focus on the semantic meaning of embeddings, while losing the sight of temporal uncertainties of the embeddings. To tackle such limitations, in this paper, we propose a novel approach to mapping the entities and relations in TKG to multivariate Gaussian Processes (MGP). With the flexibility and capacity of MGP, the global trends as well as the local fluctuations can be simultaneously modeled. Moreover, the temporal uncertainties can be also captured with the kernel function and covariance matrix of MGP. Experimental results show the effectiveness of the proposed approach on two real-world benchmark datasets compared with  some state-of-the-art TKGE methods.  ",/pdf/e1613a053c33586cdd0a0c5908c8c840a1130d24.pdf,,,,,anonymous|temporal_knowledge_graph_embedding_based_on_multivariate_gaussian_process,,,,,,,,,
348,5vyiWHwpflJ,Tokenization on the Number Line is All You Need,['aclweb.org/ACL/ARR/2021/November/Paper2537/Authors'],['Anonymous'],"Despite the recent breakthroughs in language modeling, their ability to represent numbers is insufficient. Subword tokenization, the standard choice for number representation, breaks down a number into arbitrary chunks thereby failing to explicitly capture the relationship between two numbers on on the number-line. To alleviate this shortcoming, alternate approaches have been proposed that modify numbers at various stages of the language modeling pipeline. These methods can be broadly classified into three categories that make changes to a) the notation (\eg scientific vs decimal) b) vocabulary (\eg introduce a new token for numbers in range $10-100$) and c) architectural changes to directly regress to a desired number. The contributions of this work are three fold -- firstly, we propose vocabulary level changes in the decoding stage and study its behavior. Next, we study the performance of both the proposed approach and existing number representation schemes in the context of masked number presentation. We find that a carefully designed tokenization scheme is both the simplest to implement and sufficient \ie with similar performance to the state-of-the-art approach that requires making significant architectural changes. Finally, we evaluate the various number representation schemes on the downstream task of numerical fact estimation (for fermi problems) in a zero-shot setting and find similar trends \ie changes at the tokenization level achieve near state-of-the-art results while requiring minimal resources compared to other number representation schemes.",/pdf/8988874b9b248ecd89749e72307b0e0572b9cf03.pdf,,,,,anonymous|tokenization_on_the_number_line_is_all_you_need,,,,,,,,,
349,xJ6eoFTjKxg,A Graph Enhanced BERT Model for Event Prediction,['aclweb.org/ACL/ARR/2021/November/Paper282/Authors'],['Anonymous'],"Predicting the subsequent event for an existing event context is an important but challenging task, as it requires understanding the underlying relationship between events. Previous methods propose to retrieve relational features from event graph to enhance the modeling of event correlation. However, the sparsity of event graph may restrict the acquisition of relevant graph information, and hence influence the model performance. To address this issue, we consider automatically building of event graph using a BERT model. To this end, we incorporate an additional structured variable into BERT to learn to predict the event connections in the training process.
Hence, in the test process, the connection relationship for unseen events can be predicted by the structured variable.
Results on two event prediction tasks: script event prediction and story ending prediction, show that our approach can outperform state-of-the-art baseline methods. ",/pdf/4daa9c3d3957192f2e90fc0b0bf8cfe5919bb998.pdf,/attachment/3345498314c3e19c8fde0555ea24d971b8f6a6b7.zip,,,,anonymous|a_graph_enhanced_bert_model_for_event_prediction,,,,,,,,,
350,0XOfocEp0u2,A Generative Approach for Mitigating Structural Biases in Natural Language Inference,['aclweb.org/ACL/ARR/2021/November/Paper10/Authors'],['Anonymous'],"Many natural language inference (NLI) datasets contain biases that allow models to perform well by only using a biased subset of the input, without considering the remainder features. For instance, models are able to classify samples by only using the hypothesis, without learning the true relationship between it and the premise.  These structural biases lead discriminative models to learn unintended superficial features and generalize poorly out of the training distribution. In this work, we reformulate the NLI task as a generative task, where a model is conditioned on the biased subset of the input and the label and generates the remaining subset of the input. We show that by imposing a uniform prior, we obtain a provably unbiased model. Through synthetic experiments, we find that this approach is highly robust to large amounts of bias. We then demonstrate empirically on two types of natural bias that this approach leads to fully unbiased models in practice. However, we find that generative models are difficult to train and generally perform worse than discriminative baselines. We highlight the difficulty of the generative modeling task in the context of NLI as a cause for this worse performance. Finally, by fine-tuning the generative model with a discriminative objective, we reduce the performance gap between the generative model and the discriminative baseline, while allowing for a small amount of bias.",/pdf/1c49423306704565f1990fcdd5425fb145022714.pdf,/attachment/e80c469d996fa540c63bb465848544155faca0b4.zip,,,,anonymous|a_generative_approach_for_mitigating_structural_biases_in_natural_language_inference,,,,,,/attachment/a82a26ba14e0f95d993e8d755e09791f69f5a488.zip,,,
351,Nctx6hVAQYf,ERNIE-SPARSE: Learning Hierarchical Efficient Transformer Through Regularized Self-Attention,['aclweb.org/ACL/ARR/2021/November/Paper552/Authors'],['Anonymous'],"Sparse Transformer has recently attracted a lot of attention since the ability for reducing the quadratic dependency on the sequence length. We argue that two factors, information bottleneck sensitivity and inconsistency between different attention topologies, could affect the performance of the Sparse Transformer. This paper proposes a well-designed model named ERNIE-Sparse. It consists of two distinctive parts: (i) Hierarchical Sparse Transformer (HST) to sequentially unify local and global information. (ii) Self-Attention Regularization (SAR) method, a novel regularization designed to minimize the distance for transformers with different attention topologies. To evaluate the effectiveness of ERNIE-Sparse, we perform extensive evaluations. Firstly, we perform experiments on a multi-modal long sequence modeling task benchmark, Long Range Arena (LRA). Experimental results demonstrate that ERNIE-Sparse significantly outperforms a variety of strong baseline methods including the dense attention and other efficient sparse attention methods and achieves improvements by 2.77% (57.78% vs. 55.01%). Secondly, to further show the effectiveness of our method, we pretrain ERNIE-Sparse and verified it on 3 text classification and 2 QA downstream tasks, achieve improvements on classification benchmark by 0.83% (92.46% vs. 91.63%), on QA benchmark by 3.24% (74.67% vs. 71.43%). Experimental results continue to demonstrate its superior performance. 
",/pdf/a7df5c4da16177427562b268fc5a1f0e08e4f07b.pdf,,,,,anonymous|erniesparse_learning_hierarchical_efficient_transformer_through_regularized_selfattention,,,,,,,,,
352,8pNDIkz4mpo,Non-Linear Relational Information Probing in Word Embeddings,['aclweb.org/ACL/ARR/2021/November/Paper1734/Authors'],['Anonymous'],"Pre-trained word embeddings such as SkipGram and GloVe are known to contain a myriad of useful information about words. In this work, we use multilayer perceptrons (MLP) to probe the relational information contained in these word embeddings. Previous studies that use linear models on the analogy and relation induction tasks have shown that SkipGram generally outperforms GloVe, suggesting that SkipGram embeddings contain more relational information than GloVe embeddings. However, by using non-linear probe like MLP, our results instead suggest that GloVe embeddings contain more relational information than SkipGram embeddings, but a good amount of that is stored in a non-linear form and thus previous linear models failed to reveal that. Interpreting our relation probes using post-hoc analysis provides us with an explanation for this difference.",/pdf/a87e9f97f13e792b51858c1abe1782665b9b1ccf.pdf,,,,,anonymous|nonlinear_relational_information_probing_in_word_embeddings,,,,,,,,,
353,W4Czw9mxKuQ,Learning Scalable Representation for Source Code,['aclweb.org/ACL/ARR/2021/November/Paper1219/Authors'],['Anonymous'],"This paper presents a scalable distributed code representation (SDCR) learning technique, which addresses the most common sparsity and out-of-vocabulary (OoV) concerns simultaneously. We introduce abstract syntax tree (AST) to reflect the structural information of code snippet and adopt the well-recognized 'bag of AST paths' as its intermediate representation, so that the unique structural and syntactic information of programs can be captured. Our proposed SDCR is supported by two core pillars. First, we provide comprehensive empirical study showing that only 1% of the AST paths can account for approximately 75% of the AST path occurrences. That is, dropping most of unnecessary AST paths still allows SDCR to perform well. Second, all AST paths (without leaf nodes in AST) are made up of a limited number of descriptive path elements, for which a lightweight encoder may produce a good embedding of any AST path. Incorporating these two pillars enables us to represent code snippets with better generalizability and scalability. Based on extensive experiments on two real-world datasets, we show that our SDCR have superior performance against the state-of-the-art with nearly 40% reduction in the number of model parameters.",/pdf/47c64581d78a9bbd72a84a2410b64d5849cc270c.pdf,,,,,anonymous|learning_scalable_representation_for_source_code,,,,,,,,,
354,qX9oZA8_myi,Modular Domain Adaptation,['aclweb.org/ACL/ARR/2021/November/Paper407/Authors'],['Anonymous'],"Off-the-shelf models are widely used by computational social science researchers to measure properties of text, such as sentiment. However, without access to source data it is difficult to account for domain shift, which presents a threat to validity. Here, we treat domain adaptation as a modular process that involves separate model producers and model consumers, and show how they can independently cooperate to facilitate more accurate measurements of text. We introduce two lightweight techniques for this scenario, and demonstrate that they reliably increase out-of-domain accuracy on four multi-domain text classification datasets when used with linear and contextual embedding models. We conclude with recommendations for model producers and consumers, and release models and replication code to accompany this paper.",/pdf/fba2d4c9c55f6e785f51b46f3e8fdd64d41ab2c6.pdf,,,,,anonymous|modular_domain_adaptation,,,,,,,,,
355,f1uQPPc1f4v,Multilingual Syntax-aware Language Modeling through Dependency Tree Conversion,['aclweb.org/ACL/ARR/2021/November/Paper1257/Authors'],['Anonymous'],"Incorporating stronger syntactic biases into neural language models (LMs) is a long-standing goal, but research in this area often focuses on modeling English text, where constituent treebanks are readily available. Extending constituent tree-based LMs to the multilingual setting, where dependency treebanks are more common, is possible via dependency-to-constituency conversion methods. However, this raises the question of which tree formats are best for learning the model, and for which languages. We investigate this question by training recurrent neural network grammars (RNNGs) using various conversion methods, and evaluating them empirically in a multilingual setting. We examine the effect on LM performance across nine conversion methods and five languages through seven types of syntactic tests. On average, the performance of our best model represents a 19 \% increase in accuracy over the worst choice across all languages. Our best model shows the advantage over sequential/overparameterized LMs, suggesting the positive effect of syntax injection in a multilingual setting. Our experiments highlight the importance of choosing the right tree formalism, and provide insights into making an informed decision.",/pdf/9d50ac5b696419441794e97e2e1e14b9ec3b3048.pdf,,,,,anonymous|multilingual_syntaxaware_language_modeling_through_dependency_tree_conversion,,,,,,,/attachment/053e047c2c009470c925182f4491e362f99a7058.pdf,https://openreview.net/forum?id=3v9Ls8G1igR&noteId=wUKXpNU3Ort,/attachment/95c098301a894d29e002f2799225bfa158542d29.pdf
356,oklg_YAWW1,Making Document-Level Information Extraction Right for the Right Reasons,['aclweb.org/ACL/ARR/2021/November/Paper390/Authors'],['Anonymous'],"Document-level information extraction is a flexible framework compatible with applications where information is not necessarily localized in a single sentence. For example, key features of a diagnosis in radiology a report may not be explicitly stated, but nevertheless can be inferred from the report's text. However, document-level neural models can easily learn spurious correlations from irrelevant information. This work studies how to ensure that these models make correct inferences from complex text and make those inferences in an auditable way: beyond just being right, are these models ""right for the right reasons?"" We experiment with post-hoc evidence extraction in a predict-select-verify framework using feature attribution techniques. While this basic approach can extract reasonable evidence, it can be regularized with small amounts of evidence supervision during training, which substantially improves the quality of extracted evidence. We evaluate on two domains: a small-scale labeled dataset of brain MRI reports and a large-scale modified version of DocRED (Yao et al., 2019) and show that models' plausibility can be improved with no loss in accuracy.",/pdf/cdad182f9290dafb36e903805570d1ad30db013f.pdf,,,,,anonymous|making_documentlevel_information_extraction_right_for_the_right_reasons,,,,,,,,,
357,OPz4zol0i1,Self-conditioning pre-trained language models,['aclweb.org/ACL/ARR/2021/November/Paper1214/Authors'],['Anonymous'],"We present a method to condition pre-trained Transformer-based Language Models without fine-tuning or using additional parameters. Our approach leverages the presence of existing \emph{expert units} in the model that can be used to steer text generation. We describe how to identify such expert units, and propose an inference time intervention upon them at that allows conditioning. Results show that our method is effective for conditioning, even on fine-grained homograph concepts. Furthermore, we use a large corpus of contexts that highlights the presence of inherited gender bias in the output generated by an unconditioned model. Our experiments show that our method can be used to correct this behaviour and to achieve gender parity for all of the contexts. We compare our method with PPLM-BoW (Dathathri et al., 2020), and show that our approach is able to achieve parity at a much lower perplexity. The proposed method is accessible to a wide audience thanks to its simplicity and minimal compute needs.",/pdf/7a413a452ca3a4c1db7644a508ae8ad0c89bba70.pdf,,,,,anonymous|selfconditioning_pretrained_language_models,,,,,,,,,
358,q9uLLvoLUWD,"Towards Building Automatic Medical Consultation System: Framework, Task and Dataset",['aclweb.org/ACL/ARR/2021/November/Paper2973/Authors'],['Anonymous'],"In this paper, we propose two frameworks to support automatic medical consultation, namely doctor-patient dialogue understanding and diagnosis-oriented interaction. A new medical dialogue dataset with multi-level fine-grained annotations is introduced and five evaluation tasks are established, including medical named entity recognition, dialogue act classification, symptom recognition, medical report generation and diagnosis-oriented dialogue system. We report a set of benchmark results for each track, which shows the usability of the dataset and sets a baseline for future studies. ",/pdf/4d64585a882c417a4daade46a59ffb7af2a97259.pdf,,,,,anonymous|towards_building_automatic_medical_consultation_system_framework_task_and_dataset,,,,,,,,,
359,IwE7SKn3cbg,Probing the Prompting of CLIP on Human Faces,['aclweb.org/ACL/ARR/2021/November/Paper2506/Authors'],['Anonymous'],"Large-scale multimodal models such as CLIP have caught great attention due to their generalization capability. CLIP can take free-form text prompts, but the performance varies with different text prompt manipulations, which is considered unpredictable. In this paper, we conduct a controlled study to understand how CLIP perceives images with different forms of text prompts, particularly on human facial attributes. We find that (1) using the prompt starter ""a photo of"" can guide the model to allocate higher attention weights to human faces, leading to better classification performance; (2) CLIP model is better at aligning information from shorter text prompts, as additional textual details shift away the attention from key words; (3) properly adding punctuation or removing stop words in the text prompt can shift attention to target information. Our practice on facial attributes shed light on the design of reliable text prompts for CLIP in other tasks.",/pdf/8e06be236bbf6a93da3f228734836928b26fa23c.pdf,,,,,anonymous|probing_the_prompting_of_clip_on_human_faces,,,,,,,/attachment/e3591b061b53c182f3cae4761691a0c6d4a552b4.pdf,,
360,UOvb-8b6ZN,Stress detection using non-semantic speech representation,['aclweb.org/ACL/ARR/2021/November/Paper1393/Authors'],['Anonymous'],"In today’s world, stress has become a prominent cause for many ailments. Automatic detection of stress using state-of-the-art machine learning algorithms can facilitate early detection and prevention of stress. Artificial intelligence agents involved in affective computing and human-machine interaction (HMI) might benefit from the capacity to identify human stress automatically. Despite the fact that several different methods have been established for stress detection, it is still unclear which auditory features should be considered for training a deep neural network (DNN) model. We investigate the performance of four auditory features (Mel-Frequency Cepstral Coefficients (MFCC), Perceptual Linear Prediction (PLP), x-vector and TRIpLet Loss network (TRILL) vector) with four automatic classification algorithm (support vector machine (SVM), multilayer perceptron (MLP), convolutional neural network (CNN) and long short-term memory (LSTM)). The results reveal that TRILL vectors trained on CNN provide the highest accuracy (81.86%). ",/pdf/1f96879b8ac58ba8cfc4dc6ccb1cb2c1a368773c.pdf,,,,,anonymous|stress_detection_using_nonsemantic_speech_representation,,,,,,,,,
361,pX17MqXEJcL,LipKey: A Large-Scale News Dataset with Abstractive Keyphrases and Their Benefits for Summarization,['aclweb.org/ACL/ARR/2021/November/Paper2059/Authors'],['Anonymous'],"Summaries, keyphrases, and titles are different ways of concisely capturing the content of a document. While most previous work has addressed them separately, in this work, we jointly use the three elements via multi-task training and training as joint structured inputs, in the context of document summarization. We release LipKey, the largest news corpus with human-written summaries, titles, and keyphrases, as well as being the first large-scale Indonesian keyphrase dataset. We find that including keyphrases and titles as additional context to the source document improves transformer-based summarization models.",/pdf/da2655cbb29cda10de8016d8fd7e19e6f6ad5c20.pdf,,,,,anonymous|lipkey_a_largescale_news_dataset_with_abstractive_keyphrases_and_their_benefits_for_summarization,,,,,,,,,
362,FVNhYmkc6hD,ViQA-COVID: COVID-19 Machine Reading Comprehension Dataset for Vietnamese,['aclweb.org/ACL/ARR/2021/November/Paper108/Authors'],['Anonymous'],"After two years of appearance, COVID-19 has negatively affected people and normal life around the world. As in November 2021, there are more than 250 million cases and five million deaths worldwide (including nearly one million cases and over twenty-two thousand deaths in Vietnam). Economy and society are both severely affected. The variant of COVID-19, Delta, has broken disease prevention measures of countries and rapidly increased number of infections. Resources overloading in treatment and epidemics prevention is happening all over the world. It can be seen that, application of artificial intelligence (AI) to support people at this time is extremely necessary. There have been many studies applying AI to prevent COVID-19 which are extremely useful, and studies on machine reading comprehension (MRC) are also in it. Realizing that, we created the first MRC dataset about COVID-19 for Vietnamese: ViQA-COVID and can be used to build models and systems, contributing to disease prevention. Besides, ViQA-COVID is also the first multi-span extraction MRC dataset for Vietnamese, we hope that it can contribute to promoting MRC studies in Vietnamese and multilingual.",/pdf/d91a551ad3de4f7cf28a3152268b7bbe57918f84.pdf,,,,,anonymous|viqacovid_covid19_machine_reading_comprehension_dataset_for_vietnamese,,,,,,,,,
363,fI_iI5wyjur,INDICXNLI: A Dataset for Studying NLI in Indic Languages,['aclweb.org/ACL/ARR/2021/November/Paper2237/Authors'],['Anonymous'],"While Indic NLP has made rapid advances recently in terms of availability of corpora and pre-trained models, benchmark dataset on standard NLU tasks are limited. To this end, we introduce INDICXNLI, an NLI dataset for 11 Indic languages. It has been created by high-quality machine translation of the original English XNLI dataset and out analysis attests to the quality of INDICXNLI. By finetuning different pre-trained LMs on this INDICXNLI, we analyze various cross-lingual transfer techniques with respect to the impact of choice of language models, languages,  multi-linguality, mix-language input, etc. These experiments provide us with useful insights into the behaviour of pre-trained models for a diverse set of languages. INDICXNLI will be publicly available for research.",/pdf/1d67b4f588f92b0a335c34af212a151bf966d89b.pdf,,,,,anonymous|indicxnli_a_dataset_for_studying_nli_in_indic_languages,,,,,,,,,
364,h18PaQKMbP,Input-specific Attention Subnetworks for Adversarial Detection,['aclweb.org/ACL/ARR/2021/November/Paper2812/Authors'],['Anonymous'],"Self-attention heads are characteristic of Transformer models and have been well studied for interpretability and pruning.
In this work, we demonstrate an altogether different utility of attention heads, namely for adversarial detection. 
Specifically, we propose a method to construct input-specific attention subnetworks (IAS) from which we extract three features to discriminate between authentic and adversarial inputs. The resultant detector significantly improves (by over 7.5%) the state-of-the-art adversarial detection accuracy for the BERT encoder on 10 NLU datasets with 11 different adversarial attack types. We also demonstrate that our method (a) is more accurate for larger models which are likely to have more spurious correlations and thus vulnerable to adversarial attack, and (b) performs well even with modest training sets of adversarial examples.",/pdf/f372f35a81b6e84f6d4cf6b00a6d31a99824e6a8.pdf,/attachment/a752ef8994ac9bc8562e9d9ecf84279ee8a71acd.zip,,,,anonymous|inputspecific_attention_subnetworks_for_adversarial_detection,,,,,,/attachment/f408ee4977a923f554d77f5f1d8c807a1e3ccc33.zip,/attachment/81b1b34ea3a78d8d1e577b6368d8ac4467460b6e.pdf,https://openreview.net/forum?id=zAi1uWMDsbd,/attachment/e6f57564eff4cd892c31e61f7a5a6b6d1e0776aa.pdf
365,fhJEFLoL8Jh,PoliSe: Reinforcing Politeness using User Sentiment for Customer Care Response Generation,['aclweb.org/ACL/ARR/2021/November/Paper2003/Authors'],['Anonymous'],"The interaction between a consumer and the customer service representative greatly contributes to the overall customer experience. Therefore, to ensure customers' comfort and retention, it is important that customer service agents and chatbots connect with users on social, cordial and empathetic planes. In the current work, we automatically identify the sentiment of the user and transform the neutral responses into polite responses conforming to the sentiment and the conversational history. Our technique is basically a reinforced multi-task network- the primary task being 'polite response generation' and the secondary task being 'sentiment analysis'- that uses a Transformer based encoder-decoder. We use sentiment annotated conversations from Twitter as the training data. The detailed evaluation shows that our proposed approach attains superior performance compared to the baseline models. ",/pdf/51e0c01b9a280388023c18e10c31dd2c6d943926.pdf,,,,,anonymous|polise_reinforcing_politeness_using_user_sentiment_for_customer_care_response_generation,,,,,,/attachment/be439d852b7b66d4cf240b6f3973a6d6ab919a14.zip,,,
366,lWVy7tVN__z,A Scalable Holistic approach for Age and Gender inference of Twitter Users,['aclweb.org/ACL/ARR/2021/November/Paper2566/Authors'],['Anonymous'],"Numerous studies have focused on inference of age and gender. We consider a new approach that takes advantage of contrastive learning methods by using both text and image content for this prediction task. We also consider the case where only text or image data is available. Under both of these conditions, we show that our model achieves better performance than the state-of-the-art ones, and still performs well with text/images only. Moreover, because demographic datasets can be small, we also consider combining different datasets to understand when augmentation is valuable and when it is not.",/pdf/295cfadb246a79da8f02b073957c67a9d6a36b41.pdf,,,,,anonymous|a_scalable_holistic_approach_for_age_and_gender_inference_of_twitter_users,,,,,,,,,
367,C_KskheX4uH,"Prompt Combines Paraphrase: Enhancing Biomedical “Pre-training, Prompt and Predicting” Models by Explaining Rare Biomedical Concepts",['aclweb.org/ACL/ARR/2021/November/Paper2260/Authors'],['Anonymous'],"Prompt-based fine-tuning for pre-trained models has been proven resultful in general domain for few-shot learning in downstream tasks. As to the biomedical domain, rare biomedical entities, which are quite ubiquitous in healthcare contexts, can affect the performance of pre-trained models, especially in low-resource scenarios. We propose a simple yet effective approach to helping models understand rare biomedical words during tuning with prompt. Experiments demonstrate that our method can achieve up to 5% improvement in biomedical tasks without any additional parameters or training steps in few-shot vanilla prompt settings.",/pdf/24403319293aa6ac3e9304734efee29fb56426eb.pdf,,,,,anonymous|prompt_combines_paraphrase_enhancing_biomedical_pretraining_prompt_and_predicting_models_by_explaining_rare_biomedical_concepts,,,,,,,,,
368,0n-fDxhaAHj,Cost-Effective Training in Low-Resource Neural Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper289/Authors'],['Anonymous'],"While Active Learning (AL) techniques are explored in Neural Machine Translation (NMT), only a few works focus on tackling low annotation budgets where a limited number of sentences can get translated. Such situations are especially challenging and can occur for endangered languages with few human annotators or having cost constraints to label large amounts of data. Although AL is shown to be helpful with large budgets, it is not enough to build high-quality translation systems in these low-resource conditions. In this work, we propose a cost-effective training procedure to increase the performance of NMT models utilizing a small number of annotated sentences and dictionary entries. Our method leverages monolingual data with self-supervised objectives and a small-scale, inexpensive dictionary for additional supervision to initialize the NMT model before applying AL. We show that improving the model using a combination of these knowledge sources is essential to exploit AL strategies and increase gains in low-resource conditions. We also present a novel AL strategy inspired by domain adaptation for NMT and show that it is effective for low budgets. We propose a new hybrid data-driven approach, which samples sentences that are diverse from the labelled data as well as similar to unlabelled data. Finally, we show that initializing the NMT model and further using our AL strategy can achieve gains of up to $13$ BLEU compared to conventional AL methods",/pdf/9f9ef5af4cc3b7e6f6cf05082e995f52ee397922.pdf,,,,,anonymous|costeffective_training_in_lowresource_neural_machine_translation,,,,,,,,,
369,_652yz79V9g,Multimodal Learning: Are Captions All You Need?,['aclweb.org/ACL/ARR/2021/November/Paper2/Authors'],['Anonymous'],"In today's digital world, it is increasingly common for information to be multimodal: images or videos often accompany text. Sophisticated multimodal architectures such as ViLBERT, VisualBERT, and LXMERT have achieved state-of-the-art performance in vision-and-language tasks. However, existing vision models cannot represent contextual information and semantics like transformer-based language models can. Fusing the semantic-rich information coming from text becomes a challenge. In this work, we study the alternative of first transforming images into text using image captioning. We then use transformer-based methods to combine the two modalities in a simple but effective way. We perform an empirical analysis on different multimodal tasks, describing the benefits, limitations, and situations where this simple approach can replace large and expensive handcrafted multimodal models.",/pdf/50c4aadcafe11330743219a6efd63084ab7725da.pdf,,,,,anonymous|multimodal_learning_are_captions_all_you_need,,,,,,,,,
370,33HlPgIEJ3n,Self-Distilled Pruning of Neural Networks,['aclweb.org/ACL/ARR/2021/November/Paper1296/Authors'],['Anonymous'],"Pruning aims to reduce the number of parameters while maintaining performance close to the original network. This work proposes a novel \emph{self-distillation} based pruning strategy, whereby the representational similarity between the pruned and unpruned versions of the same network is maximized. Unlike previous approaches that treat distillation and pruning separately, we use distillation to inform the pruning criteria, without requiring a separate student network as in knowledge distillation.
We show that the proposed {\em cross-correlation objective for self-distilled pruning} implicitly encourages sparse solutions, naturally complementing magnitude-based pruning criteria. Experiments on the GLUE  and XGLUE benchmarks show that self-distilled pruning increases mono- and cross-lingual language model performance. Self-distilled pruned models also outperform smaller Transformers with an equal number of parameters and are competitive against (6 times) larger distilled networks. We also observe that self-distillation (1) maximizes class separability, (2) increases the signal-to-noise ratio, and (3) converges faster after pruning steps, providing further insights into why self-distilled pruning improves generalization. ",/pdf/bcf58adb8776260079b7ce3d3bf1b12ec02503f9.pdf,,,,,anonymous|selfdistilled_pruning_of_neural_networks,,,,,,,,,
371,AL4VmTmtYtD,Slot Filling for Biomedical Information Extraction,['aclweb.org/ACL/ARR/2021/November/Paper882/Authors'],['Anonymous'],"Information Extraction (IE) from text refers to the task of extracting structured knowledge from unstructured text. The task typically consists of a series of sub-tasks such as Named Entity Recognition and Relation Extraction. Sourcing entity and relation type specific training data is a major bottleneck in domains with limited resources such as biomedicine. In this work we present a slot filling approach to the task of biomedical IE, effectively replacing the need for entity and relation-specific training data, allowing us to deal with zero-shot settings. We follow the recently proposed paradigm of coupling a Tranformer-based bi-encoder, Dense Passage Retrieval, with a Transformer-based reading comprehension model to extract relations from biomedical text. We assemble a biomedical slot filling dataset for both retrieval and reading comprehension and conduct a series of experiments demonstrating that our approach outperforms a number of simpler baselines. We also evaluate our approach end-to-end for standard as well as zero-shot settings. Our work provides a fresh perspective on how to solve biomedical IE tasks, in the absence of relevant training data. Our code, models and datasets are available at https://github.com/tba.",/pdf/e33e5e8e6b63118eeeb8f01b02bf7967f7f3a9db.pdf,,,,,anonymous|slot_filling_for_biomedical_information_extraction,,,,,,,,,
372,qZu4RC-kEZg,$\mathcal{Y}$-Tuning: An Efficient Tuning Paradigm for Large-Scale Pre-Trained Models via Label Representation Learning,['aclweb.org/ACL/ARR/2021/November/Paper2415/Authors'],['Anonymous'],"With the success of large-scale pre-trained models (PTMs), how efficiently adapting PTMs to downstream tasks has attracted tremendous attention, especially for PTMs with billions of parameters. Although some parameter-efficient tuning paradigms have been proposed to address this problem, they still require large resources to compute and store the gradients in the training phase. In this paper, we propose $\mathcal{Y}$-Tuning, an efficient yet effective paradigm to adapt frozen large-scale PTMs to specific downstream tasks. $\mathcal{Y}$-tuning learns dense representations for labels $\mathcal{Y}$ defined in a given task and aligns them to fixed feature representation. Without tuning the features of input text and model parameters, $\mathcal{Y}$-tuning is both parameter-efficient and training-efficient. Although $\mathcal{Y}$-tuning is currently still not comparable with fine-tuning in performance, it has a great advantage in saving computational cost and has the potential to further improve its performance.",/pdf/0b643a4773db14640a687daf18abf67d85a09d97.pdf,/attachment/c077a5abaf4a8cecba9ea12e90353b2e4bc11ac4.zip,,,,anonymous|\mathcalytuning_an_efficient_tuning_paradigm_for_largescale_pretrained_models_via_label_representation_learning,,,,,,,,,
373,8n2gOQ6sOBn,FeelsGoodMan: Inferring Semantics of Twitch Neologisms,['aclweb.org/ACL/ARR/2021/November/Paper1616/Authors'],['Anonymous'],"Twitch chat messages pose a unique problem in natural language understanding due to a large presence of neologisms, specifically emotes. There are a total of 8.06 million emotes, over 400k of which were observed during the study period. There is virtually no information on the meaning or sentiment of emotes, and with a constant influx of new emotes and drift in both their frequencies and their perceived meanings, it becomes impossible to maintain an updated manually-labeled dataset. Our paper makes a two-fold contribution. First, we establish a new baseline for sentiment analysis on Twitch data, outperforming the previous benchmark by 7.36 percentage points. Secondly, we introduce a simple but powerful unsupervised framework based on word embeddings and k-NN to enrich existing models with out-of-vocabulary knowledge. This framework allows us to auto-generate an emote pseudo-dictionary, and we show that we can nearly match the supervised benchmark above, even when injecting such emote knowledge into sentiment classifiers trained on extraneous datasets such as movie reviews or Twitter.",/pdf/c0008696f10754a009ab7a121d73bddfe7cb5f0a.pdf,,,,,anonymous|feelsgoodman_inferring_semantics_of_twitch_neologisms,,,,,,,,,
374,sMtCdEUntT,MAD for Robust Reinforcement Learning in Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper1595/Authors'],['Anonymous'],"We introduce a new distributed policy gradient algorithm and show that it outperforms existing reward-aware training procedures such as REINFORCE, minimum risk training (MRT) and proximal policy optimization (PPO) in terms of convergence speed and stability, and overall performance at optimising machine translation models. Our algorithm, which we call MAD (on account of using the mean absolute deviation in the importance weighting calculation), has distributed data generators sampling multiple candidates per source sentence on worker nodes, while a central learner updates the policy. MAD depends crucially on two variance reduction strategies: (1) a new robust importance weighting scheme that encourages learning from examples that are not too likely or unlikely relative to the current policy and (2) by learning from balanced numbers of high- and low-reward training examples. Finally, our algorithm has few hyperparameters, making it easy to use on new tasks with little or no adaptation. Experiments on a variety of tasks show the translation policies learned with MAD perform very well with both greedy decoding and beam search, and the learned policies are sensitive to the specific reward used during training.",/pdf/9bb889122d74a5ebb6d7b3c557e57dfa09de6fb6.pdf,,,,,anonymous|mad_for_robust_reinforcement_learning_in_machine_translation,,,,,,,,,
375,88v5hG7ZRQV,Self-Competitive Learning for Solving Math Word Problem,['aclweb.org/ACL/ARR/2021/November/Paper267/Authors'],['Anonymous'],"Math word problem (MWP) aims to automatically solve mathematical questions given in texts. Most previous MWP models tend to fit the sole ground-truth solution provided by the dataset, without considering the diverse but equivalent solution expressions. To mitigate this issue, we propose a self-competitive learning framework (called SCL), which attempts to get different predictions and improve the generalization ability of the model by cooperatively learning a source network and a pruned competitor network. The competitor network is created by pruning a source network, which perturbs the source network’s structure and is conducive to generate diverse solutions.  The source network and the competitor network learn collaboratively and teach each other throughout the training process. Extensive experiments on two large-scale benchmarks demonstrate that our model substantially outperforms the strong baseline methods. In particular, our method improves the best performance (accuracy) by 8.4% (78.4% $\rightarrow$ 86.8%) for Math23k and 6.2% (70.5% $\rightarrow$ 76.7%) for Ape210K.",/pdf/2f27529f91bd98c6ce7165b67e17036457b7473e.pdf,/attachment/6c7bab4f735ea3aed74b75a69c4eb66be1e438cc.zip,,,,anonymous|selfcompetitive_learning_for_solving_math_word_problem,,,,,,/attachment/b965a6b4dcd70930d3a1d36da05cd0e1f56af0e8.zip,,,
376,TqUzRS4WNQK,ED2LM: Encoder-Decoder to Language Model for Faster Document Re-ranking Inference,['aclweb.org/ACL/ARR/2021/November/Paper314/Authors'],['Anonymous'],"State-of-the-art neural models typically encode document-query pairs using cross-attention for re-ranking. To this end, models generally utilize an encoder-only (like BERT) paradigm or an encoder-decoder (like T5) approach. These paradigms, however, are not without flaws, i.e., running the model on all query-document pairs at inference-time incurs a significant computational cost. This paper proposes a new training and inference paradigm for re-ranking. We propose to finetune a pretrained encoder-decoder model using in the form of document to query generation. Subsequently, we show that this encoder-decoder architecture can be decomposed into a decoder-only language model during inference. This results in significant inference time speedups since the decoder-only architecture only needs to learn to interpret static encoder embeddings during inference. Our experiments show that this new paradigm achieves results that are comparable to the more expensive cross-attention ranking approaches while being up to 6.8X faster. We believe this work paves the way for more efficient neural rankers that leverage large pretrained models.",/pdf/162c7feae2dfe63059519f13a173c96e6d9c3e30.pdf,,,,,anonymous|ed2lm_encoderdecoder_to_language_model_for_faster_document_reranking_inference,,,,,,,,,
377,A2fcExq9xJZ,FewNLU: Benchmarking State-of-the-Art Methods for Few-Shot Natural Language Understanding,['aclweb.org/ACL/ARR/2021/November/Paper1174/Authors'],['Anonymous'],"The few-shot natural language understanding (NLU) task has attracted much recent attention. However, prior methods have been evaluated under a disparate set of protocols, which hinders fair comparison and measuring the progress of the field. To address this issue, we introduce an evaluation framework that improves previous evaluation procedures in three key aspects, i.e., test performance, dev-test correlation, and stability. Under this new evaluation framework, we re-evaluate several state-of-the-art few-shot methods for NLU tasks. Our framework reveals new insights:  (1) both the absolute performance and relative gap of the methods were not accurately estimated in prior literature;  (2) no single method dominates most tasks with consistent performance;  (3) improvements of some methods diminish with a larger pretrained model; and (4) gains from different methods are often complementary and the best combined model performs close to a strong fully-supervised baseline. We open-source our toolkit, FewNLU, that implements our evaluation framework along with a number of state-of-the-art methods.",/pdf/01778684cd2efeee82758e6c3d0c25e9bf6b6912.pdf,/attachment/7edd1cff1d65a9e15802bd7ea9fa0d82c2b0fa87.zip,,,,anonymous|fewnlu_benchmarking_stateoftheart_methods_for_fewshot_natural_language_understanding,,,,,,/attachment/562c8e84c00ec1ac374612f85452ea9557b5bea4.zip,,,
378,ZgRGrGjXVPg,Exploring the Influence of Dialog Input Format for Unsupervised Clinical Questionnaire Filling,['aclweb.org/ACL/ARR/2021/November/Paper62/Authors'],['Anonymous'],"In the medical field, we have seen the emergence of health-bots that interact with patients to gather data and track their state. One of the downstream application is automatic questionnaire filling, where the content of the dialog is used to automatically fill a pre-defined medical questionnaire. Answering questions from the dialog context can be cast as a Natural Language Inference (NLI) task and therefore benefit from current pre-trained NLI models. However, these models have not been generally trained on dialog input format, which may have an influence on their performance. In this paper, we study the influence of dialog input format on the task. Our results demonstrate that dialog pre-processing and content selection can significantly improve performance of zero-shot models.",/pdf/c7431c6b15d5c833c9c06ff53df3a7a6811324b8.pdf,,,,,anonymous|exploring_the_influence_of_dialog_input_format_for_unsupervised_clinical_questionnaire_filling,,,,,,,,,
379,_igq_JBYMiu,Explaining Toxic Text via Knowledge Enhanced Text Generation,['aclweb.org/ACL/ARR/2021/November/Paper2261/Authors'],['Anonymous'],"Biased or toxic speech can be harmful to various demographic groups. Therefore, it is not only important for models to detect these speech, but to also output explanations of why a given text is toxic. Previous literature has mostly focused on classifying and detecting toxic speech, and existing efforts on explaining stereotypes in toxic speech mainly use standard text generation approaches, resulting in generic and repetitive explanations. Building on these prior works, we introduce a novel knowledge-informed encoder-decoder framework to utilize multiple knowledge sources to generate implications of biased text. Experiments show that our knowledge informed models outperform prior state-of-the-art models significantly, and can generate detailed explanations of stereotypes in toxic speech compared to baselines, both quantitatively and qualitatively.",/pdf/7adc89226d2496f5d74b90b19f5dced234688a2e.pdf,,,,,anonymous|explaining_toxic_text_via_knowledge_enhanced_text_generation,,,,,,,,,
380,8bmhtQ4h5Kn,DoCoGen: Domain Counterfactual Generation for Low Resource Domain Adaptation,['aclweb.org/ACL/ARR/2021/November/Paper256/Authors'],['Anonymous'],"Natural language processing (NLP) algorithms have become very successful, but they still struggle when applied to out-of-distribution examples. In this paper we propose a controllable generation approach in order to deal with this domain adaptation (DA) challenge. 
Given an input text example, our DoCoGen algorithm generates a domain-counterfactual textual example (D-CON) – that is similar to the original in all aspects, including the task label, but its domain is changed to a desired one. Importantly, DoCoGen is trained using only unlabeled examples from multiple domains – no NLP task labels or pairs of textual examples and their domain-counterfactuals are required.
We use the D-CONs generated by DoCoGen to augment a sentiment classifier in 20 DA setups, where source-domain labeled data is scarce. Our model outperforms strong baselines and improves the accuracy of a state-of-the-art unsupervised DA algorithm.",/pdf/e23d842b2a2be6fd09c594f5e209a9d679e3adde.pdf,,,,,anonymous|docogen_domain_counterfactual_generation_for_low_resource_domain_adaptation,,,,,,,,,
381,GAneTKt2ioe,An Empirical Investigation of Commonsense Self-Supervision with Knowledge Graphs,['aclweb.org/ACL/ARR/2021/November/Paper1400/Authors'],['Anonymous'],"Large knowledge graphs have been shown to benefit zero-shot evaluation of downstream tasks, through continual pre-training of language models. Yet, little is known about how to optimally learn from this knowledge, and what is the impact of the resulting models on different task partitions. This paper studies the effect of model architectures, loss functions, and knowledge subsets on the generalization of zero-shot models across task partitions. Our experiments show that data size, model size, model architecture, and loss function all play an important role in the accuracy and generalizability of the models. Most of the improvement occurs on questions with short answers and dissimilar answer candidates, which corresponds to the characteristics of the data used for pre-training. These findings inform future work that uses self-supervision with large knowledge graphs in order to create generalizable commonsense reasoning agents.",/pdf/a067da51c6b5aaae4ea22ca8ed21a599271bc447.pdf,/attachment/c221e0ab6f21ce1b0de4068942874545d751e989.zip,,,,anonymous|an_empirical_investigation_of_commonsense_selfsupervision_with_knowledge_graphs,,,,,,/attachment/74e57fc327bff0acec54bf4d90b00f342de8fd0a.zip,,,
382,qQBcprM-gCv,How Distributed are Distributed Representations? An Observation on the Locality of Syntactic Information in Verb Agreement Tasks,['aclweb.org/ACL/ARR/2021/November/Paper1705/Authors'],['Anonymous'],"This work addresses the question of the localization of the syntactic information encoding in the Transformers representations. We tackle this question from two perspectives, considering the object-past participle agreement in French, by identifying, first, in which part of the sentence and, second, in which part of the representation syntactic information is encoded. The results of our experiments, using probing, causal analysis and feature selection method, show that syntactic information is encoded locally in a way consistent with the French grammar.",/pdf/4bb5bab6389417f62a1d3b4dc245d01f283efe8a.pdf,,,,,anonymous|how_distributed_are_distributed_representations_an_observation_on_the_locality_of_syntactic_information_in_verb_agreement_tasks,,,,,,,,,
383,6c8_5EyZYxH,Learning to execute or ask clarification questions,['aclweb.org/ACL/ARR/2021/November/Paper1486/Authors'],['Anonymous'],"Collaborative tasks are ubiquitous activities where a form of communication is required in order to reach a joint goal. Collaborative building is one of such tasks. To this end, we wish to develop an intelligent builder agent in a simulated building environment (Minecraft) that can build whatever users wish to build by just talking to the agent. However, in order to achieve this goal, such agents need to be able to take the initiative by asking clarification questions when further information is needed. Existing work on Minecraft Corpus Dataset only learned to execute instructions neglecting the importance of asking for clarifications. In this paper, we extend the Minecraft Corpus Dataset by annotating all builder utterances into eight types, including clarification questions, and propose a new builder agent model capable of determining when to ask or execute instructions. Experimental results show that our model achieves state-of-the-art performance on the collaborative building task with a substantial improvement. We also provide baselines for the new tasks, learning to ask and the joint tasks, which consists in solving both collaborating building and learning to ask tasks jointly.",/pdf/82a478d629920a544145a872298a70e424811748.pdf,,,,,anonymous|learning_to_execute_or_ask_clarification_questions,,,,,,,,,
384,HLpPGrEGgh,Dataset for N-ary Relation Extraction of Drug Combinations,['aclweb.org/ACL/ARR/2021/November/Paper2438/Authors'],['Anonymous'],"Combination therapies have become the standard of care for diseases such as cancer, tuberculosis, malaria and HIV. However, the combinatorial set of available multi-drug treatments creates a challenge, particularly in the presence of antagonistic drug combinations that may lead to negative patient outcomes. To assist medical professionals in identifying beneficial drug-combinations, we construct an expert-annotated dataset for extracting information about the efficacy of drug combinations from the scientific literature. Beyond its practical utility, the dataset also presents a unique NLP challenge, as it is the first relation extraction dataset consisting of variable-length relations. Furthermore, the relations in this dataset predominantly require language understanding beyond the sentence level, adding to the challenge of this task. We provide a strong baseline model and identify clear areas for further improvement. We release our dataset and code (https://anonymous.4open.science/r/drug-synergy-models--C8B7/README.md) publicly to encourage the NLP community to participate in this task.",/pdf/41c3842579d7d79f6782409966a5ba6825247b12.pdf,,,,,anonymous|dataset_for_nary_relation_extraction_of_drug_combinations,,,,,,,,,
385,UrtZRnO6VB,"""That Is a Suspicious Reaction!"": Interpreting Logits Variation to Detect NLP Adversarial Attacks",['aclweb.org/ACL/ARR/2021/November/Paper1347/Authors'],['Anonymous'],"Adversarial attacks are a major challenge faced by current machine learning research. These purposely crafted inputs fool even the most advanced models, precluding their deployment in safety-critical applications. Extensive research in computer vision has been carried to develop reliable defense strategies. However, the same issue remains less explored in natural language processing. Our work presents a model-agnostic detector of adversarial text examples. The approach identifies patterns in the logits of the target classifier when perturbing the input text. The proposed detector improves the current state-of-the-art performance in recognizing adversarial inputs and exhibits strong generalization capabilities across different NLP models, datasets, and word-level attacks.",/pdf/5a7ffef2972a2d09d9fd408698dd59c8d2ba7545.pdf,/attachment/057f6aacab47b723137424bb529eea6d0d4bba35.zip,,,,anonymous|that_is_a_suspicious_reaction_interpreting_logits_variation_to_detect_nlp_adversarial_attacks,,,,,,,,,
386,ySdKM1bi_N,Predicate-Argument Based Bi-Encoder for Paraphrase Identification,['aclweb.org/ACL/ARR/2021/November/Paper2885/Authors'],['Anonymous'],"Paraphrase identification involves identifying whether a pair of sentences express the same or similar meanings. While cross-encoders have achieved high performances across several benchmarks, bi-encoders such as SBERT have been widely applied to sentence pair tasks. They exhibit substantially lower computation complexity and are better suited to symmetric tasks. In this work, we adopt a bi-encoder approach to the paraphrase identification task, and investigate the impact of explicitly incorporating predicate-argument information into SBERT through weighted aggregation. Experiments on six paraphrase identification datasets demonstrate that, with a minimal increase in parameters, the proposed model is able to outperform SBERT/SRoBERTa significantly. Further, ablation studies reveal that the predicate-argument based component plays a significant role in the performance gain.",/pdf/5194119c92f05afc24da8f9dd4df6087172e0edb.pdf,,,,,anonymous|predicateargument_based_biencoder_for_paraphrase_identification,,,,,,,,,
387,cfpUdeozplN,A Light Label Denoising Method with the Internal Data Guidance,['aclweb.org/ACL/ARR/2021/November/Paper788/Authors'],['Anonymous'],"Samples with incorrect labels are common in datasets, even annotated by humans. Some approaches have been proposed to alleviate the negative impact of mislabeling on the training process by removing erroneous data or reducing their weights. Unlike previous works, this paper introduces a light yet effective denoising method based on the relationship between the samples within the dataset, namely internal guidance. We examine the method on five datasets with mainstream models. The results demonstrate that this light denoising approach can obtain consistent improvement for all the datasets and models.",/pdf/5f8ebcf9ba1bbd45d819cd2357d8776fae263c11.pdf,/attachment/c62039e4e1d2b929e967081433dbce499f77d647.zip,,,,anonymous|a_light_label_denoising_method_with_the_internal_data_guidance,,,,,,,,,
388,F-tGaDB037u,Synthetic Data Generation and Joint Learning for Robust Code-Mixed Translation,['aclweb.org/ACL/ARR/2021/November/Paper114/Authors'],['Anonymous'],"The widespread online communication in a modern multilingual world has provided opportunities to blend more than one language (aka. code-mixed language) in a single utterance. This has resulted a formidable challenge for the computational models due to the scarcity of annotated data and presence of noise. A potential solution to mitigate the data scarcity problem in low-resource setup is to leverage existing data in resource-rich language through translation. In this paper, we tackle the problem of code-mixed (Hinglish and Bengalish) to English machine translation. First, we synthetically develop HINMIX, a parallel corpus of Hinglish to English,  with ~5M sentence pairs. Subsequently, we propose JAMT, a robust perturbation based joint-training model that learns to handle noise in the real-world code-mixed text by parameter sharing across clean and noisy words. Further, we show the adaptability of JAMT in a zero-shot setup for Bengalish to English translation. Our evaluation and comprehensive analyses qualitatively and quantitatively demonstrate the superiority of JAMT over state-of-the-art code-mixed and robust translation methods.",/pdf/c8fe1414acadc763f257fa277a946c9b7875a505.pdf,/attachment/e83f7e29b4e2a47402725173f14b13370ff82f52.zip,,,,anonymous|synthetic_data_generation_and_joint_learning_for_robust_codemixed_translation,,,,,,,/attachment/330d399348cd2be8644d749899c58e2a211a53a5.pdf,https://openreview.net/forum?id=iJvRzKAN2d,/attachment/f7eb755b142ed190fc8cbf90b777d2d7b9a11017.pdf
389,3BdPjeRA1dz,Semi-supervised New Event Type Induction and Description via Contrastive Loss-Enforced Batch Attention,['aclweb.org/ACL/ARR/2021/November/Paper732/Authors'],['Anonymous'],"Most event extraction methods have traditionally relied on an annotated set of event types. However, creating event ontologies and annotating supervised training data are expensive and time-consuming. Previous work has proposed semi-supervised approaches which leverage seen (annotated) types to learn how to automatically discover new event types. State-of-the-art methods, both semi-supervised or fully unsupervised, use a form of reconstruction loss on specific tokens in a context. In contrast, we present a novel approach to semi-supervised new event type induction using a masked contrastive loss which learns similarities between event mentions by enforcing an attention mechanism over the data minibatch. We further disentangle the discovered clusters by approximating the underlying manifolds in the data, which allows us to increase normalized mutual information and Fowlkes-Mallows scores by over 20% absolute. Building on these clustering results, we extend our approach to two new tasks: predicting the type name of the discovered clusters and linking them to FrameNet frames.",/pdf/ddc88f16b385c3843e67ed55269a6405c93f50d6.pdf,,,,,anonymous|semisupervised_new_event_type_induction_and_description_via_contrastive_lossenforced_batch_attention,,,,,,,,,
390,cKaOKRNt0et,Multilingual unsupervised sequence segmentation transfers to extremely low-resource languages,['aclweb.org/ACL/ARR/2021/November/Paper691/Authors'],['Anonymous'],"We show that unsupervised sequence-segmentation performance can be transferred to extremely low-resource languages by pre-training a Masked Segmental Language Model (Downey et al., 2021) multilingually. Further, we show that this transfer can be achieved by training over a collection of low-resource languages that are typologically similar (but phylogenetically unrelated) to the target language. In our experiments, we transfer from a collection of 10 Indigenous American languages (AmericasNLP, Mager et al., 2021) to K'iche', a Mayan language. We compare our multilingual model to a monolingual (from-scratch) baseline, as well as a model pre-trained on Quechua only. We show that the multilingual pre-trained approach yields consistent segmentation quality across target dataset sizes, exceeding the monolingual baseline in 6/10 experimental settings. Our model yields especially strong results at small target sizes, including a zero-shot performance of 20.6 F1. These results have promising implications for low-resource NLP pipelines involving human-like linguistic units, such as the sparse transcription framework proposed by Bird (2020).",/pdf/75f3caa20cac124e206d5688886de427692b5418.pdf,,,,,anonymous|multilingual_unsupervised_sequence_segmentation_transfers_to_extremely_lowresource_languages,,,,,,,,,
391,gxU4jLdYCPG,To Know by the Company Words Keep and What Else Lies in the Vicinity,['aclweb.org/ACL/ARR/2021/November/Paper1162/Authors'],['Anonymous'],"The development of state-of-the-art (SOTA) Natural Language Processing (NLP) systems has steadily been establishing new techniques to absorb the statistics of linguistic data. These techniques often trace well-known constructs from traditional theories, and we study these connections to close gaps around key NLP methods as a means to orient future work. For this, we introduce an analytic model of the statistics learned by seminal algorithms (including GloVe and Word2Vec), and derive insights for systems that use these algorithms and the statistics of co-occurrence, in general. In this work, we derive—to the best of our knowledge—the first known solution to Word2Vec's softmax-optimized, skip-gram algorithm. This result presents exciting potential for future development as a direct solution to a deep learning (DL) language model's (LM's) matrix factorization. However, we use the solution to demonstrate a seemingly-universal existence of a property that word vectors exhibit and which allows for the prophylactic discernment of biases in data—prior to their absorption by DL models. To qualify our work, we conduct an analysis of independence, i.e., on the density of statistical dependencies in co-occurrence models, which in turn renders insights on the distributional hypothesis' partial fulfillment by co-occurrence statistics.",/pdf/f2fd924c25de833adad547ca1412d9a969daf064.pdf,,,,,anonymous|to_know_by_the_company_words_keep_and_what_else_lies_in_the_vicinity,,,,,,,,,
392,khB9is39GvL,A simple log-based loss function for ordinal text classification,['aclweb.org/ACL/ARR/2021/November/Paper890/Authors'],['Anonymous'],"The cross-entropy loss function is widely used and generally considered the default loss function for text classification. When it comes to ordinal text classification where there is an ordinal relationship between labels, the cross-entropy is not optimal as it does not incorporate the ordinal character into its feedback. In this paper, we propose a new simple loss function called ordinal log-loss (OLL). We show that this loss function outperforms state-of-the-art previously introduced losses on four benchmark text classification datasets.",/pdf/ba2e24ad917a222bf9bea0cf069fc3759823e8eb.pdf,,,,,anonymous|a_simple_logbased_loss_function_for_ordinal_text_classification,,,,,,,,,
393,YX9jpnLrgWz,PARE: A Simple and Strong Baseline for Monolingual and Multilingual Distantly Supervised Relation Extraction,['aclweb.org/ACL/ARR/2021/November/Paper2696/Authors'],['Anonymous'],"Neural models for distantly supervised relation extraction (DS-RE) encode each sentence in an entity-pair bag separately. These are then aggregated for bag-level relation prediction. Since, at encoding time, these approaches do not allow information to flow from other sentences in the bag, we believe that they do not utilize the available bag data to the fullest. In response, we explore a simple baseline approach (PARE) in which all sentences of a bag are concatenated into a passage of sentences, and encoded jointly using BERT. The contextual embeddings of tokens are aggregated using attention with the candidate relation as query -- this summary of whole passage predicts the candidate relation. We find that our simple baseline solution outperforms existing state-of-the-art DS-RE models in both monolingual and multilingual DS-RE datasets.",/pdf/1f0e24ac43d8331963bee5caf94236b27e30817d.pdf,/attachment/579245a141ffe11e96501efdc0918cdb96d64d8b.zip,,,,anonymous|pare_a_simple_and_strong_baseline_for_monolingual_and_multilingual_distantly_supervised_relation_extraction,,,,,,,,,
394,w64KCa6EMP6,On the Origin of Hallucinations in Conversational Models: Is it the Datasets or the Models?,['aclweb.org/ACL/ARR/2021/November/Paper1922/Authors'],['Anonymous'],"Although knowledge-grounded conversational models are able to generate fluent responses that are indistinguishable from human-generated ones, they are known to suffer from producing factually invalid statements, a phenomenon commonly called hallucination.  In this work, we investigate the underlying causes of this phenomenon: is hallucination due to the training data, or to the models? We conduct a comprehensive human study on both existing knowledge-grounded dialogue datasets and several state-of-the-art models. Our study reveals that the standard benchmarks consist of more than 60% hallucinated responses, leading to models that not only hallucinate but even amplify hallucinations. Moreover, we qualitatively analyze the nature of hallucinations, and identify key response strategies used by humans and models that lead to hallucinations. We hope these insights will show the way forward towards building hallucination-free conversational models.",/pdf/1d44e05d9717d270f6366950f4a86044532048d9.pdf,,,,,anonymous|on_the_origin_of_hallucinations_in_conversational_models_is_it_the_datasets_or_the_models,,,,,,,,,
395,70mgWeTodiu,Computer Science Articles Named Entity Recognition Datasets: Survey and Our Recent Development,['aclweb.org/ACL/ARR/2021/November/Paper2703/Authors'],['Anonymous'],"Domain-specific named entity recognition on Computer Science (CS) scholarly articles is an information extraction task that is arguably more challenging and less studied than named entity recognition (NER) for the general domain. Given that significant progress has been made on NER, we believe that scholarly domain-specific NER will receive increasing attention in the NLP community. Nevertheless, progress on the task is currently hampered in part by its recency and the lack of standardized concept types for scientific entities/terms. This paper presents a survey of the current state of research on scholarly domain-specific NER with a focus on language resources; further, it creates a novel dataset and model for CS NER.",/pdf/8fbd80690920d66117febe5acea275c39ee2fdbe.pdf,/attachment/0f99bd06a6e5fd15fdab81909556b3f632235b39.zip,,,,anonymous|computer_science_articles_named_entity_recognition_datasets_survey_and_our_recent_development,,,,,,/attachment/b23eb55eb8eb7f4f93da83f71ddefeb522785f73.zip,,,
396,XVPvYByfPxV,RE: A Study for Restorable Embeddings,['aclweb.org/ACL/ARR/2021/November/Paper1703/Authors'],['Anonymous'],"As the number of model parameters increased, large language models achieved linguistic fluency and exhibited high performance in various natural language tasks without gradient updates because the models could retain more knowledge.
However, the large model size makes difficult to apply the model to a task requiring domain knowledge not included in the training corpus, due to the fact that knowledge stored in model parameters is not controllable during generation and model parameter updates are costly.
To tackle the problem, we suggest separating the language model and knowledge, and divide the end-to-end language model into three parts: 1) encoding knowledge, 2) processing the encoded knowledge, and 3) restoring the processed knowledge embedding to natural language.
In this paper, we propose a model for learning restorable embeddings as a first step toward the study to separate the language model and knowledge.
The experimental results shows that the proposed model can restore most knowledge in 1-2 sentences by encoding knowledge in sentence-level embeddings and then restoring the embeddings back to the original sentence.
We also verify that the embeddings generated through our method significantly improves performance in the passage retrieval task.",/pdf/35456fc0429e19036e14a4ced8368a5441d18b38.pdf,,,,,anonymous|re_a_study_for_restorable_embeddings,,,,,,,,,
397,twwib_D8Xw_,How do we get there? Evaluating transformer neural networks as cognitive models for English past tense inflection,['aclweb.org/ACL/ARR/2021/November/Paper1844/Authors'],['Anonymous'],"Neural network models have achieved good performance on morphological inflection tasks, including English past tense inflection. However whether they can represent human cognitive mechanisms is still under debate. In this work, we examined transformer models with different training size to show that: 1) neural models correlate with both human behaviors and cognitive theories' predictions on nonce verbs; and the model with small-size training data that matches parents' input distribution has the highest correlation; 2) neural models make different types of errors on regular and irregular verbs, exhibiting a clear distinction between regulars and irregulars. Therefore, we conclude that neural networks have the potential to be good cognitive models for English past tense. ",/pdf/3c663d8ca850e52308316cbcdf3f8009caeb218d.pdf,,,,,anonymous|how_do_we_get_there_evaluating_transformer_neural_networks_as_cognitive_models_for_english_past_tense_inflection,,,,,,,,,
398,0sEinjti_7d,Hierarchical Inductive Transfer for Continual Dialogue Learning,['aclweb.org/ACL/ARR/2021/November/Paper2954/Authors'],['Anonymous'],"Pre-trained models have achieved excellent performance on the dialogue task. 
However, for the continual increase of online chit-chat scenarios, directly fine-tuning these models for each of the new tasks not only explodes the capacity of the dialogue system on the embedded devices but also causes knowledge forgetting on pre-trained models and knowledge interference between diverse dialogue tasks. 
In this work, we propose a hierarchical inductive transfer framework to learn and deploy the dialogue skills continually and efficiently. 
First, we introduce the adapter module into pre-trained models for learning new dialogue tasks. As the only trainable module, it is beneficial for the dialogue system on the embedded devices to acquire new dialogue skills with negligible additional parameters. 
Then, for alleviating knowledge interference between tasks yet benefiting the regularization between them, we further design hierarchical inductive transfer that enables new tasks to use general knowledge in the base adapter without being misled by diverse knowledge in task-specific adapters. 
Empirical evaluation and analysis indicate that our framework obtains comparable performance under deployment-friendly model capacity.",/pdf/5ba7f19cfbb322e9ea844ef5eb99f8522264fc81.pdf,,,,,anonymous|hierarchical_inductive_transfer_for_continual_dialogue_learning,,,,,,,,,
399,2Po_v-AG9u,There’s a Time and Place for Reasoning Beyond the Image,['aclweb.org/ACL/ARR/2021/November/Paper1687/Authors'],['Anonymous'],"Images are often more significant than only the pixels to human eyes, as we can infer, associate, and reason with contextual information from other sources to establish a more complete picture. For example, in Figure 1, we can find a way to identify the news articles related to the picture through segment-wise understandings on the signs, the buildings, the crowds, and more. This tells us the time when and the location where the image is taken, which will help us in subsequent tasks, such as evidence retrieval for criminal activities, automatic storyline construction, and upper-stream processing such as image clustering. 

In this work, we formulate this problem and introduce TARA: a dataset with 16k images with their associated news, time and location automatically extracted from New York Times (NYT), and an additional 61k examples as distant supervision from WIT. On top of the extractions, we present a crowdsourced subset in which images are believed to be feasible to find their spatio-temporal information for evaluation purpose. We show that there exists a $70\%$ gap between a state-of-the-art joint model and human performance, which is slightly filled by our proposed model that uses segment-wise reasoning, motivating higher-level vision-language joint models that can conduct open-ended reasoning with world knowledge.",/pdf/a041ec3c6b166c61e2f653d4c16f2749a58d01d4.pdf,,,,,anonymous|theres_a_time_and_place_for_reasoning_beyond_the_image,,,,,,,,,
400,otY8XMglGjt,,,,,,,,,,,,,,,,,,,
401,cDgycoo6ayT,Exploring Meaning Encoded in Random Character Sequences with Character-Aware Language Models,['aclweb.org/ACL/ARR/2021/November/Paper1469/Authors'],['Anonymous'],"Natural language processing models learn word representations based on the distributional hypothesis, which asserts that word context (e.g., co-occurrence) correlates with semantic meaning. We propose that n-grams composed of random character sequences, or garble, provide a novel context for studying word meaning both within and beyond extant language. In particular, randomly-generated character n-grams lack semantic meaning but contain primitive information based on the distribution of characters they contain. By studying the embeddings of a large corpus of garble, extant language, and pseudowords using CharacterBERT, we identify an axis in the model's high-dimensional embedding space that separates these classes of n-grams. Furthermore, we show that this axis relates to structure within extant language, including word part of speech, morphology, and concreteness. Thus, in contrast to studies that are mainly limited to extant language, our work reveals that semantic meaning and primitive information are intrinsically linked.",/pdf/5a219202f98b63e17293698c1ef209af65d12145.pdf,/attachment/bdd973cd7dd38110c5acb3cd16497288960d8ce4.zip,,,,anonymous|exploring_meaning_encoded_in_random_character_sequences_with_characteraware_language_models,,,,,,/attachment/8f9d3a93ca6e05e9f2ec0d3ad34889e352271a35.zip,,,
402,GLHYGaRdlYL,REDTABS: A Collection of Report Document Datasets for Long Text and Multi-Table Summarization,['aclweb.org/ACL/ARR/2021/November/Paper2612/Authors'],['Anonymous'],"Automatic document summarization aims to produce a concise summary covering the input document's salient content. 
Within a report document, both the textual and non-textual content (e.g., tables and figures) can be important information sources for the summary. However, most available document summarization datasets focus on the text and filter out the non-textual content. Missing tabular data can limit the informativeness of produced summaries, especially when target summaries require to cover quantitative descriptions of critical metrics, whose numerical information is usually kept in tables. In this paper, we address this issue by introducing REDTABS, the first collection of large-scale datasets for long text and multi-table summarization. Built on companies' annual reports, it includes three large-scale datasets for summarizing these companies' business, results of operations, and overall conditions, respectively. We also present the Segment-Alignment-based long Text and multi-Table summarization (SATT) method incorporating textual and tabular data into the summarization process. Besides, we propose a set of automatic evaluation metrics to assess the numerical information in summaries produced by summarization models. Dataset analyses and experimental results reveal the importance of incorporating textual and tabular data into the report document summarization. We will release our data and code to facilitate advances in summarization and text generation research.",/pdf/73a54eb8a7a51a7c0be1904909d83076e7c71691.pdf,,,,,anonymous|redtabs_a_collection_of_report_document_datasets_for_long_text_and_multitable_summarization,,,,,,,,,
403,TTwsY79odG9,Psych-E: Configurable Response Generation using Personality Traits and Pragmatics,['aclweb.org/ACL/ARR/2021/November/Paper598/Authors'],['Anonymous'],"Personality traits influence human actions and thoughts, which is manifested in day to day conversations. Although glimpses of personality traits are observable in existing open domain conversation corpora, leveraging generic language modelling for response generation overlooks the interlocutor idiosyncrasies, resulting in non-customizable personality agnostic responses. With the motivation of enabling configurable response generators, in this paper we experiment with ways to ground neural response generators based on both (i) interlocutor Big-5 personality traits, and (ii) discourse intent as control codes, training an end-to-end dialogue agent that can not only leverage the control codes as policy for nuanced response generation, but also predict and decide the generation policy to be utilized by the generator. Since most of the existing large scale open domain chat corpora do not include Big-5 personality traits and discourse intent, we employ automatic annotation schemes to enrich the corpora with policy consisting of noisy estimates of these features as control codes, and leverage automatic evaluation metrics along with ablation studies, to assess the impact of using control codes for response generation. Additionally, we leverage human judgement to demonstrate the effectiveness of using such personality and pragmatics based policy for response generation. Our experiments illustrate the effectiveness of this strategy resulting in improvements to existing benchmarks.",/pdf/c759564abb2745f1a55495c10087944f0b4a0ad3.pdf,,,,,anonymous|psyche_configurable_response_generation_using_personality_traits_and_pragmatics,,,,,,,,,
404,NKIMR7aKHA2,Structure and Features Fusion with Evidential Graph Convolutional Neural Network for Node Classification,['aclweb.org/ACL/ARR/2021/November/Paper1151/Authors'],['Anonymous'],"Recently, text-enhanced network representation learning has achieved great success by taking advantage of rich text information and network structure information. However, content-rich network representation learning and quantifying classiﬁcation uncertainty are challenging when it comes to integrating complex structural dependencies and rich content features at an evidence level. In this paper, we propose an evidential graph representation learning model (EGCN), which can not only fuse network structure and content information into a more complete and powerful representation for each node, but also assess the quality of graph node features to improve classification accuracy. To achieve better fusion, we integrate the node's features representation into structure-aware representation through a delivery operator. Besides, to overcome the difﬁculty of predicting node classification conﬁdence, we employ a novel module based on Dirichlet distribution theory of evidence and subject opinion learning to collect the evidence of the class probabilities. Experimental results on three real-world networks show that our model can improve both node classification accuracy and robustness as compared to all baselines.",/pdf/8a1bb45b5f032f0185b43f3a86f70b02d839f14b.pdf,/attachment/53674effc8f15df54ac7f275cbe96cceb627e979.zip,,,,anonymous|structure_and_features_fusion_with_evidential_graph_convolutional_neural_network_for_node_classification,,,,,,/attachment/161a85f8e5a5389e7d312f2ac944e5a327821589.zip,,,
405,OBp6HsVJGC,LogInsights: Understanding and Extracting Information from Logs for Fault Classification at run-time,['aclweb.org/ACL/ARR/2021/November/Paper1897/Authors'],['Anonymous'],"Software monitoring is the most critical part in any software management life cycle. One of the ways to detect the health of the program and the software is to monitor the logs efficiently. In this paper, we describe a method to process a stream of logs for identifying any fault being mentioned in the log at runtime. At first, we extract meaningful features for detecting the erroneous ones from the stream of logs. Next, we categorize the erroneous logs into the pre-defined categories of commonly occurring faults, using the proposed two-step framework. We propose efficient, fast and intelligent rule-based systems with the domain knowledge being incorporated using the word embedding model. We have built a domain specific corpus and trained a word embedding model for this purpose. The methods described here have shown improved results in the existing product pipeline. Experiments on logs obtained from various applications also show the efficacy of our proposed method.",/pdf/d2e332836b5cfc5b2f1f516fbcf4ce689cec09ec.pdf,,,,,anonymous|loginsights_understanding_and_extracting_information_from_logs_for_fault_classification_at_runtime,,,,,,,,,
406,zSSh7IaUbcm,Linguistic Diversity Scores for NLP Data Sets,['aclweb.org/ACL/ARR/2021/November/Paper2511/Authors'],['Anonymous'],"Quantifying linguistic diversity in multilingual data sets is important for improving cross-linguistic coverage of NLP models. However, current linguistic diversity scores rely mostly on measures such as the number of languages in the sample, which are not very informative about the structural properties of languages. In this paper, we propose a score derived from the distribution of text statistics (mean word length) as a linguistic attribute suitable for cross-linguistic comparison. We compare NLP data sets (UD, Bible100. mBERT, XTREME, XGLUE, XNLI, XCOPA, TyDiQA, XQuAD) to a new data set designed specifically for the purpose of being typologically representative (WALS-SC). To do so, we apply a version of the Jaccard index ($J_{mm}$) suitable for comparing sets of measures. This diversity score can identify the types of languages that need to be included in multilingual data sets in order to reach broad linguistic coverage. We find, for example, that (poly)synthetic languages are missing in almost all data sets. ",/pdf/df6fec210bb9c6d20f6a40f9d10d8f523227f16b.pdf,,,,,anonymous|linguistic_diversity_scores_for_nlp_data_sets,,,,,,,,,
407,IoJr7kQ33aM,Subword Information for Authorship Attribution: A Deep Learning Approach,['aclweb.org/ACL/ARR/2021/November/Paper1148/Authors'],['Anonymous'],"Authorship attribution is the process of unveiling the hidden identity of authors from a corpus of literary data. Many previous works on authorship attribution employed word-based models to capture an author's distinctive writing style. The vocabulary of the training corpus is heavily dependent on the pre-trained word vectors, which limits the performance of these models. Alternate methods using character-based models proposed to overcome the rare word problems arising from different linguistic features fail to capture the sequential relationship of words inherently present in the texts. The question we addressed in this paper is whether it is possible to tackle the ambiguity of hidden writing style (or words) as we introduce Gaussian noise while preserving the sequential context of the text to improve authorship-related tasks. In this work,  we propose two bidirectional long short-term memory (BLSTM) with a 2D convolutional neural network (CNN) over a two-dimensional pooling operation to capture sequential writing styles for distinguishing different authors. To determine the appropriate writing style representation, we used BLSTM to obtain the sequential relationship between characteristics using subword information and 2D CNN is adopted to understand the local syntactical position of the style from unlabelled input text. We extensively evaluate the model that leverages subword embedding and compare it against state-of-the-art methods for an extensive range of authors. Our methods improve 2.42\%, 0.96\% and 0.97\% on CCAT50, Blog50 and Twitter, respectively and produce comparable results on the remaining one.",/pdf/42e1230e2765af23d19aecfc8f9a5e1c64ad40d8.pdf,,,,,anonymous|subword_information_for_authorship_attribution_a_deep_learning_approach,,,,,,,,,
408,q88yjuFBggv,Neural Keyphrase Generation: Analysis and Evaluation,['aclweb.org/ACL/ARR/2021/November/Paper661/Authors'],['Anonymous'],"Keyphrase generation aims at generating topical phrases from a given text either by copying from the original text (present keyphrases) or by producing new keyphrases (absent keyphrases) that capture the semantic meaning of the text. Encoder-decoder models are most widely used for this task because of their capabilities for absent keyphrase generation. However, there has been little to no analysis on the performance and behavior of such models for keyphrase generation. In this paper, we study various tendencies exhibited by two strong models: T5 (based on a pre-trained transformer) and ExHiRD (based on a recurrent neural network). We analyze prediction confidence scores, model calibration, and the effect of position on present keyphrases generation. Moreover, we motivate and propose a novel metric, SoftKeyScore, to evaluate the similarity between two sets of keyphrases by using soft-scores to account for partial matching and semantic similarity. We find that SoftKeyScore performs better than the standard F$_{1}$ metric for evaluating two sets of given keyphrases. We will release our code.",/pdf/98e821bbae84935186bb84c0d35fbf9c3fd02866.pdf,,,,,anonymous|neural_keyphrase_generation_analysis_and_evaluation,,,,,,,,,
409,Yy2sTU8uCak,Data Augmentation for Intent Classification with Generic Large Language Models,['aclweb.org/ACL/ARR/2021/November/Paper1569/Authors'],['Anonymous'],"Data augmentation alleviates the problem of data scarcity when training language models (LMs) by generating new examples based on the existing data. A successful approach to generate new samples is to fine-tune a pretrained LM on the task-specific data and then sample from the label-conditioned LM. However, fine-tuning can be difficult when task-specific data is scarce. In this work, we explore whether large pretrained LMs can be used to generate new useful samples without fine-tuning. For a given class, we propose concatenating few examples and prompt them to GPT-3 to generate new examples. We evaluate this method for few-shot intent classification on CLINC150 and SNIPS and find that data generated by GPT-3 greatly improves the performance of the intent classifiers. Importantly, we find that, without any LM fine-tuning, the gains brought by data augmentation with GPT-3 are similar to those reported in prior work on LM-based data augmentation. Experiments with models of different sizes show that larger LMs generate higher quality samples that yield higher accuracy gains.",/pdf/c69f0e0d374d971218d0546de162923708de0fd8.pdf,/attachment/fbc80d9a2f980effb3f7380f442bf60da7482ffb.zip,,,,anonymous|data_augmentation_for_intent_classification_with_generic_large_language_models,,,,,,,,,
410,Lxf2vB1YTG2,"Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective",['aclweb.org/ACL/ARR/2021/November/Paper2372/Authors'],['Anonymous'],"Metamorphic testing has recently been used to check the safety of neural NLP models. Its main advantage is that it does not rely on a ground truth to generate test cases. However, existing studies are mostly concerned with robustness-like metamorphic relations, limiting the scope of linguistic properties they can test. We propose three new classes of metamorphic relations, which address the properties of systematicity, compositionality and transitivity. Unlike robustness, our relations are defined over multiple source inputs, thus increasing the number of test cases that we can produce by a polynomial factor. With them, we test the internal consistency of state-of-the-art NLP models, and show that they do not always behave according to their expected linguistic properties. Lastly, we introduce a novel graphical notation that efficiently summarises the inner structure of metamorphic relations.",/pdf/db0219a778daa296a55bb993aa5e9489d6980dcd.pdf,/attachment/0cd5688320eae334e9cafd6d15122957f336e31e.zip,,,,anonymous|systematicity_compositionality_and_transitivity_of_deep_nlp_models_a_metamorphic_testing_perspective,,,,,,,,,
411,C1XEENowywW,Modeling Multi-hop Question Answering as Single Sequence Prediction,['aclweb.org/ACL/ARR/2021/November/Paper1842/Authors'],['Anonymous'],"Fusion-in-decoder (Fid) (Izacard and Grave, 2020) is a generative question answering (QA) model that leverages passage retrieval with a pre-trained transformer and pushed the state of the art on single-hop QA. However, the complexity of multi-hop QA hinders the effectiveness of the generative QA approach. In this work, we propose a simple generative approach (PathFid) that extends the task beyond just answer generation by explicitly modeling the reasoning process to resolve the answer for multi-hop questions. By linearizing the hierarchical reasoning path of supporting passages, their key sentences, and finally the factoid answer, we cast the problem as a single sequence prediction task. To facilitate complex reasoning with multiple clues, we further extend the unified flat representation of multiple input documents by encoding cross-passage interactions. Our extensive experiments demonstrate that PathFid leads to strong performance gains on two multi-hop QA datasets: HotpotQA and IIRC. Besides the performance gains, PathFid is more interpretable, which in turn yields answers that are more faithfully grounded to the supporting passages and facts compared to the baseline Fid model.",/pdf/944fa7611a614c535c7d3125e85889c8218ae010.pdf,,,,,anonymous|modeling_multihop_question_answering_as_single_sequence_prediction,,,,,,,,,
412,qXF7cHUGuEI,Legal Fairness Analysis via Treatment Effect Estimation,['aclweb.org/ACL/ARR/2021/November/Paper739/Authors'],['Anonymous'],"Legal fairness is one of the most important principles pursued by modern legal systems. Unfortunately, unfairness may be inevitably introduced in real-world cases due to both objective and subjective uncertainty, such as ambiguity in the law or practical bias in judgments. Existing works for fairness analysis mainly rely on labor-intensive element annotation for cases, which suffer from limited generalization ability. To address this issue, we propose to utilize large-scale textual data to perform quantitative legal fairness analysis via our Causal-based Legal Fairness Measuring Framework (CaLF). To verify its effectiveness, we construct a legal-fairness dataset, and experimental results show that CaLF can accurately characterize the unfairness. Further, we adopt CaLF on a large-scale real-world dataset and come to several interesting experimental observations from the perspective of gender, age, and region.",/pdf/a0f85126c806a522b1d1f9fdc18045138d539a31.pdf,/attachment/a279ed5bcc21657ad0657213ac308a60a6f131ca.zip,,,,anonymous|legal_fairness_analysis_via_treatment_effect_estimation,,,,,,,/attachment/65fe970d0787f6e85d38d47d62078cbec22b9b5c.pdf,https://openreview.net/forum?id=krpuPk6VSD9,/attachment/6131c03914888cab3f09c288ceca60a1a4018efc.pdf
413,1Ziurr_xLTh,MetaPrompting: Learning to Learn Better Prompts,['aclweb.org/ACL/ARR/2021/November/Paper2838/Authors'],['Anonymous'],"Prompting method is regarded as one of the crucial progress for few-shot nature language processing. Recent research on prompting moves from discrete tokens based ""hard prompts"" to continuous ""soft prompts"", which employ learnable vectors as pseudo prompts and achieve better performance. Though showing promising prospects, these soft-prompting methods are observed to rely heavily on good initialization to take effect. Unfortunately, obtaining a perfect initialization for soft prompt requires understanding of inner language models working and elaborate design, which is no easy task and has to restart from scratch for each new task. To remedy this, we propose a generalized soft prompting method called MetaPrompting, which adopts the well-recognized model-agnostic meta-learning algorithm to automatically find better prompt initialization that facilitates fast adaptation to new prompting tasks. Experiments show MetaPrompting brings significant improvements on three different datasets (over 6.5 points improvements for 1-shot setting), and achieves new state-of-the-art performance. ",/pdf/e0b380487a7ee765ba586c2b3579f670340f3a39.pdf,,,,,anonymous|metaprompting_learning_to_learn_better_prompts,,,,,,,,,
414,e6psgL085AV,Incorporating Multiple Knowledge Sources for Targeted Aspect-based Financial Sentiment Analysis,['aclweb.org/ACL/ARR/2021/November/Paper329/Authors'],['Anonymous'],"Combining symbolic and subsymbolic methods has become a promising strategy as research tasks in AI grow increasingly complicated and require a higher levels of understanding. Targeted Aspect-based Financial Sentiment Analysis (TABFSA) is one of such complicated tasks, as it involves information extraction, specification, and domain adaptation. External knowledge has been proven useful for general-purpose sentiment analysis, but not yet for the finance domain. Current state-of-the-art Financial Sentiment Analysis (FSA) models, however, have overlooked the importance of external knowledge. To fill this gap, we propose using attentive CNN and LSTM to strategically integrate multiple external knowledge sources into the pre-trained language model fine-tuning process for TABFSA. Experiments on the FiQA Task 1 and SemEval 2017 Task 5 datasets show that the knowledge-enabled models systematically improve upon their plain deep learning counterparts, and some outperform the state-of-the-art results reported in terms of aspect sentiment analysis error.",/pdf/68f0ce0c8910a7d921af879ad73654925fb1e46a.pdf,,,,,anonymous|incorporating_multiple_knowledge_sources_for_targeted_aspectbased_financial_sentiment_analysis,,,,,,,,,
415,z6ZGKexu8un,Automatic Identification of Cuneiform Fragments Using String Alignment Algorithms,['aclweb.org/ACL/ARR/2021/November/Paper580/Authors'],['Anonymous'],"The literature from ancient Mesopotamia is still riddled with textual lacunas. Scores of fragments which could potentially fill those lacunas lie unidentified in museums's cabinets, but their identification has traditionally been slow and laborious due to the ambiguities of cuneiform script. The present article presents a novel method for dealing with these ambiguities by using a string alignment algorithm adapted for cuneiform, which makes identification much easier and speeds up the process dramatically. The availability of this algorithm and of corpora on which to use it will advance significantly the reconstruction of Mesopotamian literature.",/pdf/b451b52e30f2cdcd864bb409bd91e190478393d4.pdf,,,,,anonymous|automatic_identification_of_cuneiform_fragments_using_string_alignment_algorithms,,,,,,,,,
416,SZQVEe_4NRh,MReD: A Meta-Review Dataset for Structure-Controllable Text Generation,['aclweb.org/ACL/ARR/2021/November/Paper1679/Authors'],['Anonymous'],"When directly using existing text generation datasets for controllable generation, we are facing the problem of not having the domain knowledge and thus the aspects that could be controlled are limited. A typical example is when using CNN/Daily Mail dataset for controllable text summarization, there is no guided information on the emphasis of summary sentences. A more useful text generator should leverage both the input text and the control signal to guide the generation, which can only be built with deep understanding of the domain knowledge. Motivated by this vision, our paper introduces a new text generation dataset, named MReD. Our new dataset consists of 7,089 meta-reviews and all its 45k meta-review sentences are manually annotated with one of the 9 carefully defined categories, including abstract, strength, decision, etc. We present experimental results on start-of-the-art summarization models, and propose methods for structure-controlled generation with both extractive and abstractive models using our annotated data. By exploring various settings and analyzing the model behavior with respect to the control signal, we demonstrate the challenges of our proposed task and the values of our dataset MReD. Meanwhile, MReD also allows us to have a better understanding of the meta-review domain.",/pdf/ffcb89ca85d6b82cef056efb00a89313fda38e6a.pdf,,,,,anonymous|mred_a_metareview_dataset_for_structurecontrollable_text_generation,,,,,,/attachment/8859e0ddccc10f0c80d369bd73f048192088f4b9.zip,,,
417,5pqPZQQrraW,"Primum Non Nocere: Before working with Indigenous data, the ACL must confront ongoing colonialism",['aclweb.org/ACL/ARR/2021/November/Paper1507/Authors'],['Anonymous'],"In this paper, we challenge the ACL community to reckon with historical and ongoing colonialism by adopting a set of ethical obligations and best practices drawn from the Indigenous studies literature. While the vast majority of NLP research focuses on a very small number of very high resource languages (English, Chinese, etc), some work has begun to engage with Indigenous languages. No research involving Indigenous language data can be considered ethical without first acknowledging that Indigenous languages are not merely very low resource languages. The toxic legacy of colonialism permeates every aspect of interaction between Indigenous communities and outside academic researchers. Ethical research must actively challenge this colonial legacy by explicitly acknowledging and centering Indigenous community goals and Indigenous ways of knowing. To this end, we propose that the ACL draft and adopt an ethical framework for NLP researchers and computational linguists wishing to engage in research involving Indigenous languages.",/pdf/7c6d918aae697f420318f9aea142cdedba483266.pdf,,,,,anonymous|primum_non_nocere_before_working_with_indigenous_data_the_acl_must_confront_ongoing_colonialism,,,,,,/attachment/32b26292a64fa9f66a2814fa737dbb4ae5069a4f.zip,,,
418,z5IgrlFV_e,One General Teacher for Multi-Data Multi-Task: A New Knowledge Distillation Framework for Discourse Relation Analysis,['aclweb.org/ACL/ARR/2021/November/Paper443/Authors'],['Anonymous'],"Automatically identifying the  discourse relations can help many downstream NLP tasks such as reading comprehension. It can be categorized into explicit and implicit discourse relation recognition (EDRR and IDRR). Due to the lack of connectives, IDRR remains to be a big challenge. A good number of methods have been developed to combine explicit data with implicit ones under the multi-task learning framework. However, the difference in linguistic property and class distribution makes it hard to directly optimize EDRR and IDRR with multi-task learning.

In this paper, we take the first step to exploit the knowledge distillation (KD) technique for  discourse relation analysis. Our target is to train a focused single-data single-task student with the help of a general multi-data multi-task teacher. Specifically, we first train one teacher for both the top and second level relation classification tasks with explicit and implicit data. We then transfer the feature embeddings and soft labels from the teacher network to the student network. Extensive experimental results on the popular PDTB dataset proves that our model achieves a new state-of-the-art performance. We also show the effectiveness of our proposed KD architecture through detailed analysis.",/pdf/3401267d61587091d376272050d5fce48c7497e0.pdf,,,,,anonymous|one_general_teacher_for_multidata_multitask_a_new_knowledge_distillation_framework_for_discourse_relation_analysis,,,,,,,,,
419,TcIIMlhW4eT,AbductionRules: Training Transformers to Explain Unexpected Inputs,['aclweb.org/ACL/ARR/2021/November/Paper660/Authors'],['Anonymous'],"Transformers have recently been shown to be capable of reliably performing logical reasoning over facts and rules expressed in natural language, but abductive reasoning - inference to the best explanation of an unexpected observation - has been underexplored despite significant applications to scientific discovery, common-sense reasoning, and model interpretability.

This paper presents AbductionRules, a group of natural language datasets designed to train and test generalisable abduction over natural-language knowledge bases.
We use these datasets to finetune pretrained Transformers and discuss their performance, finding that our models learned generalisable abductive techniques but also learned to exploit the structure of our data.
Finally, we discuss the viability of this approach to abductive reasoning and ways in which it may be improved in future work.",/pdf/bb1e3cd0a1571e86388dec045d4b676c7bb275e5.pdf,,,,,anonymous|abductionrules_training_transformers_to_explain_unexpected_inputs,,,,,,,,,
420,Qqs5X8r-iPX,Query and Extract: Refining Event Extraction as Type-oriented Binary Decoding,['aclweb.org/ACL/ARR/2021/November/Paper1500/Authors'],['Anonymous'],"Event extraction is typically modeled as a multi-class classification problem where both event types and argument roles are treated as atomic symbols. These approaches are usually limited to a set of pre-defined types. We propose a novel event extraction framework that takes both event types and argument roles as natural language queries to extract candidate triggers and arguments from the input text. With the rich semantics in the queries, our framework benefits from the attention mechanisms to better capture the semantic correlation between the event types or argument roles and the input text. Furthermore, the query-and-extract formulation allows our approach to leverage all available event annotations from various ontologies as a unified model. Experiments on two public benchmark datasets, ACE and ERE, demonstrate that our approach achieves the state-of-the-art performance on each dataset and significantly outperforms existing methods on zero-shot event extraction. We will make all the programs publicly available once the paper is accepted.",/pdf/c9c2a4258b706222a52618bb9e8b09262fe6ace0.pdf,,,,,anonymous|query_and_extract_refining_event_extraction_as_typeoriented_binary_decoding,,,,,,,,,
421,xBz8_ZZWM8d,PRIMERA: Pyramid-based Masked Sentence Pre-training for Multi-document Summarization,['aclweb.org/ACL/ARR/2021/November/Paper1349/Authors'],['Anonymous'],"We introduce PRIMERA, a pre-trained model for multi-document representation with a focus on summarization that reduces the need for dataset-specific architectures and large amounts of fine-tuning labeled data. PRIMERA uses our newly proposed pre-training objective designed to teach the model to connect and aggregate information across documents. It also uses efficient encoder-decoder transformers to simplify the processing of concatenated input documents. With extensive experiments on 6 multi-document summarization datasets from 3 different domains on zero-shot, few-shot and full-supervised settings, PRIMERA outperforms current state-of-the-art dataset-specific and pre-trained models on most of these settings with large margins.",/pdf/a59f86489358ac9e02396368fa74e99e8dc3ab04.pdf,/attachment/975610e6eced19337c77b75677c1050613ecd9ab.zip,,,,anonymous|primera_pyramidbased_masked_sentence_pretraining_for_multidocument_summarization,,,,,,,,,
422,UNzc8gReN7m,Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization,['aclweb.org/ACL/ARR/2021/November/Paper709/Authors'],['Anonymous'],"Text summarization aims to generate a short summary for an input text. In this work, we propose a Non-Autoregressive Unsupervised Summarization (NAUS) approach, which does not require parallel data for training. Our NAUS first performs edit-based search towards a heuristically defined score, and generates a summary as pseudo-groundtruth. Then, we train an encoder-only non-autoregressive Transformer based on the search result. We also proposed a dynamic programming approach for length-control decoding, which is important for the summarization task. Experiments on the Gigaword headline generation and DUC2004 datasets show that NAUS achieves state-of-the-art performance for unsupervised summarization, yet largely improving inference efficiency. Further, our algorithm is able to perform length-transfer summary generation.",/pdf/477837458f359a75ee9b8c35070d1ef0f6e7a2dd.pdf,,,,,anonymous|learning_nonautoregressive_models_from_search_for_unsupervised_sentence_summarization,,,,,,,,,
423,WScs7kv3UJh,MAML-CL: Edited Model-Agnostic Meta-Learning for Continual Learning,['aclweb.org/ACL/ARR/2021/November/Paper677/Authors'],['Anonymous'],"Continual learning (CL) exhibits a learning ability to well-learn all sequentially seen tasks drawn from various domains. Yet, existing sequential training methods fail to consolidate learned knowledge from earlier tasks due to data distribution shifts, hereby leading to catastrophic forgetting. We devise an optimization-based meta learning framework for CL in accordance with MAML, where query samples are edited for generalization of learned knowledge. We conduct extensive experiments on text classification in a low resource CL setup, where we downsize training set to its 10%. The experimental results demonstrate the superiority of our method in terms of stability, fast adaptation, memory efficiency and knowledge retention across various domains.",/pdf/a1b2f885be666dd7c104ab1901c3cd0ccd2518af.pdf,,,,,anonymous|mamlcl_edited_modelagnostic_metalearning_for_continual_learning,,,,,,,,,
424,SMEv6k1Nb2,ConTFV: A Contrastive Learning Framework for Table-based Fact Verification,['aclweb.org/ACL/ARR/2021/November/Paper480/Authors'],['Anonymous'],"Table-based fact verification is a binary classification task where the challenging part lies in the table's structural parsing and symbolic reasoning. Jointly pre-training on abundant textual and tabular data has been conducted for table semantic parsing recently. However, these models are designed for the table's general understanding, directly fine-tuning for table-based fact verification cannot exploit the advantages to the full. In this paper, we propose ConTFV, a Contrastive learning framework for Table-based Fact Verification, to make the pre-trained model more task-relevant and tap its potential for better representations. By transforming it into a semantic similarity task, our method can outperform baselines with 1.2% on TabFact.",/pdf/01c9435fbcca5767e00a717317e0ed24ff7a8fe7.pdf,,,,,anonymous|contfv_a_contrastive_learning_framework_for_tablebased_fact_verification,,,,,,,,,
425,Qm_Z1UNDPN_,Pre-Training with Syntactic Structure Prediction for Chinese Semantic Error Recognition,['aclweb.org/ACL/ARR/2021/November/Paper324/Authors'],['Anonymous'],"Existing Chinese text error detection mainly focuses on spelling errors and simple grammatical errors. These errors have been studied extensively and are relatively simple for humans. Chinese Semantic Error Recognition (CSER) pays attention to more complex semantic errors that humans cannot easily recognize compared with Chinese text error detection. Considering the complex syntactic relation between words, we find that syntactic structure from the syntax tree can help identify semantic errors. In this paper, we consider adopting the pre-trained models to solve the task of CSER. To make the model learn syntactic structure in the pre-training stage, we designed a novel pre-training task to predict the syntactic structure from the syntax tree between different words. Due to the lack of a published dataset for CSER, we build a high-quality dataset for CSER for the first time named Corpus of Chinese Linguistic Semantic Acceptability (CoCLSA), which is extracted from the high school examinations. The experimental results on the CoCLSA show that our pre-trained model based on the new pre-training task has a positive performance compared with existing pre-trained models.",/pdf/7f1edeebe9d6e9938de6cf49d87022b7bd028d09.pdf,,,,,anonymous|pretraining_with_syntactic_structure_prediction_for_chinese_semantic_error_recognition,,,,,,,,,
426,S1EBBh_0_qe,Dual Architecture for Name Entity Extraction and Relation Extraction with Applications in Medical Corpora,['aclweb.org/ACL/ARR/2021/November/Paper1745/Authors'],['Anonymous'],"There is a growing interest in automatic knowledge discovery in plain text documents. Automation enables the analysis of massive collections of information. Such efforts are especially relevant in the health domain as advancements could use the large volume of available resources to transform areas important for society when addressing various health research challenges. However, knowledge discovery is usually aided by annotated corpora, which are scarce resources in the literature. This situation is particularly critical in the Spanish language, for which the volume of training resources is less widespread. This work uses a health-oriented Spanish dataset, and it also creates an English variant using the same tagging system. Furthermore, we design and analyze two separated architectures for Entity Extraction and Relation Recognition that outperform previous works in the Spanish dataset. With such promising results, we also evaluate their performance in the English version. Finally, we perform a use case experiment to evaluate the utility of the output of these two architectures in Information Retrieval systems.",/pdf/9a64fceb50186387ff49066f9bb838ca5fb88fdb.pdf,,,,,anonymous|dual_architecture_for_name_entity_extraction_and_relation_extraction_with_applications_in_medical_corpora,,,,,,,,,
427,Suu6OdT8Ml,Unified NMT models for the Indian subcontinent transcending script-barriers,['aclweb.org/ACL/ARR/2021/November/Paper2891/Authors'],['Anonymous'],"Highly accurate machine translation systems are very important in societies and countries where multilinguality is very common, and where English often does not suffice. The Indian subcontinent is such a region, with all the Indic languages currently being under-represented in the NLP ecosystem. It is essential to advance the state-of-the-art of such low-resource languages atleast by using whatever data is available in open-source, which itself is something not very explored in the Indic ecosystem. In our work, we focus on improving the performance of very-low-resource Indic languages, especially of countries in addition to India. Specifically, we propose how unified models can be built that can exploit the data from comparatively resource-rich languages of the same region. We propose strategies to unify different types of unexplored scripts, especially Perso-Arabic scripts and Indic scripts to build multilingual models for all the Indic languages despite the script barrier. We also study how augmentation techniques like back-translation can be made use-of to build unified models that achieve state-of-the-art result among open source models, especially just using openly available raw data.",/pdf/3e10fd74e4bc4fc305f86a50084119e3e31883b8.pdf,,,,,anonymous|unified_nmt_models_for_the_indian_subcontinent_transcending_scriptbarriers,,,,,,,,,
428,rx5o3aIpqKO,Reframing Instructional Prompts to GPTk's Language,['aclweb.org/ACL/ARR/2021/November/Paper2229/Authors'],['Anonymous'],"What kinds of instructional prompts are easier to follow for Language Models (LMs)? We study this question by conducting extensive empirical analysis that shed light on important features of successful instructional prompts. We propose several reframing techniques for model designers to manually create more effective  prompts. Some examples include decomposing a complex task instruction into multiple simpler tasks or itemizing instructions into sequential steps. Our experiments compare the zero-shot and few-shot performance of LMs prompted with reframed instructions on 12 NLP tasks across 6 categories. Compared with original instructions, our reframed instructions lead to  significant improvements across LMs with different sizes, underscoring the cross-model generality of these guidelines. For example, the same reframed prompts boost few-shot performance of GPT3-series and GPT2-series by 12.5% and 6.7% respectively averaged over all tasks. Furthermore,  reframed instructions reduce the number of examples required to prompt LMs in the few-shot setting. We hope these empirically-driven techniques will pave the way for more effective ways to prompt LMs in the future.",/pdf/06f1800e1ae76f2d06533f54d4e5b8df22117a5a.pdf,,,,,anonymous|reframing_instructional_prompts_to_gptks_language,,,,,,,,,
429,3Rfj-IdJ-s,"When Chosen Wisely, More Data Is What You Need: A Universal Sample-Efficient Strategy For Data Augmentation",['aclweb.org/ACL/ARR/2021/November/Paper2993/Authors'],['Anonymous'],"Data Augmentation (DA) is vital in deep learning to improve the generalizability of neural networks. Most of existing DA techniques in NLP naively add a certain number of augmented samples without paying attention to the quality and added computational cost of these samples. Furthermore, state-of-the-art DA techniques in the literature usually learn to generate or re-weight augmented samples more specific to the main task; however, these learning-based DA techniques are not sample-efficient and they are computationally  expensive.  In this work, we propose a universal DA technique, called Glitter, for NLP which aims at efficiency and performance at the same time. In other words, Glitter can be applied to any existing DA technique to improve its training efficiency and sample efficiency and maintain its competitive performance. We evaluate Glitter on several downstream tasks such as the GLUE benchmark, SQuAD, and HellaSwag in a variety of scenarios including general single network, consistency training, self-distillation and knowledge distillation (KD) setups.",/pdf/bea3a724d5f2fc1aabd7c0326c9c069ce6ff8c07.pdf,,,,,anonymous|when_chosen_wisely_more_data_is_what_you_need_a_universal_sampleefficient_strategy_for_data_augmentation,,,,,,,,,
430,Ij_XbC_RuLtK,EigenNoise: A Contrastive Prior to Warm-Start Representations,['aclweb.org/ACL/ARR/2021/November/Paper1077/Authors'],['Anonymous'],"In this work, we present a naïve initialization scheme for word vectors based on a dense, independent co-occurrence model and provide preliminary results that suggest it is competitive, and warrants further investigation. Specifically, we demonstrate through information-theoretic minimum description length (MDL) probing that our model, EigenNoise, can approach the performance of empirically trained GloVe despite the lack of any pre-training data (in the case of EigenNoise). We present these preliminary results with interest to set the stage for further investigations into how this competitive initialization works without pre-training data, as well as to invite the exploration of more intelligent initialization schemes informed by the theory of harmonic linguistic structure. Our application of this theory likewise contributes a novel (and effective) interpretation of recent discoveries which have elucidated the underlying distributional information that linguistic representations capture from data and contrast distributions.",/pdf/c80a545adc2a353674cbc34b01f999b3d21d0ac8.pdf,,,,,anonymous|eigennoise_a_contrastive_prior_to_warmstart_representations,,,,,,,,,
431,gLfSnQcTFgM,Finding the Dominant Winning Ticket in Pre-Trained Language Models,['aclweb.org/ACL/ARR/2021/November/Paper988/Authors'],['Anonymous'],"The Lottery Ticket Hypothesis suggests that for any over-parameterized model, a small subnetwork exists to achieve competitive performance compared to the backbone architecture. In this paper, we study whether there is a winning lottery ticket for pre-trained language models, which allow the practitioners to fine-tune the parameters in the ticket but achieve good downstream performance. To achieve this, we regularize the fine-tuning process with L1 distance and explore the subnetwork structure (what we refer to as the ""dominant winning ticket""). Empirically, we show that (a) the dominant winning ticket can achieve performance that is comparable with that of the full-parameter model, (b) the dominant winning ticket is transferable across different tasks, (c) and the dominant winning ticket has a natural structure within each parameter matrix. Strikingly, we find that a dominant winning ticket that takes up 0.05% of the parameters can already achieve satisfactory performance, indicating that the PLM is significantly reducible during fine-tuning.",/pdf/bb70c60f0da7960c30547455de10ba03dc000a37.pdf,,,,,anonymous|finding_the_dominant_winning_ticket_in_pretrained_language_models,,,,,,,,,
432,y4pgVX_ypf9,TENT: Text Classification Based on ENcoding Tree Learning,['aclweb.org/ACL/ARR/2021/November/Paper178/Authors'],['Anonymous'],"Text classification is a primary task in natural language processing (NLP). Recently, graph neural networks (GNNs) have developed rapidly and been applied to text classification tasks. Although more complex models tend to achieve better performance, research highly depends on the computing power of the device used. In this article, we propose TENT to obtain better text classification performance and reduce the reliance on computing power. Specifically, we first establish a dependency analysis graph for each text and then convert each graph into its corresponding encoding tree. Finally, the representation of each text is obtained by Encoding Tree Learning (ETL), which is based on the form of encoding tree and has low requirement for computing power. Experimental results show that our method outperforms other baselines on several datasets while having a simple structure and few parameters.",/pdf/9d555216413f4587bc08efc402fdbe0279a57dee.pdf,,,,,anonymous|tent_text_classification_based_on_encoding_tree_learning,,,,,,,,,
433,uWvW_Z4P8f,Can Rationalization Improve Robustness?,['aclweb.org/ACL/ARR/2021/November/Paper1875/Authors'],['Anonymous'],"A growing line of work has investigated the development of neural NLP models that can produce rationales---subsets of input that can explain their model predictions.
In this paper, we ask whether such rationale models can also provide robustness to adversarial attacks in addition to their interpretable nature. Since these models need to first generate rationales (``rationalizer'') before making predictions (``predictor''), they have the potential to ignore noise or adversarially added text by simply masking it out of the generated rationale. To this end, we systematically generate various types of `AddText' attacks for both token and sentence-level rationalization tasks, and perform an extensive empirical evaluation of state-of-the-art rationale models across five different tasks.
Our experiments reveal that the rationale models show the promise to improve robustness, while they struggle in certain scenarios---when the rationalizer is sensitive to positional bias or lexical choices of attack text. Further, leveraging human rationale as supervision does not always translate to better performance. Our study is a first step towards exploring the interplay between interpretability and robustness in the rationalize-then-predict framework.",/pdf/f7388c3203d790f7a51e9b35cdc455f43a6878f3.pdf,/attachment/cbb208ac28fd52988ebd47547ddb920885556115.zip,,,,anonymous|can_rationalization_improve_robustness,,,,,,,,,
434,7M6Rudku_sk,From Stance to Concern: Adaptation of Propositional Analysis to New Tasks and Domains,['aclweb.org/ACL/ARR/2021/November/Paper694/Authors'],['Anonymous'],"We present a generalized paradigm for adaptation of propositional analysis (predicate-argument pairs) to new tasks and domains, leveraging an analogy between stances (belief-driven sentiment) and concerns (topical issues with moral dimensions/endorsements). A key contribution is the combination of semi-automatic resource building for extraction of domain-dependent concern types (with 2-4 hours of human labor per domain) and an entirely automatic procedure for extraction of domain-independent moral dimensions and endorsement values.  Prudent (automatic) selection of terms from propositional structures for lexical expansion (via semantic similarity) produces new moral dimension lexicons at three levels of granularity beyond a strong baseline lexicon. We develop a ground truth (GT) based on expert annotators and compare our concern detection output to GT, to yield 231% improvement in recall over baseline, with only a 10% loss in precision. F1 yields 66% improvement over baseline and 97.8% of human performance. Moreover, our lexically based approach yields large savings in terms of human labor and costly model building. Work produced herein provides to the community a newly expanded moral dimension/value lexicon, annotation guidelines, and GT.",/pdf/0dce18c469491dadbaccf1976d701f2ff8061775.pdf,,,,,anonymous|from_stance_to_concern_adaptation_of_propositional_analysis_to_new_tasks_and_domains,,,,,,,,,
435,9kXOFRtrEj,E-KAR: A Benchmark for Rationalizing Natural Language Analogical Reasoning,['aclweb.org/ACL/ARR/2021/November/Paper2673/Authors'],['Anonymous'],"The ability to recognize analogies is fundamental to human cognition. Existing benchmarks to test word analogy does not reveal the underneath process of analogical reasoning of neural models. Holding the belief that models capable of reasoning should be right for the right reasons, we propose a first-of-its-kind Explainable Knowledge-intensive Analogical Reasoning benchmark (E-KAR). Our benchmark consists of 1,665 problems sourced from the Civil Service Exams, which require intensive background knowledge to solve. Besides, we design a free-text explanation scheme to explain how an analogy is drawn, and manually annotate E-KAR with 8,325 knowledge-rich sentences of such explanations. Empirical results suggest that this benchmark is very challenging to some state-of-the-art models for both explanation generation and analogical question answering tasks, which invites further research in this area.",/pdf/5c4c9067f3e8c61995e810bf2938d8ccb9be953f.pdf,,,,,anonymous|ekar_a_benchmark_for_rationalizing_natural_language_analogical_reasoning,,,,,,/attachment/ba646ca3ed701cb782b7cab0fa215c723927fd2c.zip,,,
436,UFg2s8Yabc7,Training Dynamics for Text Summarization Models,['aclweb.org/ACL/ARR/2021/November/Paper1419/Authors'],['Anonymous'],"Pre-trained language models (e.g. BART) have shown impressive results when fine-tuned on large summarization datasets. However, little is understood about this fine-tuning process, including what knowledge is retained from pre-training models or how content selection and generation strategies are learnt across iterations. In this work, we analyze the training dynamics for generation models, focusing on news summarization. Across different datasets (CNN/DM, XSum, MediaSum) and model behaviors (content selection, abstractiveness, hallucination), we study what the model learns at different stages of its fine-tuning process. We find that properties such as copy behavior and content selection are learnt earlier in the training process and these observations are robust across domains. On the other hand, factual errors, such as hallucination of unsupported facts, are learnt in the later stages, and this behavior is more varied across domains. Based on these observations, we demonstrate two techniques for modifying training: first, disregarding high-loss tokens that are challenging to learn and second, disregarding low-loss tokens that are learnt very quickly. We show that these simple modifications can help achieve different goals, such as improving factuality or improving abstractiveness.
",/pdf/05c02a8aee6b60b470ada4c34f6f1cd3362fcde1.pdf,,,,,anonymous|training_dynamics_for_text_summarization_models,,,,,,,,,
437,ULHJwUO0AUx,A Simple Information-Based Approach to Unsupervised Domain-Adaptive Aspect-Based Sentiment Analysis,['aclweb.org/ACL/ARR/2021/November/Paper636/Authors'],['Anonymous'],"Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task which aims to extract the aspects from sentences and identify their corresponding sentiments. Aspect term extraction (ATE) is the crucial step for ABSA. Due to the expensive annotation for aspect terms, we often lack labeled target domain data for fine-tuning. To address this problem, many approaches have been proposed recently to transfer common knowledge in an unsupervised way, but such methods have too many modules and require expensive multi-stage preprocessing. In this paper, we propose a simple but effective technique based on mutual information maximization, which can serve as an additional component to enhance any kind of model for cross-domain ABSA and ATE. Furthermore, we provide some analysis of this approach. Experiment results show that our proposed method outperforms the state-of-the-art methods for cross-domain ABSA by 4.32\% Micro-F1 on average over 10 different domain pairs. Apart from that, our method can be extended to other sequence labeling tasks, such as named entity recognition (NER). Codes will be released. ",/pdf/cb5c9ef320a32802edd0752fa919b2f7523b0201.pdf,,,,,anonymous|a_simple_informationbased_approach_to_unsupervised_domainadaptive_aspectbased_sentiment_analysis,,,,,,,,https://openreview.net/forum?id=MSuoZW7HvY3,
438,_twxtCxGs9l,Your fairness may vary: Pretrained language model fairness in toxic text classification,['aclweb.org/ACL/ARR/2021/November/Paper1531/Authors'],['Anonymous'],"Warning: This paper contains samples of offensive text.

The popularity of pretrained language models in natural language processing systems calls for a careful evaluation of such models in down-stream tasks, which have a higher potential for societal impact. The evaluation of such systems usually focuses on accuracy measures. Our findings in this paper call for attention to be paid to fairness measures as well. Through the analysis of more than a dozen pretrained language models of varying sizes on two toxic text classification tasks, we demonstrate that focusing on accuracy measures alone
can lead to models with wide variation in fairness characteristics. Specifically, we observe that fairness can vary even more than accuracy with increasing training data size and different random initializations. At the same time, we find that little of the fairness variation is explained by model size, despite claims in the literature. To improve model fairness without retraining, we show that two post-processing methods developed for structured, tabular data can be successfully applied to a range of pretrained language models.",/pdf/5e2c5ddab4de1638f784e7dd27fee1890681c3e3.pdf,,,,,anonymous|your_fairness_may_vary_pretrained_language_model_fairness_in_toxic_text_classification,,,,,,,,,
439,XhSkr46udBW,Multi-layer Biaffine Model for Neural Dependency Parsing,['aclweb.org/ACL/ARR/2021/November/Paper253/Authors'],['Anonymous'],"The biaffine model is a strong and efficient model for graph-based dependency parsing. However, previous work only used the biaffine method in single-layer form. In this paper, we propose a multi-layer biaffine model for neural dependency parsing. In this model, we modify the biaffine method so that it can be utilized in multi-layer form. We evaluate our model on PTB and CTB and show our model achieves state-of-the-art results on both datasets. Further experiments show the benefits of introducing multi-layer form into the biaffine method with low efficiency loss.",/pdf/e5f790a81af505586cc80ffce029bb1786395a3c.pdf,,,,,anonymous|multilayer_biaffine_model_for_neural_dependency_parsing,,,,,,,,,
440,pJeVcX8_Et,Predictive text for agglutinative and polysynthetic languages,['aclweb.org/ACL/ARR/2021/November/Paper370/Authors'],['Anonymous'],"This paper presents a set of experiments in the area of morphological modelling and 
predictioning. We examine the tasks of segmentation
and predictive text entry for two under-resourced and indigenous languages, K'iche'
and Chukchi. We use different segmentation methods to make datasets for language modelling and then train models of different types: single-way segmented, which are trained using data from one segmentor; two-way segmented, which are trained using concatenated data from two segmentors; and finetuned, which are trained on two datasets from different segmentors. We 
measure word and character level perplexities of the language models and find that single-way segmented models trained using morphologically segmented data and finetuned models work the best.
Finally, we test the language models on the task of predictive text entry using gold standard data and measure
the average number of clicks per character and keystroke savings rate. We find that the models trained using morphologically segmented data work better,
although with substantial room for improvement. At last, we propose the usage of morphological segmentation in order to improve the end-user experience while using predictive text and we plan on testing this assumption by training other models and experimenting on more languages.",/pdf/920ccdf98b1bcb283d05951fa31294456a07246a.pdf,,,,,anonymous|predictive_text_for_agglutinative_and_polysynthetic_languages,,,,,,,,,
441,pfjbxxqih3x,Cross-domain Named Entity Recognition via Graph Matching,['aclweb.org/ACL/ARR/2021/November/Paper711/Authors'],['Anonymous'],"Cross-domain NER is a practical yet challenging problem since the data scarcity in the real-world scenario. A common practice is first to learn a NER model in a rich-resource general domain and then adapt the model to specific domains. Due to the mismatch problem between entity types across domains, the wide knowledge in the general domain can not effectively transfer to the target domain NER model. To this end, we model the label relationship as a probability distribution and construct label graphs in both source and target label spaces. To enhance the contextual representation with label structures, we fuse the label graph into the word embedding output by BERT. By representing label relationships as graphs, we formulate cross-domain NER as a graph matching problem. Furthermore, the proposed method has good applicability with pre-training methods and is potentially capable of other cross-domain prediction tasks. Empirical results on four datasets show that our method outperforms a series of transfer learning, multi-task learning, and few-shot learning methods.",/pdf/634bed2336a1be6a464d598f495b3b69133b5757.pdf,/attachment/5c431d067de4bd07adf0168d914880f68cd41cd9.zip,,,,anonymous|crossdomain_named_entity_recognition_via_graph_matching,,,,,,/attachment/fa78994d7bcbb63b96a565b4a890b675da22d475.zip,,,
442,b5YiEef9sTI,Should a Bot be Sarcastic?\\Understanding User Preferences Towards Sarcasm Generation,['aclweb.org/ACL/ARR/2021/November/Paper2893/Authors'],['Anonymous'],"Previous sarcasm generation research has focused on \emph{how} to generate text that people perceive as sarcastic to create more human-like interactions. In this paper, we argue that we should first turn our attention to the question of \emph{when} sarcasm should be generated, finding that humans consider sarcastic responses inappropriate to many input utterances. Next, we use a theory-driven framework for generating sarcastic responses, which allows us to control the linguistic devices included during generation. For each device, we investigate how much humans associate it with sarcasm, finding that pragmatic insincerity and emotional markers are devices crucial for making sarcasm recognisable.",/pdf/2efd1f5f332ef62ff4b108b59e8debf8e0ec1d37.pdf,,,,,anonymous|should_a_bot_be_sarcastic\\understanding_user_preferences_towards_sarcasm_generation,,,,,,,/attachment/ae16395afb4458d3ffb2706f2a2f985388088df7.pdf,https://openreview.net/forum?id=kV-PzsxIUu2,/attachment/56295c095c8e18cec5b2a796a34d27c59c61d0cf.pdf
443,XKEFSwYUewV,Inverse is Better! Fast and Accurate Prompt for Slot Tagging,['aclweb.org/ACL/ARR/2021/November/Paper2970/Authors'],['Anonymous'],"Prompting methods recently achieve impressive success in few-shot learning. These methods embed input samples with prompt sentence pieces and decode label-related tokens to map samples to the label. However, such a paradigm is very inefficient for the task of slot tagging. Because the slot tagging samples are multiple consecutive words in a sentence, the prompting methods have to enumerate all n-grams token span to find all the possible slots, which greatly slows down the prediction. To tackle this, we introduce an inverse paradigm for prompting. Different from the classic prompts map tokens to labels, we reversely predict slot values given slot types. Such inverse prompting only requires a one-turn prediction for each slot type and greatly speeds up the prediction. Besides, we propose a novel Iterative Prediction Strategy, from which the model learns to refine predictions by considering the relations between different slot types. We find, somewhat surprisingly, the proposed method not only predicts faster, but also significantly improves the effect (improve over 6.1 F1-scores on 10-shot setting) and achieves new state-of-the-art performance.",/pdf/8fb64a56500fe87fad1d5b3c143c1bb5fb83c3c3.pdf,,,,,anonymous|inverse_is_better_fast_and_accurate_prompt_for_slot_tagging,,,,,,,,,
444,2yB6VQkPJW6,A self-reliant finite automata for reduplication detection,['aclweb.org/ACL/ARR/2021/November/Paper274/Authors'],['Anonymous'],"Reduplication is a common phenomenon in almost all human languages. It implies the repetition of the smallest linguistic unit partially (e.g. flip flop) or completely (e.g. bye bye). Symbolically it can be written as WiWj , where Wi and Wj are similar or almost similar and Wi is any linguistic unit or token or sequence of symbols. Identifying such reduplication in a text is an important aspect of various language processing tasks. Several researchers have tried to address the issue and solve using the heuristic approach, 1-way / 2-way finite-state transducers. This paper presented a sophisticated generic (NFA-based) automaton that is self-reliant generates dynamically and identifies all the reduplicated words from the text.",/pdf/7d0825c50c8591113b08baaf2f1868c8eecacffa.pdf,,,,,anonymous|a_selfreliant_finite_automata_for_reduplication_detection,,,,,,,,,
445,ZySnFGEBgvC,The Dark Side of the Language: Pre-trained Transformers in the DarkNet,['aclweb.org/ACL/ARR/2021/November/Paper1005/Authors'],['Anonymous'],"Pre-trained Transformers are challenging human performances in many natural language processing tasks. 
The gigantic datasets used for pre-training seem to be the key for their success on existing tasks. 
In this paper, we explore how a range of pre-trained natural language understanding models perform on truly novel and unexplored data, provided by classification tasks over a DarkNet corpus. Surprisingly, results show that syntactic and lexical neural networks largely outperform pre-trained Transformers. This seems to suggest that pre-trained Transformers have serious difficulties in adapting to radically novel texts.   ",/pdf/5af1d74ba39687dcabfd52356a5ab25da98d6c1f.pdf,/attachment/e5e1727500e9e65a64ab46caf37daf8651a13215.zip,,,,anonymous|the_dark_side_of_the_language_pretrained_transformers_in_the_darknet,,,,,,/attachment/598f41546acb40e415a9fc8d580be5c1c5dd4338.zip,,,
446,fa2XGLrSkI,MOROCCO: Model Resource Comparison Framework,['aclweb.org/ACL/ARR/2021/November/Paper2814/Authors'],['Anonymous'],"A new generation of pre-trained transformer language models has established new state-of-the-art results on many tasks, even exceeding the human level in standard NLU benchmarks. Despite the rapid progress, the benchmark-based evaluation has generally relied on the downstream performance as a primary metric which limits the scope of model comparison in terms of their practical use. This paper presents MOdel ResOurCe COmparison (MOROCCO), a framework that allows to assess models with respect to their downstream quality combined with two computational efficiency metrics such as memory consumption and throughput during the inference stage. The framework allows for a flexible integration with popular leaderboards compatible with jiant environment that supports over 50 downstream tasks. We demonstrate the MOROCCO applicability by evaluating 10 transformer models on two multi-task GLUE-style benchmarks in English and Russian and provide the model analysis.",/pdf/c1822e09649fe1abc15079e984090d866100097e.pdf,,,,,anonymous|morocco_model_resource_comparison_framework,,,,,,,,,
447,5GdS7K37pKN,Active Dialogue Simulation in Conversational Systems,['aclweb.org/ACL/ARR/2021/November/Paper1554/Authors'],['Anonymous'],"Semantic parsing helps conversational systems in satisfying users' requests through dialogues. To train these models, collecting annotated dialogues as a dataset is a very expensive and time-consuming process. In this paper, our goal is to utilize large language models and active learning to replace Wizard-of-Oz (WoZ) collection via crowdsourcing for bootstrapping training data for task-driven semantic parsers.  We first demonstrate the utility of utterances generated by GPT-3 when seeded with prior training dialogues, as evaluated by human judges.  We then explore the use of parser uncertainty on generated outputs as a selection criteria for annotation and contrast this with a strategy based on Core-sets. Our pipeline leads to more useful examples on average, motivating future work on active generation for bootstrapping semantic parsers.",/pdf/c0c371499401dbe8756f1097baace002c21513ab.pdf,,,,,anonymous|active_dialogue_simulation_in_conversational_systems,,,,,,,,,
448,xQOZlfF8M-,Lot or Not: Identifying Multi-Quantity Offerings in E-Commerce ,['aclweb.org/ACL/ARR/2021/November/Paper502/Authors'],['Anonymous'],"The term \textit{lot} in \ecom is defined to mean an offering that contains a collection of multiple identical items for sale. In a large online marketplace, lot offerings play an important role, allowing buyers and sellers to set price levels to optimally balance supply and demand needs. In spite of their central role, \ecom platforms often struggle to identify lot offerings, since explicit lot status identification is frequently not provided by sellers. The ability to identify lot offerings plays a key role in many fundamental \ecom tasks, from matching offerings to catalog products, through ranking \ecom search results, to providing effective pricing guidance. In this work, we seek to determine the lot status (and lot size) of each offering, in order to facilitate an improved buyer experience, while reducing the friction for sellers posting new offerings. We demonstrate experimentally the ability to accurately classify offerings as lots (and predict their lot size) using only the offer title, by adapting state-of-the-art natural language techniques to the lot identification  problem.",/pdf/61595bd5c13210b0703e4cf6bd778faebf2d9c07.pdf,,,,,anonymous|lot_or_not_identifying_multiquantity_offerings_in_ecommerce,,,,,,,,,
449,vmqMLOTPfcG,A Survey of Networking Cipher Algorithms and How Natural Language Can Be Used to Enhance Them,['aclweb.org/ACL/ARR/2021/November/Paper162/Authors'],['Anonymous'],"This paper provides a survey of several of the networking cipher algorithms and proposes a method for integrating natural language processing (NLP) as a protective agent for them. Two main proposals are covered for the use of NLP in networking. First, NLP is considered as the weakest link in a networking encryption model; and, second, as a hefty deterrent when combined as an extra layer over what could be considered a strong type of encryption – the stream cipher. This paper summarizes how languages can be integrated into symmetric encryption as a way to assist in the encryption of vulnerable streams that may be found under attack due to the natural frequency distribution of letters or words in a local language stream.",/pdf/4729cfcb3ad10a706e9923f4338a297f163a536d.pdf,,,,,anonymous|a_survey_of_networking_cipher_algorithms_and_how_natural_language_can_be_used_to_enhance_them,,,,,,,,,
450,WEyYNUwgD9u,Aggregating Pairwise Semantic Differences for Few-Shot Claim Veracity Classification,['aclweb.org/ACL/ARR/2021/November/Paper265/Authors'],['Anonymous'],"As part of an automated fact-checking pipeline, the claim veracity classification task consists in determining if a claim is supported by an associated piece of evidence. The complexity of gathering labelled claim-evidence pairs leads to a scarcity of datasets, particularly when dealing with new domains. In this paper, we introduce SEED, a novel vector-based method to few-shot claim veracity classification that aggregates pairwise semantic differences for claim-evidence pairs. We build on the hypothesis that we can find class representative vectors that capture average semantic differences for claim-evidence pairs in a class, which can then be used for classification of new instances. We compare the performance of our method with competitive baselines including fine-tuned BERT/RoBERTa models, as well as the state-of-the-art few-shot veracity classification method that leverages language model perplexity. Experiments conducted on the FEVER and SCIFACT datasets show consistent improvements over competitive baselines in few-shot settings. Our code will be made publicly available upon publication.",/pdf/0cf59e61e613e0866b98b8b30b9a310b2a3c4e66.pdf,,,,,anonymous|aggregating_pairwise_semantic_differences_for_fewshot_claim_veracity_classification,,,,,,,,,
451,M9sPdWzEu0,,,,,,,,,,,,,,,,,,,
452,hqmnjdcYZW7,One Agent To Rule Them All: Towards Multi-agent Conversational AI,['aclweb.org/ACL/ARR/2021/November/Paper996/Authors'],['Anonymous'],"The increasing volume of commercially available conversational agents (CAs) on the market has resulted in users being burdened with learning and adopting multiple agents to accomplish their tasks.
Though prior work has explored supporting a multitude of domains within the design of a single agent, the interaction experience suffers due to the large action space of desired capabilities.
To address these problems, we introduce a new task BBAI: Black-Box Agent Integration, focusing on combining the capabilities of multiple black-box CAs at scale.
We explore two techniques: question agent pairing and question response pairing aimed at resolving this task.
Leveraging these techniques, we design One For All (OFA), a scalable system that provides a unified interface to interact with multiple CAs.
Additionally, we introduce MARS: Multi-Agent Response Selection, a new encoder model for question response pairing that jointly encodes user question and agent response pairs.
We demonstrate that the OFA system is able to automatically and accurately integrate an ensemble of commercially available CAs spanning disparate domains.
Specifically, using the MARS encoder we achieve 88.5% accuracy on our BBAI task, outperforming strong baselines.",/pdf/8dde561cefb261c4940d4d54329c1022c9475b7d.pdf,,,,,anonymous|one_agent_to_rule_them_all_towards_multiagent_conversational_ai,,,,,,/attachment/17d48cbabf7e5ded987745806f35ad5a61f907fb.zip,/attachment/b19ce498e10da3122367a5f6af5de60724d832e8.pdf,,/attachment/ab1549e38dfc9b7a26fb24cd8da70d5a945eefef.pdf
453,BXfSKkEbCtW,All Birds with One Stone: Multi-task Learning for Inference with One Forward Pass,['aclweb.org/ACL/ARR/2021/November/Paper1796/Authors'],['Anonymous'],"Task-specific fine-tuning of pre-trained language models like Transformers has shown their effectiveness in various NLP tasks. To achieve better storage efficiency and model performance, Multi-task Learning (MTL) has been studied to share model parameters and utilize knowledge transfer between tasks. However, in real applications where enormous numbers of tasks (e.g., large sets of labels to be classified) need to be conducted on a large corpus, the inference efficiency is still hindered by the number of tasks.
For a document with N sets of labels to be predicted, recent MTL methods with adaptive modules or prompts need to encode the input data N times to extract the hidden representation needed for the tasks. Notice that the hidden representation is not sharable between tasks, as task-specific features are extracted at very bottom layers in the Transformer. 
In this paper, we seek to maintain the computational efficiency of only requiring one forward pass for a document to get a generalized feature for all N tasks, without sacrificing overall model performance.
We design a prompt-sharing module to let the model take all tasks into considerations and output N heads simultaneously. 
We also design a dynamic task scheduling module to sample tasks according to their training progress. 
In our evaluation, we show that our method is able to outperform previous MTL state-of-the-arts and single task fine-tuning by 0.4-1.5% on GLUE benchmark dataset. We also perform comprehensive module analysis to demonstrate the effectiveness and robustness of our method.",/pdf/523d6bf05cf35f28732e871efd1f0f93a105860b.pdf,,,,,anonymous|all_birds_with_one_stone_multitask_learning_for_inference_with_one_forward_pass,,,,,,,,,
454,3FIjaX458P,Enhancing Robustness of Pre-trained Language Model with Lexical Simplification,['aclweb.org/ACL/ARR/2021/November/Paper1908/Authors'],['Anonymous'],"For both human readers and pre-trained language models (PrLMs), lexical diversity may lead to confusion and inaccuracy when understanding the underlying semantic meanings of given sentences. By substituting complex words with simple alternatives, lexical simplification (LS) is a recognized method to reduce such lexical diversity. In this paper, we leverage a novel improved LS approach which can enhance robustness of PrLMs, resulting in improved performances in downstream tasks. A rule-based simplification process is applied to a given sentence. PrLMs are encouraged to predict the real label of the given sentence with auxiliary inputs from the simplified version. Using strong PrLMs (BERT and ELECTRA) as baselines, our approach can still further improve the performance in various text classification tasks.",/pdf/d06f3129aa10398c64cb516dae5a43677559124f.pdf,,,,,anonymous|enhancing_robustness_of_pretrained_language_model_with_lexical_simplification,,,,,,,,,
455,VZ2oO6KYbBB,AdapterBias: Parameter-efficient Token-dependent Embedding Shift for Adapters in NLP Tasks,['aclweb.org/ACL/ARR/2021/November/Paper2181/Authors'],['Anonymous'],"Transformer-based pre-trained models with millions of parameters require large storage. Recent approaches tackle this shortcoming by training adapters, but these approaches still require a relatively large number of parameters. In this study, AdapterBias, a surprisingly simple yet effective adapter architecture, is proposed. AdapterBias adds a token-dependent shift to the embedding to adapt to downstream tasks with only a vector and a linear layer. Extensive experiments are conducted to demonstrate the effectiveness of AdapterBias. The experiments show that our proposed method can dramatically reduce the trainable parameters than the previous works with a minimal decrease in task performances compared with fine-tuned pre-trained models. We further find that AdapterBias automatically learns to assign more significant shifts to the tokens related to the task in consideration. ",/pdf/f3390c234d7e2fed86e3515c0449fc4e350257eb.pdf,,,,,anonymous|adapterbias_parameterefficient_tokendependent_embedding_shift_for_adapters_in_nlp_tasks,,,,,,,,,
456,XOI2xQDpzqz,Solving Probability and Statistics Problems by Program Synthesis,['aclweb.org/ACL/ARR/2021/November/Paper2110/Authors'],['Anonymous'],"We solve university level probability and statistics questions by program synthesis using OpenAI's Codex, a Transformer trained on text and fine-tuned on code. We transform course problems from MIT's 18.05 Introduction to Probability and Statistics and Harvard's STAT110 Probability into programming tasks. We then execute the generated code to get a solution. Since these course questions are grounded in probability, we often aim to have Codex generate probabilistic programs that simulate a large number of probabilistic dependencies, to compute its solution. Our approach requires prompt engineering to transform the question from its original form to an explicit, tractable form that results in a correct program and solution. To estimate the amount of work needed to translate an original question into its tractable form, we measure the similarity between original and transformed questions. Our work is the first to introduce a new dataset of university-level probability and statistics problems and solve these problems in a scalable fashion using the program synthesis capabilities of large language models.",/pdf/7c057b2b00b471fac5a26558788c7911667a3d6e.pdf,,,,,anonymous|solving_probability_and_statistics_problems_by_program_synthesis,,,,,,,,,
457,sEd4EJK-QVl,ROCK: A Causal Inference Framework for Reasoning about Commonsense Causality,['aclweb.org/ACL/ARR/2021/November/Paper2018/Authors'],['Anonymous'],"Commonsense causality reasoning (CCR) aims at identifying plausible causes and effects in natural language descriptions that deemed reasonable by an average person. Although being of great academic and practical interest, this problem is still shadowed by the lack of a well-posed theoretical framework; existing work usually relies on various notions of correlation and is susceptible to confounding co-occurrences. This paper articulates the central question of CCR and develops a novel framework, ROCK, to Reason O(A)bout Commonsense K(C)ausality based on classical causal inference principles. ROCK leverages temporal signals as incidental supervision, and makes use of temporal propensities that are analogous to propensity scores for balancing confounding effects. We implement a modular zero-shot pipeline which is effective and demonstrates good potential for CCR on various datasets.",/pdf/3e0a78d4b91cbeda2ca5f8db24c27f62164331f6.pdf,/attachment/b1ab5752f65b41bda08e624a16778fcdd3b5b55c.zip,,,,anonymous|rock_a_causal_inference_framework_for_reasoning_about_commonsense_causality,,,,,,,,,
458,c3wXWy6xe3O,Sparsifying Transformer Models with Trainable Representation Pooling,['aclweb.org/ACL/ARR/2021/November/Paper1220/Authors'],['Anonymous'],"We propose a novel method to sparsify attention in the Transformer model by learning to select the most-informative token representations during the training process, thus focusing on the task-specific parts of an input. 
A reduction of quadratic time and memory complexity to sublinear was achieved due to a robust trainable top-$k$ operator.
Our experiments on a challenging long document summarization task show that even our simple baseline performs comparably to the current SOTA, and with trainable pooling we can retain its top quality, while being $1.8\times$ faster during training, $4.5\times$ faster during inference and up to $13\times$ more computationally efficient in the decoder.
",/pdf/b8e7a25d39961cf2f23fd4ae3a0c51cc9d98509e.pdf,/attachment/941c17a6fa5f6060a33e78bb09899de41ca83176.zip,,,,anonymous|sparsifying_transformer_models_with_trainable_representation_pooling,,,,,,,/attachment/cadac6f7d8cc7c5b1297018854bde5b4b6afbda3.pdf,https://openreview.net/forum?id=F_tMnw8FAV9,/attachment/a9d352a820fea6783e9fac43e52636dcb67f1026.pdf
459,YjZH6EpuSY,Better Language Model with Hypernym Class Prediction,['aclweb.org/ACL/ARR/2021/November/Paper1915/Authors'],['Anonymous'],"Class-based language models (LMs) have been long devised to address context sparsity in $n$-gram LMs. In this study, we revisit this approach in the context of neural LMs. We hypothesize that class-based prediction leads to an implicit context aggregation for similar words and thus can improve generalization for rare words. We map words that have a common WordNet hypernym to the same class and train large neural LMs by gradually annealing from predicting the class to token prediction during training. Empirically, this curriculum learning strategy consistently improves perplexity over various large, highly-performant state-of-the-art Transformer-based models on two datasets, WikiText-103 and Arxiv. Our analysis shows that the performance improvement is achieved without sacrificing performance on rare words. Finally, we document other attempts that failed to yield empirical gains, and discuss future directions for the adoption of class-based LMs on a larger scale.",/pdf/1ba62612e3b41645b1037aeac9b4b9137c64c5d4.pdf,/attachment/ce83f4f342e97914e9c253554bc9d252cfe79403.zip,,,,anonymous|better_language_model_with_hypernym_class_prediction,,,,,,,,,
460,OC1o4_OI6Jw,Structural Characterization for Dialogue Disentanglement,['aclweb.org/ACL/ARR/2021/November/Paper1207/Authors'],['Anonymous'],"Tangled multi-party dialogue contexts lead to challenges for dialogue reading comprehension, where multiple dialogue threads flow simultaneously within a common dialogue history, increasing difficulties in understanding a dialogue history for both human and machine. Previous studies mainly focus on utterance encoding methods with carefully designed features and pay inadequate attention to characteristic features of the structure of dialogues.  We specially take dialogue structure factors into account and design a novel model for dialogue disentangling. Based on the fact that dialogues are constructed on successive participation of speakers and interactions between users of interest, we extract clues of speaker property and reference of users to model structural information of dialogues. The proposed method achieves new state-of-the-art on benchmark dataset and contributes to dialogue-related comprehension.",/pdf/856a2de4ba8c05513656ec856e68441c56c6894a.pdf,/attachment/3c4c3f43fc6974f68a153788405b62857197d531.zip,,,,anonymous|structural_characterization_for_dialogue_disentanglement,,,,,,/attachment/2d07462b21ba4c4e4595cbdfa49350aa1ee9293f.zip,,,
461,VRhs8XzoF6W,Event Detection via Derangement Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper429/Authors'],['Anonymous'],"Event detection (ED), aiming to detect events from texts and categorize them, is vital to understanding the messages.  Recently, ED without triggers has been proposed and gained benefits since it relieves the tedious effort of data labeling.  However, it still suffers from several formidable challenges: multi-label, insufficient clues, and imbalanced event types.  We, therefore, propose a novel Derangement Question-Answering (DQA) framework on top of BERT to tackle the above challenges.  More specially, we treat the input text as a {\em question} and directly concatenate it with all event types, who are deemed as {\em answers}. Thus, by utilizing the original information, we can facilitate the power of self-attention in BERT to absorb the semantic relation between the original input text and the event types.  Moreover, we design a simple yet effective {\em derangement} mechanism to relieve the issue of imbalanced event types.  By including such perturbation, we can train a more robust model to promote the semantic information in the major events while recording the position of the minor events than the vanilla QA framework.  The empirical results show that: (1) our proposed DQA framework attains state-of-the-art performance over previous competitive models. (2) Our model can automatically link the triggers with the event types while signifying the corresponding arguments. ",/pdf/f942851828e4a4dbc5fbe470ee12ecefdcbdcb90.pdf,/attachment/1d38fee37c6a992603d0f50cbede0f84071ad8d3.zip,,,,anonymous|event_detection_via_derangement_question_answering,,,,,,,,,
462,d8efWWr2IPH,Knowledge Enhanced Embedding: Improve Model Generalization Through Knowledge Graphs,['aclweb.org/ACL/ARR/2021/November/Paper1034/Authors'],['Anonymous'],"Pre-trained language models have achieved excellent results in NLP and NLI, and since the birth of Bert, various new types of Bert have emerged.They are able to grasp the ubiquitous linguistic representational information from large-scale corpora in different ways, but when reading texts, it is difficult for them to combine and use external knowledge to make inferences about other meanings that the text may contain, as people do.To this end, we propose a linguistic model (K2E-BERT) capable of simply incorporating external knowledge, which fuses information from the knowledge graph (triad) with the entity information in the original text.In order to better integrate external knowledge into the original text without letting it deviate from the original meaning of the sentence, we propose a method called EaKA (Entity and Knowledge Align), which can better distance and combine entities and knowledge so that the model can accept new external knowledge without losing the meaning of the original sentence; additionally, we can easily and beyond Bert without changing the internal structure of Bert, we can easily and go beyond the results of BERT, which shows that our approach is feasible.After our experiments, we found good results in several NLP tasks we selected, which indicated that K2E-BERT easily surpassed BERT in generalization ability, proving its effectiveness.",/pdf/4df599e5544b6488dfa1d86c2c1358d1d157741d.pdf,,,,,anonymous|knowledge_enhanced_embedding_improve_model_generalization_through_knowledge_graphs,,,,,,,,,
463,QGZMStjUHVt,D$^4$: A Psychiatrist-proofread Dialogue Dataset for Depression Diagnosis,['aclweb.org/ACL/ARR/2021/November/Paper2685/Authors'],['Anonymous'],"Depression has affected large populations and become a significant threat to life expectations globally.
Automatic depression diagnosis methods have been a new research focus. 
In particular, automatic dialogue-based diagnosis systems are desired since depression diagnosis highly relies on clinical consultation.
Based on clinical diagnosis criteria, doctors initiate a conversation with ample emotional support that guides the patients to expose their symptoms. 
Such a dialog is a combination of task-oriented and chitchat, different from traditional single-purpose human-machine dialog systems. 
However, due to the social stigma associated with mental illness, the dialogue data related to the diagnosis of actual patients are rarely disclosed. The lack of data has become one of the major factors restricting the research on the consultation dialogue system of depression.
%Although there are effective methods of diagnosis and treatment for depression, more than 75\% of people in low- and middle-income countries receive no treatment. 
Based on clinical depression diagnostic criteria ICD-11 and DSM-5, we construct a Psychiatrist-proofread Dialogue Dataset for Depression Diagnosis which simulates the dialogue between the doctor and the patient during the diagnosis of depression and provides diagnosis results and symptom summary given by professional psychiatrists for each dialogue.
Finally, we finetune on state-of-art pre-training models and respectively give our dataset baselines on response generation, topic prediction, dialog summary, and severity classification of depression and suicide risk.",/pdf/ebc1231dbdaca350c113d873669c5ac6aa17498a.pdf,,,,,anonymous|d^4_a_psychiatristproofread_dialogue_dataset_for_depression_diagnosis,,,,,,/attachment/0a123a33a9466a205e221776c48568e4d61dc061.zip,,,
464,W2wE4vUe1Te,Are Shortest Rationales the Best Explanations For Human Understanding?,['aclweb.org/ACL/ARR/2021/November/Paper822/Authors'],['Anonymous'],"Existing self-explaining models typically favor extracting the shortest rationales possible (“shortest yet coherent subset of input to predict the same label”), with the assumption that short rationales are more intuitive to humans, even though short rationales lead to lower accuracy.   However, there is a lack of human studies on validating the effect of rationale length on human understanding. Is the shortest rationale indeed the most understandable for humans? To answer this question, we design a self-explaining model that can take control on rationale length.  Our model incorporates contextual information and supports flexibly extracting rationales at any target length. Through quantitative evaluation on model performance, we further verify that our method  LIMITEDINK outperforms existing self-explaining baselines on both end-task prediction and human-annotated rationale agreement.  We use it to generate rationales at 5 length levels, and conduct user studies to understand how much rationale would be sufficient for humans to confidently make predictions. We show that while most prior work extracts 10%-30% of the text to be the rationale, human accuracy tends to stabilize after seeing 40% of the full text.  Our result suggests the need for more careful design of the best human rationales.",/pdf/021bfd6ddbe775fd257d55f3857c756cbf68e077.pdf,,,,,anonymous|are_shortest_rationales_the_best_explanations_for_human_understanding,,,,,,,,,
465,8llHNkzlQMe,DISAPERE: A Dataset for Discourse Structure in Peer Review Discussions,['aclweb.org/ACL/ARR/2021/November/Paper1776/Authors'],['Anonymous'],"At the foundation of scientific evaluation is the labor-intensive process of peer review. This critical task requires participants to consume vast amounts of highly technical text. Prior work has annotated different aspects of review argumentation, but discourse relations between reviews and rebuttals have yet to be examined.

We present DISAPERE, a labeled dataset of 20k sentences contained in 506 review-rebuttal pairs in English, annotated by experts. DISAPERE synthesizes label sets from prior work and extends them to include fine-grained annotation of the rebuttal sentences, characterizing the authors' stance towards review arguments, and their context in the review. Further, we annotate \textit{every} review and rebuttal sentence.

We show that discourse cues from rebuttals can shed light on the quality and interpretation of reviews. Further, an understanding of the argumentative strategies employed by the reviewers and authors provides useful signal for area chairs and other decision makers.",/pdf/eba0ae050f641edbccff303d341ed4bea23dd145.pdf,,,,,anonymous|disapere_a_dataset_for_discourse_structure_in_peer_review_discussions,,,,,,/attachment/3ae2794c93b8dfd030539c27986cc6889f981942.tgz,,,
466,9lH-J1uPY2i,Low rank softmax can have unargmaxable classes in theory but rarely in practice,['aclweb.org/ACL/ARR/2021/November/Paper693/Authors'],['Anonymous'],"Classifiers in natural language processing (NLP) often have a large number of output classes. For example, neural language models (LMs) and machine translation (MT) models both predict tokens from a vocabulary of thousands. The softmax output layer of these models typically receives as input a dense feature representation, which has much lower dimensionality than the output. In theory, the result is some words may be impossible to predict via argmax, irrespective of input features, and empirically, this has been shown to happen in small language models (Demeter et al., 2020). In this paper we ask whether it can happen in practical large language models and translation models. To do so, we develop algorithms to detect such unargmaxable tokens in public models. We find that that 13 out of 150 models do indeed have such tokens; however, they are very infrequent and unlikely to impact model quality. We release our algorithms and code to the public.",/pdf/edb81ca59274742e2cea3a4a1e92d756f36611d2.pdf,/attachment/47ab142fde2bc7f5222d98ac689396a2bc92d6f6.zip,,,,anonymous|low_rank_softmax_can_have_unargmaxable_classes_in_theory_but_rarely_in_practice,,,,,,,,,
467,IEcWf--zVAG,Controlling Pretrained Language Generation Models by Learning to Focus,['aclweb.org/ACL/ARR/2021/November/Paper632/Authors'],['Anonymous'],"Transformer-based language models, which are pretrained on large-scale unsupervised data and then finetuned on task-specific datasets, have become the dominant paradigm for various natural language generation tasks. The finetuning and usages of such models are typically conducted in an end-to-end manner. This work attempts to develop a control mechanism by which a user can select spans of context as ""highlights'' for the model to focus on, while generating output text. To achieve this goal, we augment a pretrained model with trainable ""attention vectors'' that are directly applied to the model's embeddings, while the model itself is kept fixed. These vectors, trained on automatic annotations derived from attribution methods, act as indicators for context importance. We test our approach on two core generation tasks: dialogue response generation and abstractive summarization. We also collect evaluation data where the highlight-generation pairs are annotated by humans. Our experiments show that the trained attention vectors are effective in steering the model to generate outputs that are relevant to user-selected highlights. ",/pdf/0b18840b8f21cee2379eded21f3e08477be84382.pdf,,,,,anonymous|controlling_pretrained_language_generation_models_by_learning_to_focus,,,,,,/attachment/790928ccec2e9c22b61ac86ea128d7f7ec3a76a2.zip,,,
468,aYNjzZJP9qa,Quality-Aware Decoding for Neural Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper1547/Authors'],['Anonymous'],"Despite the progress in machine translation quality estimation and evaluation in the last years, decoding in neural machine translation (NMT) is mostly oblivious to this and centers around finding the most probable translation according to the model (MAP decoding), approximated with beam search. In this paper, we bring together these two lines of research and propose \emph{quality-aware decoding} for NMT, by leveraging recent breakthroughs in reference-free and reference-based MT evaluation through various inference methods like $N$-best reranking and minimum Bayes risk decoding. We perform an extensive comparison of various possible candidate generation and ranking methods across four datasets and two model classes and find that quality-aware decoding consistently outperforms MAP-based decoding according  both to state-of-the-art automatic metrics (COMET and BLEURT) and to human assessments. ",/pdf/e031c4649eadb2bf98c4f884339c380192bca67f.pdf,/attachment/6dec406321202be222e9de6899aeb67ff7d337f9.zip,,,,anonymous|qualityaware_decoding_for_neural_machine_translation,,,,,,,,,
469,Vtl4GfQJ9K,Modeling speech recognition and synthesis simultaneously: Encoding and decoding lexical and sublexical semantic information into speech with no access to speech data,['aclweb.org/ACL/ARR/2021/November/Paper441/Authors'],['Anonymous'],"Human speakers encode information into raw speech which is then decoded by the listeners. This complex relationship between encoding (production) and decoding (perception) is often modeled separately. Here, we test how decoding of lexical and sublexical semantic information can emerge automatically from raw speech in unsupervised generative deep convolutional networks that combine both the production and perception principle. We introduce, to our knowledge, the most challenging objective in unsupervised lexical learning: an unsupervised network that must learn to assign unique representations for lexical items with no direct access to training data. We train several models (ciwGAN and fiwGAN by Beguš 2021) and test how the networks classify raw acoustic lexical items in the unobserved test data. Strong evidence in favor of lexical learning emerges. The architecture that combines the production and perception principles is thus able to learn to decode unique information from raw acoustic data in an unsupervised manner without ever accessing real training data. We propose a technique to explore lexical and sublexical learned representations in the classifier network. The results bear implications for both unsupervised speech synthesis and recognition as well as for unsupervised semantic modeling as language models increasingly bypass text and operate from raw acoustics. ",/pdf/51e18806651730c7bbd512995218aa156241f406.pdf,,,,,anonymous|modeling_speech_recognition_and_synthesis_simultaneously_encoding_and_decoding_lexical_and_sublexical_semantic_information_into_speech_with_no_access_to_speech_data,,,,,,/attachment/ff3fcdfa0be94e5ef4b587b94ff79dd88fbfe0c9.zip,,,
470,CxLph8ur-hB,CTM - A Model for Large-Scale Multi-View Tweet Topic Classification,['aclweb.org/ACL/ARR/2021/November/Paper1303/Authors'],['Anonymous'],"Automatically associating social media posts with topics is an important prerequisite for effective search and recommendation on many social media platforms. However, topic classification of such posts is quite challenging because of (a) a large topic space (b) short text with weak topical cues, and (c) multiple topic associations per post. In contrast to most prior work which only focuses on post classification into a small number of topics ($10-20$), we consider the task of large-scale topic classification in the context of Twitter where the topic space is $10$ times larger with potentially multiple topic associations per Tweet. We address the challenges above and propose a novel neural model, CTM that (a) associates tweets from a large topic space of $300$ topics (b) takes a holistic approach to tweet content modeling -- leveraging multi-modal content, author context, and deeper semantic cues in the tweet.  We evaluate CTM quantitatively and show that our method offers an effective way to classify Tweets into topics at scale and is superior in performance to other approaches yielding a significant relative lift of $\mathbf{20}\%$.",/pdf/1a8e0828499b1b43df86ff8f3d8312ea27f2cbe9.pdf,,,,,anonymous|ctm_a_model_for_largescale_multiview_tweet_topic_classification,,,,,,,,,
471,IFISLX7krsj,Feature-rich Open-vocabulary Interpretable Neural Representations for All of the World’s 7000 Languages,['aclweb.org/ACL/ARR/2021/November/Paper1799/Authors'],['Anonymous'],"Modern NLP research is firmly predicated on two assumptions: that very large corpora are available, and that the word, rather than the morpheme, is the primary meaning-bearing unit of language. For the vast majority of the world's languages, these assumptions fail to hold, and as a result existing state-of-the-art neural representations such as BERT fail to meet the needs of thousands of languages. In this paper, we present a novel general-purpose neural representation using Tensor Product Representations that is designed from the beginning to be both linguistically interpretable and fully capable of handling the broad variety found in the world's diverse set of 7000 languages, regardless of corpus size or morphological characteristics.

We demonstrate the applicability of our representation through examples drawn from a typologically diverse set of languages whose morphology includes prefixes, suffixes, infixes, circumfixes, templatic morphemes, derivational morphemes, inflectional morphemes, and reduplication.",/pdf/43f1911704b6dd754915b8e9c795809f0cc0b4e4.pdf,,,,,anonymous|featurerich_openvocabulary_interpretable_neural_representations_for_all_of_the_worlds_7000_languages,,,,,,,,,
472,jAk0IoZVbP6,"Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions",['aclweb.org/ACL/ARR/2021/November/Paper2716/Authors'],['Anonymous'],"A long-term goal of AI research is to build intelligent agents that can communicate with humans in natural language, perceive the environment, and perform real-world tasks. Vision-and-Language Navigation (VLN) is a fundamental and interdisciplinary research topic towards this goal, and receives increasing attention from the natural language processing, computer vision, and machine learning communities. In this paper, we review contemporary studies in the emerging field of VLN, covering tasks, evaluation metrics, methods, etc. Through structured analysis of current progress and challenges, we also highlight the limitations of current VLN and opportunities for future work. This paper serves as a thorough reference for the VLN research community.",/pdf/929e6de0b6887165a0b6b7127678c19279e3a58e.pdf,,,,,anonymous|visionandlanguage_navigation_a_survey_of_tasks_methods_and_future_directions,,,,,,,,,
473,WtlQ4cal2Y-,Bridging the Data Gap between Training and Inference for Unsupervised Neural Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper2232/Authors'],['Anonymous'],"Back-translation is a critical component of Unsupervised Neural Machine Translation (UNMT), which generates pseudo parallel data from target monolingual data. A UNMT model is trained on the pseudo parallel data with $\text{\bf translated source}$, and translates $\text{\bf natural source}$ sentences in inference. The source discrepancy between training and inference hinders the translation performance of UNMT models. By carefully designing experiments, we identify two representative characteristics of the data gap in source: (1) $\text{\textit{style gap}}$ (i.e., translated vs. natural text style) that leads to poor generalization capability; (2) $\text{\textit{content gap}}$ that induces the model to produce hallucination content biased towards the target language. To narrow the data gap, we propose an online self-training approach, which simultaneously uses the pseudo parallel data $\{$natural source, translated target$\}$ to mimic the inference scenario. Experimental results on several widely-used language pairs show that our approach outperforms two strong baselines (XLM and MASS) by remedying the style and content gaps.",/pdf/aa6028492e54ae67679e089794db4ca0d0bb631f.pdf,/attachment/6ea518f2249dc78484636b25ca64e1f3d5f41a4f.zip,,,,anonymous|bridging_the_data_gap_between_training_and_inference_for_unsupervised_neural_machine_translation,,,,,,,,,
474,3-g3nuYuf_w,MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective,['aclweb.org/ACL/ARR/2021/November/Paper2933/Authors'],['Anonymous'],"NER model has achieved promising performance on standard NER benchmarks. However, recent studies show that previous approaches may over-rely on entity mention information, resulting in poor performance on out-of-vocabulary(OOV) entity recognition.  In this work, we propose MINER, a novel NER learning framework, to remedy this issue from an information-theoretic perspective. The proposed approach contains two mutual information based training objectives: i) generalizing information maximization, which enhances representation via deep understanding of context and entity surface forms; ii) superfluous information minimization, which discourages representation from rotate memorizing entity names or exploiting biased cues in data. Experiments on various settings and datasets demonstrate that it achieves better performance in predicting OOV entities.",/pdf/210ac70b5b28f08c3d37f6aca610b20f57aeeac6.pdf,,,,,anonymous|miner_improving_outofvocabulary_named_entity_recognition_from_an_information_theoretic_perspective,,,,,,,,,
475,ZOTtvHg_uR2,Metaphor Detection for Low Resource Languages: From Zero-Shot to Few-Shot Learning in Middle High German,['aclweb.org/ACL/ARR/2021/November/Paper2670/Authors'],['Anonymous'],"In this work, we present a novel unsupervised
method for adjective-noun metaphor detection
on low resource languages. We propose two
new approaches: First, a way of artificially
generating metaphor training examples and
second, a novel way to find metaphors rely-
ing only on word embeddings. The latter en-
ables application for low resource languages.
Our method is based on a transformation of
word embedding vectors into another vector
space, in which the distance between the ad-
jective word vector and the noun word vec-
tor represents the metaphoricity of the word
pair. We train this method in a zero-shot
pseudo-supervised manner by generating arti-
ficial metaphor examples and show that our
approach can be used to generate a metaphor
dataset with low annotation cost. It can then
be used to finetune the system in a few-shot
manner. In our experiments we show the capa-
bilities of the method in its unsupervised and
in its supervised version. Additionally, we test
it against a comparable unsupervised baseline
method and a supervised variation of it.",/pdf/3d0623711154ff17a5ed4e2ddf2c65b3b696a0e1.pdf,,,,,anonymous|metaphor_detection_for_low_resource_languages_from_zeroshot_to_fewshot_learning_in_middle_high_german,,,,,,,,,
476,sRQa1-O3N0,Contextual Fine-to-Coarse Distillation for Coarse-grained Response Selection in Open-Domain Conversations,['aclweb.org/ACL/ARR/2021/November/Paper431/Authors'],['Anonymous'],"We study the problem of coarse-grained response selection in retrieval-based dialogue systems. The problem is equally important with fine-grained response selection, but is less explored in existing literature. In this paper, we propose a Contextual Fine-to-Coarse (CFC) distilled model for coarse-grained response selection in open-domain conversations. In our CFC model, dense representations of query, candidate contexts and responses is learned based on the multi-tower architecture using contextual matching, and richer knowledge learned from the one-tower architecture (fine-grained) is distilled into the multi-tower architecture (coarse-grained) to enhance the performance of the retriever. To evaluate the performance of the proposed model, we construct two new datasets based on the Reddit comments dump and Twitter corpus. Extensive experimental results on the two datasets show that the proposed method achieves huge improvement over all evaluation metrics compared with traditional baseline methods. ",/pdf/03a387562daf67262423e803be6be9fc042d3032.pdf,,,,,anonymous|contextual_finetocoarse_distillation_for_coarsegrained_response_selection_in_opendomain_conversations,,,,,,,,,
477,sagXUkJ1fDn,Softmax Bottleneck Makes Language Models Unable to Represent Multi-mode Word Distributions,['aclweb.org/ACL/ARR/2021/November/Paper103/Authors'],['Anonymous'],"Neural language models (LMs) such as GPT-2 estimate the probability distribution over the next word by a softmax over the vocabulary. The softmax layer produces the distribution based on the dot products of a single hidden state and the embeddings of words in the vocabulary. However, we discover that this single hidden state cannot produce all probability distributions regardless of the LM size or training data size because the single hidden state embedding cannot be close to the embeddings of all the possible next words simultaneously when there are other interfering word embeddings between them. In this work, we demonstrate the importance of this limitation both theoretically and practically.  Our work not only deepens our understanding of softmax bottleneck and mixture of softmax (MoS) but also inspires us to propose multi-facet softmax (MFS) to address the limitations of MoS. Extensive empirical analyses confirm our findings and show that against MoS, the proposed MFS achieves two-fold improvements in the perplexity of GPT-2 and BERT.",/pdf/b7c467741d852d0fdf8f0cfae00ab5ddfe501c12.pdf,/attachment/13accf4a6923c9b6e99c518cacd76738e2ee0f7a.zip,,,,anonymous|softmax_bottleneck_makes_language_models_unable_to_represent_multimode_word_distributions,,,,,,,,,
478,h3nJi5MOm04,Freezing the Pivot for Triangular Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper816/Authors'],['Anonymous'],"Triangular machine translation is a special case of low-resource machine translation where the language pair of interest has limited parallel data, but both languages have abundant parallel data with a pivot language. Naturally, the key to triangular machine translation is the successful exploitation of such auxiliary data. In this work, we propose a transfer-learning-based approach that utilizes all types of auxiliary data. As we train auxiliary source-pivot and pivot-target translation models, we initialize some parameters of the pivot side with a pre-trained language model and freeze them to encourage both translation models to work in the same pivot language space, so that they can be smoothly transferred to the source-target translation model. Experiments show that our approach can outperform previous ones.",/pdf/dea27492544959cec9035ca66bf72241a7fcfe16.pdf,,,,,anonymous|freezing_the_pivot_for_triangular_machine_translation,,,,,,,,,
479,uwGI98wh025,Topic Sentence Named Entity Recognition: A New Task with Its Dataset and Benchmarks,['aclweb.org/ACL/ARR/2021/November/Paper2713/Authors'],['Anonymous'],"In this paper, we focus on a new type of named entity recognition (NER) task called topic sentence NER. A topic sentence means a short and compact sentence that acts as a summary of a long document. For example, a title can be seen as a topic sentence of its article. Topic sentence NER aims to extract named entities in a topic sentence given the corresponding unlabeled document as a reference. This task represents real-world scenarios where full-document NER is too expensive and obtaining the entities only in topic sentences is enough for downstream tasks. To achieve this, we construct a large-scale human-annotated Topic Sentence NER dataset, named TSNER. The dataset contains 12,000 annotated sentences accompanied by their unlabeled document. Based on TSNER, we propose a family of representative and strong baseline models, which can utilize both single-sentence and document-level features. We will make the dataset public in the hope of advancing the research on the topic sentence NER task.",/pdf/aa2f8cb4ee9f51b1a47b0077d3e6be190b82fb31.pdf,,,,,anonymous|topic_sentence_named_entity_recognition_a_new_task_with_its_dataset_and_benchmarks,,,,,,/attachment/d2e0706516a1c3f0d76b8877fe25c2b25c14d51c.zip,,,
480,u_9SBxaOqI-,Contrastive Learning for Low Resource Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper2759/Authors'],['Anonymous'],"Representation learning plays a vital role in natural language processing tasks. More recent works study the geometry of the representation space for each layer of pre-trained language models.  They find that the context representation of all words is not isotropic in any layer of the pre-trained language model. However, how contextual are the contextualized representations produced by transformer-based machine translation models? In this paper, we find that the contextualized representations of the same word in different contexts have a greater cosine similarity than those of two different words, but this self-similarity is still relatively low between the same words. This suggests that output of machine translation models produce more context-specific representations. In this work, we present a contrastive framework for machine translation, that adopts contrastive learning to train  model in a supervised way. By making use of data augmentation, our supervised contrastive learning method solves the issue of low-resource machine translation representations learning. Experimental results on the IWSLT14 and WMT14 datasets show our method can outperform competitive baselines significantly.",/pdf/c8f9a938f402db954bf3df1f786795fbab1e6733.pdf,,,,,anonymous|contrastive_learning_for_low_resource_machine_translation,,,,,,,,,
481,iU7nNeWLbA7,Few-shot Controllable Style Transfer for Low-Resource Multilinugal Settings,['aclweb.org/ACL/ARR/2021/November/Paper512/Authors'],['Anonymous'],"Style transfer is the task of rewriting an input sentence into a target style while approximately preserving its content. While most prior literature assumes access to large style-labelled corpora, recent work (Riley et al. 2021) has attempted ""few-shot"" style transfer using only 3-10 sentences at inference for extracting the target style. In this work we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available. We find that existing few-shot methods perform this task poorly, with a strong tendency to copy inputs verbatim. We push the state-of-the-art for few-shot style transfer with a new method modeling the stylistic difference between paraphrases. When compared to prior work using automatic and human evaluations, our model achieves 2-3x better performance and output diversity in formality transfer and code-mixing addition across seven languages. Moreover, our method is better able to control the amount of style transfer using an input scalar knob. We report promising qualitative results for several attribute transfer directions, including sentiment transfer, text simplification, gender neutralization and text anonymization, all without retraining the model. Finally we found model evaluation to be difficult due to the lack of evaluation datasets and metrics for many languages. To facilitate further research in formality transfer for Indic languages, we crowdsource annotations for 4000 sentence pairs in four languages, and use this dataset to design our automatic evaluation suite.",/pdf/5332f4df36d51fc74133b913098fbccf678b7e4c.pdf,,,,,anonymous|fewshot_controllable_style_transfer_for_lowresource_multilinugal_settings,,,,,,,,,
482,kNT-aYVaYyx,Cross-lingual Word Embeddings in Hyperbolic Space,['aclweb.org/ACL/ARR/2021/November/Paper2810/Authors'],['Anonymous'],"Cross-lingual word embeddings can be applied to several natural language processing applications across multiple languages. Unlike prior works that use word embeddings based on the Euclidean space, this short paper presents a simple and effective cross-lingual Word2Vec model that adapts to the Poincaré  ball model of hyperbolic space to learn unsupervised cross-lingual word representations from a German-English parallel corpus. It has been shown that hyperbolic embeddings can capture and preserve hierarchical relationships.
We evaluate the model on both hypernymy and analogy tasks. The proposed model achieves comparable performance with the %standard 
vanilla Word2Vec model on the cross-lingual analogy task, the hypernymy task shows that the cross-lingual Poincaré Word2Vec model can capture latent hierarchical structure from free text across languages, which are absent from the Euclidean-based Word2Vec representations. Our results show that by preserving the latent hierarchical information, hyperbolic spaces can offer better representations for cross-lingual embeddings.",/pdf/ad1d8ff98420ef3a766b2259241bdfd5bbde99f4.pdf,,,,,anonymous|crosslingual_word_embeddings_in_hyperbolic_space,,,,,,,,,
483,vVNYde75l4m,PESTO: A Post-User Fusion Network for Rumour Detection on Social Media,['aclweb.org/ACL/ARR/2021/November/Paper2074/Authors'],['Anonymous'],"Rumour detection on social media is an important topic due to the challenges of misinformation propagation and slow verification of misleading information.
Most previous work focus on the response posts on social media, ignoring the useful characteristics of involved users and their relations.
In this paper, we propose a novel framework, Post-User Fusion Network (PESTO), which models the patterns of rumours from both post diffusion and user social networks. Specifically, we propose a novel Chronologically-masked Transformer architecture to model both temporal sequence and diffusion structure of rumours, and apply a Relational Graph Convolutional Network to model the social relations of involved users, with a fusion network based on self-attention mechanism to incorporate the two aspects. Additionally, two data augmentation techniques are leveraged to improve the robustness and accuracy of our models. Empirical results on several benchmarks show the superiority of the proposed method.",/pdf/bc8e76fda191e9e5c1bcd4a4999460bd433ab3eb.pdf,,,,,anonymous|pesto_a_postuser_fusion_network_for_rumour_detection_on_social_media,,,,,,,,,
484,-eOO1r7NB7N,Context-Paraphrase Enhanced Commonsense Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper2837/Authors'],['Anonymous'],"Commonsense question answering (CQA) generally means that the machine use the mastered commonsense to answer questions without relevant background material, which is a challenging task in natural language processing. Many prior methods mainly retrieve question related evidences from the structured knowledge base as the background material of the question, while the extracted evidence is generally described through the entities and the relationship between the entities, making it difficult for the machine to understand the meaning of the evidence completely. In this paper, we integrate the paraphrase in WordNet and Wiktionary into the evidence extraction process and machine reading comprehension (MRC) model, and propose a context-paraphrase enhanced commonsense question answering method. Specifically, the context-paraphrase obtained by WordNet and Wiktionary is first incorporated into the construction process of the heterogeneous graph, and the question related triple is extracted based on the heterogeneous graph, the triple is converted to triple-text based on a relational template. Then, the triple-text is used as the context of the question to establish an association graph containing the relationship between the context entities and the paraphrases. We further integrate the association graph into the MRC model to better guide the model to answer. Experimental results on CommonsenseQA and OpenBookQA show that context-paraphrase is effective in improving the answer accuracy of the MRC model.",/pdf/6197d679ac30ef1ba5bf2c66e966a4570af5925a.pdf,,,,,anonymous|contextparaphrase_enhanced_commonsense_question_answering,,,,,,,,,
485,-dylrl0Ell,Generative Pretraining for Paraphrase Evaluation,['aclweb.org/ACL/ARR/2021/November/Paper2388/Authors'],['Anonymous'],"We introduce ParaBLEU, a paraphrase representation learning model and evaluation metric for text generation. Unlike previous approaches, ParaBLEU learns to understand paraphrasis using generative conditioning as a pretraining objective. ParaBLEU correlates more strongly with human judgements than existing metrics, obtaining new state-of-the-art results on the 2017 WMT Metrics Shared Task. We show that our model is robust to data scarcity, exceeding previous state-of-the-art performance using only $50\%$ of the available training data and surpassing BLEU, ROUGE and METEOR with only $40$ labelled examples. Finally, we demonstrate that ParaBLEU can be used to conditionally generate novel paraphrases from a single demonstration, which we use to confirm our hypothesis that it learns abstract, generalized paraphrase representations.",/pdf/828711703e5fea6710189968f1b7d42a85078776.pdf,,,,,anonymous|generative_pretraining_for_paraphrase_evaluation,,,,,,,,,
486,cpNsYH0OwF,EmoWOZ: A Large-Scale Corpus and Labelling Scheme for Emotion Recognition in Task-Oriented Dialogue Systems,['aclweb.org/ACL/ARR/2021/November/Paper2448/Authors'],['Anonymous'],"The ability to recognise emotions lends a conversational artificial intelligence a human touch. While emotions in chit-chat dialogues have received substantial attention, emotions in task-oriented dialogues have been largely overlooked despite having an equally important role, such as to signal failure or success. Existing emotion-annotated task-oriented corpora are limited in size, label richness, and public availability, creating a bottleneck for downstream tasks. To lay a foundation for studies on emotions in task-oriented dialogues, we introduce EmoWOZ, a large-scale manually emotion-annotated corpus of task-oriented dialogues. EmoWOZ is based on MultiWOZ, a multi-domain task-oriented dialogue dataset. It contains more than 11K dialogues with more than 83K emotion annotations of user utterances. In addition to Wizard-of-Oz dialogues from MultiWOZ, we collect human-machine dialogues within the same set of domains to sufficiently cover the space of various emotions that can happen during the lifetime of a data-driven dialogue system. To the best of our knowledge, this is the first large-scale open-source corpus of its kind. We propose a novel emotion labelling scheme, which is tailored to task-oriented dialogues. We report a set of experimental results to show the usability of this corpus for emotion recognition and state tracking in task-oriented dialogues.",/pdf/740e11618744c9355f303d69c1dfa1d2f10f047c.pdf,,,,,anonymous|emowoz_a_largescale_corpus_and_labelling_scheme_for_emotion_recognition_in_taskoriented_dialogue_systems,,,,,,/attachment/d4a96eb52f8e7c3f906060283ff3a7dc1fdfe3c1.zip,,,
487,I-9kHa74lzM,Deep-to-bottom Weights Decay: A Systemic Knowledge Review Learning Technique for Transformer Layers in Knowledge Distillation,['aclweb.org/ACL/ARR/2021/November/Paper1109/Authors'],['Anonymous'],"There are millions of parameters and huge computational power consumption behind the outstanding performance of pre-trained language models in natural language processing tasks. Knowledge distillation is considered as a compression strategy to address this problem. However, previous works (i) distill partial transformer layers of the teacher model, which ignore the importance of bottom base information, or (ii) neglect the difficulty differences of knowledge from deep to shallow, which corresponds to different level information of teacher model. We introduce a deep-to-bottom weights decay review mechanism to knowledge distillation, which fuses teacher-side information taking each layer’s difficulty level into consideration. To validate our claims, we distill a 12-layer BERT into a 6-layer model and evaluate it on the GLUE dataset. Experimental results show that our review approach is able to outperform other existing techniques.",/pdf/77f2e7a58b5e3eb0621fd9aecccea6a5592e444c.pdf,,,,,anonymous|deeptobottom_weights_decay_a_systemic_knowledge_review_learning_technique_for_transformer_layers_in_knowledge_distillation,,,,,,,,,
488,U0seCGsNj78,IDPG: An Instance-Dependent Prompt Generation Method,['aclweb.org/ACL/ARR/2021/November/Paper734/Authors'],['Anonymous'],"Prompt tuning is a new, efficient NLP transfer learning paradigm that adds a task-specific prompt in each input instance during the model training stage. It freezes the pre-trained language model and only optimizes a few task-specific prompts. In this paper, we propose a conditional prompt generation method to generate prompts for each input instance, referred to as the Instance-Dependent Prompt Generation (IDPG). Unlike traditional prompt tuning methods that use a fixed prompt, IDPG introduces a lightweight and trainable component to generate prompts based on each input sentence. Empirical experiments on ten natural language understanding (NLU) tasks show that our proposed method consistently outperforms various prompt tuning methods and other efficient transfer learning methods such as Compacter while tuning far fewer model parameters.",/pdf/1a160a5de238f1d57902723d837e2fbff055319b.pdf,,,,,anonymous|idpg_an_instancedependent_prompt_generation_method,,,,,,,,,
489,YBujxHx3VmL,Are We Evaluating Paraphrase Generation Accurately?,['aclweb.org/ACL/ARR/2021/November/Paper817/Authors'],['Anonymous'],"Paraphrase is a restatement of a text that conveys the same meaning using different expressions. The evaluation of paraphrase generation (PG) is a complex task and currently lacks a complete picture of the criteria and metrics. In this paper, we survey the automatic evaluation metrics and human evaluation criteria of PG evaluation. Base on the survey result,  we propose a reference-free automatic toolkit and list clear human evaluation criteria. Moreover, we notice the paraphrases selection in downstream tasks and propose a simple but effective evaluation Filter model. It can fusion multi automatic metrics to fit the human evaluation without any references.",/pdf/bbad8b616ff01d7f14b163ae9e83eb57789c3bff.pdf,,,,,anonymous|are_we_evaluating_paraphrase_generation_accurately,,,,,,,,,
490,b-064TCPoyB,LordBERT: Embedding Long Text by Segment Ordering with BERT,['aclweb.org/ACL/ARR/2021/November/Paper236/Authors'],['Anonymous'],"Although BERT has achieved significant improvements on many downstream NLP tasks, it has difficulty handling long text because of its quadratic computation complexity. A typical approach to this issue is splitting the input into shorter segments and utilizing order-independent attention mechanism to conduct inter-segment interaction, but the approach ignores the segment order information, which is greatly beneficial for capturing implicit relations across different segments. To address this problem, we propose a novel multi-task learning framework, named LordBERT, which fully exploits both intra- and inter-segment information in long text by segment ordering with BERT. LordBERT learns segment-level representations from segments through BERT and a reasoner, and utilizes an auxiliary segment ordering module to reorder disordered segments. With this module, the model implicitly encodes inter-segment relations and global information of long text into segment representations. The downstream task and the ordering task are jointly optimized during training, while for inferencing we mainly conduct the downstream task. Experimental results show that LordBERT outperforms the state-of-the-art models by up to 0.94% in accuracy for text classification tasks on long text.",/pdf/6bce328c670646b858c3896f00651313152664d3.pdf,/attachment/e20e7aa0189b22dcfd74763989fcbd0ab436b23b.zip,,,,anonymous|lordbert_embedding_long_text_by_segment_ordering_with_bert,,,,,,,,,
491,GzK8XG-3MvE,MDERank: A Masked Document Embedding Rank Approach for Unsupervised Keyphrase Extraction,['aclweb.org/ACL/ARR/2021/November/Paper2479/Authors'],['Anonymous'],"Keyphrase extraction (KPE) automatically extracts phrases in a document that provide a concise summary of the core content, which benefits downstream information retrieval and NLP tasks. Previous state-of-the-art methods select candidate keyphrases based on the similarity between learned representations of the candidates and the document. They suffer performance degradation on long documents due to discrepancy between sequence lengths which causes mismatch between representations of keyphrase candidates and the document. In this work, we propose a novel unsupervised embedding-based KPE approach, Masked Document Embedding Rank (MDERank), to address this problem by leveraging a mask strategy and ranking candidates by the similarity between embeddings of the source document and the masked document. We further develop a KPE-oriented BERT (KPEBERT) model by proposing a novel self-supervised contrastive learning method, which is more compatible to MDERank than vanilla BERT. Comprehensive evaluations on six KPE benchmarks demonstrate that the proposed MDERank outperforms state-of-the-art unsupervised KPE approach by average 1.80 $F1@15$ improvement. MDERank further benefits from KPEBERT and overall achieves average 3.53 $F1@15$ improvement over SIFRank.",/pdf/cf5cdaa1b6bf2784106b038f65401c7113216353.pdf,,,,,anonymous|mderank_a_masked_document_embedding_rank_approach_for_unsupervised_keyphrase_extraction,,,,,,,,,
492,A-9_nSN2UIu,Pre-training Pre-trained Models with Auxiliary Labels and Fine-tuning for Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper1384/Authors'],['Anonymous'],"With the development of pre-trained models, the performance of text classification has been continuously improved. However, we argue that directly employing features generated by pre-trained models for text classification might fail to fully capture discriminative features. For example, in sentiment classification, both the words
``very good'' and ``I would still choose'' are indicative of the positive sentiment. Most pre-trained model based approaches pay more attention to ``very good'' while ignoring the second when both are in the same sentence. To fully capture discriminative features, in this paper, we incorporate auxiliary labels to exploit the knowledge in the pre-trained model. In specific, we pre-train a pre-trained model incorporating auxiliary labels to effectively extract the discriminative textual semantic representation. Then, the classifier is fine tuned. Moreover, multiple pre-trained models are combined to further provide the textual semantic representation. Experiments were conducted on seven classification tasks and the results show that the proposed approach outperforms several baselines.",/pdf/9cfae96ab01e9121762121f215d4b76e87126f8f.pdf,,,,,anonymous|pretraining_pretrained_models_with_auxiliary_labels_and_finetuning_for_text_classification,,,,,,,,,
493,1llL_tYlV54,EntSUM: A Data Set for Entity-Centric Extractive Summarization,['aclweb.org/ACL/ARR/2021/November/Paper1916/Authors'],['Anonymous'],"Controllable summarization aims to provide summaries that take into account user-specified aspects and preferences to better assist them with their information need, as opposed to the standard summarization setup which build a single generic summary of a document.
We introduce a human-annotated data set EntSUM for controllable summarization with a focus on named entities as the aspects to control.
We conduct an extensive quantitative analysis to motivate the task of entity-centric summarization and show that existing methods for controllable summarization fail to generate entity-centric summaries. We propose extensions to state-of-the-art summarization approaches that achieve substantially better results on our data set. Our analysis and results show the challenging nature of this task and of the proposed data set.",/pdf/4a0a8b82fa3302376f0ea9b8e0dde0bcf5702dc0.pdf,,,,,anonymous|entsum_a_data_set_for_entitycentric_extractive_summarization,,,,,,/attachment/5762785fb7306f2b68a975734b7eca65d4a49707.zip,,,
494,ThTMwcCPzkG,Mukayese: Turkish NLP Strikes Back,['aclweb.org/ACL/ARR/2021/November/Paper2966/Authors'],['Anonymous'],"Having sufficient resources for a language X lifts it from the $\textit{under-resourced}$ languages class, but does not necessarily lift it from the $\textit{under-researched}$ class. In this paper, we address the problem of the absence of organized benchmarks in the Turkish language. We demonstrate that languages such as Turkish are left behind the State-of-the-Art in NLP applications. As a solution, we present Mukayese, a set of NLP benchmarks for the Turkish language that contains several NLP tasks. For each benchmark, we work on one or more datasets and present two or more baselines. Moreover, we present four new benchmarking datasets in Turkish for language modeling, sentence segmentation, and spellchecking and correction.",/pdf/f184fe52e905520e93b605b2010d696e3edbb474.pdf,,,,,anonymous|mukayese_turkish_nlp_strikes_back,,,,,,,,,
495,6awg2A5yUm_,Alignment based Sequence Ensemble with Multiple Results from a Single Neural Model Architecture,['aclweb.org/ACL/ARR/2021/November/Paper2290/Authors'],['Anonymous'],"Sequence labeling is a fundamental framework that provides the elemental structure and content information for additional natural language processing. However, existing proposed ensemble approaches do not focus on sequence alignment during post-processing. Here, we present a weighted ensemble technique using a sequence alignment approach for a sequence labeling task. Our proposed technique addresses two problems of ensemble technique. First, an ensemble technique requires a multiple model system, and we used a model with multiple random seeds and an additional dropout layer to build a simple ensemble system. Second, we focused on a sequence label list that increased accuracy using alignment for the ensemble technique during post-processing. We evaluated our approach on a representative sequence labeling tasks, part-of-speech and dependency parser. Most results obtained by ensemble sequence alignment approach with various sub-sequence units showed an increase in the F1-score over a single neural network result in the sequence labeling task. Comparing with the hard voting result on the Penn-treebank\cite{marcus1993PTB}, the F1-scores increased up to 0.45 at POS-tagged dataset, and up to 0.12 at DP-tagged dataset.",/pdf/b8af783b80d3bd0dd44499a8343e9cdd0975a711.pdf,/attachment/b6e870ae71e5c56502df68ec23ed04b2f6d54158.zip,,,,anonymous|alignment_based_sequence_ensemble_with_multiple_results_from_a_single_neural_model_architecture,,,,,,/attachment/9f9e7635ca9f7c23b9a133f89bf472f61e117fcd.zip,,,
496,KixJ4-yJsZI,Removing Out-of-Distribution Data Improves Adversarial Robustness,['aclweb.org/ACL/ARR/2021/November/Paper976/Authors'],['Anonymous'],"Deep neural networks are vulnerable to adversarial examples crafted maliciously. Existing defense methods often improve the adversarial robustness of models by enlarging the training set with adversarial examples and fitting the models on the augmented training set. The introduced adversarial examples in the training stage may not be natural, which might even hurt the training distribution, resulting in lowter performance in the clean examples. Increasing the size of the training set also requires a long training time.We hypothesize that removing out-of-distribution samples from the training set could make the decision boundary of models smoother, leading to more robust models.We propose two methods to detect and remove out-of-distribution samples. Experimental results show that our methods can significantly boost the robustness of models without suffering any drop in clean accuracy.",/pdf/f6f945e3c88e52bf36a4bb2a8cccf8f9800c9832.pdf,/attachment/96db1a3f411cf5cb8d0bb4d2d698b33d25ea26a5.zip,,,,anonymous|removing_outofdistribution_data_improves_adversarial_robustness,,,,,,/attachment/1e3e45cb134901d272edd96af6addee61a8eb25e.zip,,,
497,_GmDuK79Jtl,KART: Parameterization of Privacy Leakage Scenarios from Pre-trained Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2977/Authors'],['Anonymous'],"For the safe sharing pre-trained language models, no guidelines exist at present owing to the difficulty in estimating the upper bound of the risk of privacy leakage. One problem is that previous studies have assessed the risk for different real-world privacy leakage scenarios and attack methods, which reduces the portability of the findings.
To tackle this problem, we represent complex real-world privacy leakage scenarios under a universal parameterization, \textit{Knowledge, Anonymization, Resource, and Target} (KART). KART parameterization has two merits: (i) it clarifies the definition of privacy leakage in each experiment and (ii) it improves the comparability of the findings of risk assessments. We show that previous studies can be simply reviewed by parameterizing the scenarios with KART. We also demonstrate privacy risk assessments in different scenarios under the same attack method, which suggests that KART helps approximate the upper bound of risk under a specific attack or scenario. We believe that KART helps integrate past and future findings on privacy risk and will contribute to a standard for sharing language models.",/pdf/09b2371faffc26dd5cde00dafb499068a3dcae5e.pdf,,,,,anonymous|kart_parameterization_of_privacy_leakage_scenarios_from_pretrained_language_models,,,,,,,,,
498,dLmmkAkIWSF,Discourse Context Primes Hindi Word Order,['aclweb.org/ACL/ARR/2021/November/Paper2208/Authors'],['Anonymous'],"Hindi has a flexible word order, yet certain word orders are consistently preferred over others. A number of factors are known to influence Hindi word order preferences in isolation, including information structure and syntactic complexity. However, the relative impact of these factors on Hindi constituent ordering is not well understood. Inspired by prior work on syntactic priming, we investigate how the words and syntactic structures in a sentence influence the word order of the following sentences. Specifically, we extract sentences from the Hindi-Urdu Treebank corpus (HUTB), we permute the preverbal constituents of those sentences, and we build a classifier to predict which sentences actually occurred in the corpus against our generated distractors. The classifier uses a number of discourse-based features and cognitive features to make its predictions, including dependency length, surprisal, and information status. We find that lexical and syntactic priming and referent givenness drive order preferences. Moreover, along the lines of previous work in psycholinguistics, we find that certain verbs are more susceptible to priming than others. We conclude by situating our results within the broader syntactic priming literature.",/pdf/de26e832b52b5ae54b727f3cc13edee7f62902c1.pdf,,,,,anonymous|discourse_context_primes_hindi_word_order,,,,,,,,,
499,04Z6uZG1CII,Dict-NMT: Bilingual Dictionary based NMT for Extremely Low Resource Languages,['aclweb.org/ACL/ARR/2021/November/Paper2186/Authors'],['Anonymous'],"Neural Machine Translation (NMT) models have been effective on large bilingual datasets. However, the existing methods and techniques show that the model's performance is highly dependent on the number of examples in training data. For many languages, having such an amount of corpora is a far-fetched dream. Taking inspiration from monolingual speakers exploring new languages using bilingual dictionaries, we investigate the applicability of bilingual dictionaries for languages with extremely low, or no bilingual corpus. In this paper, we explore methods using bilingual dictionaries with an NMT model to improve translations for extremely low resource languages. We extend this work for multilingual systems, exhibiting zero-shot property. We present a detailed analysis of the effects of the quality of dictionary, training dataset size, language family, etc., on the translation quality. Results on multiple low-resource test languages show a clear advantage of our bilingual dictionary-based method over the baselines.",/pdf/9a7547b1e509a3ac84a39b01097b7c522aa1ed81.pdf,,,,,anonymous|dictnmt_bilingual_dictionary_based_nmt_for_extremely_low_resource_languages,,,,,,,,,
500,ZCmUqcIjuGc,SHCT: A Successively Hierarchical Conditional Transformer for  Controllable Paraphrase Generation,['aclweb.org/ACL/ARR/2021/November/Paper49/Authors'],['Anonymous'],"Paraphrase generation has consistently been a challenging area in the field of NLP. Despite the considerable achievements made by previous work, existing methods lack a flexible way to include multiple controllable attributes to enhance the diversity of paraphrased sentences. To overcome this challenge, we propose a Successively Hierarchical Conditional Transformer(SHCT) to tackle this task. SHCT is based on a combination of Conditional Variational AutoEncoder(CVAE) with Transformer framework to benefit from the advantage of generating diversified words. More specifically, our SHCT deploys multi-head attention and dynamic memory mechanism to keep the interaction between each of the attributes and the corresponding encoder layer hidden state. To address the problem of absorbing flexible attributes, we apply a hierarchical structure to our SHCT which enables the framework to couple the CVAE latent variables with encoder layer hidden states successively. In addition, Our SHCT is trained by minimizing a tailor-designed loss for producing paraphrased sentences as required.  Finally, We conduct extensive experiments to substantiate the validity and effectiveness of our proposed model. The results show that SHCT significantly outperforms the existing state-of-the-art approaches and generates more diverse paraphrased sentences.",/pdf/e2ccff213b46a360679c86df4a27ccdd3bf10184.pdf,,,,,anonymous|shct_a_successively_hierarchical_conditional_transformer_for_controllable_paraphrase_generation,,,,,,,,,
501,bmCKitFWGD0,Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper2264/Authors'],['Anonymous'],"Tuning pre-trained language models (PLMs) with task-specific prompts has been a promising approach for text classification. Particularly, previous studies suggest that prompt-tuning has remarkable superiority in the low-data scenario over the generic fine-tuning methods with extra classifiers. The core idea of prompt-tuning is to insert text pieces, i.e., template, to the input and transform a classification problem into a masked language modeling problem, where a crucial step is to construct a projection, i.e., verbalizer, between a label space and a label word space. A verbalizer is usually handcrafted or searched by gradient descent, which may lack coverage and bring considerable bias and high variances to the results. In this work, we focus on incorporating external knowledge into the verbalizer, forming a knowledgeable prompttuning (KPT), to improve and stabilize prompttuning. Specifically, we expand the label word space of the verbalizer using external knowledge bases (KBs) and refine the expanded label word space with the PLM itself before predicting with the expanded label word space. Extensive experiments on zero and few-shot text classification tasks demonstrate the effectiveness of knowledgeable prompt-tuning.",/pdf/eec382519483555c4ffbb691556b910f0db0670a.pdf,/attachment/ae58f300c23b602208eee4a3b42e189c98340999.zip,,,,anonymous|knowledgeable_prompttuning_incorporating_knowledge_into_prompt_verbalizer_for_text_classification,,,,,,,/attachment/ee6c0a33be3e0f1c63a86e1425dcf72f696746c3.pdf,https://openreview.net/forum?id=qmpCC1qsJF_,/attachment/a4ca5d637aa7f79e3b894f42ec311351371cc980.pdf
502,RTLpzL_eSLy,Extracting and Inferring Personal Attributes from Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper294/Authors'],['Anonymous'],"Personal attributes represent structured information about a person, such as their hobbies, pets, family, likes and dislikes. We introduce the tasks of extracting and inferring personal attributes from human-human dialogue, and analyze the linguistic demands of these tasks. To meet these challenges, we introduce a simple and extensible model that combines an autoregressive language model utilizing constrained attribute generation with a discriminative reranker. Our model outperforms strong baselines on extracting personal attributes as well as inferring personal attributes that are not contained verbatim in utterances and instead requires commonsense reasoning and lexical inferences, which occur frequently in everyday conversation. Finally, we demonstrate the benefit of incorporating personal attributes in social chit-chat and task-oriented dialogue settings. ",/pdf/b3151e4a7b0dd25dc9eb9a98da68ea814c0fa6c8.pdf,/attachment/1acc7889525bc06070d008ea2805e159aefba984.zip,,,,anonymous|extracting_and_inferring_personal_attributes_from_dialogue,,,,,,,,,
503,Oeikp9N4fzi,FedParsing: a Semi-Supervised Federated Learning Model on Semantic Parsing,['aclweb.org/ACL/ARR/2021/November/Paper381/Authors'],['Anonymous'],"Although many semantic parsing models have been proven to work effectively on ""NL-to-SQL"", the limitation of annotated datasets remains a great challenge. In many semi-supervised models, while they use unlabeled data to greatly improve the model accuracy, they fail to take data privacy of users into account. In this work, we focus on improving the performance of the semantic parsing model  and protecting the users’ data privacy without increasing the size of the labeled dataset. Our new model, which is named FedParsing, is a semi-supervised Federated Learning model. In order to solve the difficulty on convergence of traditional semi-supervised Federated Learning model, we incorporate the Mean Teacher algorithm and apply the Exponential Moving Average algorithm to update model parameters. Experiments on WikiSQL show that with extra unlabeled data, our model performs better than supervised training model and traditional semi-supervised Federated Learning model, which proves the effectiveness of FedParsing model.",/pdf/cab4582e34c695a1c2167ad0c41a5d66171a07c5.pdf,,,,,anonymous|fedparsing_a_semisupervised_federated_learning_model_on_semantic_parsing,,,,,,,,,
504,TA1_okqeCFa,Fair NLP Models with Differentially Private Text Encoders,['aclweb.org/ACL/ARR/2021/November/Paper2883/Authors'],['Anonymous'],"Encoded text representations often capture sensitive attributes about individuals (e.g., gender, race, or age), which can raise privacy concerns and contribute to making downstream models unfair to certain groups. In this work, we propose FEDERATE, an approach that combines ideas from differential privacy and adversarial learning to learn private text representations which also induces fairer models. We empirically evaluate the trade-off between the privacy of the representations and the fairness and accuracy of the downstream model on two challenging NLP tasks. Our results show that FEDERATE consistently improves upon previous methods.",/pdf/055a81e3a9707b9f69c5375eb6a8e4a4b2559565.pdf,,,,,anonymous|fair_nlp_models_with_differentially_private_text_encoders,,,,,,,,,
505,uKGVHs4EMy,Probing Schema Linking Information from Pre-trained Language Models for Text-to-SQL Parsing,['aclweb.org/ACL/ARR/2021/November/Paper2099/Authors'],['Anonymous'],"The importance of building text-to-SQL parsers which can be applied to new databases has long been acknowledged, and a critical step to achieve this goal is schema linking, i.e., properly recognizing mentions of unseen columns or tables when generating SQLs. In this work, we propose a novel framework to elicit relational structures from large-scale pre-trained language models (PLMs) via a probing procedure based on Poincaré distance metric, and use the induced relations to augment current graph-based parsers for better schema linking. Compared with commonly-used rule-based methods for schema linking, we found that probing relations can robustly capture semantic correspondences, even when surface forms of mentions and entities differ. Moreover, our probing procedure is entirely unsupervised and requires no additional parameters. Extensive experiments show that our framework outperforms strong baselines on three benchmarks, and sets new state-of-the-art performance on two of them. We empirically verify that our probing procedure can indeed find desired relational structures through qualitative analysis.  For reproducibility, we will release our code and data upon the publication of this paper.",/pdf/df118ebe9539089ea6384a85d871f6434f6217c8.pdf,/attachment/71852c96830d29c1af6ff0e538d349b9b06d17e8.zip,,,,anonymous|probing_schema_linking_information_from_pretrained_language_models_for_texttosql_parsing,,,,,,,,,
506,BNLGjR2DGeu,Letters from the past: modeling historical sound change through diachronic character embeddings,['aclweb.org/ACL/ARR/2021/November/Paper1260/Authors'],['Anonymous'],"While a great deal of work has been done on NLP approaches to Lexical Semantic Change detection,  other  aspects  of  language  change have received less attention from the NLP community. In this paper, we address the detection of  sound  change  through  historical  spelling. We propose that a sound change, a→b / c, can be captured by comparing the relative distance through time between the distributions of the corresponding characters, a and b.  We model these  distributions  using  PPMI  character  embeddings.   We  verify  this  hypothesis  in  synthetic  data  and  then  test  the  method’s  ability to trace the well-known historical change of lenition of plosives in Danish historical sources. We show that the models are able to identify several of the changes under consideration and to uncover meaningful contexts in which they appeared.  The methodology has the potential to  contribute  to  the  study  of  open  questions such as the relative chronology of sound shifts and their geographical distribution.",/pdf/8ba334d1fdc0c8eb94870a70e45749f4111c46cd.pdf,,,,,anonymous|letters_from_the_past_modeling_historical_sound_change_through_diachronic_character_embeddings,,,,,,,,,
507,ycgOlOnbbMq,Improving Word Translation via Two-Stage Contrastive Learning,['aclweb.org/ACL/ARR/2021/November/Paper1674/Authors'],['Anonymous'],"Word translation or bilingual lexicon induction (BLI) is a key cross-lingual task, aiming to bridge the lexical gap between different languages. In this work, we propose a robust and effective two-stage contrastive learning framework for the BLI task. As Stage C1, we propose to refine standard cross-lingual linear maps between static word embeddings (WEs) via a contrastive learning objective; we also show how to integrate it into the self-learning procedure for even more refined cross-lingual maps. In Stage C2, we conduct BLI-oriented contrastive fine-tuning of mBERT, unlocking its word translation capability. We also show that static WEs induced from the 'C2-tuned' mBERT complement static WEs from Stage C1. Comprehensive experiments on standard BLI datasets for diverse languages and different experimental setups demonstrate substantial gains achieved by our framework. While the BLI method from Stage C1 already yields substantial gains over all state-of-the-art BLI methods in our comparison, even stronger improvements are met with the full two-stage framework: e.g., we report gains for 112/112 BLI setups, spanning 28 language pairs.
",/pdf/0523bb4f8298d1ba7e1eb4b184cbcff11dea2410.pdf,/attachment/28256ca7aa04bac5eea6e7dc29001a7d330ca179.zip,,,,anonymous|improving_word_translation_via_twostage_contrastive_learning,,,,,,,,,
508,y10NjrWsSmH,Persian Natural Language Inference: A Meta-learning approach,['aclweb.org/ACL/ARR/2021/November/Paper352/Authors'],['Anonymous'],"Incorporating information from other languages can improve the results of tasks in low-resource languages. A powerful method of building functional natural language processing systems for low-resource languages is to combine multilingual pre-trained representations with cross-lingual transfer learning. In general, however, shared representations are learned separately, either across tasks or across languages. This paper proposes a meta-learning approach for inferring natural language in Persian. Alternately, meta-learning uses different task information (such as QA in Persian) or other language information (such as natural language inference in English). Also, we investigate the role of task augmentation strategy for forming additional high-quality tasks. We evaluate the proposed method using four languages and an auxiliary task. Compared to the baseline approach, the proposed model consistently outperforms it, improving accuracy by roughly six percent. We also examine the effect of finding appropriate initial parameters using zero-shot evaluation and CCA similarity.",/pdf/a2861c5ab4d2b2e8a937b0a44690212f049dd9b1.pdf,,,,,anonymous|persian_natural_language_inference_a_metalearning_approach,,,,,,,,,
509,z8HsAJoLGF6,On Vision Features in Multimodal Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper1300/Authors'],['Anonymous'],"Previous work on multimodal machine translation (MMT) has focused on the way of incorporating vision features into translation but little attention is on the quality of vision models. In this work, we investigate the impact of vision models on MMT. Given the fact that Transformer is becoming popular in computer vision, we experiment with various strong models (such as Vision Transformer) and enhanced features (such as object-detection and image captioning). We develop a selective attention model to study the patch-level contribution of an image in MMT. On detailed probing tasks, we find that stronger vision models are helpful for learning translation from the vision modality. Our results also suggest the need of carefully examining MMT models, especially when current benchmarks are small-scale and biased.",/pdf/14143f4caba604bba60ecef5cd173fe26379a6d2.pdf,,,,,anonymous|on_vision_features_in_multimodal_machine_translation,,,,,,,,,
510,zHdGnwxZCdo,Learning and Evaluating Character Representations in Novels,['aclweb.org/ACL/ARR/2021/November/Paper1499/Authors'],['Anonymous'],"We address the problem of learning fixed-length vector representations of characters in novels. Recent advances in word embeddings have proven successful in learning entity representations from short texts, but fall short on longer documents because they do not capture full book-level information. To overcome the weakness of such text-based embeddings, we propose two novel methods for representing characters: (i) graph neural network-based embeddings from a full corpus-based character network; and (ii) low-dimensional embeddings constructed from the occurrence pattern of characters in each novel. We test the quality of these character embeddings using a new benchmark suite to evaluate character representations, encompassing 12 different tasks. We show that our representation techniques combined with text-based embeddings lead to the best character representations, outperforming text-based embeddings in four tasks. Our dataset and evaluation script will be made publicly available to stimulate additional work in this area.",/pdf/b9d457c0218a8fdad87f777aba4db672ed431a4c.pdf,,,,,anonymous|learning_and_evaluating_character_representations_in_novels,,,,,,,,,
511,h4CH-gL3b_x,Self-training with Modeling Ambiguous Data for Low-Resource Relation Extraction,['aclweb.org/ACL/ARR/2021/November/Paper2576/Authors'],['Anonymous'],"We present a simple yet effective approach to improve the performance of self-training relation extraction in a low-resource scenario. The approach first classifies the auto-annotated instances into two groups: confident instances and uncertain instances, according to the probabilities predicted by a teacher model. In contrast to most previous studies, which mainly only use the confident instances for self-training, we make use of the uncertain instances. We propose a method to identify some ambiguous but useful instances from the uncertain instances. Then, we propose to utilize negative training for the ambiguous instances and positive training for the confident instances. Finally, they are combined in a joint-training manner to build a relation extraction system. Experimental results on two widely used datasets with low-resource settings demonstrate that this new approach indeed achieves significant and consistent improvements when compared to several competitive self-training systems.",/pdf/44bc5f729d78587e21218c5a5e126fe4e28ba3ee.pdf,,,,,anonymous|selftraining_with_modeling_ambiguous_data_for_lowresource_relation_extraction,,,,,,,,,
512,22Vop3KyNI1,Interpretable embeddings to understand computing careers,['aclweb.org/ACL/ARR/2021/November/Paper764/Authors'],['Anonymous'],"We propose an approach for analyzing and comparing curricula of study programs in higher education. Pre-trained word embeddings are fine-tuned in a study program classification task, where each curriculum is represented by the names and content of its courses. By combining metric learning with a novel course-guided attention mechanism, our method obtains more accurate curriculum representations than strong baselines. Experiments on a new dataset containing curricula of computing programs demonstrate the interpretability power of our approach via attention weights, topic modeling, and embeddings visualizations. We also present a use case that compares computing study programs in the US and Latin America and showcase the capabilities of our method for identifying similarities and differences in topics of study in curricula from different countries.",/pdf/bd4025036331b883a46594cc8b65997616211ad3.pdf,,,,,anonymous|interpretable_embeddings_to_understand_computing_careers,,,,,,,,,
513,IZreMhYT8gW,Can Explanations Be Useful for Calibrating Black Box Models?,['aclweb.org/ACL/ARR/2021/November/Paper589/Authors'],['Anonymous'],"One often wants to take an existing, trained NLP model and use it on data from a new domain. While fine-tuning or few-shot learning can be used to adapt the base model, there is no one simple recipe to getting these working; moreover, one may not have access to the original model weights if it is deployed as a black box. To this end, we study how to improve a black box model's performance on a new domain given examples from the new domain by leveraging explanations of the model's behavior. Our approach first extracts a set of features combining human intuition about the task with model attributions generated by black box interpretation techniques, and then uses a simple model to calibrate or rerank the model's predictions based on the features. We experiment with our method on two tasks, extractive question answering and natural language inference, covering adaptation from several pairs of domains. The experimental results across all the domain pairs show that explanations are useful for calibrating these models. We show that the calibration features transfer to some extent between tasks and shed light on how to effectively use them.",/pdf/2c1fb8e7988df02e568ab2890e70b83f43805f09.pdf,/attachment/04a76256627b4c0fe59d6ac5a7ee69b35d8840f4.zip,,,,anonymous|can_explanations_be_useful_for_calibrating_black_box_models,,,,,,,,,
514,0X1-qVxSlzm,Text Smoothing: Enhance Various Data Augmentation Methods on Text Classification Tasks,['aclweb.org/ACL/ARR/2021/November/Paper2475/Authors'],['Anonymous'],"Before entering the neural network, a token needs to be converted to its one-hot representation, which is a discrete distribution of the vocabulary. Smoothed representation is the probability of candidate tokens obtained from the pre-trained masked language model, which can be seen as a more informative augmented substitution to the one-hot representation. We propose an efficient data augmentation method,  dub as text smoothing, by converting a sentence from its one-hot representation to controllable smoothed representation.
We evaluate text smoothing on different datasets in a low-resource regime. Experimental results show that text smoothing outperforms various mainstream data augmentation methods by a substantial margin. Moreover, text smoothing can be combined with these data augmentation methods to achieve better performance.",/pdf/4410dad0f4c5af47c20567a956597a5a83211f0d.pdf,,,,,anonymous|text_smoothing_enhance_various_data_augmentation_methods_on_text_classification_tasks,,,,,,,,,
515,Tle_t5AxcTL,An Empirical Study on Explanations in Out-of-Domain Settings,['aclweb.org/ACL/ARR/2021/November/Paper963/Authors'],['Anonymous'],"Recent work in Natural Language Processing has focused on developing approaches that extract faithful explanations, either via identifying the most important tokens in the input (i.e. post-hoc explanations) or by designing inherently faithful models that first select the most important tokens and then use them to predict the correct label (i.e. select-then-predict models). Currently, these approaches are largely evaluated on in-domain settings. Yet, little is known about how post-hoc explanations and inherently faithful models perform in out-of-domain settings. In this paper, we conduct an extensive empirical study that examines: (1) the out-of-domain faithfulness of post-hoc explanations, generated by five feature attribution methods; and (2) the out-of-domain performance of two inherently faithful models over six datasets. Contrary to our expectations, results show that in many cases out-of-domain post-hoc explanation faithfulness measured by sufficiency and comprehensiveness is higher compared to in-domain. We find this misleading and suggest using a random baseline as a yardstick for evaluating post-hoc explanation faithfulness. Our findings also show that select-then predict models demonstrate comparable predictive performance in out-of-domain settings to full-text trained models.",/pdf/a238847b27e61658258e2805e91d0379597fec49.pdf,/attachment/491a3e211b045e4709ae5ffc152647475688dad1.zip,,,,anonymous|an_empirical_study_on_explanations_in_outofdomain_settings,,,,,,,,,
516,K7KZoGl7M2r,KenMeSH: Knowledge-enhanced End-to-end Biomedical Text Labelling,['aclweb.org/ACL/ARR/2021/November/Paper147/Authors'],['Anonymous'],"Currently, Medical Subject Headings (MeSH) are manually assigned to every biomedical article published and subsequently recorded in the PubMed database to facilitate retrieving relevant information. With the rapid growth of the PubMed database, large-scale biomedical document indexing becomes increasingly important. MeSH indexing is a challenging task for machine learning, as it needs to assign multiple labels to each article from an extremely large hierachically organized collection. To address this challenge, we propose KenMeSH, an end-to-end model that combines new text features and a dynamic knowledge-enhanced mask attention that integrates document features with MeSH label hierarchy and journal correlation features to index MeSH terms. Experimental results show the proposed method achieves state-of-the-art performance on a number of measures.   ",/pdf/ceda6088e7c50406afa82e9d16d73f6957837b7b.pdf,,,,,anonymous|kenmesh_knowledgeenhanced_endtoend_biomedical_text_labelling,,,,,,,,,
517,qkgEZxDAGh,Morphosyntactic Tagging with Pre-trained Language Models for Arabic and its Dialects,['aclweb.org/ACL/ARR/2021/November/Paper549/Authors'],['Anonymous'],"We present state-of-the-art results on morphosyntactic tagging across different varieties of Arabic using fine-tuned pre-trained transformer language models. Our models consistently outperform existing systems in Modern Standard Arabic and all the Arabic dialects we study, achieving 2.6% absolute improvement over the previous state-of-the-art in Modern Standard Arabic, 2.8% in Gulf, 1.6% in Egyptian, and 8.3% in Levantine. We explore different training setups for fine-tuning pre-trained transformer language models, including training data size, the use of external linguistic resources, and the use of annotated data from other dialects in a low-resource scenario. Our results show that strategic fine-tuning using datasets from other high-resource dialects is beneficial for a low-resource dialect. Additionally, we show that high-quality morphological analyzers as external linguistic resources are beneficial especially in low-resource settings.",/pdf/9944437eb039d8cd5dbbfc159cd40473d0ba3b8d.pdf,,,,,anonymous|morphosyntactic_tagging_with_pretrained_language_models_for_arabic_and_its_dialects,,,,,,,,,
518,SywWbpTa8ix,Improving Neural Topic Models by Contrastive Learning with BERT,['aclweb.org/ACL/ARR/2021/November/Paper2861/Authors'],['Anonymous'],"We present a general plug-and-play contrastive learning framework that improves existing neural topic models (NTMs) by incorporating the knowledge distilled from pre-trained language models. Recent NTMs have been applied to many applications and shown promising improvement on text analysis. However, they mainly focus on word-occurrences and are often optimized by maximizing the likelihood-based objective, which could lead to suboptimal topic coherence and document representation. To overcome the above bottleneck, we introduce an additional contrastive loss that pushes the topical representation of a document learned by an NTM close to the semantic representation of the document obtained from pre-trained language models. In this way, the prior knowledge of the pre-trained language models can enrich the contextual information of the target corpus for NTMs. Comprehensive experiments show that the proposed framework achieve the state-of-the-art performance. Importantly, our framework is general approach to improve most of the existing NTMs.",/pdf/1146917334472e0d7a9ffe1c999defa147dbfe98.pdf,,,,,anonymous|improving_neural_topic_models_by_contrastive_learning_with_bert,,,,,,,,,
519,ULxpGsMp5HY,Generation of News Articles from Tweets : An Experiment,['aclweb.org/ACL/ARR/2021/November/Paper2461/Authors'],['Anonymous'],"With millions of users, Twitter is among the most popular social media platforms today, making it one of the largest sources of continuous real-time information on the Internet. Users frequently broadcast events occurring across the world on this platform, providing a scope for the production of news articles by aggregating event-specific tweets. This paper contributes to this task and evaluates the existing state-of-the-art abstractive summarization models to see how efficient or capable they are when it comes to the task of generating news articles from tweets. We compare summaries generated by five such models qualitatively in order to see how concise or coherent they are, whether they can capture the important facts of the entire tweet dataset relating to a topic and how similar they are to form news articles written by humans. PEGASUS (Pre-training with Extracted Gap-Sentences for Abstractive SUmmarization Sequence-to-sequence models) pretrained with CNN/Daily mail dataset outperformed over T5 (Text-to-Text Transfer Transformer). Manual evaluation shows that the generated summaries are concise and cohesive.",/pdf/474028b6dadb175bf978a4e5f9fc40594c65cf9a.pdf,,,,,anonymous|generation_of_news_articles_from_tweets_an_experiment,,,,,,,,,
520,LcWuB5SjD9,Adaptive Testing and Debugging of NLP Models,['aclweb.org/ACL/ARR/2021/November/Paper1645/Authors'],['Anonymous'],"Current approaches to testing and debugging NLP models rely on highly variable human creativity and extensive labor, or only work for a very restrictive class of bugs. We present AdaTest, a process for adaptive testing and debugging of NLP models inspired by the test-debug cycle in traditional software engineering. AdaTest encourages a partnership between the user and a large language model (LM): the LM proposes tests that are validated and organized by the user, who in turn gives feedback and steers the LM towards better tests. Once enough bugs are discovered, these are fixed (e.g. finetuning), and the user resumes testing. In experiments with expert and non-expert users and commercial / research models for 8 different tasks, AdaTest makes users 5-10x more effective at finding bugs than current approaches, and helps users effectively fix bugs without adding new bugs.",/pdf/ae2712817e95217e0426f9f6dc24c493134dbb3c.pdf,,,,,anonymous|adaptive_testing_and_debugging_of_nlp_models,,,,,,,,,
521,CBaAwVcAd2G,Reasoning Like Program Executors,['aclweb.org/ACL/ARR/2021/November/Paper210/Authors'],['Anonymous'],"Reasoning over natural language is a long-standing goal for the research community. However, studies have shown that existing language models are inadequate in reasoning. To address the issue, we present POET, a new pre-training paradigm. Through pre-training language models with programs and their execution results, POET empowers language models to harvest the reasoning knowledge possessed in program executors via a data-driven approach. POET is conceptually simple and can be instantiated by different kinds of programs. In this paper, we show three empirically powerful instances, i.e., POET-Math, POET-Logic, and POET-SQL. Experimental results on six benchmarks demonstrate that POET can significantly boost model performance on natural language reasoning, such as numerical reasoning, logical reasoning, and multi-hop reasoning. Taking the DROP benchmark as a representative example, POET improves the F1 metric of BART from 69.2% to 80.6%. Furthermore, POET shines in giant language models, pushing the F1 metric of T5-11B to 87.6% and achieving a new state-of-the-art performance on DROP. POET opens a new gate on reasoning-enhancement pre-training and we will make our code, models, and data publicly available to facilitate future research.",/pdf/603e4643b4aa77786ab6b0be02aa57fdc9835911.pdf,,,,,anonymous|reasoning_like_program_executors,,,,,,,,,
522,zZOyzUCFFt,"One Country, 700+ Languages: NLP Challenges for Underrepresented Languages and Dialects in Indonesia",['aclweb.org/ACL/ARR/2021/November/Paper478/Authors'],['Anonymous'],"NLP research is impeded by a lack of resources and awareness of the challenges presented by under-represented languages and dialects. Focusing on the languages spoken in Indonesia, the second most linguistically diverse and the fourth most populous nation of the world, we provide an overview of the current state of NLP research for Indonesia's 700+ languages. We highlight challenges in Indonesian NLP and how these affect the performance of current NLP systems. Finally, we provide general recommendations to help develop NLP technology not only for languages of Indonesia, but also other underrepresented languages.",/pdf/da5160d91670edcf531732051a196b260a526203.pdf,,,,,anonymous|one_country_700_languages_nlp_challenges_for_underrepresented_languages_and_dialects_in_indonesia,,,,,,,,,
523,WCBAn7V584l,Multilingual offensive lexicon annotated with contextual information,['aclweb.org/ACL/ARR/2021/November/Paper78/Authors'],['Anonymous'],"Online hate speech and offensive comments detection is not a trivial research problem since pragmatic (contextual) factors influence what is considered offensive. Moreover, offensive terms are hardly found in classical lexical resources such as wordnets, sentiment, and emotion lexicons. In this paper, we embrace the challenges and opportunities of the area and introduce the first multilingual offensive lexicon (MOL), which is composed of 1,000 explicit and implicit pejorative terms and expressions annotated with contextual information. The terms and expressions were manually extracted by a specialist from Instagram abusive comments originally written in Portuguese and manually translated by American English, Latin American Spanish, African French, and German native speakers. Each expression was annotated by three different annotators, producing high human inter-annotator agreement. Accordingly, this resource provides a new perspective to explore abusive language detection.",/pdf/75cf33385d875e31f024e55dd6263960b922747d.pdf,,,,,anonymous|multilingual_offensive_lexicon_annotated_with_contextual_information,,,,,,/attachment/a2329914dfed57d9b859f8546a0b7368202ec237.zip,,,
524,-MoY6seu_x,Bootstrapping Text Anonymization Models with Distant Supervision,['aclweb.org/ACL/ARR/2021/November/Paper2662/Authors'],['Anonymous'],"We propose a novel method to bootstrap text anonymization models based on distant supervision.  Instead of requiring manually labeled training data, the approach relies on a knowledge graph expressing the background information assumed to be publicly available about various individuals. This knowledge graph is employed to automatically annotate text documents including personal data about a subset of those individuals. More precisely, the method determines which text spans ought to be masked in order to guarantee $k$-anonymity, assuming an adversary with access to both the text documents and the background information expressed in the knowledge graph. The resulting collection of labeled documents is then used as training data to fine-tune a pre-trained language model for text anonymization. We illustrate this approach using a knowledge graph extracted from Wikidata and short biographical texts from Wikipedia. Evaluation results with a BERT-based model and a manually annotated collection of 553 summaries showcase the potential of the approach, but also unveil a number of issues that may arise the knowledge graph is noisy or incomplete.  The results also illustrate that, contrary to most sequence labeling problems, the text anonymization task may admit several alternative solutions. ",/pdf/f7f32f1eed27604dbe67fa5b1410b255e9cb4cdb.pdf,,,,,anonymous|bootstrapping_text_anonymization_models_with_distant_supervision,,,,,,,,,
525,6mpzVBZ6Mf8,QubitE: Qubit Embedding for Knowledge Graph Completion,['aclweb.org/ACL/ARR/2021/November/Paper2129/Authors'],['Anonymous'],"Knowledge graph embeddings (KGEs) learn low-dimensional representations of entities and relations to predict missing facts based on existing ones.

Quantum-based KGEs utilise variational quantum circuits for link prediction and score triples via the probability distribution of measuring the qubit states. However, there exists another best measurement for training variational quantum circuits. Besides, current quantum-based methods ignore theoretical analysis which are essential for understanding the model performance and applying for downstream tasks such as reasoning, path query answering, complex query answering, etc.

To address measurement issue and bridge theory gap, we propose QubitE whose score of a triple is defined as the similarity between qubit states.
Here, our measurements are viewed as kernel methods to separate the qubit states, while preserving quantum adavantages.
Furthermore, we show that (1) QubitE is full-expressive; (2) QubitE can infer various relation patterns including symmetry/antisymmetry, inversion, and commutative/non-commutative composition; (3) QubitE subsumes serveral existing approaches, \eg~DistMult, pRotatE, RotatE, TransE and ComplEx; (4) QubitE owns linear space complexity and linear time complexity.

Experiments results on multiple benchmark knowledge graphs demonstrate that QubitE can achieve comparable results to the state-of-the-art classical models.",/pdf/004a99662b36e69e4952bb8b88201b9f308a7a20.pdf,,,,,anonymous|qubite_qubit_embedding_for_knowledge_graph_completion,,,,,,,,,
526,5Q-ihWzhSi,"AMRize, then Parse! Enhancing AMR Parsing with PseudoAMR Data",['aclweb.org/ACL/ARR/2021/November/Paper554/Authors'],['Anonymous'],"As Abstract Meaning Representation (AMR) implicitly involves compound semantic annotations, we hypothesize auxiliary tasks which are semantically or formally related can better enhance AMR parsing. With carefully designed control experiments, we find that 1) Semantic role labeling (SRL) and dependency parsing (DP), would bring much more significant performance gain than unrelated tasks in the text-to-AMR transition. 2) To make a better fit for AMR, data from auxiliary tasks should be properly ""AMRized'' to PseudoAMR before training. 3) Intermediate-task training paradigm outperforms multitask learning when introducing auxiliary tasks to AMR parsing. From an empirical perspective, we propose a principled method to choose, reform, and train auxiliary tasks to boost AMR parsing. Extensive experiments show that our method achieves new state-of-the-art performance on in-distribution, out-of-distribution, and few-shots benchmarks of AMR parsing.",/pdf/4b97bf2b70c706c038774ed965efd1a36915f0ea.pdf,,,,,anonymous|amrize_then_parse_enhancing_amr_parsing_with_pseudoamr_data,,,,,,,,,
527,iEqUccu6yII,Zero-Shot Aspect-Based Scientific Document Summarization using Self-Supervised Pre-training,['aclweb.org/ACL/ARR/2021/November/Paper1197/Authors'],['Anonymous'],"We study the zero-shot setting for the aspect-based scientific document summarization task. Summarizing scientific documents with respect to an aspect can remarkably improve document assistance systems and readers experience. However, existing large-scale datasets contain a limited variety of aspects, causing summarization models to over-fit to a small set of aspects. We establish baseline results in zero-shot performance (over unseen aspects and the presence of domain shift), paraphrasing, leave-one-out, and limited supervised samples experimental setups. We propose a self-supervised pre-training approach to enhance the zero-shot performance. Experimental results on the FacetSum and PubMed aspect-based datasets show promising performance when the model is pre-trained using unlabeled in-domain data.",/pdf/8039a02bf6179a5c69b63f60498ec1954bda5758.pdf,,,,,anonymous|zeroshot_aspectbased_scientific_document_summarization_using_selfsupervised_pretraining,,,,,,,,,
528,Gs-GKGuR0t,Using Interactive Feedback to Improve the Accuracy and Explainability of Question Answering Systems Post-Deployment,['aclweb.org/ACL/ARR/2021/November/Paper2015/Authors'],['Anonymous'],"Most research on question answering focuses on the pre-deployment stage; i.e., building an accurate model for deployment.
In this paper, we ask the question: Can we improve QA systems further post-deployment based on user interactions? 
We focus on two kinds of improvements: 1) improving the QA system's performance itself, and 2) providing the model with the ability to explain the correctness or incorrectness of an answer.
We collect a retrieval-based QA dataset, FeebackQA, which contains interactive feedback from users. We collect this dataset by deploying a base QA system to crowdworkers who then engage with the system and provide feedback on the quality of its answers.
The feedback contains both structured ratings and unstructured natural language explanations.
We train a neural model with this feedback data that can generate explanations and re-score answer candidates. We show that usage of the feedback data improves the accuracy of the QA system, and helps users make informed decisions about the correctness of answers.\footnote{We will make both the data and the code public.} ",/pdf/9c0919cd7b7bc85e10835abe68233b811e79b879.pdf,,,,,anonymous|using_interactive_feedback_to_improve_the_accuracy_and_explainability_of_question_answering_systems_postdeployment,,,,,,,,,
529,f9gYRaGv934,Analyzing Dynamic Adversarial Training Data in the Limit,['aclweb.org/ACL/ARR/2021/November/Paper1835/Authors'],['Anonymous'],"To create models that are robust across a wide range of test inputs, training datasets should include diverse examples that span numerous phenomena. Dynamic adversarial data collection (DADC), where annotators craft examples that challenge continually improving models, holds promise as an approach for generating such diverse training sets. Prior work has shown that running DADC over 1-3 rounds can help models fix some error types, but it does not necessarily lead to better generalization beyond adversarial test data. We argue that running DADC over many rounds maximizes its training-time benefits, as the different rounds can together cover many of the task-relevant phenomena. We present the first study of longer-term DADC, where we collect 20 rounds of NLI examples for a small set of premise paragraphs, with both adversarial and non-adversarial approaches. Models trained on DADC examples make 26% fewer errors on our expert-curated test set compared to models trained on non-adversarial data. Our analysis shows that DADC yields examples that are more difficult, more lexically and syntactically diverse, and contain fewer annotation artifacts compared to non-adversarial examples.",/pdf/1a6d0e77105ea3dc3d50ebca32051ee435af8c50.pdf,,,,,anonymous|analyzing_dynamic_adversarial_training_data_in_the_limit,,,,,,,,,
530,3Huneg3YkiV,Evidence Decomposition Graph Network for Fact Verification,['aclweb.org/ACL/ARR/2021/November/Paper2632/Authors'],['Anonymous'],"Fact verification is the task to verify a given claim according to extracted evidence sentences. 
Most existing works use whole evidence sentences or break them into phrases to perform evidence interaction, where evidence is treated either too coarsely or over fragmented. We also find that many models suffer from exposure bias, which finally leads to them only paying attention to the evidence ranked higher by previous steps while failing to recognize crucial pieces from all candidates. In this paper, we propose an Evidence Decomposition Graph Network (EDGN), which decomposes each evidence sentence, especially the complex ones, into several simple sentences, highlighting the required key information without losing sentence structure and meaning. EDGN also absorbs a simple but effective evidence shuffling method to mitigate exposure bias. Experiments on the FEVER benchmark show our model can take all evidence candidates into account, distill necessary key information from complex evidence, and outperform existing methods in the literature. We will release our code to the community for further exploration.",/pdf/9ce5514011ddda18aacae5dbe5f0f144bfbf8a84.pdf,,,,,anonymous|evidence_decomposition_graph_network_for_fact_verification,,,,,,,,,
531,L7d3vpKjQhZ,Control False Negative Instances In Contrastive Learning To ImproveLong-tailed Item Categorization,['aclweb.org/ACL/ARR/2021/November/Paper1710/Authors'],['Anonymous'],"Item categorization (IC) is an important core technology in e-commerce natural language processing (NLP). Given category labels' long-tailed distribution, IC performances on tail labels tend to be poor due to sporadic supervision. To address the long-tail issue in classification, an increasing number of methods have been proposed in the computer vision domain. In this paper, we adopted a new method, which consists of decoupling the entire classification task into (a) learning representations in a k-positive contrastive learning (KCL) way and (b) training a classifier on balanced data set, into IC tasks. Using SimCSE to be our self-learning backbone, we demonstrated that the proposed method works on the IC text classification task. In addition, we spotted a shortcoming in the KCL: false negative instances (FN) may harm the representation learning step. After eliminating FN instances, IC performance (measured by macro-F1) has been further improved. ",/pdf/17757aa480f873ccdbe23188c5852342ae16031a.pdf,,,,,anonymous|control_false_negative_instances_in_contrastive_learning_to_improvelongtailed_item_categorization,,,,,,,,,
532,JT-Xedd1zJQ,"FrugalScore: Learning Cheaper, Lighter and Faster Evaluation Metrics for Automatic Text Generation",['aclweb.org/ACL/ARR/2021/November/Paper2888/Authors'],['Anonymous'],"Fast and reliable evaluation metrics are key to R&D progress. While traditional natural language generation metrics are fast, they are not very reliable. Conversely, new metrics based on large pretrained language models are much more reliable, but require significant computational resources. In this paper, we propose FrugalScore, an approach to learn a fixed, low cost version of any expensive NLG metric, while retaining most of its original performance. Experiments with BERTScore and MoverScore on summarization and translation show that FrugalScore is on par with the original metrics (and sometimes better), while having several orders of magnitude less parameters and running several times faster. On average over all learned metrics, tasks, and variants, FrugalScore retains 96.8% of the performance, runs 24 times faster, and has 35 times less parameters than the original metrics. We make our trained metrics publicly available, to benefit the entire NLP community and in particular researchers and practitioners with limited resources.",/pdf/cce49c6db2375af9afb4d16713f40e40c07adbf9.pdf,,,,,anonymous|frugalscore_learning_cheaper_lighter_and_faster_evaluation_metrics_for_automatic_text_generation,,,,,,,,,
533,vyiDjt4UNPv,Cross-Lingual UMLS Named Entity Linking using UMLS Dictionary Fine-Tuning,['aclweb.org/ACL/ARR/2021/November/Paper474/Authors'],['Anonymous'],"We study cross-lingual UMLS named entity linking, where mentions in a given source language are mapped to UMLS concepts, most of which are labeled in English. We propose a general solution that can be easily adapted to any source language and demonstrate the method on Hebrew documents. 
Our cross-lingual framework includes an offline unsupervised construction of a bilingual UMLS dictionary and a per-document pipeline which identifies UMLS candidate mentions and uses a fine-tuned pretrained transformer language model to filter candidates according to context.
Our method exploits a small dataset of manually annotated UMLS mentions in the source language and uses this supervised data in two ways: to extend the unsupervised UMLS dictionary and to fine-tune the contextual filtering of candidate mentions in full documents. Our method addresses cross-lingual UMLS NEL in a low resource setting, where the ontology is large, there is a lack of descriptive text defining most entities, and labeled data can only cover a small portion of the ontology. We demonstrate results of our approach on both Hebrew and English. We achieve new state-of-the-art results on the Hebrew Camoni corpus, +8.9 F1 on average across three communities in the dataset. We also achieve new SOTA on the English dataset MedMentions with +7.3 F1.",/pdf/bbb715e05adae0c3ef1fb2145edf5eacb671dfa4.pdf,/attachment/a0117ee4898bca84ee4f01c9d746e11ebd83bcc6.zip,,,,anonymous|crosslingual_umls_named_entity_linking_using_umls_dictionary_finetuning,,,,,,,,,
534,YRia3RRZHXm,Incorporating Dual-Aware with Hierarchical Interactive Memory Networks for Task-Oriented Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper2982/Authors'],['Anonymous'],"Recent years, end-to-end task-oriented dialogue systems have made a remarkable breakthrough. However, existing dialogue models tend to equally summarize all the history as the context representation and apply memory networks to incorporate external knowledge. They neglect to highlight the latest request of users, which will cause the unexpected responses to be generated. In addition, it is insufficient for the original memory networks to interact between memories only at hop-level and difficult to extract more useful knowledge information. To address this issue, we propose a novel neural model which incorporates Dual-Aware with Hierarchical Interactive Memory Networks (DA-HIMN). The dual-aware constituting static  request-aware and dynamic KB-aware is responsible for capturing the latest request of users and collecting related knowledge information. Furthermore, we design a hierarchical interaction mechanism to augment the memory networks at layer-level to more adequately learn the knowledge representation. Our experimental results demonstrate that our model outperforms the baseline model on two task-oriented dialogue datasets in several evaluation metrics.",/pdf/f561c732a28d0dc28e2852d3bcc9cf26740a4106.pdf,,,,,anonymous|incorporating_dualaware_with_hierarchical_interactive_memory_networks_for_taskoriented_dialogue,,,,,,,,,
535,5Ph0fRJg9c-,Expanding Pretrained Models to Thousands More Languages via Lexicon-based Adaptation,['aclweb.org/ACL/ARR/2021/November/Paper606/Authors'],['Anonymous'],"The performance of multilingual pretrained models is highly dependent on the availability of monolingual or parallel text present in a target language. Thus, the majority of the world’s languages cannot benefit from recent progress in NLP as they have no or limited textual data. To expand possibilities of using NLP technology in these under-represented languages, we systematically study strategies that relax the reliance on conventional language resources through the use of bilingual lexicons, an alternative resource with much better language coverage. We analyze different strategies to synthesize textual or labeled data using lexicons, and how this data can be combined with monolingual or parallel text when available. For 19 under-represented languages across 3 tasks, our methods lead to consistent improvements of up to 5 and 15 points with and without extra monolingual text respectively.  Overall, our study highlights how NLP methods can be adapted to thousands more languages that are under-served by current technology.",/pdf/5e3f45d1449901db75f02e1056e40c7d4fe1c55c.pdf,,,,,anonymous|expanding_pretrained_models_to_thousands_more_languages_via_lexiconbased_adaptation,,,,,,,,,
536,ZkFuUac0Hc0,Understanding and Improving Sequence-to-Sequence Pretraining for Neural Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper1685/Authors'],['Anonymous'],"In this paper, we present a substantial step in better understanding the SOTA sequence-to-sequence (Seq2Seq) pretraining for neural machine translation~(NMT). We focus on studying the impact of the jointly pretrained decoder, which is the main difference between Seq2Seq pretraining and previous encoder-based pretraining approaches for NMT. By carefully designing experiments on three language pairs, we find that Seq2Seq pretraining is a double-edged sword: On one hand, it helps NMT models to produce more diverse translations and reduce adequacy-related translation errors. On the other hand, the discrepancies between Seq2Seq pretraining and NMT finetuning limit the translation quality (i.e., domain discrepancy) and induce the over-estimation issue (i.e., objective discrepancy). Based on these observations, we further propose simple and effective strategies, named in-domain pretraining and input adaptation to remedy the domain and objective discrepancies, respectively. Experimental results on several language pairs show that our approach can consistently improve both translation performance and model robustness upon Seq2Seq pretraining.",/pdf/d07401d36fccc28235f5e74246859af21d1956b6.pdf,,,,,anonymous|understanding_and_improving_sequencetosequence_pretraining_for_neural_machine_translation,,,,,,,,,
537,NaVgf-NPQev,Description-Driven Task-Oriented Dialog Modeling,['aclweb.org/ACL/ARR/2021/November/Paper2349/Authors'],['Anonymous'],"Task-oriented dialogue (TOD) systems are required to identify key information from conversations for the completion of given tasks. Such information is conventionally specified in terms of intents and slots contained in task-specific ontology or schemata. Since these schemata are designed by system developers, the naming convention for slots and intents is not uniform across tasks, and may not convey their semantics effectively. This can lead to models memorizing arbitrary patterns in data, resulting in suboptimal performance and generalization. In this paper, we propose that schemata should be modified by replacing names or notations entirely with natural language descriptions. We show that a language description-driven system exhibits better understanding of task specifications, higher performance on state tracking, improved data efficiency, and effective zero-shot transfer to unseen tasks. Following this paradigm, we present a simple yet effective Description-Driven Dialog State Tracking (D3ST) model, which relies purely on schema descriptions and an ""index-picking'' mechanism. We demonstrate the superiority in quality, data efficiency and robustness of our approach as measured on the MultiWOZ (Budzianowski et al.,2018), SGD (Rastogi et al., 2020), and the recent SGD-X (Lee et al., 2021) benchmarks.",/pdf/135b6ff92f658db567590d3adfa6c7dc31dcbdad.pdf,,,,,anonymous|descriptiondriven_taskoriented_dialog_modeling,,,,,,,,,
538,Uhnw1smvKt,MSP: Multi-Stage Prompting for Making Pre-trained Language Models Better Translators,['aclweb.org/ACL/ARR/2021/November/Paper2440/Authors'],['Anonymous'],"Prompting has recently been shown as a promising approach for applying pre-trained language models to perform downstream tasks. We present Multi-Stage Prompting, a simple and automatic approach for leveraging pre-trained language models to translation tasks. To better mitigate the discrepancy between pre-training and translation, MSP divides the translation process via pre-trained language models into three separate stages: the encoding stage, the re-encoding stage, and the decoding stage. During each stage, we independently apply different continuous prompts for allowing pre-trained language models better shift to translation tasks. We conduct extensive experiments on three translation tasks. Experiments show that our method can significantly improve the translation performance of pre-trained language models.",/pdf/df9d99e65477ba7bcd5aa33e5bfcd0fcb8287902.pdf,,,,,anonymous|msp_multistage_prompting_for_making_pretrained_language_models_better_translators,,,,,,,,,
539,kXo7lEh7OaX,Code Synonyms Do Matter: Multiple Synonyms Matching Network for Automatic ICD Coding,['aclweb.org/ACL/ARR/2021/November/Paper725/Authors'],['Anonymous'],"Automatic ICD coding is defined as assigning disease codes to electronic medical records (EMRs).
Existing methods apply label attention with code representations to match related text snippets for coding.
Unlike these works that model the label with the code hierarchy or description, we argue that the code synonyms can provide more comprehensive knowledge based on the observation that the code expressions in EMRs vary from their descriptions in ICD. 
By aligning codes to concepts in UMLS, we collect synonyms of every code in ICD. Then, we propose a multiple synonyms matching network to leverage synonyms for better code representation learning, and finally help the code classification. 
Experiments on two settings of the MIMIC-III dataset show that our proposed method outperforms previous state-of-the-art methods.
",/pdf/d29c107ed4dccc859c8a72888662899371f247b9.pdf,/attachment/2c369563deecdf3ef4a83ce6659d936d80a61a3a.zip,,,,anonymous|code_synonyms_do_matter_multiple_synonyms_matching_network_for_automatic_icd_coding,,,,,,,,,
540,og2PWB6U0K0,Towards Focused and Connected Document-Level Event Extraction,['aclweb.org/ACL/ARR/2021/November/Paper2381/Authors'],['Anonymous'],"Document-level event extraction (DEE) is indispensable when events are naturally described in the form of a document. Although previous methods have made great success on DEE, they are limited by two bottlenecks: losing focus and losing the connection. In this paper, to break through the above bottlenecks, we annotated a new dataset, named WIKIEVENT++, towards focused and connected DEE.  Besides, we propose two different models to approach this task: the extractive model and the generative model. Experimental results verify the effectiveness of our proposed methods. We further present a promising case study to explore the performance bottleneck for this task. Data and code will be released at \url{http://anonymized} to advance the research on document-level event extraction.",/pdf/d24d47eec66050236d8aa6f46ad0838b28b1bea1.pdf,,,,,anonymous|towards_focused_and_connected_documentlevel_event_extraction,,,,,,,,,
541,QXMahjntD_C,GLM: General Language Model Pretraining with Autoregressive Blank Infilling,['aclweb.org/ACL/ARR/2021/November/Paper1636/Authors'],['Anonymous'],"There have been various types of pretraining architectures including autoencoding models (e.g., BERT), autoregressive models (e.g., GPT), and encoder-decoder models (e.g., T5). However, none of the pretraining frameworks performs the best for all tasks of three main categories including natural language understanding (NLU), unconditional generation, and conditional generation. We propose a General Language Model (GLM) based on autoregressive blank infilling to address this challenge. GLM improves blank filling pretraining by adding 2D positional encodings and allowing an arbitrary order to predict spans, which results in performance gains over BERT and T5 on NLU tasks. Meanwhile, GLM can be pretrained for different types of tasks by varying the number and lengths of blanks. On a wide range of tasks across NLU, conditional and unconditional generation, GLM outperforms BERT, T5, and GPT given the same model sizes and data, and achieves the best performance from a single pretrained model with 1.25× parameters of BERT Large , demonstrating its generalizability to different downstream tasks.",/pdf/9879b8b2d25d386d0f8a87de70aef9bcf67c8cef.pdf,,,,,anonymous|glm_general_language_model_pretraining_with_autoregressive_blank_infilling,,,,,,,,,
542,-NcPJhsLhtJ,PeerSum: A Peer Review Dataset for Abstractive Multi-document Summarization,['aclweb.org/ACL/ARR/2021/November/Paper1974/Authors'],['Anonymous'],"We present PeerSum, a new MDS dataset using peer reviews of scientific publications. Our dataset differs from the existing MDS datasets in that our summaries (i.e., the meta-reviews) are highly abstractive and they are real summaries of the source documents (i.e., the reviews) and it also features disagreements among source documents. We found that current state-of-the-art MDS models struggle to generate high-quality summaries for PeerSum, offering new research opportunities.",/pdf/f784ec5b1f35bd618f481e4e044f3643dd7379c6.pdf,/attachment/cf3fa135b45cb528737cdfcd2b7209347ea8e036.zip,,,,anonymous|peersum_a_peer_review_dataset_for_abstractive_multidocument_summarization,,,,,,/attachment/c57cb2852fa11f2762b201d220c725949fe86bba.zip,,,
543,7vSof0oWJKN,A Simple General Method for Detecting Textual Adversarial Examples,['aclweb.org/ACL/ARR/2021/November/Paper718/Authors'],['Anonymous'],"Although deep neural networks have achieved state-of-the-art performance in various machine learning and artificial intelligence tasks, adversarial examples, constructed by adding small non-random perturbations to correctly classified inputs, successfully fool highly expressive deep classifiers into incorrect predictions. Approaches to adversarial attacks in natural language tasks have boomed in the last five years using character-level, word-level, phrase-level, or sentence-level textual perturbations. While there is some work in NLP on defending against such attacks through proactive methods, like adversarial training, there is to our knowledge no effective reactive approaches to defence via detection of textual adversarial examples such as is found in the image processing literature. In this paper, we apply distance-based ensemble learning and semantic representations from different representation learning models based on our understanding of the reason for adversarial examples to fill this gap. Our technique, MultiDistance Representation Ensemble Method (MDRE), obtains state-of-the-art results on character-level, word-level, and phrase-level attacks on the IMDB dataset as well as on the later two with respect to the MultiNLI dataset. If this paper is accepted, we will publish our code.",/pdf/58353e4b36ae7ec7660301c83b5c3b0aefded099.pdf,,,,,anonymous|a_simple_general_method_for_detecting_textual_adversarial_examples,,,,,,,,,
544,46-q5-S-mEF,Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System,['aclweb.org/ACL/ARR/2021/November/Paper71/Authors'],['Anonymous'],"Pre-trained language models have been recently shown to benefit task-oriented dialogue (TOD) systems. Despite their success, existing methods often formulate this task as a cascaded generation problem which can lead to error accumulation across different sub-tasks and greater data annotation overhead. In this study, we present PPTOD, a unified plug-and-play model for task-oriented dialogue. In addition, we introduce a new dialogue multi-task pre-training strategy that allows the model to learn the primary TOD task completion skills from heterogeneous dialog corpora. We extensively test our model on three benchmark TOD tasks, including end-to-end dialogue modelling, dialogue state tracking, and intent classification. Experimental results show that PPTOD achieves new state of the art on all evaluated tasks in both high-resource and low-resource scenarios. Furthermore, comparisons against previous SOTA methods show that the responses generated by PPTOD are more factually correct and semantically coherent as judged by human annotators.",/pdf/8f7097e183cb99d45b28c1b66a0512c8f66cb162.pdf,/attachment/f5256a0846d5e9ca59e3fd8bce1c160a6eeeb9d7.zip,,,,anonymous|multitask_pretraining_for_plugandplay_taskoriented_dialogue_system,,,,,,/attachment/9d1d8aefb29043df4fe638bd0cc8ed3333ca49b5.zip,,,
545,HlTDIkxaWCI,A Simple Overlapping Relation Extraction Method Based on Dropout,['aclweb.org/ACL/ARR/2021/November/Paper829/Authors'],['Anonymous'],"The relation extraction (RE) task of knowledge acquisition aims to identify all specific relations of two entities. Prior works had proved the effectiveness of tagging methods, especially on the overlapping triple extraction problem. In this work, we introduce a simple relation extraction method (DropRel) based on dropout. We propose a Dropout-Normalization layer to generate different vectors for one token pair. Our model also provides a unified perspective for entity boundary and relation tagging tasks. We define a novel dependence relation for relation triple to integrate boundary into relation. The empirical experiments show that the DropRel model outperforms previous state-of-the-art methods on NYT and WEBNLG datasets. And our ablation study shows the DropRel without the dependence relation is better on the WEBNLG dataset.",/pdf/8ad81abfc5050bcd645a9b3f43940c01d6045bc8.pdf,/attachment/dd770b58ec84295ec25255c953c5b9c9f5f753b8.zip,,,,anonymous|a_simple_overlapping_relation_extraction_method_based_on_dropout,,,,,,/attachment/516831f8dd2bf82c3d176a270fe1fd462f357f85.zip,,,
546,nRqzJxJXcCb,Target-Guided Dialogue Response Generation Using Commonsense and Data Augmentation,['aclweb.org/ACL/ARR/2021/November/Paper2623/Authors'],['Anonymous'],"Targeted-guided response generation enables dialogue systems to smoothly guide a conversation from a dialogue context toward a target sentence. Such control is useful for designing dialogue systems that direct a conversation toward specific goals, such as providing counselling and creating non-obtrusive  recommendations. In this paper, we introduce a new technique for target-guided response generation, which first finds a bridging path of commonsense knowledge concepts between the source and target, and then uses the identified bridging path to generate transition responses. Additionally, we propose techniques to re-purpose existing dialogue datasets for target-guided generation. Finally, we demonstrate the shortcomings of existing automated metrics for this task, and propose a novel evaluation metric that we show is more effective for target-guided response evaluation. Our experiments show that our proposed evaluation metric is reliable and our techniques outperform baselines on the generation task. Our work generally enables dialog system designers to exercise more control over the conversations that their systems produce.",/pdf/f508518bb02c11f4d7cd512164c51cdb8c02351b.pdf,,,,,anonymous|targetguided_dialogue_response_generation_using_commonsense_and_data_augmentation,,,,,,,,,
547,Lz2fD-uQyeh,Neural Pipeline for Zero-Shot Data-to-Text Generation,['aclweb.org/ACL/ARR/2021/November/Paper1477/Authors'],['Anonymous'],"In data-to-text (D2T) generation, training on in-domain data leads to overfitting to the data representation and repeating training data noise. We examine how to avoid finetuning the pretrained language models (PLMs) on D2T generation datasets while still taking advantage of surface realization capabilities of PLMs. Inspired by pipeline approaches, we propose to generate text by rephrasing single-item templates using a sequence of modules trained on general-domain text-based operations—ordering, aggregation, and paragraph compression. We train PLMs for performing these operations on a synthetic corpus WikiFluent which we build from English Wikipedia. Our experiments on two major triple-to-text datasets—WebNLG and E2E—show that our approach enables D2T generation from RDF triples in zero-shot settings.",/pdf/a6e79a97b07af932883203f65cd23815a87a16f7.pdf,,,,,anonymous|neural_pipeline_for_zeroshot_datatotext_generation,,,,,,/attachment/5060927a4e3dd00432b367ca7376e6617cb749b6.zip,,,
548,Qj5PZOZgPRS,Parameter-Efficient Abstractive Question Answering over Tables and over Text,['aclweb.org/ACL/ARR/2021/November/Paper1203/Authors'],['Anonymous'],"A long-term ambition of information seeking question answering (QA) systems is to reason over multi-modal contexts and generate
natural answers to user queries. Today, memory intensive pre-trained language models are adapted to downstream tasks such as QA by fine-tuning the model on QA data in a specific modality like unstructured text or structured tables. To avoid training such memory-hungry models and utilizing a uniform architecture for each modality, parameter-efficient transfer learning techniques such as adapters add and train small task-specific bottle-neck layers between transformer layers. However, modality-specific adapter layers infused in a pre-trained transformer also require uniformity in the input sequence, which contradicts with existing work that trains structure-specific layers on multi-modal data. In this work, we study parameter-efficient abstractive QA in encoder-decoder models over structured tabular data and unstructured textual data using only 1.5% additional parameters for each modality. We retain table structure information by a hierarchy preserving transformation of complex hierarchical tables to 1-dimensional sequences, thus maintaining uniformity in the model input. We also ablate over adapter layers in both encoder and decoder modules and study the efficiency-performance trade-off and demonstrate that reducing additional trainable parameters down to 0.7%–1.0% leads to comparable results. Our models outperform current state-of-the-art models on tabular QA datasets such as Tablesum and FeTaQA and achieve comparable performance on a text QA dataset such as NarrativeQA using significantly less trainable parameters.",/pdf/93396d7d1a4e038d80b52933007c087fdc04c059.pdf,,,,,anonymous|parameterefficient_abstractive_question_answering_over_tables_and_over_text,,,,,,,,,
549,6NEOigYYbRk,Error-Correcting Codes For Approximate Neural Sequence Prediction,['aclweb.org/ACL/ARR/2021/November/Paper125/Authors'],['Anonymous'],"We propose a novel neural sequence prediction method based on \textit{error-correcting codes} that avoids exact softmax normalization and allows for a tradeoff between speed and performance. Error-correcting codes represent predictions and targets as a binary code where each bit is represented by a logit. The codebook is arranged such that similar tokens are close to each other using word embedding similarity, ensuring that incorrect predictions are at least semantically close to the target. We also address the well-established problem of compounding errors by mixing the latent codes of past predictions and past targets in one of two ways: (1) according to a predefined sampling schedule or (2) a differentiable sampling procedure that replaces the argmax operation. Low dimensional codes show similar performance to models that use the full softmax and outperform alternative approximate methods for language modeling and text generation, while generation further benefits from our mixture sampling. ",/pdf/a9f5b0c2a77fce477147755ca33baca93daf9a87.pdf,,,,,anonymous|errorcorrecting_codes_for_approximate_neural_sequence_prediction,,,,,,,,,
550,7EemgCzGXAN,Prompt-Learning for Fine-Grained Entity Typing,['aclweb.org/ACL/ARR/2021/November/Paper1888/Authors'],['Anonymous'],"As an effective approach to tune pre-trained language models (PLMs) for specific tasks, prompt-learning has recently attracted much attention from researchers. By using cloze-style language prompts to stimulate the versatile knowledge of PLMs, prompt-learning can achieve promising results on a series of NLP tasks, such as natural language inference, sentiment classification, and knowledge probing. In this work, we investigate the application of prompt-learning on fine-grained entity typing in fully supervised, few-shot, and zero-shot scenarios. 
We first develop a simple and effective prompt-learning pipeline by constructing entity-oriented verbalizer and templates and conducting masked language modeling. Further, to tackle the zero-shot regime, we propose a self-supervised strategy that carries out distribution-level optimization in prompt-learning to automatically summarize the information of entity types. Extensive experiments on three fine-grained entity typing benchmarks (with up to 86 classes) under fully supervised, few-shot and zero-shot settings show that prompt-learning methods significantly outperform fine-tuning baselines, especially when the training data is insufficient.
",/pdf/d904ae87912ddcfeec42c425e81102b58383b1ed.pdf,,,,,anonymous|promptlearning_for_finegrained_entity_typing,,,,,,,,,
551,QAuS7grHtkO,Probing Position-Aware Attention Mechanism in Long Document Understanding,['aclweb.org/ACL/ARR/2021/November/Paper1291/Authors'],['Anonymous'],"Long document understanding is a challenging problem in natural language understanding. Most current transformer-based models only employ textual information for attention calculation due to high computation limit. To address those issues for long document understanding, we explore new approaches using different position-aware attention masks and investigate their performance on different benchmarks. Experimental results show that our models have the advantages on long document understanding based on various evaluation metrics. Furthermore, our approach makes changes only to the attention module in the transformer and thus can be flexibly detached and plugged into any other transformer-based solutions with ease. ",/pdf/0e0aab6b32fe1f9c81fa791c23c3436e9f52f62d.pdf,/attachment/50f0f34735da7ed522759f05c9bcaf5085dbe761.zip,,,,anonymous|probing_positionaware_attention_mechanism_in_long_document_understanding,,,,,,,,,
552,H6kbvowD2Bv,,,,,,,,,,,,,,,,,,,
553,BM3y-ZnNwoG,CLGP: Multi-Feature Embedding based Cross-Attention for Chinese NER,['aclweb.org/ACL/ARR/2021/November/Paper993/Authors'],['Anonymous'],"The previous works fused lexicon information while ignoring two important Chinese language characteristics: glyph and pinyin, which carry significant syntax and semantics information for sequence tagging tasks. This paper proposes CLGP, which utilizes three specific extractors to obtain the embeddings of the glyph, pinyin, and lexicon, and further uses a  network based on cross-attention to perform multi-feature embedding fusion. Specifically, we introduce the embedding scheme to preserve the lexicon matching results, and design two specific CNN architectures to extract glyph and pinyin embeddings. Moreover, we fuse the four embeddings by the cross-attention-based network to enhance the Chinese NER. The experimental results on four famous datasets show that CLGP achieves the SOTA performance.",/pdf/86e29bc53da2a4e742100569b971d2b19d1389be.pdf,/attachment/845da27249fe7ac7eb61713ad1d78130e434ef87.zip,,,,anonymous|clgp_multifeature_embedding_based_crossattention_for_chinese_ner,,,,,,/attachment/70e0c5d7fbc48682ce1f69a9e47f9e4f233c2aa2.zip,,,
554,paaFqtxNcxT,Detecting Rumor Veracity with Only Textual Information by Double-Channel Structure,['aclweb.org/ACL/ARR/2021/November/Paper2876/Authors'],['Anonymous'],"We develop a double-channel classifier to detect the veracity of social media rumors, relying only on the most basic textual information. Our model first assigns each thread into a “certain” or “uncertain” category. Since authors with a proprietary source of information are likely to post threads with a certain textual tone, we apply lie detection algorithms to certain texts. In contrast, as uncertain threads are arbitrary, we examine whether the replies are in accordance with the threads instead of applying the lie detection algorithms. This approach yields a macro-F1 score of 0.4027, outperforming all the baseline models and the second-place winner of SemEval 2019 Task 7. Further, we show that dividing the sample into two subgroups significantly improves the classification accuracy, reinforcing our claim that applying appropriate classifiers is crucial in rumor veracity detection.",/pdf/6af91cd4a70bf2074c4a3446f4a03ac1fb6ab0a8.pdf,,,,,anonymous|detecting_rumor_veracity_with_only_textual_information_by_doublechannel_structure,,,,,,,,,
555,UQk8XMFAE2u,Knowledge Graph is in Rescue: Task Oriented Dialogue System for Response Generation without NLU and DM,['aclweb.org/ACL/ARR/2021/November/Paper2064/Authors'],['Anonymous'],"Natural language understanding (NLU) and dialogue management (DM) are the standard prerequisites for response generation in a task-oriented dialogue system. In the existing literature, NLU and DM have been tackled as two independent tasks, requiring separate labeled data. Besides this problem of additional data requirements, NLU and DM also introduce errors in the pipe-lined processing of dialogue. Direct generation of responses from the user utterances without using any intermediate NLU and DM modules is, thus, a worthy goal. To accomplish this, the model should be able to (implicitly) understand the intent of the user, fetch the appropriate data from the knowledge base, (implicitly) decide an action by looking at the fetched data and conversation history, and finally, generate the response. In this work, we build an end-to-end dialogue generation system that does not require NLU and DM components or their associated labels in the data. We propose an effective technique based on the pre-trained GPT-2 and Graph Convolution Network (GCN) that takes conversation history and knowledge graph as input and produces appropriate responses. Experiments on three benchmark datasets viz. MultiWOZ, InCar Assist, and CamRest show that our proposed model achieves performance comparable to state-of-the-art systems without using the NLU and DM labels. Human evaluation conducted on the outputs also confirms that our proposed model generates highly fluent and contextually relevant responses.",/pdf/a52118a86397cde24356c49b7f2293a7adf3a349.pdf,/attachment/b4854b6665a9ff1ddaf6cc21aff0205d4306423e.zip,,,,anonymous|knowledge_graph_is_in_rescue_task_oriented_dialogue_system_for_response_generation_without_nlu_and_dm,,,,,,,,,
556,YTGg7kv8qIq,Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation,['aclweb.org/ACL/ARR/2021/November/Paper2592/Authors'],['Anonymous'],"The recent large-scale vision-language pre-training (VLP) of dual-stream architectures (e.g., CLIP) with a tremendous amount of image-text pair data, has shown its superiority on various multimodal alignment tasks. Despite its success, the resulting models are not capable of generative multimodal tasks due to the weak text encoder. To tackle this problem, we propose to augment the dual-stream VLP model with a textual pre-trained language model (PLM) via vision-language knowledge distillation (VLKD), enabling the capability for multimodal generation. VLKD is pretty data- and computation-efficient compared to the pre-training from scratch. Experimental results show that the resulting model has strong zero-shot performance on multimodal generation tasks, such as open-ended visual question answering and image captioning. For example, it achieves 39.7% zero-shot accuracy on the VQA 2.0 dataset, surpassing the previous state-of-the-art zero-shot model with 14x fewer parameters. Furthermore, the original text processing ability of the PLM is maintained after VLKD, which makes our model versatile for both multimodal and unimodal tasks.",/pdf/ab1ed962b526a7ae3c45e6c7f7c16d554f1663bb.pdf,,,,,anonymous|enabling_multimodal_generation_on_clip_via_visionlanguage_knowledge_distillation,,,,,,,,,
557,fX8TXF-LD21,HIE-SQL: History Information Enhanced Network for Context-Dependent Text-to-SQL Semantic Parsing,['aclweb.org/ACL/ARR/2021/November/Paper234/Authors'],['Anonymous'],"Recently, context-dependent text-to-SQL semantic parsing which translates natural language into SQL in an interaction process has attracted a lot of attentions. Previous works leverage context dependence information either from interaction history utterances or previous predicted queries but fail in taking advantage of both of them since of the mismatch between the natural language and logic-form SQL. In this work, we propose a History Information Enhanced text-to-SQL model (HIE-SQL) to exploit context dependence information from both history utterances and the last predicted SQL query. In view of the mismatch, we treat natural language and SQL as two modalities and propose a bimodal pre-trained model to bridge the gap between them. Besides, we design a schema-linking graph to enhance connections from utterances and the SQL query to database schema. We show our history information enhanced methods improve the performance of HIE-SQL by a significant margin, which achieves new state-of-the-art results on two context-dependent text-to-SQL benchmarks, the SparC and CoSQL datasets, at the writing time.",/pdf/27b4b519f041bb582ab0c9f8fb3aae69a326c195.pdf,,,,,anonymous|hiesql_history_information_enhanced_network_for_contextdependent_texttosql_semantic_parsing,,,,,,,,,
558,3_KnXEevm2E,TableIE: Capture the Interactions among Joint Information Extraction Explicitly via Double Tables,['aclweb.org/ACL/ARR/2021/November/Paper1752/Authors'],['Anonymous'],"Information Extraction (IE) mainly consists of three sub-tasks, Named Entity Recognition, Relation Extraction, and Event Extraction. Although the sub-tasks are highly correlated with each other, most previous works simply focus on part of them and ignore the interactions among different sub-tasks. In this paper, we propose TableIE, a double-tables based method to capture the interactions among joint information extraction (Joint IE, i.e., conduct all sub-tasks jointly) explicitly. Different from the complicated graph-based Joint IE methods, we maintain two tables for entity-relation extraction and event extraction respectively instead and implement the interactions among three IE sub-tasks explicitly. The experiment show that our TableIE model outperforms the previous state-of-the-art up to 2.5 in the ACE05 dataset.",/pdf/a47051eb2675e0ac357506de5247840ce7d985a5.pdf,,,,,anonymous|tableie_capture_the_interactions_among_joint_information_extraction_explicitly_via_double_tables,,,,,,,,,
559,9O7V12vSx8t,Towards Unified Prompt Tuning for Few-shot Learning,['aclweb.org/ACL/ARR/2021/November/Paper2262/Authors'],['Anonymous'],"Prompt-based fine-tuning has boosted the performance of Pre-trained Language Models (PLMs) on few-shot learning by employing task-specific prompts. However, PLMs are unfamiliar with the prompt-style expressions during pre-training, which limits the few-shot learning performance on downstream tasks. It would be desirable if models can acquire some prompting knowledge before task adaptation. We present the Unified Prompt Tuning (UPT) framework, leading to better few-shot learning for BERT-style models by explicitly capturing prompting semantics from non-target NLP datasets. In UPT, a novel paradigm Prompt-Options-Verbalizer is proposed for joint prompt learning across different NLP tasks, forcing PLMs to capture task-invariant prompting knowledge. We further design a self-supervised task named Knowledge-enhanced Selective Masked Language Modeling to improve the PLM's generalization abilities for accurate adaptation to previously unseen tasks. After multi-task learning, the PLM can be fine-tuned for any target few-shot NLP tasks using the same prompting paradigm. Experiments over a variety of NLP tasks show that UPT consistently outperforms state-of-the-arts for prompt-based fine-tuning.",/pdf/9b17e9b15884db1e048c91ec477aeed21fd59fda.pdf,/attachment/6cf61c70d4383637114d51729c64de1f7b37bb0c.zip,,,,anonymous|towards_unified_prompt_tuning_for_fewshot_learning,,,,,,,,,
560,7A4Fel5OBYQ,Metadata Shaping: Natural Language Annotations for the Long Tail,['aclweb.org/ACL/ARR/2021/November/Paper2351/Authors'],['Anonymous'],"Language models (LMs) struggle to capture knowledge about rare entities. To better capture entity knowledge, a common procedure in prior work is to start with a base LM such as BERT and to modify the LM architecture or objective function to produce a knowledge-aware LM. Proposed knowledge-aware LMs perform well compared to base LMs on entity-rich tasks; however deploying, understanding, and maintaining many different specialized architectures is challenging, and they also often introduce additional computational costs. Thus we ask to what extent we can match the quality of these architectures using a base LM and only changing the data. We propose metadata shaping, a method which inserts readily available entity metadata, such as descriptions and categorical tags, into examples at train and inference time based on mutual information. Intuitively, if metadata corresponding to popular entities overlap with metadata for rare entities, the LM may be able to better reason about the rare entities using patterns learned from similar popular entities. On standard entity-rich tasks (TACRED, FewRel, OpenEntity), metadata shaping exceeds the BERT-baseline by an average of 4.3 F1 points and achieves state-of-the-art results. We further show the gains are on average 4.4x larger for the slice of examples containing tail vs. popular entities.",/pdf/24698ac8bbe6bd4efd053a65f717be8211c337ba.pdf,,,,,anonymous|metadata_shaping_natural_language_annotations_for_the_long_tail,,,,,,,,,
561,NThz_6MqDuG,Word2Box: Capturing Set-Theoretic Semantics of Words using BoxEmbeddings,['aclweb.org/ACL/ARR/2021/November/Paper3003/Authors'],['Anonymous'],"Learning representations of words in a continuous space is perhaps the most fundamental task in NLP, a prerequisite for nearly all modern machine-learning techniques. Often the objective is to capture distributional similarity via vector dot product, however this is just one relation between word meanings we may wish to capture.  It is natural to consider words as (soft) equivalence classes based on similarity, it is natural to expect the ability to perform set-theoretic operations (intersection, union, difference) on these representations. This is particularly relevant for words which are homographs- for example, “tongue”∩“body” should be similar to “mouth”, while “tongue”∩“language” should  be  similar  to  “dialect”. Box embeddings are a novel region-based representation which provide the capability to perform these set-theoretic operations. In this work, we provide a fuzzy-set interpretation of box embeddings, and train box embeddings with a CBOW objective where contexts are represented using intersection. We demonstrate improved performance on various word similarity tasks, particularly on less common words, and perform a quantitative and qualitative analysis exploring the additional unique expressivity provided by Word2Box.",/pdf/09a781c9254a8308b36eaf33729802760a4b30f3.pdf,/attachment/dc84aede6afd03afd5720e1db8373699f1a8ae19.zip,,,,anonymous|word2box_capturing_settheoretic_semantics_of_words_using_boxembeddings,,,,,,,,,
562,1z0HSEAOoWs,KESA: A Knowledge Enhanced Approach For Sentiment Analysis,['aclweb.org/ACL/ARR/2021/November/Paper2117/Authors'],['Anonymous'],"Though some recent works focus on injecting sentiment knowledge into pre-trained language models, they usually design mask and reconstruction tasks in the post-training phase. In this paper, we aim to benefit from sentiment knowledge in a lighter way. To achieve this goal, we study sentence-level sentiment analysis and, correspondingly, propose two sentiment-aware auxiliary tasks named sentiment word cloze and conditional sentiment prediction. The first task learns to select the correct sentiment words within the input, given the overall sentiment polarity as prior knowledge. On the contrary, the second task predicts the overall sentiment polarity given the sentiment polarity of the word as prior knowledge. In addition, two kinds of label combination methods are investigated to unify multiple types of labels in each task. We argue that more information can promote the models to learn more profound semantic representation. We implement it in a straightforward way to verify this hypothesis. The experimental results demonstrate that our approach consistently outperforms pre-trained models and is additive to existing knowledge-enhanced post-trained models.",/pdf/783d69d347a52277506e14bc7a9f443b0f42fa45.pdf,/attachment/dc6f0893efdc77302b4de2e5ebb202e46704ab9d.zip,,,,anonymous|kesa_a_knowledge_enhanced_approach_for_sentiment_analysis,,,,,,,,,
563,GCq16dADbK7,Multi-stage Distillation Framework for Cross-Lingual Semantic Similarity Matching,['aclweb.org/ACL/ARR/2021/November/Paper1002/Authors'],['Anonymous'],"Previous studies have proved that cross-lingual knowledge distillation can significantly improve the performance of pre-trained models for cross-lingual similarity matching tasks. However, the student model needs to be large in this operation.  Otherwise, its performance will drop sharply, thus making it impractical to be deployed to memory-limited devices. To address this issue, we delve into cross-lingual knowledge distillation and propose a multi-stage distillation framework for constructing a small-size but high-performance cross-lingual model. In our framework, the contrastive learning and an assistant model are introduced to prevent performance from being compromised during the compression process. The experimental results demonstrate that our method can compress the size of XLM-R and MiniLM by more than 50%, while the performance is only reduced by about 1%. In addition, our framework is model-independent and applicable to all transformer-based models.",/pdf/d15182685c1ea0070480f0862dd3fad8d66eec74.pdf,,,,,anonymous|multistage_distillation_framework_for_crosslingual_semantic_similarity_matching,,,,,,,,,
564,v4hr8SvBl4L,Get Your Model Puzzled: Introducing Crossword-Solving as a New NLP Benchmark,['aclweb.org/ACL/ARR/2021/November/Paper2213/Authors'],['Anonymous'],"Solving crossword puzzles requires diverse reasoning capabilities, access to a vast amount of knowledge about language and the world, and the ability to satisfy the constraints imposed by the structure of the puzzle. In this work, we introduce solving crossword puzzles as a new natural language understanding task. We release a corpus of crossword puzzles collected from the New York Times daily crossword spanning 25 years and containing a total of 9152 puzzles, with an average of 85 clues per puzzle. These puzzles include a diverse set of clues: historic, factual, word meaning, synonyms/antonyms, fill-in-the-blank, abbreviations, prefixes/suffixes, wordplay, and cross-lingual, as well as clues that depend on the answers to other clues. We separately release the clue-answer pairs from these puzzles as an open-domain question answering dataset containing over half a million unique clue-answer pairs. For the question answering task, our baselines include several sequence-to-sequence and retrieval-based generative models. We also introduce a non-parametric constraint satisfaction baseline for solving the entire crossword puzzle. Finally, we propose an evaluation framework which consists of several complementary performance metrics.",/pdf/c1f4f67aa963cd5268b536048eab092e1086cf97.pdf,,,,,anonymous|get_your_model_puzzled_introducing_crosswordsolving_as_a_new_nlp_benchmark,,,,,,/attachment/7eec13cc3c6460b8b2db5339ce772086970b8066.zip,,,
565,-AGBhcs5JP9,TACO: Pre-training of Deep Transformers with Attention Convolution using Disentangled Positional Representation,['aclweb.org/ACL/ARR/2021/November/Paper2248/Authors'],['Anonymous'],"Word order, as a crucial part to understand natural language, has been carefully considered in pre-trained models by incorporating different kinds of positional encodings. However, existing pre-trained models mostly lack the ability to maintain robustness against minor permutation of words in learned representations. We therefore propose a novel architecture named Transformer with Attention COnvolution (TACO), to explicitly disentangle positional representations and incorporate convolution over multi-source attention maps before softmax in self-attention. Additionally, we design a novel self-supervised task, masked position modeling (MPM), to assist our TACO model in capturing complex patterns with regard to word order. Combining MLM (masked language modeling) and MPM objectives, the proposed TACO model can efficiently learn two disentangled vectors for each token, representing its content and position respectively. Experimental results show that TACO significantly outperforms BERT in various downstream tasks with fewer model parameters. Remarkably, TACO achieves +2.6% improvement over BERT on SQuAD 1.1 task, +5.4% on SQuAD 2.0 and +3.4% on RACE, with only 46K pre-training steps.",/pdf/7f0ebcdc581dbd6bcc031b7be559b4aa5a92b14e.pdf,,,,,anonymous|taco_pretraining_of_deep_transformers_with_attention_convolution_using_disentangled_positional_representation,,,,,,,,,
566,6-l23Qjgu2u,Aligning Annotation with User Perceptions for the Evaluation of Voice-Based Intelligent Personal Digital Assistants ,['aclweb.org/ACL/ARR/2021/November/Paper1401/Authors'],['Anonymous'],"Evaluating voice-based Intelligent Personal Digital Assistants (or IPDAs) like Alexa, Google Assistant, and Siri is a challenge, as they offer increasingly complex interactions and are found in ever-increasing contexts. The problem is compounded by users expecting more sophisticated, human-like behavior of IPDAs. Building an automated evaluation mechanism requires high quality ground truth data on user-IPDA interaction success, which incorporates these diverse and changing user expectations. Ignoring them may lead to divergence between user perceptions and what IPDAs are designed to optimize. To address this problem, we describe Response Quality (RQ) annotation and introduce response categories that incorporate the user’s perspective. To validate these categories, we present an in-lab study — the first on a large-scope conversational system that covers hundreds of domains — that tests the hypothesis that users judge human-like responses from IPDAs (like admitted fallibility and relevance) more favorably than non-human-like ones. We find support for this hypothesis, confirming that (1) Generic Fails are highly rated by older users in particular, (2) Irrelevant Responses are rated as poorly as Generic Fails and (3) disambiguation responses are highly rated (with caveats). We then baseline RQ ratings against user ratings to improve RQ’s alignment with user perceptions.",/pdf/055ab8ebbc0b27d15f4d717421e529993aa4def7.pdf,,,,,anonymous|aligning_annotation_with_user_perceptions_for_the_evaluation_of_voicebased_intelligent_personal_digital_assistants,,,,,,,,,
567,Zh4kJ4JOcHo,Redistributing Low-Frequency Words: Making the Most of Monolingual Data in Non-Autoregressive Translation,['aclweb.org/ACL/ARR/2021/November/Paper2548/Authors'],['Anonymous'],"Knowledge distillation (KD) is the preliminary step for training non-autoregressive translation (NAT) models, which eases the training of NAT models at the cost of losing important information for translating low-frequency words. In this work, we provide an appealing alternative for NAT -- monolingual KD, which trains NAT student on external monolingual data with AT teacher trained on the original bilingual data. Monolingual KD is able to transfer both the knowledge of the original bilingual data (implicitly encoded in the trained AT teacher model) and that of the new monolingual data to the NAT student model. Extensive experiments on eight WMT benchmarks over two advanced NAT models show that monolingual KD consistently outperforms the standard KD by improving low-frequency word translation, without introducing any computational cost. Monolingual KD enjoys desirable expandability, which can be further enhanced (when given more computational budget) by combining with the standard KD, a reverse monolingual KD, or enlarging the scale of monolingual data. Extensive analyses demonstrate that these techniques can be used together profitably to further recall the useful information lost in the standard KD. Encouragingly, combining with standard KD, our approach achieves 30.4 and 34.1 BLEU points on the WMT14 English-German and German-English datasets, respectively. Code, data, and models will be released.",/pdf/675a2d34b5c9068d5cc33221a38c66b6c4c193d3.pdf,,,,,anonymous|redistributing_lowfrequency_words_making_the_most_of_monolingual_data_in_nonautoregressive_translation,,,,,,,,,
568,1Sx_XJeJTLh,Self-Supervised Contrastive Learning with Adversarial Perturbations for Robust Pretrained Language Models,['aclweb.org/ACL/ARR/2021/November/Paper1147/Authors'],['Anonymous'],"In this paper, we present an approach to improve the robustness of BERT language models against word substitution-based adversarial attacks by leveraging adversarial perturbations for self-supervised contrastive learning. We create an efficient word-level adversarial attack, and use it to finetune BERT on adversarial examples generated \textit{on the fly} during training.
In contrast with previous works, our method improves model robustness without using any labeled data. Experimental results show that our method improves robustness of BERT against four different word substitution-based adversarial attacks, and combining our method with adversarial training gives higher robustness than adversarial training alone.
As our method improves the robustness of BERT purely with unlabeled data, it opens up the possibility of using large text datasets to train robust language models.
",/pdf/da3697007f796a5c9c140c737997c6a5ad64b4ac.pdf,,,,,anonymous|selfsupervised_contrastive_learning_with_adversarial_perturbations_for_robust_pretrained_language_models,,,,,,,,,
569,mpmtcQTIErU,Voxel-informed Language Grounding,['aclweb.org/ACL/ARR/2021/November/Paper1527/Authors'],['Anonymous'],"Even when applied to 2D images, natural language describes a fundamentally 3D world. 
We present the Voxel-informed Language Grounder (VLG), a language grounding model that leverages 3D geometric information in the form of voxel maps derived from the visual input using a volumetric reconstruction model.  
We show that VLG significantly improves grounding accuracy on SNARE, an object reference game task.
At the time of writing, VLG holds the top place (anonymized) on the SNARE leaderboard, achieving SOTA results with a 1.9% absolute improvement on grounding geometric descriptions and 1.7% overall improvement on all descriptions.  ",/pdf/c9ebbedcb412b457056ae557de87383f811c689c.pdf,,,,,anonymous|voxelinformed_language_grounding,,,,,,,,,
570,-J2Pefs3cw,Textual Entailment with Dynamic Contrastive Learning for Zero-shot NER,['aclweb.org/ACL/ARR/2021/November/Paper1941/Authors'],['Anonymous'],"In this paper, we study the problem of zero-shot NER, which aims at building a Named Entity Recognition (NER) system from scratch. It needs to identify the entities in the given sentences when we have zero token-level annotations for training. Previous works usually use sequential labeling models to solve the NER task and obtain weakly labeled data from entity dictionaries in the zero-shot setting. However, these labeled data are quite noisy since we need the labels for each token and the entity coverage of the dictionaries is limited. Here we propose to formulate the NER task as a Textual Entailment problem and solve the task via Textual Entailment with Dynamic Contrastive Learning (TEDC). TEDC not only alleviates the noisy labeling issue, but also transfers the knowledge from pre-trained textual entailment models. Additionally, the dynamic contrastive learning framework contrasts the entities and non-entities in the same sentence and improves the model's discrimination ability. Experiments on two datasets show that TEDC can achieve state-of-the-art performance on the task of zero-shot NER.",/pdf/bd0786834f6c3497d017e5219fcd87d55265a30d.pdf,,,,,anonymous|textual_entailment_with_dynamic_contrastive_learning_for_zeroshot_ner,,,,,,,,,
571,UiSsgooXn_4,Multi-head or Single-head? An Empirical Comparison for Transformer Training,['aclweb.org/ACL/ARR/2021/November/Paper1707/Authors'],['Anonymous'],"Multi-head attention plays a crucial role in the recent success of Transformer, which leads to consistent performance improvements over conventional attention in various applications. The popular belief is that its effectiveness stems from the ability to attend multiple positions jointly. In this paper, we first demonstrate that jointly attending multiple positions is not a unique feature of multi-head attention, as multi-layer single-head attention also attends multiple positions. Then, we suggest the main advantage of multi-head attention is the training stability, since it has fewer layers than the single-head attention when attending the same number of positions. Meanwhile, we show that, with recent advances in deep learning, we can successfully stabilize the training of the deep single-head Transformer. As the training difficulty is no longer a bottleneck, substantially deeper single-head Transformers achieve consistent performance improvements.",/pdf/80c45ade48a36883ab4956140e759686b00eb868.pdf,,,,,anonymous|multihead_or_singlehead_an_empirical_comparison_for_transformer_training,,,,,,,/attachment/94587fba7bd1796066dcf61771c87454c958e2aa.pdf,https://openreview.net/forum?id=kEay9-ECbb-,/attachment/657a0969b0a511329c5d4473522975e337e2d251.pdf
572,N0b2XDcHLLI,Two-Level Supervised Contrastive Learning for Response Selection in Multi-Turn Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper683/Authors'],['Anonymous'],"Selecting an appropriate response from many candidates given the utterances in a multi-turn dialogue is the key problem for a retrieval-based dialogue system.  Existing work formalizes the task as matching between the utterances and a candidate and uses the cross-entropy loss in learning of the model. This paper applies contrastive learning to the problem by using the supervised contrastive loss.  In this way, the learned representations of positive examples and representations of negative examples can be more distantly separated in the embedding space, and the performance of matching can be enhanced. We further develop a new method for supervised contrastive learning, referred to as two-level supervised contrastive learning, and employ the method in response selection in multi-turn dialogue. Our method exploits two techniques:  sentence token shuffling (STS) and sentence re-ordering (SR) for supervised contrastive learning. Experimental results on three benchmark datasets demonstrate that the proposed method significantly outperforms the contrastive learning baseline and the state-of-the-art methods for the task.",/pdf/1147c12e878bcb87fffbf9be398b6e46607b8ed6.pdf,,,,,anonymous|twolevel_supervised_contrastive_learning_for_response_selection_in_multiturn_dialogue,,,,,,,,,
573,xU6V4SrKd8C,Diversifying Neural Text Generation with Part-of-Speech Guided Softmax and Sampling,['aclweb.org/ACL/ARR/2021/November/Paper790/Authors'],['Anonymous'],"Neural text generation models are likely to suffer from the low-diversity problem. Various decoding strategies and training-based methods have been proposed to promote diversity only by exploiting contextual features, but rarely do they consider incorporating syntactic structure clues. In this work, we propose using linguistic annotation, i.e., part-of-speech (POS), to guide the text generation. In detail, we introduce POS Guided Softmax to explicitly model two posterior probabilities: (i) next-POS, and (ii) next-token from the vocabulary of the target POS. A POS Guided Sampling strategy is further proposed to address the low-diversity problem by enriching the diversity of POS. Extensive experiments and human evaluations demonstrate that, compared with existing state-of-the-art methods, our POS Guided Softmax and Sampling (POSG) can generate more diverse text while maintaining comparable quality.",/pdf/ba174665e562d28f0f56f26213088413af3779e5.pdf,/attachment/386af9d12cd08013fc96aa99f47ed341c96d7008.zip,,,,anonymous|diversifying_neural_text_generation_with_partofspeech_guided_softmax_and_sampling,,,,,,,,,
574,h0lckggpp4X,Zero-Shot Dependency Parsing with Worst-Case Aware Automated Curriculum Learning,['aclweb.org/ACL/ARR/2021/November/Paper288/Authors'],['Anonymous'],"Large multilingual pretrained language models such as mBERT and XLM-RoBERTa have been found to be surprisingly effective for cross-lingual transfer of syntactic parsing models Wu and Dredze (2019), but only between related languages. However, source and training languages are rarely related, when parsing truly low-resource languages. To close this gap, we adopt a method from multi-task learning, which relies on automated curriculum learning, to dynamically optimize for parsing performance on {\em outlier} languages. We show that this approach is significantly better than uniform and size-proportional sampling in the zero-shot setting. ",/pdf/5b63489d9abfb8235a0e38892acd9fddc7815120.pdf,,,,,anonymous|zeroshot_dependency_parsing_with_worstcase_aware_automated_curriculum_learning,,,,,,,,,
575,h9FRrlcs8yo,Cross-Document Temporal Relation Extraction with Temporal Anchoring Events,['aclweb.org/ACL/ARR/2021/November/Paper2409/Authors'],['Anonymous'],"Automatically extracting a timeline on a certain topic from multiple documents has been a challenge in natural language processing, partly due to the difficulty of collecting large amounts of training data. In this work, we collect a dataset for cross-document timeline extraction from online news that gives access to metadata such as hyperlinks and publication dates. The metadata allows us to define a set of important events while linking them to time anchors, which opens the opportunity to scale up data collection. Furthermore, with this set of linked news articles, we propose a method to enhance the inference process of temporal relation prediction, by utilizing a model to link events to a set of anchoring events that are added to the inference program. We report performance of common neural models and show that our method can boost the performance of all baseline models.",/pdf/e4de1831af34dfd59c1634037aec6ae0794f7bef.pdf,,,,,anonymous|crossdocument_temporal_relation_extraction_with_temporal_anchoring_events,,,,,,/attachment/337a52669294a86f41bd46e8d3f92d3d07c956ae.tgz,,,
576,FvmGqUEuh7,Bi-Matching Mechanism to Combat the Long Tail of Word Sense Disambiguation,['aclweb.org/ACL/ARR/2021/November/Paper1107/Authors'],['Anonymous'],"The long tail phenomenon of word sense distribution in linguistics causes the Word Sense Disambiguation (WSD) task to face a serious polarization of word sense distribution, that is, Most Frequent Senses (MFSs) with huge sample sizes and Long Tail Senses (LTSs) with small sample sizes. The single matching mechanism model that does not distinguish between the two senses will cause LTSs to be ignored because LTSs are in a weak position. The few-shot learning method that mainly focuses on LTSs is not conducive to grasping the advantage of easy identification of MFSs. This paper proposes a bi-matching mechanism to serve the WSD model to deal with two kinds of senses in a targeted manner, namely definition matching and collocation feature matching. The experiment is carried out under the evaluation framework of English all-words WSD and is better than the baseline models. Moreover, state-of-the-art performance is achieved through data enhancement.",/pdf/0df958d1ceba3c0f1d12dc7adbc33bcc80a1ed11.pdf,,,,,anonymous|bimatching_mechanism_to_combat_the_long_tail_of_word_sense_disambiguation,,,,,,,,,
577,LNqI1OWu4NI,Neural Dynamic Focused Topic Model,['aclweb.org/ACL/ARR/2021/November/Paper1475/Authors'],['Anonymous'],"Topic models and all their variants analyse text by learning meaningful representations through word co-occurrences. As pointed out by Williamson et al. (2010), such models implicitly assume that the probability of a topic to be active and its proportion within each document are positively correlated. This correlation can be strongly detrimental in the case of documents created over time, simply because recent documents are likely better described by new and hence rare topics.

In this work we leverage recent advances in neural variational inference and present an alternative neural approach to the Focused Topic Model and its dynamic extensions. Indeed, we develop a neural model for topic evolution which exploits a compound Bernoulli structure in order to track the appearances of topics, thereby decoupling their activities from their proportions.
On three different corpora namely, the UN general debates, the collection of NeurIPS papers, and the ACL Anthology dataset, our model outperforms  competing neural variational topic models.",/pdf/2b43d023ee65ab411132c76aa3d1a9b79b490897.pdf,/attachment/d538425b8b250b30cf7e8eb67c8a3c9ac3d68998.zip,,,,anonymous|neural_dynamic_focused_topic_model,,,,,,,,,
578,lcerLgEt6ss,"Evaluating Inclusivity, Equity, and Accessibility of NLP Technology: A Case Study for Indian Languages",['aclweb.org/ACL/ARR/2021/November/Paper1424/Authors'],['Anonymous'],"In order for NLP technology to be widely applicable and useful, it needs to be inclusive of users across the world's languages, equitable, i.e., not unduly biased towards any particular language, and accessible to users, particularly in low-resource settings where compute constraints are common. In this paper, we propose an evaluation paradigm that assesses NLP technologies across all three dimensions, hence quantifying the diversity of users they can serve. While inclusion and accessibility have received attention in recent literature, equity is currently unexplored. We propose to address this gap using the Gini coefficient, a well-established metric used for estimating societal wealth inequality. Using our paradigm, we highlight the distressed state of diversity of current technologies for Indian (IN) languages. Our focus on IN is motivated  by their linguistic diversity and their large, varied speaker population. To improve upon these metrics, we demonstrate the importance of region-specific choices in model building and dataset creation and also propose a novel approach to optimal resource allocation during fine-tuning. Finally, we discuss steps that must be taken to mitigate these biases and call upon the community to incorporate our evaluation paradigm when building linguistically diverse technologies.",/pdf/14c4cdc134a8e1f150c2a3ca0a2f3b64a06bad0f.pdf,,,,,anonymous|evaluating_inclusivity_equity_and_accessibility_of_nlp_technology_a_case_study_for_indian_languages,,,,,,,,,
579,hYB_ozQvbVV,XLM-E: Cross-lingual Language Model Pre-training via ELECTRA,['aclweb.org/ACL/ARR/2021/November/Paper1779/Authors'],['Anonymous'],"In this paper, we introduce ELECTRA-style tasks to cross-lingual language model pre-training. Specifically, we present two pre-training tasks, namely multilingual replaced token detection, and translation replaced token detection. Besides, we pretrain the model, named as XLM-E, on both multilingual and parallel corpora. Our model outperforms the baseline models on various cross-lingual understanding tasks with much less computation cost. Moreover, analysis shows that XLM-E tends to obtain better cross-lingual transferability.",/pdf/b664b40b6ff26caa9f619b0db131305a275e7cdf.pdf,,,,,anonymous|xlme_crosslingual_language_model_pretraining_via_electra,,,,,,,,,
580,USuyAFWEuY,Event-Event Relation Extraction using Probabilistic Box Embedding,['aclweb.org/ACL/ARR/2021/November/Paper566/Authors'],['Anonymous'],"To understand a story with multiple events, it is important to capture the proper relations across these events. However, existing event relation extraction (ERE) framework regards it as a multi-class classification task and do not guarantee any coherence between different relation types, such as anti-symmetry. If a phone line ""died"" after ""storm"", then it is obvious that the ""storm"" happened before the ""died"". Current framework of event relation extraction do not guarantee this coherence and thus enforces it via constraint loss function (Wang et al., 2020). In this work, we propose to modify the underlying ERE model to guarantee coherence by representing each event as a box representation (BERE) without applying explicit constraints. From our experiments, BERE also shows stronger conjunctive constraint satisfaction while performing on par or better in F1 compared to previous models with constraint injection.",/pdf/96d2b3bd854334f6d01f719c9884db30d346cc8f.pdf,,,,,anonymous|eventevent_relation_extraction_using_probabilistic_box_embedding,,,,,,,,,
581,bkagwUGBYU1,Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?,['aclweb.org/ACL/ARR/2021/November/Paper48/Authors'],['Anonymous'],"Despite their recent popularity and well known advantages, dense retrievers still lag behind sparse methods such as BM25 in their ability to reliably match salient phrases and rare entities in the query. It has been argued that this is an inherent limitation of dense models. We disprove this claim by introducing the Salient Phrase Aware Retriever (SPAR), a dense retriever with the lexical matching capacity of a sparse model. In particular, we show that a dense retriever Λ can be trained to imitate a sparse one, and SPAR is built by augmenting a standard dense retriever with Λ. When evaluated on five open-domain question answering datasets and the MS MARCO passage retrieval task, SPAR sets a new state of the art for dense and sparse retrievers and can match or exceed the performance of more complicated dense-sparse hybrid systems.",/pdf/24151ef77e095abe8a6918efed9b8eb50260827d.pdf,,,,,anonymous|salient_phrase_aware_dense_retrieval_can_a_dense_retriever_imitate_a_sparse_one,,,,,,,,,
582,qrCCfJ6uR1m,Towards Improving Topic Models with the BERT-based Neural Topic Encoder,['aclweb.org/ACL/ARR/2021/November/Paper2899/Authors'],['Anonymous'],"Neural Topic Models (NTMs) have been popular for mining a set of topics from a collection of corpora. Recently, there is an emerging direction of combining NTMs with pre-trained language models such as BERT, which aims to use the contextual information to of BERT to help train better NTMs.
However, existing works in this direction either use the contextual information of pre-trained language models as the input of NTMs or align the outputs of the two kinds of models.
In this paper, we study how to build deeper interactions between NTMs and pre-trained language and propose a BERT-based neural topic encoder, which deeply integrates with the transformer layers of BERT. Our proposed encoder encodes both the BoW data and the sequence of words of a document, which can be complementary to each other for learning a better topic distribution for the document.
The proposed encoder is a better alternative to the ones used in existing NTMs.
Thanks to the in-depth integration with BERT, extensive experiments show that the proposed model achieves the state-of-art performances the comparisons with many advanced models.",/pdf/8f461170a8c3c0926c89460511885228cc203f65.pdf,,,,,anonymous|towards_improving_topic_models_with_the_bertbased_neural_topic_encoder,,,,,,,,,
583,mMECu_poAs,Moving the Eiffel Tower to ROME: Tracing and Editing Facts in GPT,['aclweb.org/ACL/ARR/2021/November/Paper2434/Authors'],['Anonymous'],"We investigate the mechanisms underlying factual knowledge recall in auto-regressive transformer language models. To this end, we develop a method for identifying neuron activations that are capable of altering a model's factual predictions. Within GPT-2, this reveals two distinct sets of neurons that we hypothesize correspond to knowing an abstract fact and saying a concrete word, respectively. Based on this insight, we propose ROME, a simple and efficient rank-one model editing method for rewriting abstract facts in auto-regressive language models. For validation, we introduce CounterFact, a dataset of over twenty thousand rewritable facts, as well as tools to facilitate sensitive measurements of edit quality. Compared to previously-published knowledge editing methods, ROME achieves superior generalization and specificity.",/pdf/2c2c6364c0964e7ef93cb8a499739662318a1b86.pdf,,,,,anonymous|moving_the_eiffel_tower_to_rome_tracing_and_editing_facts_in_gpt,,,,,,,,,
584,2D3ibn1aeUS,Nested Named Entity Recognition as Latent Lexicalized Constituency Parsing,['aclweb.org/ACL/ARR/2021/November/Paper2476/Authors'],['Anonymous'],"Nested named entity recognition (NER) has been receiving increasing attention. Recently, Fu et al. (2020) adapt a span-based constituency parser to tackle nested NER. They treat nested entities as partially-observed constituency trees and propose the masked inside algorithm for partial marginalization. However, their method cannot leverage entity heads, which have been shown useful in entity mention detection and entity typing. In this work, we resort to more expressive structures, lexicalized constituency trees in which constituents are annotated by headwords, to model nested entities. We leverage the Eisner-Satta algorithm to perform partial marginalization and inference efficiently.
In addition, we propose to use (1) a two-stage strategy (2) a head regularization loss and (3) a head-aware labeling loss in order to enhance the performance. We make a thorough ablation study to investigate the functionality of each component. Experimentally, our method achieves the state-of-the-art performance on ACE2004, ACE2005 and NNE, and competitive performance on GENIA, and meanwhile has a fast inference speed.",/pdf/e134381a32ca822e70b118b940fa243ced3c54eb.pdf,,,,,anonymous|nested_named_entity_recognition_as_latent_lexicalized_constituency_parsing,,,,,,,,,
585,RhhZo7CpksR,$AmbiPun$ : Generating Humorous Puns with Ambiguous Context,['aclweb.org/ACL/ARR/2021/November/Paper2145/Authors'],['Anonymous'],"Computational humor has garnered interest of the natural language processing community due to its wide applications to real world scenarios. One way to express humor is via the use of puns. A homographic pun plays on words that are spelled the same way but have different meanings. In this paper, we propose a simple yet effective way to generate pun sentences that does not require any pun sentences to train on. Our approach is inspired by humor theories that ambiguity comes from the context rather than the pun word itself. Given a pair of definitions of a pun word, our model first produces a list of related concepts through a reverse dictionary. We then utilize one-shot GPT3 to generate context words, and then generate punning sentences that incorporate context words from both worlds.
We also investigate how the position of a pun word appearing in the sentence will influence the generated results. We compare our proposed $\textsc{AmbiPun}$ with well crafted baselines. Human evaluation shows that our method successfully generates pun 52% of the time, outperforming the the state-of-the-art model by a large margin. ",/pdf/b5c51dbb12108292c17c0ea078e44e351c277867.pdf,/attachment/19de1455743af9f1db8801f39e74e8a67145740c.zip,,,,anonymous|ambipun_generating_humorous_puns_with_ambiguous_context,,,,,,,,,
586,JWVB2_QbT8W,Unsupervised multiple-choice question generation for out-of-domain Q\&A fine-tuning,['aclweb.org/ACL/ARR/2021/November/Paper1256/Authors'],['Anonymous'],"Pre-trained models have shown very good performances on a number of question answering benchmarks especially when fine-tuned on multiple question answering datasets at once. In this work, we propose an approach for generating a fine-tuning dataset thanks to a rule-based algorithm that generates questions and answers from unannotated sentences. We show that the state-of-the-art model UnifiedQA can greatly benefit from such a system on a multiple-choice benchmark about physics, biology and chemistry it has never been trained on. We further show that improved performances may be obtained by selecting the most challenging distractors (wrong answers), with a dedicated ranker based on a pretrained RoBERTa model.",/pdf/b34d9d7b1113847600dfa20d4ac4ccd168982bf3.pdf,/attachment/b61d942ec71138f899e42322d9da2568e545fa94.zip,,,,anonymous|unsupervised_multiplechoice_question_generation_for_outofdomain_q\a_finetuning,,,,,,/attachment/03999877c494603a4c6a80b3113bbf1499b2b5c0.zip,,,
587,SFVLa0a4rNg,"Relevance in Dialogue: Is Less More? An Empirical Comparison of Existing Metrics, and a Novel Simple Metric",['aclweb.org/ACL/ARR/2021/November/Paper1733/Authors'],['Anonymous'],"In this work, we evaluate various existing dialogue relevance metrics, find strong dependencies on the dataset, often with poor correlation with human scores of relevance, and propose modifications to reduce data requirements and domain sensitivity while improving correlation. With these changes, our metric achieves state-of-the-art performance on the HUMOD dataset (Merdivan et al., 2020) while reducing measured sensitivity to dataset by 50%. We achieve this without fine-tuning, using only 3750 unannotated human dialogues and a single negative example. Despite these limitations, we demonstrate competitive performance on four datasets from different domains. Our code including our metric and experiments is open sourced.",/pdf/ee383721df9668b82babcbb472128c24d4eeb26d.pdf,/attachment/1ab522f4fcfd8bf18870764dd69650ad054c8b53.zip,,,,anonymous|relevance_in_dialogue_is_less_more_an_empirical_comparison_of_existing_metrics_and_a_novel_simple_metric,,,,,,,/attachment/4be176d75c66714ec9672e2cf72ec654a8b908c1.pdf,https://openreview.net/forum?id=aOl-UPZeSwt,/attachment/2f80ee04560fa296181e9ff33b059f4c66cfca46.pdf
588,de9ufgUZFox,Graph-based Fine-grained Multimodal Attention Mechanism for Sentiment Analysis,['aclweb.org/ACL/ARR/2021/November/Paper369/Authors'],['Anonymous'],"Multimodal sentiment analysis is a popular research area in natural language processing. Mainstream multimodal learning models barely consider that the visual and acoustic behaviors often have a much higher temporal frequency than words. Therefore, these models lack the representation capability to accurately model multimodal interactions. In this paper, we propose an attachment called Graph-based Fine-grained Multimodal Attention Mechanism (GFMAM), which can utilize the multimodal information from different subspaces to achieve accurate multimodal interactions. Firstly, the attachment further splits the information of every modality into multiple subspaces.
Then, the fine-grained multimodal information from different subspaces is converted into multimodal interaction graphs dominant by the language modality. The multimodal interaction graph can capture significant interactions among multiple modalities at the subspace level.
Finally, the information of nonverbal modalities is additionally added to compensate for the loss of continuity caused by the splitting operation. Embedding GFMAM into BERT, we propose a new model called GFMAM-BERT that can directly accept nonverbal modalities in addition to language modality. We conducted experiments on both publicly available multimodal sentiment analysis datasets CMU-MOSI and CMU-MOSEI. The experiment results demonstrate that GFMAM-BERT exceeds the state-of-the-art models. Moreover, the proposed model outperforms humans on most metrics on the CMU-MOSI dataset.",/pdf/50e2535b739ec27cdf20de075a026a760c6af801.pdf,/attachment/c69c9b73dd84d582d479f072fc10dfeba78c6e39.zip,,,,anonymous|graphbased_finegrained_multimodal_attention_mechanism_for_sentiment_analysis,,,,,,/attachment/3e469f1d9490ae082968348d69587ee55987e7d5.zip,,,
589,nuocH643Ezt,Morphology Informed Selections for Subword Vocabulary Size,['aclweb.org/ACL/ARR/2021/November/Paper1689/Authors'],['Anonymous'],"Currently, guidance around selection of an optimal or appropriate subword vocabulary size is incomplete and confusing at best. Using a measure of subword-morpheme overlap, our analysis shows that one can find a ""sweet spot"" for a morphology informed subword vocabulary size. This sweet spot exhibits some variation with respect to text complexity and the morphological characteristics of a language. However, it is relatively constant with respect to corpus size.",/pdf/b3b0dd68a2205ab9e04ba6b9fa901776302b41a9.pdf,,,,,anonymous|morphology_informed_selections_for_subword_vocabulary_size,,,,,,,,,
590,JegLdW0zORF,MoFE: Mixture of Factual Experts for Controlling Hallucinations in Abstractive Summarization,['aclweb.org/ACL/ARR/2021/November/Paper826/Authors'],['Anonymous'],"Neural abstractive summarization models are susceptible to generating factually inconsistent content, a phenomenon known as hallucination. This limits the usability and adoption of these systems in real-world applications. To reduce the presence of hallucination, we propose the Mixture of Factual Experts (MoFE) model, which combines multiple summarization experts that each target a specific type of factual error. We construct MoFE by combining the experts using weights and logits ensembling strategies and find that the MoFE provides a modular approach to control different factual errors while maintaining performance on standard ROUGE metrics.",/pdf/c417ac29804fa09e5e2df4f7f1c6024274a836a6.pdf,,,,,anonymous|mofe_mixture_of_factual_experts_for_controlling_hallucinations_in_abstractive_summarization,,,,,,,,,
591,NEvmCSnnj63,Achieving Conversational Goals with Unsupervised Post-hoc Knowledge Injection,['aclweb.org/ACL/ARR/2021/November/Paper1854/Authors'],['Anonymous'],"A limitation of current neural dialog models is that they tend to suffer from a lack of specificity and informativeness in generated responses, primarily due to dependence on training data that covers a limited variety of scenarios and conveys limited knowledge. One way to alleviate this issue is to extract relevant knowledge from external sources at decoding time and incorporate it into the dialog response. In this paper, we propose a post-hoc knowledge-injection technique where we first retrieve a diverse set of relevant knowledge snippets conditioned on both the dialog history and an initial response from an existing dialog model. We construct multiple candidate responses, individually injecting each retrieved snippet into the initial response using a gradient-based decoding method, and then select the final response with an unsupervised ranking step. Our experiments in goal-oriented and knowledge-grounded dialog settings demonstrate that human annotators judge the outputs from the proposed method to be more engaging and informative compared to responses from prior dialog systems. We further show that knowledge-augmentation promotes success in achieving conversational goals in both experimental settings.",/pdf/a874198a838e6e2baa35d71553001baea255b9f1.pdf,/attachment/b792ce19f3177fd4347602da935bd1a22647426c.zip,,,,anonymous|achieving_conversational_goals_with_unsupervised_posthoc_knowledge_injection,,,,,,,,,
592,PZIiXj2FcAP,"Accurate, yet Inconsistent? Consistency Analysis on Language Models",['aclweb.org/ACL/ARR/2021/November/Paper807/Authors'],['Anonymous'],"Consistency, which refers to generating the same predictions for semantically similar contexts, is highly desirable for a sound language model. Although recent pre-trained language models (PLMs) deliver an outstanding performance in various downstream tasks,  they should also exhibit a  consistent behaviour, given that the models truly understand language. In this paper, we propose a simple framework, called consistency analysis on language models (CALM), to evaluate a model's lower-bound consistency ability. Via experiments, we confirm that current PLMs are prone to generate inconsistent predictions even for semantically identical inputs with high confidence. We also observe that multi-task training is of benefit to improve consistency, increasing the value by 17% on average. ",/pdf/93407d40eb3a1345da6539b0f50a9df85561e541.pdf,/attachment/941d1882200139fa62219f88fe40adf6a853d070.zip,,,,anonymous|accurate_yet_inconsistent_consistency_analysis_on_language_models,,,,,,,,,
593,r6z-A8wyD-W,Quantum-inspired Representation for Long-tail Senses of Word Sense Disambiguation,['aclweb.org/ACL/ARR/2021/November/Paper1108/Authors'],['Anonymous'],"Data imbalance, also known as the long-tailed distribution of data, is an important challenge for data-driven models. Due to the long tail phenomenon of word sense distribution in linguistics, it is difficult to learn accurate representations for Long-Tail Senses (LTSs) in Word Sense Disambiguation (WSD) tasks. Without data augmentation, exploring representation methods that do not rely on large sample sizes is an important means to combat the long tail. In this paper, inspired by the superposition state in quantum mechanics, a representation method in Hilbert space is proposed to reduce the dependence on large sample sizes. We theoretically prove the correctness of the method, verify its effectiveness on the WSD task, and achieve state-of-the-art performance.",/pdf/7f4fed6864e98f79658137988b9074e1461c7d5f.pdf,,,,,anonymous|quantuminspired_representation_for_longtail_senses_of_word_sense_disambiguation,,,,,,,,,
594,Sx5wGWcuETA,Towards Coding Social Science Datasets with Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2050/Authors'],['Anonymous'],"Researchers often rely on humans to code (label, annotate, etc.) large sets of texts. This is a highly variable task and requires a great deal of time and resources. Efforts to automate this process have achieved human-level accuracies in some cases, but often rely on thousands of hand-labeled training examples, which makes them inapplicable to small-scale research studies and still costly for large ones.  At the same time, it is well known that language models can classify text; in this work, we use OpenAI's GPT-3 as a synthetic coder, and explore what classic methodologies and metrics (such as intercoder reliability) look like in this new context.  We find that GPT-3 is able to match the performance of typical human coders and frequently outperforms humans in terms of intercoder agreement across a variety of social science tasks, suggesting that language models could be a useful tool to the social sciences.",/pdf/51e91c2497e27f2dc6725c61b1ee37dc2d735b6c.pdf,,,,,anonymous|towards_coding_social_science_datasets_with_language_models,,,,,,,,,
595,HQ1M0wv2RrL,Utterance Rewriting with Contrastive Learning in Multi-turn Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper704/Authors'],['Anonymous'],"Context modeling plays a significant role in building multi-turn dialogue systems. In order to make full use of context information, systems can use Incomplete Utterance Rewriting(IUR) methods to simplify the multi-turn dialogue into single-turn by merging current utterance and context information into a self-contained utterance. However, previous approaches ignore the intent consistency between the original query and rewritten query. The detection of omitted or coreferred locations in the original query can be further improved. In this paper, we introduce contrastive learning and multi-task learning to jointly model the problem. Our method benefits from carefully designed self-supervised objectives, which act as auxiliary tasks to capture semantics at both sentence-level and token-level. The experiments show that our proposed model achieves state-of-the-art performance on several public datasets.",/pdf/956539f501e1520bdcbf291b0bc35c5922e0e6fb.pdf,,,,,anonymous|utterance_rewriting_with_contrastive_learning_in_multiturn_dialogue,,,,,,,/attachment/e38392491ca8431fd491138e9441dc2376398199.pdf,https://openreview.net/forum?id=4VzVcbbF9Hs,
596,8LQwB0FkR0X,AutoTriggER: Named Entity Recognition with Auxiliary Trigger Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1698/Authors'],['Anonymous'],"Deep neural models for low-resource named entity recognition (NER) have shown impressive results by leveraging distant super-vision or other meta-level information (e.g. explanation). However, the costs of acquiring such additional information are generally prohibitive, especially in domains where existing resources (e.g. databases to be used for distant supervision) may not exist. In this paper, we present a novel two-stage framework (AutoTriggER) to improve NER performance by automatically generating and leveraging ""entity triggers"" which are essentially human-readable clues in the text that can help guide the model to make better decisions. Thus, the framework is able to both create and leverage auxiliary supervision by itself. Through experiments on three well-studied NER datasets, we show that our automatically extracted triggers are well-matched to human triggers, and AutoTriggER improves performance over a RoBERTa-CRFarchitecture by nearly 0.5 F1 points on average and much more in a low resource setting.",/pdf/5652cfb41ddcf7df51d8d1e78e06dd455c87f61a.pdf,/attachment/57d3f55fded48e0ab8195f01f80e0418817010cd.zip,,,,anonymous|autotrigger_named_entity_recognition_with_auxiliary_trigger_extraction,,,,,,,,,
597,1GZzXcmivZ4,Non-Parametric Domain Adaptation for End-to-End Speech Translation,['aclweb.org/ACL/ARR/2021/November/Paper828/Authors'],['Anonymous'],"The end-to-end speech translation (E2E-ST) has received increasing attention due to the potential of its less error propagation, lower latency, and fewer parameters. However, the effectiveness of neural-based approaches to this task is severely limited by the available training corpus, especially for domain adaptation where in-domain triplet training data is scarce or nonexistent. In this paper, we propose a novel non-parametric method that leverages domain-specific text translation corpus to achieve domain adaptation for the E2E-ST system. To this end, we first incorporate an additional encoder into the pre-trained E2E-ST model to realize text translation modeling and then unify the decoder's output representation for text and speech translation tasks by reducing the correspondent representation mismatch in available triplet training data. During domain adaptation, a $k$-nearest-neighbor ($k$NN) classifier is introduced to produce the final translation distribution using the external datastore built by the domain-specific text translation corpus, while the universal output representation is adopted to perform a similarity search. Experiments on the Europarl-ST benchmark demonstrate that when in-domain text translation data is used only, our proposed approach significantly improves the baseline by 12.82 BLEU on average in all translation directions.",/pdf/0c7ecd4dfd57e3316be86d3b88e2afd75a26c399.pdf,,,,,anonymous|nonparametric_domain_adaptation_for_endtoend_speech_translation,,,,,,,,,
598,cnMI-mshhv5,Revisiting Softmax for Uncertainty Approximation in Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper2197/Authors'],['Anonymous'],"Uncertainty approximation in text classification is an important area with applications in domain adaptation and interpretability. The most widely used uncertainty approximation method is Monte Carlo Dropout, which is computationally expensive as it requires multiple forward passes through the model. A cheaper alternative is to simply use a softmax to estimate model uncertainty. However, prior work has indicated that the softmax can generate overconfident uncertainty estimates and can thus be tricked into producing incorrect predictions. In this paper, we perform a thorough empirical analysis of both methods on three datasets with two base neural architectures in order to reveal insight into the trade-offs between the two. We compare the methods' uncertainty approximations and downstream text classification performance, while weighing their performance against their computational complexity as a cost-benefit analysis. We find that, while Monte Carlo produces the best uncertainty approximations, using a simple softmax leads to competitive F1 results for text classification at a much lower computational cost, suggesting that softmax can in fact be a sufficient uncertainty estimate when computational resources are a concern.",/pdf/9c5b3d5d4fb788eed3c954b6f44e8e333d4e63f2.pdf,/attachment/a562992e33bf427531c55acffdf6828ee669eaad.zip,,,,anonymous|revisiting_softmax_for_uncertainty_approximation_in_text_classification,,,,,,,,,
599,DX8E-03pBrV,Listen to Both Sides and be Enlightened! -- Hierarchical Modality Fusion Network for  Entity and Relation Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1016/Authors'],['Anonymous'],"Multimodal named entity recognition and relation extraction (MNER and MRE) is a fundamental and crucial branch in multimodal learning. 
However, existing approaches for MNER and MRE mainly suffer from 1)  error sensitivity when images contain irrelevant concepts not mentioned in texts; and 2) large modality gap between image and text features, especially hierarchical visual features. 
To deal with these issues, we propose a novel Hierarchical Modality fusion NeTwork (HMNeT) for visual-enhanced entity and relation extraction, aim to reduce the modality gap and achieve more effective and robust performance. Specifically, we innovatively leverage hierarchical pyramidal visual features to conduct multi-layer internal integration in Transformer. We further present a dynamic gated aggregation strategy to decide modality integration according to different images. Extensive  experiments on three benchmark datasets demonstrate the effectiveness of our method, and achieve  state-of-the-art performance.",/pdf/48afcc705b8996a8d32d1f6f5205d554f528cdca.pdf,/attachment/248003c3e57f80caba5eb08de94a289913823ae3.zip,,,,anonymous|listen_to_both_sides_and_be_enlightened_hierarchical_modality_fusion_network_for_entity_and_relation_extraction,,,,,,,,,
600,7uE-SSLTgxw,MarkBERT: Marking Word Boundaries Improves Chinese BERT,['aclweb.org/ACL/ARR/2021/November/Paper122/Authors'],['Anonymous'],"We present a Chinese BERT model dubbed MarkBERT that uses word information in this work.
Existing word-based BERT models regard words as basic units, however,
due to the vocabulary limit of BERT, they only cover high-frequency words and fall back to character level when encountering out-of-vocabulary (OOV) words.
Different from existing works, MarkBERT keeps the vocabulary being Chinese characters and inserts boundary markers between contiguous words. 
Such design enables the model to handle any words in the same way, no matter they are OOV words or not.
Besides, our model has two additional benefits:
first, it is convenient to add word-level learning objectives over markers, which is complementary to traditional character and sentence-level pretraining tasks;
second, it can easily incorporate richer semantics such as POS tags of words by replacing generic markers with POS tag-specific markers.
MarkBERT pushes the state-of-the-art of Chinese named entity recognition from 95.4\% to 96.5\% on the MSRA dataset and from 82.8\% to 84.2\% on the OntoNotes dataset, respectively.
Compared to previous word-based BERT models, MarkBERT achieves better accuracy on text classification, keyword recognition, and semantic similarity tasks.\footnote{All the codes and models will be made publicly available at \url{https://github.com/}}",/pdf/fdcf307c8e6957189d4b49669d2b2840a45022ac.pdf,,,,,anonymous|markbert_marking_word_boundaries_improves_chinese_bert,,,,,,/attachment/ce95b95a29e25c69b5619c743a4a882998c61707.zip,,,
601,8kD13-NXpZ,ReCo: Reliable Multi-hop Causal Reasoning via Structural Causal Recurrent Unit,['aclweb.org/ACL/ARR/2021/November/Paper1934/Authors'],['Anonymous'],"Multi-hop causal reasoning (MCR) is an essential ability for many decision-making AI systems, which requires the model to perform multi-step causal reasoning by connecting causal event pairs. However, MCR still suffers from two main transitive problems of threshold effect and scene drift. In this paper, we propose a novel reliable multi-hop causal reasoning framework (ReCo), which introduces a structural causal recurrent unit (SCRU) to model the causal reasoning chains. In SCRU, we devise two control mechanisms to solve the threshold effect and scene drift problems, and implement a logical constraint for better optimization of ReCo. Experiments show that ReCo achieves state-of-the-art (SOTA) results on both Chinese and English multi-hop causal reasoning datasets. Finally, BERT obtains the best results on four downstream causal-related tasks by injecting reliable causal knowledge distilled from ReCo.",/pdf/4897806e8bc28899b3e21417835beffa6b6bf8ce.pdf,/attachment/394bbfb459b0620be4f2343ba2463e9b833d9cd0.zip,,,,anonymous|reco_reliable_multihop_causal_reasoning_via_structural_causal_recurrent_unit,,,,,,/attachment/99a88372fbe88553bb2b9ac207b696a83aa4f60e.zip,,,
602,SpwEk_yswpS,Comparative Opinion Summarization via Collaborative Decoding,['aclweb.org/ACL/ARR/2021/November/Paper1355/Authors'],['Anonymous'],"Opinion summarization focuses on generating summaries that reflect popular opinions of multiple reviews for a single entity (e.g., a hotel or a product.) While generated summaries offer general and concise information about a particular entity, the information may be insufficient to help the user compare multiple entities. Thus, the user may still struggle with the question ``Which one should I pick?'' 
In this paper, we propose a {\em comparative opinion summarization} task, which is to generate two contrastive summaries and one common summary from two given sets of reviews from different entities. We develop a comparative summarization framework CoCoSum, which consists of two few-shot summarization models that jointly generate contrastive and common summaries.
Experimental results on a newly created benchmark CoCoTrip show that CoCoSum can produce higher-quality contrastive and common summaries than state-of-the-art opinion summarization models.",/pdf/46616a22538fa91c2f2f8a1734c0ea5b84285ba3.pdf,,,,,anonymous|comparative_opinion_summarization_via_collaborative_decoding,,,,,,,,,
603,IbQJVkI-96I,Constructing Phrase-level Semantic Labels to Form Multi-GrainedSupervision for Image-Text Retrieval,['aclweb.org/ACL/ARR/2021/November/Paper2061/Authors'],['Anonymous'],"Existing research for image text retrieval mainly relies on sentence-level supervision to distinguish matched and mismatched sentences for a query image. However, semantic mismatch between an image and sentences usually happens in finer grain, i.e., phrase level. In this paper, we explore to introduce additional phrase-level supervision for the better identification of mismatched units in the text. In practice, multi-grained semantic labels are automatically constructed for a query image in both sentence-level and phrase-level. We construct text scene graphs for the matched sentences and extract entities and triples as the phrase-level labels. In order to integrate both supervision of sentence-level and phrase-level, we propose Semantic Structure Aware Multimodal Transformer (SSAMT) for multi-modal representation learning. Inside the SSAMT, we utilize different kinds of attention mechanisms to enforce interactions of multi-grain semantic units in both sides of vision and language. For the training, we propose multi-scale matching losses from both global and local perspectives, and penalize mismatched phrases. Experimental results on MS-COCO and Flickr30K show the effectiveness of our approach compared to some state-of-the-art models. ",/pdf/688ea4c8b50973cb86b9b99fb54c15caf393882a.pdf,,,,,anonymous|constructing_phraselevel_semantic_labels_to_form_multigrainedsupervision_for_imagetext_retrieval,,,,,,,,,
604,gu5N_MqOzHp,BERT is Robust! A Case Against Synonym-Based Adversarial Examples in Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper665/Authors'],['Anonymous'],"In this work, we investigate the robustness of BERT using four word substitution-based attacks. We combine a human evaluation of individual word substitutions and a probabilistic analysis to show that between 96% and 99% of the analyzed attacks do not preserve semantics, indicating that their success is mainly based on feeding poor data to the model. To further confirm that, we introduce an efficient data augmentation procedure and show that many successful attacks can be prevented by including data similar to adversarial examples during training. Compared to traditional adversarial training, our data augmentation procedure requires 30x less computation time per epoch, while achieving better performance on two out of three datasets. We introduce an additional post-processing step that reduces the success rates of state-of-the-art attacks below 4%, 5%, and 8% on the three considered datasets. Finally, by looking at constraints for word substitutions that better preserve the semantics, we conclude that BERT is considerably more robust than previous research suggests. 
",/pdf/71c99181ea0e1a59a1034d6a277800b71b5d19bd.pdf,,,,,anonymous|bert_is_robust_a_case_against_synonymbased_adversarial_examples_in_text_classification,,,,,,,,,
605,8BUje8JD-_Q,A Comparative Study of Faithfulness Metrics for Model Interpretability Methods,['aclweb.org/ACL/ARR/2021/November/Paper893/Authors'],['Anonymous'],"Interpretable methods to reveal the internal reasoning processes behind machine learning models have attracted increasing attention in recent years. To quantify the extent to which the identified interpretations truly reflect the intrinsic decision-making mechanisms, various faithfulness evaluation metrics have been proposed. However, we find that different faithfulness metrics show conflicting preferences when comparing different interpretations. Motivated by this observation, we aim to conduct a comprehensive and comparative study of the widely adopted faithfulness metrics. In particular, we introduce two assessment dimensions, namely diagnosticity and complexity. Diagnosticity refers to the degree to which the faithfulness metric favors relatively faithful interpretations over randomly generated ones, and complexity is measured by the average number of model forward passes. According to the experimental results, we find that sufficiency and comprehensiveness metrics have higher diagnosticity and lower complexity than the other faithfulness metrics.",/pdf/ed09527851b1da75cadec31051ed90b9362bb42f.pdf,,,,,anonymous|a_comparative_study_of_faithfulness_metrics_for_model_interpretability_methods,,,,,,,,,
606,4zUWJyt0Ja4,ArchivalQA: A Large-scale Benchmark Dataset for Open Domain Question Answering over Archival News Collections,['aclweb.org/ACL/ARR/2021/November/Paper2749/Authors'],['Anonymous'],"In the last few years, open-domain question answering (ODQA) has advanced rapidly due to the development of deep learning techniques and the availability of large-scale QA datasets. However, the current datasets are essentially designed for synchronic document collections (e.g., Wikipedia). Temporal news collections such as long-term news archives spanning several decades, are rarely used in training the models despite they are quite valuable for our society. To foster the research in the field of ODQA on such historical collections, we present ArchivalQA, a large question answering dataset consisting of 532,444 question-answer pairs which is designed for temporal news QA. 
We divide our dataset into four subparts based on the question difficulty levels and the containment of temporal expressions, which we believe are useful for training and testing ODQA systems characterized by different strengths and abilities. The novel QA dataset-constructing framework that we introduce can be also applied to create datasets over other types of collections.",/pdf/95d4658ef8cfb448c3585e48388bb961578adc96.pdf,,,,,anonymous|archivalqa_a_largescale_benchmark_dataset_for_open_domain_question_answering_over_archival_news_collections,,,,,,/attachment/cebf0db8cf4a018b83735eb4f14b2cf7c8948604.zip,/attachment/c0ae6f7a803c06054f9abff3f34535d2eab60424.pdf,https://openreview.net/group?id=aclweb.org/ACL/ARR/2021/September,/attachment/f04da8353e9b103363a29241544109ed4c796457.pdf
607,HZRUtYo7x9R,Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks,['aclweb.org/ACL/ARR/2021/November/Paper291/Authors'],['Anonymous'],"Backdoor attacks are a kind of emergent security threat in deep learning. After injected into a backdoor, a deep neural model will behave normally on standard inputs but give adversary-specified predictions once the input contains specific backdoor triggers. Current textual backdoor attacks have poor attack performance in some tough situations. In this paper, we find two simple tricks that can make existing textual backdoor attacks much more harmful. The first trick is to add an extra training task to distinguish poisoned and clean data during the training of the victim model, and the second one is to use all the clean training data rather than remove the original clean data corresponding to the poisoned data. These two tricks are universally applicable to different attack models.
We conduct experiments in three tough situations including clean data fine-tuning, low-poisoning-rate, and label-consistent attacks. Experimental results show that the two tricks can significantly improve attack performance. This paper exhibits the great potential harmfulness of backdoor attacks. All the code and data will be made public to facilitate further research.",/pdf/3ece454d095f520df464a443f447d691ef0dd4a1.pdf,/attachment/b814849352534a91ee1fda871c690ed907f6a568.zip,,,,anonymous|textual_backdoor_attacks_can_be_more_harmful_via_two_simple_tricks,,,,,,/attachment/ea780db06b662229a746864271d310be185995d6.zip,,,
608,H8L5q6lcWqM,Divide and Rule: Effective Pre-Training for Context-Aware Multi-Encoder Translation Models,['aclweb.org/ACL/ARR/2021/November/Paper1270/Authors'],['Anonymous'],"Multi-encoder models are a broad family of context-aware neural machine translation systems that aims to improve translation quality by encoding document-level contextual information alongside the current sentence. The context encoding is undertaken by contextual parameters, trained on document-level data. In this work, we discuss the difficulty of training these parameters effectively, due to the sparsity of the words in need of context (i.e., the training signal), and their relevant context. We propose to pre-train the contextual parameters over split sentence pairs, which makes an efficient use of the available data for two reasons. Firstly, it increases the contextual training signal by breaking intra-sentential syntactic relations, and thus pushing the model to search the context for disambiguating clues more frequently. Secondly, it eases the retrieval of relevant context, since context segments become shorter. We propose four different splitting methods, and evaluate our approach with BLEU and contrastive test sets. Results show that it consistently improves learning of contextual parameters, both in low and high resource settings.",/pdf/c147fa973d2c12130f623562f09bdadfea5bbfac.pdf,/attachment/ede661ec14ca4e0e5ca1e39d973c48fdca24e55a.zip,,,,anonymous|divide_and_rule_effective_pretraining_for_contextaware_multiencoder_translation_models,,,,,,,/attachment/a4e71d33591035d184f95f69b18dca242c2ced38.pdf,https://openreview.net/forum?id=dYg10Kalyc3,/attachment/71ad020f67c6997d17cf7ac07ef1388ff07a1f5c.pdf
609,IQWOVFz1Bs,Generic Dependency Modeling in Multi-Party Conversation,['aclweb.org/ACL/ARR/2021/November/Paper2773/Authors'],['Anonymous'],"Modeling the dependency between utterances in a multi-party conversation facilitates the understanding of conversation more precisely and holistically. In this paper, we propose a simple and generic framework for this purpose, in which the dependency is built on discourse parsing of utterances. Particularly, we present two approaches to encoding the dependency, namely absolute dependency encoding and relative dependency encoding, and combine them in Transformers by modifying the computation of self-attention. To enhance the understanding of utterance dependency, we further introduce a span distance prediction pre-training task for the proposed model. Experimental results on four multi-party conversation benchmarks for different tasks show that this model successfully boosts the generic performance of Transformer-based language models. Systematic studies are conducted to investigate why utterance dependencies are essential for multi-party conversation tasks and how they are learned in a simple and effective framework.",/pdf/b559d4ad5ef7731e64282384faca2a0aac25a347.pdf,,,,,anonymous|generic_dependency_modeling_in_multiparty_conversation,,,,,,,,,
610,RFVK6x4NBhD,Contrastive Demonstration Tuning for Pre-trained Language Models,['aclweb.org/ACL/ARR/2021/November/Paper140/Authors'],['Anonymous'],"Pretrained language models can be effectively stimulated by textual prompts or demonstrations, especially in low-data scenarios. Recent works have focused on automatically searching discrete or continuous prompts or optimized verbalizers, yet studies for the demonstration are still limited. Concretely, the demonstration examples are crucial for an excellent final performance of prompt-tuning. In this paper, we propose a novel pluggable, extensible, and efficient approach named contrastive demonstration tuning, which is free of demonstration sampling. Furthermore, the proposed approach can be: (i) Plugged to any previous prompt-tuning approaches; (ii) Extended to widespread classification tasks with a large number of categories. Experimental results on 16 datasets illustrate that our method integrated with previous approaches LM-BFF and P-tuning can yield better performance.",/pdf/6d120a32342c7dd26415b48bc9b0ad17c83185e8.pdf,/attachment/a3c8d753a6ab447ae2da4a024bb92985c7bacc98.zip,,,,anonymous|contrastive_demonstration_tuning_for_pretrained_language_models,,,,,,,,,
611,SrW4CWx3ox5,On Spoken Language Understanding Systems for Low Resourced Languages,['aclweb.org/ACL/ARR/2021/November/Paper337/Authors'],['Anonymous'],"Spoken dialog systems are slowly becoming and integral part of the human experience due to their various advantages over textual interfaces. Spoken language understanding (SLU) systems are fundamental building blocks of spoken dialog systems. But creating SLU systems for low resourced languages is still a challenge. In a large number of low resourced settings we don't have access to enough data to build automatic speech recognition (ASR) technologies, which are fundamental to any SLU system. Also, ASR based SLU systems do not generalize to unwritten languages. In this paper, we present a series of experiments to explore an extremely low resourced setting - something we refer to as a true k-shot setting, where we perform intent classification with systems trained on different values of k. We test our system on English and Flemish and find that even in such granular settings and no language specific ASR technology, we can create SLU systems that can be deployed in the real world. ",/pdf/47195ee2391434021f8cc4e7587df06f76d46e90.pdf,/attachment/409c7d3d8b713621fdb174ddba96823c06affaad.zip,,,,anonymous|on_spoken_language_understanding_systems_for_low_resourced_languages,,,,,,,,,
612,ecHLq1bWFvk,Can Pre-trained Language Models Interpret Similes as Smart as Human?,['aclweb.org/ACL/ARR/2021/November/Paper2650/Authors'],['Anonymous'],"Simile interpretation is a crucial task in natural language processing. Nowadays, pre-trained language models (PLMs) have achieved state-of-the-art performance on many tasks. However, it remains under-explored whether PLMs can interpret similes or not. In this paper, we investigate the ability of PLMs in simile interpretation by designing a novel task named Simile Property Probing, i.e., to let the PLMs infer the shared properties of similes. We construct our simile property probing datasets from both general textual corpus and human-designed questions, which contain a total of 1,633 examples covering seven main categories. Our empirical study based on the constructed datasets shows that PLMs exhibit the ability to infer shared properties of similes, while they still underperform humans. To bridge the gap with human performance, we additionally design a knowledge-enhanced training objective by incorporating the simile knowledge into PLMs via knowledge embedding methods. Our method brings up to an 8.58% gain in the probing task, and up to a 1.37% gain in the downstream task of sentiment classification. The datasets and code will be publicly available soon.",/pdf/cff4fcd8eec1a41af359d8df06dc74cfcd26e6b5.pdf,,,,,anonymous|can_pretrained_language_models_interpret_similes_as_smart_as_human,,,,,,,,,
613,YDwkCkgFFFn,The patient is more dead than alive: exploring the current state of the multi-document summarisation of the biomedical literature,['aclweb.org/ACL/ARR/2021/November/Paper2063/Authors'],['Anonymous'],"Although multi-document summarisation (MDS) of the biomedical literature is a highly valuable task that has recently attracted substantial interest, evaluation of the quality of biomedical summaries lacks consistency and transparency. In this paper, we examine the summaries generated by two current models in order to understand the deficiencies of existing evaluation approaches in the context of the challenges that arise in the MDS task. Based on this analysis, we propose a new approach to human evaluation and identify several challenges that must be overcome to develop effective biomedical MDS systems.",/pdf/a9aef4afd36c29fb63507f67c548b601c6cea964.pdf,,,,,anonymous|the_patient_is_more_dead_than_alive_exploring_the_current_state_of_the_multidocument_summarisation_of_the_biomedical_literature,,,,,,,,,
614,6DOaEO5KV0,ICLEA: Interactive Contrastive Learning for Self-supervised Entity Alignment,['aclweb.org/ACL/ARR/2021/November/Paper2017/Authors'],['Anonymous'],"Self-supervised entity alignment (EA) aims to link equivalent entities across different knowledge graphs (KGs) without seed alignments. The current SOTA self-supervised EA method draws inspiration from contrastive learning, originally designed in computer vision based on instance discrimination and contrastive loss, and suffers from two shortcomings. Firstly, it puts unidirectional emphasis on pushing sampled negative entities far away rather than pulling positively aligned pairs close, as is done in the well-established supervised EA. Secondly, KGs contain rich side information (e.g., entity description), and how to effectively leverage those information has not been adequately investigated in self-supervised EA. In this paper, we propose an interactive contrastive learning model for self-supervised EA. The model encodes not only structures and semantics of entities (including entity name, entity description, and entity neighborhood), but also conducts cross-KG contrastive learning by building pseudo-aligned entity pairs. Experimental results show that our approach outperforms previous best self-supervised results by a large margin (over 9% average improvement) and performs on par with previous SOTA supervised counterparts, demonstrating the effectiveness of the interactive contrastive learning for self-supervised EA.",/pdf/824fab81056f054b3c492efbd8f72acda04a5c05.pdf,,,,,anonymous|iclea_interactive_contrastive_learning_for_selfsupervised_entity_alignment,,,,,,,,,
615,MHnRhU7zmDX,Learning Universal Sentence Embeddings with Large-scale Parallel Translation Datasets,['aclweb.org/ACL/ARR/2021/November/Paper76/Authors'],['Anonymous'],"Although contrastive learning has greatly improved sentence representation, its performance is still limited by the size of monolingual sentence-pair datasets. Meanwhile, there exist large-scale parallel translation pairs (100x larger than monolingual pairs) that are highly correlated in semantic, but have not been utilized for learning universal sentence representation. Furthermore, given parallel translation pairs, previous contrastive learning frameworks can not well balance the monolingual embeddings’ alignment and uniformity which represent the quality of embeddings. In this paper, we build on the top of dual encoder and propose to freeze the source language encoder, utilizing its consistent embeddings to supervise the target language encoder via contrastive learning, where source-target translation pairs are regarded as positives. We provide the first exploration of utilizing parallel translation sentence pairs to learn universal sentence embeddings and show superior performance to balance the alignment and uniformity. We achieve a new state-of-the-art performance on the average score of standard semantic textual similarity (STS), outperforming both SimCSE and Sentence-T5, and the best performance in corresponding tracks on transfer tasks.",/pdf/83ded99f8b92de913aff536cb8ccfdc3febdffd2.pdf,/attachment/7569eaf87677b1870d273ff4177bfa791723615c.zip,,,,anonymous|learning_universal_sentence_embeddings_with_largescale_parallel_translation_datasets,,,,,,,,,
616,WuxlPPY23K,MoEfication: Conditional Computation of Transformer Models for Efficient Inference,['aclweb.org/ACL/ARR/2021/November/Paper1050/Authors'],['Anonymous'],"Transformer-based pre-trained language models achieve superior performance on most NLP tasks due to large parameter capacity, but also lead to huge computation cost. Fortunately, we observe that most inputs only activate a tiny ratio of neurons of large Transformer-based pre-trained models during inference. Hence, we propose to convert a model into its mixture-of-experts (MoE) version with the same parameters, namely MoEfication, which accelerates large-model inference by conditional computation based on the sparse activation phenomenon. Specifically, MoEfication consists of two phases: (1) splitting the parameters of feed-forward neural networks (FFNs) into multiple parts as experts, and (2) building expert routers to decide which experts will be used for each input. Experimental results show that MoEfication can save $80\%$ computation cost of FFNs while maintaining over $95\%$ original performance for different models, including models with different sizes (up to 3 billion parameters) and distilled models, on various downstream tasks. Moreover, we find that the MoEfied model achieves better performance than the MoE model pre-trained from scratch with the same model size. We will release all the code and models of this paper.

",/pdf/e7216a53283eb4466d73b3a9f5cfc798de192fd8.pdf,,,,,anonymous|moefication_conditional_computation_of_transformer_models_for_efficient_inference,,,,,,,,,
617,xcelRQScTjP,RELiC: Retrieving Evidence for Literary Claims,['aclweb.org/ACL/ARR/2021/November/Paper1948/Authors'],['Anonymous'],"Humanities scholars commonly provide evidence for claims that they make about a work of literature (e.g., a novel) in the form of quotations from the work. We collect a large-scale dataset (RELiC) of 90K literary quotations and surrounding critical analysis and use it to formulate the novel task of literary evidence retrieval, in which models are given an excerpt from a literary analysis surrounding a masked quotation and asked to retrieve the quoted passage from the set of all passages in the work. Solving this retrieval task requires a deep understanding of complex literary and linguistic phenomena, which proves challenging to methods that  overwhelmingly rely on lexical and semantic similarity matching. We implement a RoBERTa-based dense passage retriever for this task that outperforms existing pretrained information retrieval baselines; however, experiments and analysis by human domain experts indicate that there is substantial room for improvement.",/pdf/1c20cf49b96fc7fde23530055d0dc692180fd3fd.pdf,,,,,anonymous|relic_retrieving_evidence_for_literary_claims,,,,,,/attachment/ebe63d14e73288fb9ff0962d09616eb0f948d15d.zip,,,
618,5P8vhb5bV2_,A Dual-Channel Framework for Sarcasm Recognition by Detecting Sentiment Conflict,['aclweb.org/ACL/ARR/2021/November/Paper659/Authors'],['Anonymous'],"Sarcasm employs ambivalence, where one says something positive but actually means negative, vice versa. The essence of sarcasm, which is also a sufficient and necessary condition, is the conflict between literal and implied sentiments. However, it is difficult to recognize the sentiment conflict because more than one mixed or even implicit sentiments coexist in one text. As a result, the recognition of sophisticated and obscure sentiment brings in a great challenge to sarcasm detection.  In this paper, we propose a dual-channel framework by modeling both literal and implied sentiment separately. Based on the flexible dual-channel framework, we design Dual-Channel Net (DC-Net) to recognize the sentiment conflict. Experiments on political debates (i.e. IAC-V1 and IAC-V2) and Twitter datasets show that our proposed DC-Net achieves state-of-the-art performance on sarcasm recognition.",/pdf/2612ff16cf7d67fb90c406089f36579430c4d5bd.pdf,,,,,anonymous|a_dualchannel_framework_for_sarcasm_recognition_by_detecting_sentiment_conflict,,,,,,,,,
619,dshFaeku9Me,A Parameter Aggregation Strategy on Personalized Federated Learning,['aclweb.org/ACL/ARR/2021/November/Paper207/Authors'],['Anonymous'],"We investigate the parameter aggregation weights of federated learning (FL), simulate a variety of data access scenarios for experiments, and propose a model parameter weight self-learning strategy for horizontal FL. For application use of this study, a personalized FL network structure model based on edge computing is designed.",/pdf/0d52810fdcd2c633e18a98ed06618e2716d395be.pdf,,,,,anonymous|a_parameter_aggregation_strategy_on_personalized_federated_learning,,,,,,,,,
620,k9p9ML7otLG,Graph Neural Networks for Multiparallel Word Alignment,['aclweb.org/ACL/ARR/2021/November/Paper2747/Authors'],['Anonymous'],"After a period of decrease, interest in word alignments is increasing again for their usefulness in domains such as typological research, cross-lingual annotation projection and machine translation. Generally, alignment algorithms only use bitext and do not make use of the fact that many parallel corpora are multiparallel. Here, we compute high-quality word alignments between multiple language pairs by considering all language pairs together. First, we create a multiparallel word alignment graph, joining all bilingual word alignment pairs in one graph. Next, we use graph neural networks (GNNs) and community detection algorithms to exploit the graph structure. Our GNN approach (i) utilizes information about the meaning, position and language of the input words, (ii) incorporates information from multiple parallel sentences, (iii) adds and removes edges from the initial alignments, and (iv) provides a prediction model that can generalize beyond the sentences it is trained on. We show that community detection provides valuable information for multiparallel word alignment.  Our method outperforms previous work on three word alignment datasets and on a downstream task.
",/pdf/10e29cef699f6cffcedece833422715bd947ae58.pdf,,,,,anonymous|graph_neural_networks_for_multiparallel_word_alignment,,,,,,,/attachment/55e4953837e8d76dd2df20b2c44ae7f846b1022f.pdf,https://openreview.net/forum?id=b61q_mqtf31,/attachment/fa72d4974327a1308da76d9a2a9bfa72e23513bb.pdf
621,GAtDhA2VH88,ComSearch: Equation Searching with  Combinatorial Mathematics for Solving Math Word Problems with Weak Supervision,['aclweb.org/ACL/ARR/2021/November/Paper2116/Authors'],['Anonymous'],"Previous studies have introduced a weakly-supervised paradigm for solving math word problems requiring only the answer value annotation. While these methods search for correct value equation candidates as pseudo labels, they search among a narrow sub-space of the enormous equation space. To address this problem, we propose a novel search algorithm with combinatorial mathematics \textbf{ComSearch}, which can compress the search space by excluding mathematical equivalent equations. The compression allows the searching algorithm to enumerate all possible equations and obtain high-quality data. Experimental results show that our method achieves state-of-the-art results, especially for problems with more variables.",/pdf/1bd5954e5ca0c1296e8a8df1c200a18756f96653.pdf,/attachment/6dfb72eee7cf962405aeadc382dbfd011c87c0eb.zip,,,,anonymous|comsearch_equation_searching_with_combinatorial_mathematics_for_solving_math_word_problems_with_weak_supervision,,,,,,/attachment/ee9f9d38015a32f55dffd2bcaf3b4e965f90a0a3.zip,,,
622,bAyJN10c_5N,MATHion: Solving Math Word Problems with Logically Consistent Problems,['aclweb.org/ACL/ARR/2021/November/Paper692/Authors'],['Anonymous'],"Solving the math word problems (MWPs) is a challenging task. Some existing MWP solvers retrieve textually similar problems and draw on their solutions to solve the given problem. However, textually similar questions are not guaranteed to have similar solutions. And questions could share the same solution but with different descriptions. Therefore in this work, we investigate the logical consistency among different problems and propose a novel framework named MATHion which solves math word problems with logically consistent problems. Experimental results show that our method outperforms many strong baselines, including some pre-trained language model-based methods. Further analysis shows that our retrieval method can learn the logical similarity between questions and plays a key role in our model's performance. ",/pdf/3b10a012125b365d73e23875de718d184d41612d.pdf,,,,,anonymous|mathion_solving_math_word_problems_with_logically_consistent_problems,,,,,,,,,
623,zm8gQvBzFAM,Under the Morphosyntactic Lens: A Multifaceted Evaluation of Gender Bias in Speech Translation,['aclweb.org/ACL/ARR/2021/November/Paper1661/Authors'],['Anonymous'],"Gender bias is largely recognized as a problematic phenomenon affecting language technologies, with recent studies underscoring that it might surface differently across languages. However, most evaluation practices adopt a word-level focus on a narrow set of occupational nouns under synthetic conditions. Such protocols overlook key features of grammatical gender languages, which are characterized by morphosyntactic chains of gender agreement, marked on a variety of lexical items and parts-of-speech (POS). To overcome this limitation, we enrich the natural, gender-sensitive MuST-SHE corpus with two new annotation layers: POS and agreement chains. On this basis, we conduct multifaceted automatic and manual evaluations for three speech translation models, trained on varying amounts of data and different word segmentation techniques. Our work sheds light on model behaviours, gender bias, and its detection at several levels of granularity for English-French/Italian/Spanish. ",/pdf/cb28914b3f65484f4c1a7004ff3fba090c5b84f9.pdf,,,,,anonymous|under_the_morphosyntactic_lens_a_multifaceted_evaluation_of_gender_bias_in_speech_translation,,,,,,/attachment/bf59c12bcda52e21999354650ab82c65d20d7c3f.zip,,,/attachment/b0f88cbfe54755d6033d333ec4a0d53abd8c2fbc.pdf
624,uecnUP0-PjZ,One-Shot Learning from a Demonstration with Hierarchical Latent Language,['aclweb.org/ACL/ARR/2021/November/Paper1869/Authors'],['Anonymous'],"Humans have the capability, aided by the expressive compositionality of their language, to learn quickly by demonstration. They are able to describe unseen task-performing procedures and generalize their execution to other contexts. In this work, we introduce DescribeWorld, an environment designed to test this sort of generalization skill in grounded agents, where tasks are linguistically and procedurally composed of elementary concepts. The agent observes a single task demonstration in a Minecraft-like grid world, and is then asked to carry out the same task in a new map.To enable such a level of generalization, we propose a neural agent infused with hierarchical latent language—both at the level of task inference and subtask planning. Our agent first generates a textual description of the demonstrated unseen task, then leverages this description to replicate it. Through multiple evaluation scenarios and a suite of generalization tests, we find that agents that perform text-based inference are better equipped for the challenge under a random split of tasks. ",/pdf/8715f33fb99a1704a22317327c1bbe9d8908f1be.pdf,,,,,anonymous|oneshot_learning_from_a_demonstration_with_hierarchical_latent_language,,,,,,,,,
625,lm8Fb0c5k7_,UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining,['aclweb.org/ACL/ARR/2021/November/Paper620/Authors'],['Anonymous'],"High-quality phrase representations are essential to finding topics and related terms in documents (a.k.a.  topic mining).  Existing phrase representation learning methods either simply combine unigram representations in a context-free manner or rely on extensive annotations to learn context-aware knowledge. In this paper,  we propose UCTopic,  a novel unsupervised contrastive learning framework for context-aware phrase representations and topic mining. UCTopic is pretrained in a large scale to distinguish if the contexts of two phrase mentions have the same semantics. The key to the pretraining is positive pair construction from our phrase-oriented assumptions.   However,  we find traditional in-batch negatives cause performance decay when finetuning on a  dataset with small topic numbers. Hence, we propose cluster-assisted contrastive learning  (CCL)  which largely reduces noisy negatives by selecting negatives from clusters and further improves phrase representations for topics accordingly.   UCTopic outperforms the state-of-the-art phrase representation model by 38.2% NMI in average on four entity clustering tasks. Comprehensive evaluation on topic mining shows that UCTopic can extract coherent and diverse topical phrases.",/pdf/a09ae2d87fb9b338406771133620669512be7969.pdf,/attachment/23411e38ab6d5a34ac0a20539d012ce085c9e944.zip,,,,anonymous|uctopic_unsupervised_contrastive_learning_for_phrase_representations_and_topic_mining,,,,,,/attachment/daadef972903bd4629e732059a418548412fe186.zip,,,
626,xicP8EAgXFU,AlephBERT: Language Model Pre-training and Evaluation from Sub-Word to Sentence Level,['aclweb.org/ACL/ARR/2021/November/Paper2045/Authors'],['Anonymous'],"Large Pre-trained Language Models (PLMs) have become ubiquitous in the development of language understanding technology and lie at the heart of many artificial intelligence advances.
While advances reported for English using PLMs are unprecedented, reported advances using PLMs for Hebrew are few and far between.
The problem is twofold.
First, so far, Hebrew resources for training large language models are not of the same magnitude as their English counterparts.
Second, there are no accepted benchmarks to evaluate the progress of Hebrew PLMs on, and in particular, sub-word (morphological) tasks.
We aim to remedy both aspects.
We present AlephBERT, a large PLM for Modern Hebrew, trained on larger vocabulary and a larger dataset than any Hebrew PLM before.
Moreover, we introduce a novel language-agnostic architecture that can recover all of the sub-word morphological segments encoded in contextualized word embedding vectors.
Based on this new morphological component we offer a new PLM evaluation suite consisting of multiple tasks and benchmarks, that cover sentence level word-level and sub-word level analyses.
On all tasks, AlephBERT obtains state-of-the-art results beyond contemporary Hebrew baselines. 
We make our AlephBERT model, the morphological extraction mode, and the Hebrew evaluation suite publicly available, providing a single point of entry for assessing Hebrew PLMs.",/pdf/49845bda2052e7bf21ff9f4663a36aecb7a8537e.pdf,,,,,anonymous|alephbert_language_model_pretraining_and_evaluation_from_subword_to_sentence_level,,,,,,,/attachment/b9acd21194db443cb8ccb7cb8338e8598a4250fd.pdf,https://openreview.net/forum?id=4IgzCL-ytZs,/attachment/60a6dc1e8da919960627b49f87c349dcd15a878d.pdf
627,o0CMTqnn9kM,AutoMin: A Novel Dataset for Automatic Minuting from Multi-Party Meetings in English and Czech,['aclweb.org/ACL/ARR/2021/November/Paper2568/Authors'],['Anonymous'],"Taking minutes is an essential component of every meeting, although the goals, style, and procedure  of this activity (``minuting'' for short) can vary. Minuting is a rather unstructured writing activity and is affected by who is taking the minutes and for whom the intended minutes are. With the rise of online meetings, automatic minuting would be an important benefit for the meeting participants as well as for those who might have missed the meeting. However, automatically generating meeting minutes is a challenging problem due to a variety of factors including the quality of automatic speech recorders (ASRs), availability of public meeting data, subjective knowledge of the minuter, etc. In this work, we present the first of its kind dataset on Automatic Minuting. We develop a dataset of English and Czech technical project meetings which consists of transcripts generated from ASRs, manually corrected, and minuted by several annotators. Our dataset, AutoMin, consists of 113 (English) and 53 (Czech) meetings, covering more than 160 hours of meeting content. The meeting sessions are recorded, automatically transcribed, corrected, equipped with human-generated minutes, and finally de-identified. We would publicly release (aaa.bbb.ccc) the dataset as a set of meeting transcripts and minutes, excluding the recordings for privacy reasons. 
A unique feature of our dataset is that most meetings are equipped with more than one minute, each created independently. Our corpus thus allows studying differences in what people find important while taking the minutes. We also provide baseline experiments for the community to explore this novel problem further. To the best of our knowledge AutoMin is probably the first resource on minuting in English and also in a language other than English (Czech).",/pdf/2004b12f549695b43471846f6c779e63dab833a8.pdf,/attachment/b4e3139e242a8304220587f1476d2a80a1a6f832.zip,,,,anonymous|automin_a_novel_dataset_for_automatic_minuting_from_multiparty_meetings_in_english_and_czech,,,,,,/attachment/1c2f67884e04ca79fbeca052342d531bba2dca71.zip,,,
628,Xf7cE59PJuP,Multi-Granularity Contrastive Knowledge Distillation for Multimodal Named Entity Recognition,['aclweb.org/ACL/ARR/2021/November/Paper2532/Authors'],['Anonymous'],"It is very valuable to recognize named entities from short and informal multimodal posts in this age of information explosion. Despite existing methods success in multi-modal named entity recognition (MNER), they rely on the well aligned text and image pairs, while a lot of noises exist in the datasets. And the representation of text and image with internal correlations is difficult to establish a deep connection, because of the mismatched semantic levels of the text encoder and image encoder.  In this paper, we propose multi-granularity contrastive knowledge distillation (MGC) to build a unified joint representation space of two modalities. By leveraging multi-granularity contrastive loss, our approach pushes representations of matched image-text pairs or image-entity pairs together while pushing those unrelated image-text or image-entity pairs apart. By utilizing CLIP model for knowledge distillation, we can obtain a more fine-grained visual concept. Experimental results on two benchmark datasets prove the effectiveness of our method.",/pdf/cc07b4d6e75e37f411fa2f0958f4a1908ad4b81e.pdf,/attachment/6553df6ab9898c8ed5b91024c183c72b179181c1.zip,,,,anonymous|multigranularity_contrastive_knowledge_distillation_for_multimodal_named_entity_recognition,,,,,,,,,
629,KkF3IHfdT_z,The Change that Matters in Discourse Parsing: Estimating the Impact of Domain Shift on Parser Error,['aclweb.org/ACL/ARR/2021/November/Paper1331/Authors'],['Anonymous'],"Discourse analysis allows us to attain high-level inferences of a text document beyond the sentence-level. However, currently the performance of discourse models is very low on texts outside of the training distribution's coverage. There is need for a measure that can inform us to what extent our model generalizes from the training to the test sample when these samples may be drawn from distinct distributions. While this can be estimated via distribution shift, we argue that this does not directly correlate with change in the observed error of a classifier (i.e. error-gap). Thus, we propose to use a statistic from the theoretical domain adaptation literature which can be directly tied to error-gap. We study the bias of this statistic as an estimator of error-gap both theoretically and through a large-scale empirical study of over 2400 experiments on 6 discourse datasets from domains including, but not limited to: news, biomedical texts, TED talks, Reddit posts, and fiction. Our results not only motivate our proposal and help us to understand its limitations, but also provide insight on the properties of discourse models and datasets which improve performance in domain adaptation. For instance, we find that non-news datasets are slightly easier to transfer to than news datasets when the training and test sets are very different. We plan to release our code as a Python package to allow practitioners to make more informed model and dataset choices.",/pdf/4f58af30a2c03ec77c9936407c2e34af4ed956b0.pdf,,,,,anonymous|the_change_that_matters_in_discourse_parsing_estimating_the_impact_of_domain_shift_on_parser_error,,,,,,,,,
630,sU9fYzNZ3xX,An Empirical Study of Document-to-document Neural Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper1167/Authors'],['Anonymous'],"This paper does not aim at introducing a novel method for document NMT. Instead, we head back to the original transformer model with document-level training and hope to answer the following question: Is the capacity of current models strong enough for document-level NMT? Interestingly, we observe that the original transformer with appropriate training techniques can achieve strong results for document translation, even with a length of 2000 words. We evaluate this model and several recent approaches on nine document-level datasets and two sentence-level datasets across six languages. Experiments show that the original Transformer model outperforms sentence-level models and many previous methods in a comprehensive set of metrics, including BLEU, four lexical indices, three newly proposed assistant linguistic indicators, and human evaluation.",/pdf/cc792284db90d620bd7098638a9bbf2b6f9a708d.pdf,,,,,anonymous|an_empirical_study_of_documenttodocument_neural_machine_translation,,,,,,/attachment/5732a4b9964a99c4f92680a974bef314309e0ca9.zip,/attachment/68fcae326b13911136e6049778fb6287358a3911.pdf,https://openreview.net/forum?id=lTbIVRBq8Ta&noteId=Qjnk42T0NU,/attachment/64370f6fbae1f87aa05b5752e94590d15bb093fd.pdf
631,sVMB_r7oPpv,A Re-examination of Neural Selective Prediction for Natural Language Processing,['aclweb.org/ACL/ARR/2021/November/Paper181/Authors'],['Anonymous'],"We provide a survey and careful empirical comparison of the state-of-the-art in neural selective classification for NLP tasks. Across multiple trials on multiple datasets, only one of the surveyed techniques -- Monte Carlo Dropout -- significantly outperforms the simple baseline of using the maximum softmax probability as an indicator of prediction confidence. Our results provide a counterpoint to recent claims made on the basis of single-trial experiments on a small number of datasets. We also provide a blueprint and open-source code to support the future evaluation of selective prediction techniques. ",/pdf/9a95747aa1417ea2a54ca02882ec70ddc53ad865.pdf,/attachment/25b6b24fd9fff2282b69fe3bfeaecb5d158df4bc.zip,,,,anonymous|a_reexamination_of_neural_selective_prediction_for_natural_language_processing,,,,,,/attachment/b786a2f4b39f44fbf8845ef41d03d2a51e762684.zip,,,
632,TpPhoHHfIKl,The Algorithmic Inflection and Morphological Variability of Russian,['aclweb.org/ACL/ARR/2021/November/Paper1039/Authors'],['Anonymous'],"We present a set of deterministic algorithms for Russian inflection and automated text synthesis. These algorithms are implemented in a publicly available web-service www.passare.ru. This service provides functions for inflection of single words, word matching and synthesis of grammatically correct Russian text. The inflectional functions have been tested against the annotated corpus of Russian language OpenCorpora and used for estimating the morphological variability and complexity of different parts of speech in Russian.",/pdf/a5a2ed7c3a82d90ae5f1130a0ea86631716f17ed.pdf,,,,,anonymous|the_algorithmic_inflection_and_morphological_variability_of_russian,,,,,,,,,
633,vS9XeUdk-Yc,Multi-Stage Prompting for Knowledgeable Dialogue Generation,['aclweb.org/ACL/ARR/2021/November/Paper326/Authors'],['Anonymous'],"Existing knowledge-grounded dialogue systems typically use finetuned versions of a pretrained language model (LM) and large-scale knowledge bases. These models typically fail to generalize on topics outside of the knowledge base, and require maintaining separate potentially large checkpoints each time finetuning is needed. In this paper, we aim to address these limitations by leveraging the inherent knowledge stored in the pretrained LM as well as its powerful generation ability. We propose a multi-stage prompting approach to generate knowledgeable responses from a single pretrained LM. We first prompt the LM to generate knowledge based on the dialogue context. Then, we further prompt it to generate responses based on the dialogue context and the previously generated knowledge. Results show that our knowledge generator outperforms the state-of-the-art retrieval-based model by 5.8\% when combining knowledge relevance and correctness. In addition, our multi-stage prompting outperforms the finetuning-based dialogue model in terms of response knowledgeability and engagement by up to 10% and 5%, respectively. Furthermore, we scale our model up to 530 billion parameters and demonstrate that larger LMs improve the generation correctness score by up to 10%, and response relevance, knowledgeability and engagement by up to 10%.",/pdf/ed44c3a5ce840e949c0e766e971e7b0a55bbb9c1.pdf,,,,,anonymous|multistage_prompting_for_knowledgeable_dialogue_generation,,,,,,,,,
634,E7xLOw5YHR5,Learning from Missing Relations: Contrastive Learning with Commonsense Knowledge Graphs for Commonsense Inference,['aclweb.org/ACL/ARR/2021/November/Paper926/Authors'],['Anonymous'],"Commonsense inference poses a unique challenge to reason and generate the physical, social, and causal conditions of a given event. Existing approaches to commonsense inference utilize commonsense transformers, which are large-scale language models that learn commonsense knowledge graphs. However, they suffer from a lack of coverage and expressive diversity of the graphs, resulting in a degradation of the representation quality. In this paper, we focus on addressing missing relations in commonsense knowledge graphs, and propose a novel contrastive learning framework called SOLAR. Our framework contrasts sets of semantically similar and dissimilar events, learning richer inferential knowledge compared to existing approaches. Empirical results demonstrate the efficacy of SOLAR in commonsense inference of diverse commonsense knowledge graphs. Specifically, SOLAR outperforms the state-of-the-art commonsense transformer on commonsense inference with ConceptNet by 1.84% on average among 8 automatic evaluation metrics. In-depth analysis of SOLAR sheds light on the effects of the missing relations utilized in learning commonsense knowledge graphs.",/pdf/f124c4fafca88539e1e90e1d16326b33b759c973.pdf,,,,,anonymous|learning_from_missing_relations_contrastive_learning_with_commonsense_knowledge_graphs_for_commonsense_inference,,,,,,,,,
635,xTsom6Vyem0,ANNA: Enhanced Language Representation for Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper231/Authors'],['Anonymous'],"Pre-trained language models have brought significant improvements in performance in a variety of natural language processing tasks. Most existing models performing state-of-the-art results have shown their approaches in the separate perspectives of data processing, pre-training tasks, neural network modeling, or fine-tuning. In this paper, we demonstrate how the approaches affect performance individually, and that the language model performs the best results on a specific question answering task when those approaches are jointly considered in pre-training models. In particular, we propose an extended pre-training task, and a new neighbor-aware mechanism that attends neighboring tokens more to capture the richness of context for pre-training language modeling. Our best model achieves new state-of-the-art results of 95.7\% F1 and 90.6\% EM on SQuAD 1.1 and also outperforms existing pre-trained language models such as RoBERTa, ALBERT, ELECTRA, and XLNet on the SQuAD 2.0 benchmark.",/pdf/19e1c3c2f7f05c1bf4e31214f521e38593e888ad.pdf,,,,,anonymous|anna_enhanced_language_representation_for_question_answering,,,,,,,,,
636,eYe4HOt0Zx,Meet Your Favorite Character: Open-domain Chatbot Mimicking Fictional Characters with only a Few Utterances,['aclweb.org/ACL/ARR/2021/November/Paper1234/Authors'],['Anonymous'],"In this paper, we consider mimicking fictional characters as a promising direction for building engaging conversation models. To this end, we present a new practical task where only a few utterances of each fictional character are available to generate responses mimicking them. Furthermore, we propose a new method named Pseudo Dialog Prompting (PDP) that generates responses by leveraging the power of large-scale language models with prompts containing the target character's utterances. To better reflect the style of the character, PDP builds the prompts in the form of dialog that includes the character's utterances as dialog history. Since only utterances of the characters are available in the proposed task, PDP matches each utterance with an appropriate pseudo-context from a predefined set of context candidates using a retrieval model. Through human and automatic evaluation, we show that PDP generates responses that better reflect the style of fictional characters than baseline methods.",/pdf/fbec74980d1966d6f449a22ce663de797cad2452.pdf,/attachment/70dd33c8dac7d40d92ad0c86d4100c5f884e0175.zip,,,,anonymous|meet_your_favorite_character_opendomain_chatbot_mimicking_fictional_characters_with_only_a_few_utterances,,,,,,,,,
637,LykFSG2ZUZS,CLD²: Language Documentation Meets Natural Language Processing for Revitalising Endangered Languages,['aclweb.org/ACL/ARR/2021/November/Paper2034/Authors'],['Anonymous'],"Language revitalisation should not be understood as a direct outcome of language documentation, which is mainly focused on the creation of language repositories. Natural language processing (NLP) offers the potential to complement and exploit these repositories through the development of language technologies that may directly impact the vitality status of endangered languages. In this paper, we discuss the current state of the interaction between language documentation and computational linguistics, present a diagnosis of how the outputs of recent documentation projects for endangered languages are underutilised for the NLP community, and discuss how the situation could change from both the documentary linguistics and NLP perspectives. All this is introduced as a bridging paradigm called Computational Language Documentation and Development (CLD²). CLD² calls for (1) the inclusion of NLP-friendly annotated data as a deliverable of future language documentation projects; and (2) the exploitation of language documentation databases by the NLP community to promote the computerisation of endangered languages at a global scale.
",/pdf/2256c036926794bdce55db4d154c4baabf7db2f0.pdf,,,,,anonymous|cld_language_documentation_meets_natural_language_processing_for_revitalising_endangered_languages,,,,,,,,,
638,fCqi1FgubBb,BACN: Bi-direction Attention Capsule-based Network for Multimodal Sentiment Analysis,['aclweb.org/ACL/ARR/2021/November/Paper261/Authors'],['Anonymous'],"Capsule-based network has currently identified its effectiveness in analyzing the heterogeneity issue of multimodal sentiment analysis. 
However, existing manners could only exploit the spatial relation between representation and output layer via down-top attention, which fails to effectively explore both inter-modality and intra-modality context. In this paper, during the preprocess period, we first present the multimodal dynamic enhanced module to facilitate the intra-modality context, which significantly boost the learning efficiency in dealing with multimodal heterogeneity issue. Furthermore, the bi-direction attention capsule-based network (BACN) is proposed to capture dynamic inter-modality context via the novel bi-direction dynamic routing mechanism. Specifically, BACN firstly highlights the static and low-level inter-modality context based on top-down attention. Then, the static multimodal context is transmitted to dynamic routing procedure, naturally allowing us to investigate dynamic and high-level inter-modality context. This indeed unleash the expressive power and provides the superior capability to bridge the modality gap among all the modalities. The experiments demonstrate that BACN can achieve state-of-the-art performance. ",/pdf/ef5676bcc0c10f69c4fe303e6400ba5189b59695.pdf,/attachment/c38c279be458a018d81709b8509a588f2766189d.zip,,,,anonymous|bacn_bidirection_attention_capsulebased_network_for_multimodal_sentiment_analysis,,,,,,/attachment/5f59738d8600b136df6667e0ceaff0c1a738018e.zip,,,
639,zybG6tEamxk,Rebuild and Ensemble: Exploring Defense Against Text Adversaries,['aclweb.org/ACL/ARR/2021/November/Paper75/Authors'],['Anonymous'],"Adversarial attacks can mislead strong neural models; as such, in NLP tasks, substitution-based attacks are difficult to defend. 
Current defense methods usually assume that the substitution candidates are accessible, which cannot be widely applied against adversarial attacks unless knowing the mechanism of the attacks. 
In this paper, we propose a \textbf{Rebuild and Ensemble} Framework to defend against adversarial attacks in texts without knowing the candidates.
We propose a rebuild mechanism to train a robust model and ensemble the rebuilt texts during inference to achieve good adversarial defense results.
Experiments show that our method can improve accuracy under the current strong attack methods. ",/pdf/dc0153d640a8adf0606fbe174c1e56f2c29e5fe0.pdf,,,,,anonymous|rebuild_and_ensemble_exploring_defense_against_text_adversaries,,,,,,/attachment/13c93f55064c9badc80623c4e029efced51d84e5.zip,/attachment/8d4f2dcfc364459e461fdf7d11f862c4c94d9a87.pdf,https://openreview.net/forum?id=l3UVZ30slvl&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Daclweb.org%2FACL%2FARR%2F2021%2FSeptember%2FAuthors%23your-submissions),/attachment/59065e17250a13c08e88d3d1f532a9c09e5bf8bd.pdf
640,Dkayo1AmMpC,From Rewriting to Remembering: Common Ground for Conversational QA Models,['aclweb.org/ACL/ARR/2021/November/Paper252/Authors'],['Anonymous'],"In conversational QA, models have to leverage information in previous turns to answer upcoming questions. Current approaches, such as Question Rewriting, struggle to extract relevant information as the conversation unwinds. We introduce the Common Ground (CG), 
an approach to accumulate conversational information as it emerges and select the relevant information at every turn. We show that CG offers a more efficient and human-like way to exploit conversational information compared to existing approaches, leading to improvements on Open Domain Conversational QA.",/pdf/993da6c05db0c06472ab61e5616d441e8e368668.pdf,,,,,anonymous|from_rewriting_to_remembering_common_ground_for_conversational_qa_models,,,,,,,,,
641,kcZcqo9ROA-,Knowledge-guided Transformer for Joint Theme and Emotion Classification of Chinese Classical Poetry,['aclweb.org/ACL/ARR/2021/November/Paper328/Authors'],['Anonymous'],"The classifications of the theme and emotion are essential for understanding and organizing  Chinese classical poetry. Existing works fail to consider the lexical knowledge mined from poem  annotations, which intuitively reflects the theme and emotion. In addition, they just treat them as two separate tasks without considering that the emotion is usually related with the theme. In this paper, we propose a Knowledge-guided Transformer Model (KTM) for joint theme and emotion classification of  Chinese classical poetry. Specifically, we first respectively construct two lexical dictionaries for the theme and emotion based on the poem annotations. Then we take full advantage of the lexical dictionaries with a knowledge-based mask-transformer to represent poems. Furthermore, considering the correlations between the theme and emotion, our model jointly classifies the theme and emotion for Chinese classical poetry by stacking the two subtasks. Extensive experiments demonstrate that our model achieves state-of-the-art performance on both theme and emotion classifications, especially on tail labels.",/pdf/b1ef6f936683d18ee806acdcfef41875a21f90ef.pdf,/attachment/9c6dc8b36174a3ccefddaf43ed07c4e0893e4f86.zip,,,,anonymous|knowledgeguided_transformer_for_joint_theme_and_emotion_classification_of_chinese_classical_poetry,,,,,,/attachment/8606341afbdd082c1399e9a663885f6d6448a85a.zip,,,
642,tZ6cm6PY1hQ,Hierarchical Attention Decoder for Solving Math Word Problems,['aclweb.org/ACL/ARR/2021/November/Paper1675/Authors'],['Anonymous'],"To answer math word problems (MWPs), models need to formalize equations from the source text of math problems. Recently, the tree-structured decoder has significantly improved model performance on this task by generating the target equation in a tree format. However, current decoders usually ignore the hierarchical relationships between tree nodes and their parents, which hinders further improvement. Thus, we propose a structure called hierarchical attention tree to aid the generation procedure of the decoder. As our decoder follows a graph-based encoder, our full model is therefore named as Graph to Hierarchical Attention Tree (G2HAT). We show a tree-structured decoder with hierarchical accumulative multi-head attention leads to significant performance improvement and reaches new state-of-the-art (SOTA) on both English MAWPS and Chinese Math23k MWP benchmarks. For further study, we also apply pre-trained language models for G2HAT, which even results in new higher performance.",/pdf/d733da3da90f7cddab1821e100a0a162d86ab5b1.pdf,,,,,anonymous|hierarchical_attention_decoder_for_solving_math_word_problems,,,,,,,,,
643,Nu1o7f13hBo,Repetition Facilitates Processing: The Processing Advantage of Construction Repetition in Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper1414/Authors'],['Anonymous'],"Repetitions occur frequently in dialogue. This study focuses on the repetition of lexicalised constructions—i.e., recurring multi-word units—in English open domain spoken dialogues. We hypothesise that construction repetition is an efficient communication strategy that reduces processing effort, and make three predictions based on this hypothesis. Our three predictions are confirmed: repetitions facilitate the processing of constructions and of their linguistic context; facilitating effects are higher when repetitions accumulate, and lower when repetitions are less locally distributed. We measure reduction in processing effort using two surprisal-based measures and estimate surprisal with an adaptive neural language model. Our findings suggest that human-like patterns of repetitions can be learned implicitly by utterance generation models equipped with psycholinguistically motivated surprisal-based objectives and adaptation mechanisms.
",/pdf/89036565af65e97d1310a5731e84774cb4648a77.pdf,/attachment/1a76a28203b44e31b7cc4a96f0281a68e578c68a.zip,,,,anonymous|repetition_facilitates_processing_the_processing_advantage_of_construction_repetition_in_dialogue,,,,,,/attachment/271664d5fcbfdcc3bba0de44aa1dbc9b41d26392.zip,,,
644,fVaB0w-H1hJ,Building a Role Specified Open-Domain Dialogue System Leveraging Large-Scale Language Models,['aclweb.org/ACL/ARR/2021/November/Paper1651/Authors'],['Anonymous'],"Recent open-domain dialogue models have brought numerous breakthroughs. However, building a chat system is not scalable since it often requires a considerable volume of human-human dialogue data, especially when enforcing features such as persona, style, or safety. In this work, we study the challenge of imposing roles on open-domain dialogue systems, with the goal of making the systems maintain consistent roles while conversing naturally with humans. To accomplish this, the system must satisfy a role specification that includes certain conditions on the stated features as well as a system policy on whether or not certain types of utterances are allowed. For this, We propose an efficient data collection framework leveraging in-context few-shot learning of large-scale language models for building role-satisfying dialogue dataset from scratch. We then compare various architectures for open-domain dialogue systems in terms of meeting role specifications while maintaining conversational abilities. Automatic and human evaluations show that our models return few out-of-bounds utterances, keeping competitive performance on general metrics. We release a Korean dialogue dataset we built for further research.",/pdf/54b87e654607fe6be4c00bf030d452a683ae6ee5.pdf,,,,,anonymous|building_a_role_specified_opendomain_dialogue_system_leveraging_largescale_language_models,,,,,,/attachment/f0a5b75f5cd04f41dada81fab6e230feca57e5b5.zip,,,
645,3GilrFL7aU7,GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems,['aclweb.org/ACL/ARR/2021/November/Paper2172/Authors'],['Anonymous'],"Over the last few years, there has been a move towards data curation for multilingual task-oriented dialogue (ToD) systems that can serve people speaking different languages. However, existing multilingual ToD datasets either have a limited coverage of languages due to the high cost of data curation, or ignore the fact that dialogue entities barely exist in countries speaking these languages. To tackle these limitations, we introduce a novel data curation method that generates GlobalWoZ --- a large-scale multilingual ToD dataset globalized from an English ToD dataset for three unexplored use cases of  multilingual ToD systems. Our method is based on translating dialogue templates and filling them with local entities in the target-language countries. Besides, we extend the coverage of target languages to 20 languages. We will release our dataset and a set of strong baselines to encourage research on multilingual ToD systems for real use cases.",/pdf/51a5af507374e82d4af69b9b692a82f203fed214.pdf,/attachment/99101a453be82f77f2011767a0bab6feaeb80b15.zip,,,,anonymous|globalwoz_globalizing_multiwoz_to_develop_multilingual_taskoriented_dialogue_systems,,,,,,,,,
646,Omw-DFgi6S,High Interpretable Transfer Network for Aspect Level Sentiment Classification,['aclweb.org/ACL/ARR/2021/November/Paper2863/Authors'],['Anonymous'],"Aspect-level affective classification (ASC)
aims to detect the affective polarity of a
given viewpoint target in a sentence. In the
ASC method based on neural network,
most of the work uses the attention
mechanism to capture the sentiment words
corresponding to the opinion target, and
then gather them as evidence to infer the
emotion of the target. However, due to the
complexity of annotation, the scale of
aspect level data sets is relatively small.
Data scarcity leads to the attention
mechanism sometimes unable to pay
attention to the sentiment words
corresponding to the target, which finally
weakens the performance of the neural
model. In order to solve this problem, this
paper proposes a complete High
Interpretable Transfer Network transfer
learning framework (HITN), which adopts
methods such as data enhancement,
attention adjustment and transfer to
effectively improve the performance of
ASC model. A large number of
experimental results show that our method
has always been all the previous migration
methods in this field, even compared with
some complex models.",/pdf/5ac6608876401e31037fb022cba86e36195ae9ab.pdf,,,,,anonymous|high_interpretable_transfer_network_for_aspect_level_sentiment_classification,,,,,,,,,
647,VyQrpIsouZ,NEWSFARM: the Largest Chinese Corpus for Long News Summarization,['aclweb.org/ACL/ARR/2021/November/Paper539/Authors'],['Anonymous'],"Recently, driven by a large number of datasets, the field of natural language processing(NLP) has developed rapidly. However, the lack of large-scale and high-quality Chinese datasets is still a critical bottleneck for further research on automatic text summarization. To close this gap, we searched Chinese news websites of domestic and abroad media, designed the algorithm HSS(hidden text topic, semantic similarity, and syntactic similarity) to crawl and filter these records to construct NEWSFARM. NEWSFARM is the largest highest quality Chinese long news summarization corpus, containing more than 200K Chinese long news and summaries written by professional editors or authors, which are all released to the public. Based on the corpus, we calculated the static metrics and designed many experiments with the baseline models. By comparing with the common datasets, the experiment results show that the high quality of our dataset and training effect of the models, which not only demonstrates the usefulness and challenges of the proposed corpus for automatic text summarization but also provides a benchmark for further research.",/pdf/7e0b2feaad4e8dfe5aaab30d44fa4e3a4801460b.pdf,,,,,anonymous|newsfarm_the_largest_chinese_corpus_for_long_news_summarization,,,,,,/attachment/c674572d8985a0c95d5bdea114a5a9db910b84d1.zip,,,
648,1-A3ADcohr,Life after BERT: What do Other Muppets Understand about Language?,['aclweb.org/ACL/ARR/2021/November/Paper2433/Authors'],['Anonymous'],"Pre-trained transformers are at the core of natural language processing today. However, the understanding of what model learns during pre-training is still limited. Existing model analysis works usually focus only on one or two model families at a time, overlooking the variety of existing architectures and pre-training objectives. In our work, we utilize the oLMpics benchmark and psycholinguistic probing datasets for a diverse set of 28 models including T5, BART, and ALBERT. Additionally, we adapt the oLMpics zero-shot setup for autoregressive models and evaluate GPT networks of different sizes. Our findings show that none of these models can resolve compositional questions in a zero-shot fashion, suggesting that this skill is not learnable using existing pre-training objectives. Additionally, we find that global model decisions such as architecture, directionality, size of the dataset, and pre-training objective are not predictive of a model's linguistic capabilities.
",/pdf/86b24b22b0b21b0006aa7d352185f7a1fa1c08e5.pdf,,,,,anonymous|life_after_bert_what_do_other_muppets_understand_about_language,,,,,,,,,
649,UDFO2MjWRUR,Towards a Progression-Aware Autonomous Dialogue Agent,['aclweb.org/ACL/ARR/2021/November/Paper2195/Authors'],['Anonymous'],"Recent advances in large-scale language modeling and generation have enabled the creation of dialogue agents that exhibit human-like responses in a wide range of conversational scenarios spanning a diverse set of tasks, from general chit-chat to focused goal-oriented discourse. While these agents excel at generating high-quality responses that are relevant to prior context, they suffer from a lack of awareness of the overall direction in which the conversation is headed, and the likelihood of task success inherent therein. Thus, we propose a framework in which dialogue agents can evaluate the progression of a conversation toward or away from desired outcomes, and use this signal to inform planning for subsequent responses. Our framework is composed of three key elements: (1) the notion of a ""global"" dialogue state (GDS) space, (2) a task-specific progression function (PF) computed in terms of a conversation's trajectory through this space, and (3) a planning mechanism by which a dialogue agent may use progression signals to select its next response.",/pdf/8c3adb251d16470732141c0d05fde421687f2c75.pdf,/attachment/10871e6c27bd59676912a2fbddbb378d5efe4caa.zip,,,,anonymous|towards_a_progressionaware_autonomous_dialogue_agent,,,,,,,,,
650,BOluefHO9tQ,Some Languages are More Equal than Others: Probing Deeper into the Linguistic Disparity in the NLP World,['aclweb.org/ACL/ARR/2021/November/Paper2038/Authors'],['Anonymous'],"Linguistic disparity in the NLP world is a problem that has been widely acknowledged recently. However, different facets of this problem, or the reasons behind this disparity are seldom discussed within the NLP community. This paper provides a comprehensive analysis of the disparity that exists within the languages of the world. Using an existing language categorisation based on speaker population and vitality, we analyse the distribution of language data resources, amount of NLP/CL research, inclusion in multilingual web-based platforms, and the inclusion in pre-trained multilingual models.
We show that many languages do not get covered in these resources or platforms, and even within the languages belonging to the same language group, there is wide disparity. We analyse the impact of family, geographical location, and the speaker population of languages, provide possible reasons for this disparity, and argue that a solution to this problem should be orchestrated by a wide alliance of stakeholders, of which ACL, as an association should be a key partner.",/pdf/935e01f0257ca3cd6459fd520d6e9d61d450aca7.pdf,,,,,anonymous|some_languages_are_more_equal_than_others_probing_deeper_into_the_linguistic_disparity_in_the_nlp_world,,,,,,,,,
651,eFeYI1YPuwb,Detect Low-Resource Rumors in Microblog Posts via Adversarial Contrastive Learning,['aclweb.org/ACL/ARR/2021/November/Paper1131/Authors'],['Anonymous'],"Massive false rumors emerging along with breaking news or trending topics severely hinder the truth. Exiting rumor detection approaches achieve promising performance on the yesterday's news, since there is enough corpus collected from the same domain for model training. However, they are poor at detecting rumors about unforeseen events such as COVID-19 due to the lack of training data and prior knowledge (i.e., low-resource rumors). In this paper, we propose an adversarial contrastive learning framework to detect low-resource rumors by adapting the features learned from well-resourced rumor data to that of the low-resourced. Our model explicitly overcomes the restriction of both domain and language usage via language alignment and contrastive training. Moreover, we develop an adversarial augmentation mechanism to further enhance the robustness of low-resource rumor representation. Extensive experiments conducted on two low-resource datasets collected from real-world microblog platforms demonstrate that our framework achieves much better performance than state-of-the-art methods and exhibits a superior capacity for detecting rumors at early stages.",/pdf/b14b0705a851624f6cabd6fd1e5f9b1e7d13eff6.pdf,,,,,anonymous|detect_lowresource_rumors_in_microblog_posts_via_adversarial_contrastive_learning,,,,,,,,,
652,3EehDxnUXrS,Solving Linear Algebra by Program Synthesis,['aclweb.org/ACL/ARR/2021/November/Paper1589/Authors'],['Anonymous'],"We solve MIT's Linear Algebra 18.06 course and Columbia University's Computational Linear Algebra COMS3251 courses with perfect accuracy by interactive program synthesis. This surprisingly strong result is achieved by turning the course questions into programming tasks and then running the programs to produce the correct answers. We use OpenAI Codex with zero-shot learning, without providing any examples in the prompts, to synthesize code from questions. We quantify the difference between the original question text and the transformed question text that yields a correct answer. Since all COMS3251 questions are not available online the model is not overfitting. We go beyond just generating code for questions with numerical answers by interactively generating code that also results visually pleasing plots as output. Finally, we automatically generate new questions given a few sample questions which may be used as new course content. This work is a significant step forward in solving quantitative math problems and opens the door for solving many university level STEM courses by machine.",/pdf/0753c823cff5c8d7123396b6156be2a1f4161d1d.pdf,,,,,anonymous|solving_linear_algebra_by_program_synthesis,,,,,,,,,
653,8ds7iPDUrls,Pre-training and Fine-tuning Neural Topic Model: A Simple yet Effective Approach to Incorporating External Knowledge,['aclweb.org/ACL/ARR/2021/November/Paper1067/Authors'],['Anonymous'],"Recent years have witnessed growing interests in incorporating external knowledge such as pre-trained word embeddings (PWEs) or pre-trained language models (PLMs) into neural topic modeling. However, we found that employing PWEs and PLMs for topic modeling only achieved limited performance improvements but with huge computational overhead. In this paper, we propose a novel strategy to incorporate external knowledge into neural topic modeling where the neural topic model is pre-trained on a large corpus and then fine-tuned on the target dataset. Experiments have been conducted on three datasets and results show that the proposed approach significantly outperforms both current state-of-the-art neural topic models and some topic modeling approaches enhanced with PWEs or PLMs. Moreover, further study shows that the proposed approach greatly reduces the need for the huge size of training data.",/pdf/7c8f1c65a4f6d817ca39edf5ee520cedef675b40.pdf,,,,,anonymous|pretraining_and_finetuning_neural_topic_model_a_simple_yet_effective_approach_to_incorporating_external_knowledge,,,,,,/attachment/901376ba65c6c67f7fc7ccd7fbb4317cbf40b216.zip,,,
654,whERrjsVCcZ,CluSent – Combining Semantic Expansion and De-Noising for Dataset-Oriented Sentiment Analysis of Short Texts,['aclweb.org/ACL/ARR/2021/November/Paper1138/Authors'],['Anonymous'],"The lack of sufficient information, mainly in short texts, is a major challenge to building effective sentiment models. Short texts can be enriched with more complex semantic relationships that can better capture affective information, with a potential undesired side effect of noise introduced into the data. In this work, we propose a new strategy for customized dataset-oriented sentiment analysis -- CluSent -- that exploits a powerful, recently proposed concept for representing semantically related words -- CluWords. CluSent tackles the issues mentioned above of information shortage and noise by: (i) exploiting the semantic neighborhood of a given pre-trained word embedding to enrich document representation, and (ii) introducing dataset-oriented filtering and weighting mechanisms to cope with noise, which take advantage of the polarity and intensity information from lexicons. In our experimental evaluation, considering 19 datasets,  5 state-of-the-art baselines (including modern transformer architectures) and two metrics, CluSent was the best method in 30 out of 38 possibilities, with significant gains over the strongest baselines (over 14%).",/pdf/7990161ddf52bd1f8777eafc73ad71244c92a593.pdf,,,,,anonymous|clusent_combining_semantic_expansion_and_denoising_for_datasetoriented_sentiment_analysis_of_short_texts,,,,,,/attachment/88bd5c9ea335ccf78d6ee5050023d50c67b23291.zip,,,
655,B_hhBeNshop,Remove Noise and Keep Truth: A Noisy Channel Model for Semantic Role Labeling,['aclweb.org/ACL/ARR/2021/November/Paper1800/Authors'],['Anonymous'],"Semantic role labeling usually models structures using sequences, trees, or graphs. Past works focused on researching novel modeling methods and neural structures and integrating more features. In this paper, we re-examined the noise in neural semantic role labeling models, a problem that has been long-ignored. By proposing a noisy channel model structure, we effectively eliminate the noise in the labeling flow and thus improve performance. Without relying on additional features, our proposed novel model significantly outperforms a strong baseline on multiple popular semantic role labeling benchmarks, which demonstrates the effectiveness and robustness of our proposed model.",/pdf/b6e9658f23d7d54d2928125b4e5664647a331ccc.pdf,,,,,anonymous|remove_noise_and_keep_truth_a_noisy_channel_model_for_semantic_role_labeling,,,,,,,,,
656,HuGPs9-uHP,Research on the Evaluation of Token Imbalance Degree of NMT Corpus,['aclweb.org/ACL/ARR/2021/November/Paper1683/Authors'],['Anonymous'],"As a kind of classifier, neural machine translation (NMT) is known to perform better with balanced tokens during training. Studying the token distribution in NMT corpus is of guiding significance to improve its quality and the translation effect. Due to the existing researches on token imbalance degree have deficiencies in algorithm performance and word segmentation scope, we propose the Dispersion of Token Distribution (DTD) algorithm, and use it to evaluate corpus from three segmentation levels: character, subword and word. Our experiments show that this algorithm has an improvement in accuracy, effectiveness and robustness. Meanwhile, we find that the token imbalance degree of NMT corpus varies greatly at different segmentation levels, among which character has the highest, word has the lowest and subword is in between. In addition, we also find the regularities of token imbalance degree in languages German (DE), English (EN), French (FR) and Russian (RU).",/pdf/06895cb40d58c2248dffb96556c12c39a66ad57c.pdf,,,,,anonymous|research_on_the_evaluation_of_token_imbalance_degree_of_nmt_corpus,,,,,,,,,
657,CJQqdS-fx3K,Boosting coherence of language models,['aclweb.org/ACL/ARR/2021/November/Paper1276/Authors'],['Anonymous'],"Naturality of long-term information structure -- coherence -- remains a challenge in language generation. Large language models have insufficiently learned such structure, as their long-form generations differ from natural text in measures of coherence. To alleviate this divergence, we propose coherence boosting, an inference procedure that increases the effect of distant context on next-token prediction. We show the benefits of coherence boosting with pretrained models by distributional analyses of generated ordinary text and dialog responses. We also find that coherence boosting with state-of-the-art models for various zero-shot NLP tasks yields performance gains with no additional training.",/pdf/97bc3baba2892a4f00956d181251a4ba40ddeb16.pdf,/attachment/8ed82ccdac9f78e996a094244c142e21a6ef53ef.zip,,,,anonymous|boosting_coherence_of_language_models,,,,,,/attachment/55d6c42e60cca5beb9af4c17009af1b777ee5e19.zip,,,
658,9_j8yJ6ISSr,Contrastive Conditional Masked Language Model for Non-autoregressive Neural Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper1334/Authors'],['Anonymous'],"Inspired by the success of contrastive learning in natural language processing, we incorporate contrastive learning into the conditional masked language model which is extensively used in non-autoregressive neural machine translation (NAT) that we term Contrastive Conditional Masked Language Model (CCMLM). CCMLM optimizes the similarity of several different representations of the same token in the same sentence, resulting in a richer and more robust representation. We propose two methods to obtain various representations: Contrastive Common Mask and Contrastive Dropout. Positive pairs are various different representations of the same token, while negative pairs are representations of different tokens. In the feature space, the model with contrastive loss pulls positive pairs together and pushes negative pairs away. We conduct extensive experiments on four translation directions with different data sizes. The results demonstrate that CCMLM showed a consistent and significant improvement with margins ranging from 0.80-1.04 BLEU and is state-of-the-art on WMT'16 Ro-En (34.18 BLEU).",/pdf/341b4389c320c543f058f025ba66f0b6f83ec2e3.pdf,,,,,anonymous|contrastive_conditional_masked_language_model_for_nonautoregressive_neural_machine_translation,,,,,,,,,
659,5_ANw2eDtyl,Fix Bugs with Transformer through a Neural-Symbolic Edit Grammar,['aclweb.org/ACL/ARR/2021/November/Paper613/Authors'],['Anonymous'],"We introduce NSEdit (neural-symbolic edit), a novel Transformer-based code repair method. Given only the source code that contains bugs, NSEdit predicts an editing sequence that can fix the bugs. The edit grammar is formulated as a regular language, and the Transformer uses it as a neural-symbolic scripting interface to generate editing programs. We modify the Transformer and add a pointer network to select the edit locations. An ensemble of rerankers are trained to re-rank the editing sequences generated by beam search. We fine-tune the rerankers on the validation set to reduce over-fitting. NSEdit is evaluated on various code repair datasets and achieved a new state-of-the-art accuracy ($24.04\%$) on the Tufano small dataset of the CodeXGLUE benchmark. NSEdit performs robustly when programs vary from packages to packages and when buggy programs are concrete. We conduct detailed analysis on our methods and demonstrate the effectiveness of each component.",/pdf/52d4f66a2ac30b5268d47fd728be5630361adc03.pdf,,,,,anonymous|fix_bugs_with_transformer_through_a_neuralsymbolic_edit_grammar,,,,,,,,,
660,btMPtNTrVU-,Investigating Crowdsourcing Protocols for Evaluating the Factual Consistency of Summaries,['aclweb.org/ACL/ARR/2021/November/Paper2414/Authors'],['Anonymous'],"Current pre-trained models applied for summarization are prone to factual inconsistencies which misrepresent the source text. Thus, evaluating the factual consistency of summaries is necessary to develop better models. However, the optimal human evaluation setup for factual consistency has not been standardized. To address this issue, we crowdsourced evaluations for factual consistency using the rating-based Likert Scale and ranking-based Best-Worst Scaling to determine the factors that affect the reliability of the human evaluation. Our crowdsourced evaluations are conducted on the summaries of CNN-Daily Mail and XSum datasets generated by four state-of-the-art models. Ranking-based Best-Worst Scaling offers a more reliable measure of summary quality across datasets, and the reliability of Likert ratings highly depends on the target dataset and the evaluation design. To improve the reliability, we extend the scale of the Likert rating to make it more flexible and we present a scoring algorithm for Best-Worst Scaling, called value learning. Our crowdsourcing guidelines and evaluation protocols will be publicly available to facilitate future research on factual consistency in summarization.",/pdf/41064167c4f99774e294cc65704e6fb550482196.pdf,,,,,anonymous|investigating_crowdsourcing_protocols_for_evaluating_the_factual_consistency_of_summaries,,,,,,,/attachment/244cc7979717f9aa3c01a79a5d95c0821b904c91.pdf,https://www.softconf.com/emnlp2021/papers/user/scmd.cgi?scmd=aLogin&passcode=1719X-C3F6F6C3A3,/attachment/944590bddccb9130b267093005847eec53bbe3ee.pdf
661,MCl8iyuFpFL,Probing and Generalization of Metaphorical Knowledge in Pre-Trained Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2962/Authors'],['Anonymous'],"Human languages are full of metaphorical expressions. Metaphors help people understand the world by connecting new concepts and domains to more familiar ones. Large pre-trained language models (PLMs) are therefore assumed to encode metaphorical knowledge useful for NLP systems. In this paper, we investigate this hypothesis for PLMs, by probing metaphoricity information in their encodings, and by measuring the cross-lingual and cross-dataset generalization of this information. We present studies in multiple metaphor detection datasets and in four languages (i.e., English, Spanish, Russian, and Farsi). Our extensive experiments suggest that contextual representations in PLMs do encode metaphorical knowledge, and mostly in their middle layers. The knowledge is transferable between languages and datasets, especially when the annotation is consistent across training and testing sets. Our findings give helpful insights for both cognitive and NLP scientists.",/pdf/e1f6e7aad96ce1a6416331fa475174a9debc0539.pdf,/attachment/57516f427266aa784a8cbaff6d453b57fd584eee.zip,,,,anonymous|probing_and_generalization_of_metaphorical_knowledge_in_pretrained_language_models,,,,,,/attachment/863a730db775b41f1e94f0576a4fb501582ccdb5.zip,/attachment/77eee6eb8d02b802a0c65ae931f8fe381985158b.pdf,https://openreview.net/forum?id=dhHpdiUiwrP&noteId=QLQioixKh8o&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Daclweb.org%2FACL%2FARR%2F2021%2FSeptember%2FAuthors%23your-submissions),/attachment/fc921803fddde843b6019fd5d10e2d614cc92842.pdf
662,HDun3Bd39ja,What does it take to bake a cake? The RecipeRef corpus and anaphora resolution in procedural text,['aclweb.org/ACL/ARR/2021/November/Paper2357/Authors'],['Anonymous'],"Procedural text contains rich anaphoric phenomena yet has not received much attention in NLP. To fill this gap, we investigate the textual properties of two types of procedural text, recipes and chemical patents, and generalize an anaphora annotation framework developed for the chemical domain for modelling anaphoric phenomena in recipes. We apply this framework to annotate the RecipeRef corpus with both bridging and coreference relations. Through comparison to chemical patents, we show the complexity of anaphora resolution in recipes. We demonstrate empirically that transfer learning from the chemical domain improves resolution of anaphora in recipes, suggesting transferability of general procedural knowledge.  The corpus is made available at \url{withheld\_for\_review}.",/pdf/d41cc14d744b7845d49b43e2a662710bb1b5a429.pdf,,,,,anonymous|what_does_it_take_to_bake_a_cake_the_reciperef_corpus_and_anaphora_resolution_in_procedural_text,,,,,,,,,
663,s8J1uDLlufg,Speaker Information Can Guide Models to Better Inductive Biases: A Case Study On Predicting Code-Switching,['aclweb.org/ACL/ARR/2021/November/Paper2466/Authors'],['Anonymous'],"Natural language processing (NLP) models trained on people-generated data can be unreliable because, without any constraints, they can learn from spurious correlations or propagate dangerous biases about personal identities. We hypothesize that enriching models with speaker information in a controlled, educated way can guide them to pick up on relevant inductive biases. For the speaker-driven task of predicting code-switching points in English--Spanish bilingual dialogues, we show that adding sociolinguistically-grounded speaker features as prepended prompts significantly helps to improve accuracy.  We find that by adding influential phrases to the input, speaker-informed models learn useful and explainable linguistic information. To our knowledge, we are the first to incorporate speaker characteristics in the code-switching setup, and more generally, take a step towards developing transparent models that control for biases in person-centric tasks.",/pdf/5064e7a648bf0e048e1946b0a9c4007e6d0f0c8e.pdf,/attachment/b4ba262af8a095d78022522492cd145172c5d318.zip,,,,anonymous|speaker_information_can_guide_models_to_better_inductive_biases_a_case_study_on_predicting_codeswitching,,,,,,/attachment/356fcf4810f098a59e10ea0dea3af602d32fa708.tgz,,,
664,MxkLIlvZU6E,Ensembling and Knowledge Distilling of Large Sequence Taggers for Grammatical Error Correction,['aclweb.org/ACL/ARR/2021/November/Paper1344/Authors'],['Anonymous'],"In this paper, we investigate GEC sequence tagging architecture with focusing on ensembling of the recent cutting-edge Transformers’ encoders in their Large configurations. We encourage ensembling models by majority votes on span-level edits because it's tolerant to the model architecture and vocabulary size. Our best ensemble achieves a new SOTA result, the F_0.5 score of 76.05 on BEA-2019 (test), even without pre-training on synthetic datasets. Also, we perform model distillation of a trained ensemble to generate new training synthetic datasets, ""Troy-Blogs"" and ""Troy-1BW"". Our best single sequence tagging model that is pretrained on generated Troy- datasets in combination with publicly available synthetic PIE dataset achieves a near-SOTA result of the F_0.5 score of 73.21 on BEA-2019 (test). The code, datasets, and trained models are publicly available.",/pdf/db651a05c8091d5d37dddc62c4e729779bf613a6.pdf,/attachment/8cdf134e90a9ea07adef4a95e22abb74975740ab.zip,,,,anonymous|ensembling_and_knowledge_distilling_of_large_sequence_taggers_for_grammatical_error_correction,,,,,,,,,
665,nVTVR4YvX06,Rethinking News Text Classification from a Timeliness Perspective under the Pre-training and Fine-tuning Paradigm,['aclweb.org/ACL/ARR/2021/November/Paper2138/Authors'],['Anonymous'],"Pre-trained language models (PLMs) have made significant progress in NLP. News text classification is one of the most fundamental tasks in NLP, and various existing works have shown that fine-tuned on PLMs could score up to the accuracy of 98% on the target task. It seems that this task has been well-addressed. However, we discover that news timeliness can cause a massive impact on the news text classification, which drops nearly 20% points from the initial results. In this paper, we define timeliness issues in news classification and design the experiment to measure the influence. Moreover, we investigate several methods to recognize and replace obsolete vocabularies. However, the results show that it is difficult to eliminate the impact of news timeliness from the words' perspective. In addition, we propose a set of large-scale, time-sensitive news datasets to facilitate the study of this problem.",/pdf/db759d132f58c6eac38ff39206e52ef0cd196155.pdf,/attachment/d4f1ac8902a1f7a695ab1552094bcac70a8c3288.zip,,,,anonymous|rethinking_news_text_classification_from_a_timeliness_perspective_under_the_pretraining_and_finetuning_paradigm,,,,,,/attachment/1438bfd56c55196689306be25398fb63c6533d1e.zip,,,
666,q3jMqEy4bgX,Efficient Long Sequence Encoding via Synchronization,['aclweb.org/ACL/ARR/2021/November/Paper421/Authors'],['Anonymous'],"Pre-trained Transformer models have achieved successes in a wide range of NLP tasks, but are inefficient when dealing with long input sequences. Existing studies try to overcome this challenge via segmenting the long sequence followed by hierarchical encoding or post-hoc aggregation. We propose a synchronization mechanism for hierarchical encoding. Our approach first identifies anchor tokens across segments and groups them by their roles in the original input sequence. Then inside Transformer layer, anchor embeddings are synchronized within their group via a self-attention module. Our approach is a general framework with sufficient flexibility -- when adapted to a new task, it is easy to be enhanced with the task-specific anchor definitions. Experiments on two representative tasks with different types of long input texts, NarrativeQA summary setting and wild multi-hop reasoning from HotpotQA, demonstrate that our approach is able to improve the global information exchange among segments while maintaining efficiency.",/pdf/ad745c9f0adef5367e48ec0f79e5f63f1022df60.pdf,,,,,anonymous|efficient_long_sequence_encoding_via_synchronization,,,,,,,,,
667,9V5V9O9DCSX,End-to-end Reference-free Single-document Summary Quality Assessment,['aclweb.org/ACL/ARR/2021/November/Paper1911/Authors'],['Anonymous'],"Canonical automatic summary evaluation metrics, such as ROUGE, require the presence of reference summaries, which are often expensive or impractical to obtain, especially in industry applications. Such metrics do not capture linguistic qualities effectively either. To holistically address the limitations, we introduce a reference-free, weakly supervised approach to summary quality assessment. Two negative sampling methods are proposed to generate training samples from massively available document-summary pairs and our approach is as simple as fine-tuning a pre-trained language model using the generated samples on a straightforward task.  Although simple, our strategy outperforms reference-free baselines with substantial improvements nearly all the time at the summary level, and oftentimes at the system level, on TAC2010, RealSumm and  Newsroom datasets. It also outperforms many reference-based metrics including ROUGE on linguistic aspects. 
Our code and models are open-sourced at \url{https://anonymous.4open.science/r/37CF}. ",/pdf/92df7818d528dc6a53830031ed26927c01d47619.pdf,,,,,anonymous|endtoend_referencefree_singledocument_summary_quality_assessment,,,,,,,,,
668,hyQFVwTynuA,Generating a Temporally Coherent Image Sequence for a Story by Multimodal Recurrent Transformers,['aclweb.org/ACL/ARR/2021/November/Paper844/Authors'],['Anonymous'],"Story visualization is a challenging text-to-image generation task for the difficulty of rendering visual details from abstract text descriptions. 
Besides the difficulty of image generation, the generator also need to conform to the narrative of a multi-sentence story input. 
While prior arts in this domain has focused on improving semantic relevance between generated images and input text, controlling the generated images to be temporally consistent still remains as a challenge. To generate a semantically coherent image sequence, we propose an explicit memory controller which can augment the temporal coherence of images in the multi-modal autoregressive transformer, and call Story visualization by MultimodAl Recurrent Transformers or SMART for short. Our method generates high resolution high quality images, outperforming prior works by a significant margin across multiple evaluation metrics on PororoSV dataset.",/pdf/c2a5e0360f278ef89c63eaed34c8a97012ad3465.pdf,,,,,anonymous|generating_a_temporally_coherent_image_sequence_for_a_story_by_multimodal_recurrent_transformers,,,,,,,,,
669,hCOfuizvidH,EventBERT,['aclweb.org/ACL/ARR/2021/November/Paper2536/Authors'],['Anonymous'],"Pre-trained language models (PrLMs) have shown impressive performance in natural language understanding. However, they mainly rest on extracting context-sensitive statistical patterns without explicit modeling of linguistic information such as semantic relationships entailed in natural language. In this work, we propose EventBERT, an event-based semantic representation model that takes BERT as the backbone and refines with event-based structural semantics in terms of graph convolution network. EventBERT benefits simultaneously from rich event-based structures embodied in the graph and contextual semantics learned in pre-trained model BERT. Experimental results on the GLUE benchmark show the effectiveness.",/pdf/a30ab2edcd303a2f639b052375a74c30bcdd9902.pdf,,,,,anonymous|eventbert,,,,,,,,,
670,c9pFDJXSGa5,Phrase-aware Unsupervised Constituency Parsing,['aclweb.org/ACL/ARR/2021/November/Paper1997/Authors'],['Anonymous'],"Recent studies have achieved inspiring success in unsupervised grammar induction using masked language modeling (MLM) as the proxy task. Despite their high accuracy in identifying low-level structures, prior arts tend to struggle in capturing high-level structures like clauses, since the MLM task usually only requires information from local context. In this work, we revisit LM-based constituency parsing from a phrase-centered perspective. Inspired by the natural reading process of human, we propose to regularize the parser with phrases extracted by an unsupervised phrase tagger to help the LM model quickly manage low-level structures. For a better understanding of high-level structures, we propose a phrase-guided masking strategy for LM to emphasize more on reconstructing non-phrase words. We show that the initial phrase regularization serves as an effective bootstrap, and phrase-guided masking improves the identification of high-level structures. Experiments on the public benchmark with two different backbone models demonstrate the effectiveness and generality of our method.",/pdf/5a31ff4a00dbefc00ded43e5dad2562a67b2ba25.pdf,,,,,anonymous|phraseaware_unsupervised_constituency_parsing,,,,,,,,,
671,bmF2qC-CUG,Semantic Role Labeling as Dependency Parsing: Exploring Latent Tree Structures Inside Arguments,['aclweb.org/ACL/ARR/2021/November/Paper358/Authors'],['Anonymous'],"Semantic role labeling (SRL) is a fundamental yet challenging task in the NLP community.
Recent works of SRL mainly fall into two lines: 1) BIO-based; 2) span-based.
Despite ubiquity, they share some intrinsic drawbacks of not explicitly considering internal argument structures, which may potentially hinder the model's expressiveness.
To remedy this, we propose to reduce SRL to a dependency parsing task and regard the flat argument spans as latent subtrees.
In particular, we equip our formulation with a novel span-constrained TreeCRF to make tree structures span-aware, and further extend it to the second-order case.
Experiments on CoNLL05 and CoNLL12 benchmarks reveal that the results of our methods outperform all previous works and achieve the state-of-the-art.",/pdf/73bc5cf3f09ca1d03b7bd9ab9c1ebde6530722af.pdf,,,,,anonymous|semantic_role_labeling_as_dependency_parsing_exploring_latent_tree_structures_inside_arguments,,,,,,,,,
672,h6g0lrtuaYA,MSAMSum: Towards Benchmarking Multi-lingual Dialogue Summarization,['aclweb.org/ACL/ARR/2021/November/Paper2151/Authors'],['Anonymous'],"Dialogue summarization helps users capture salient information from various types of dialogues has received much attention recently. However, current works mainly focus on English dialogue summarization, leaving other languages under exploration. Therefore, we present a multi-lingual dialogue summarization dataset, namely MSAMSum, which covers dialogue-summary pairs in six languages. Specifically, we derive MSAMSum from the standard SAMSum using sophisticated translation techniques and further employ two methods to ensure the integral translation quality and summary factual consistency. Given the proposed MSAMum, we systematically set up five multi-lingual settings for this task, including a novel mix-lingual dialogue summarization setting. To illustrate the utility of our dataset, we benchmark various experiments with pre-trained models under different settings and report results in both supervised and zero-shot manners. We also discuss some future works towards this task to motivate future researches.",/pdf/adfc74d843c7b651b920af987a55923f8b248729.pdf,,,,,anonymous|msamsum_towards_benchmarking_multilingual_dialogue_summarization,,,,,,,,,
673,AxPhYKiSbp,DialFact: A Benchmark for Fact-Checking in Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper1508/Authors'],['Anonymous'],"Fact-checking is an essential tool to mitigate the spread of misinformation and disinformation. We introduce the task of fact-checking in dialogue, which is a relatively unexplored area. We construct DialFact, a testing benchmark dataset of 22,123 annotated conversational claims, paired with pieces of evidence from Wikipedia. There are three sub-tasks in DialFact: 1) Verifiable claim detection task distinguishes whether a response carries verifiable factual information; 2) Evidence retrieval task retrieves the most relevant Wikipedia snippets as evidence; 3) Claim verification task predicts a dialogue response to be supported, refuted, or not enough information. We found that existing fact-checking models trained on non-dialogue data like FEVER} fail to perform well on our task, and thus, we  propose  a  simple  yet  data-efficient solution to effectively improve fact-checking performance in dialogue. We point out unique challenges in DialFact such as handling the colloquialisms, coreferences and retrieval ambiguities in the error analysis to shed light on future research in this direction.",/pdf/11ece6be4871384652956a2d9e133d20bc94ff26.pdf,,,,,anonymous|dialfact_a_benchmark_for_factchecking_in_dialogue,,,,,,,,,
674,C6zRtm5sMzA,Personality Prediction of Narrative Characters from Movie Scripts,['aclweb.org/ACL/ARR/2021/November/Paper747/Authors'],['Anonymous'],"An NLP model that understands stories should be able to understand the characters in them. To support the development of neural models for this purpose, we construct a benchmark, Story2Personality. The task is to predict a movie character’s personality based on the narratives of the character in the movie script. Experiments show that our task is challenging for the existing text classification models, as none is able to largely outperform random guesses. We further proposed a multi-view model to use both verbal and non-verbal descriptions for personality prediction, which gives improvement compared to using only verbal descriptions. The uniqueness and challenges in our dataset call for the development of narrative comprehension techniques from the perspective of understanding characters.
",/pdf/08f896f9b2d6c8b3b5327692b1f7ab17f2f1f449.pdf,,,,,anonymous|personality_prediction_of_narrative_characters_from_movie_scripts,,,,,,,,,
675,eJUGH5CaCJK,"When did you become so smart, oh wise one?! Sarcasm Explanation in Multi-modal Multi-party Dialogues",['aclweb.org/ACL/ARR/2021/November/Paper2157/Authors'],['Anonymous'],"Indirect speech such as sarcasm achieves a constellation of discourse goals in human communication. While the indirectness of figurative language warrants speakers to achieve certain pragmatic goals, it is challenging for AI agents to comprehend such idiosyncrasies of human communication. Though sarcasm identification has been a well-explored topic in dialogue analysis, for conversational systems to truly grasp a conversation's innate meaning and generate appropriate responses, simply detecting sarcasm is not enough; it is vital to explain its underlying sarcastic connotation to capture its true essence. In this work, we study the discourse structure of sarcastic conversations and propose a novel task -- Sarcasm Explanation in Dialogue (SED). Set in a multimodal and code-mixed setting, the task aims to generate natural language explanations of satirical conversations. To this end, we curate WITS, a new dataset to support our task. We propose MAF (Modality Aware Fusion), a multimodal context-aware attention and global information fusion module to capture multimodality and use it to benchmark WITS. The proposed attention module surpasses the traditional multimodal fusion baselines and reports the best performance on almost all metrics. Lastly, we carry out detailed analysis both quantitatively and qualitatively.",/pdf/4fdf64c47ed116d358c0de25e69805ca791162ad.pdf,/attachment/6116b4af76e82b45240c093320d7f630d928ccd6.zip,,,,anonymous|when_did_you_become_so_smart_oh_wise_one_sarcasm_explanation_in_multimodal_multiparty_dialogues,,,,,,/attachment/afe33ba7c143a548abbfed3d6bf1449a0a13fa0e.zip,,,
676,L4cbpTxl72U,Sequence-to-Sequence Multilingual Pre-Trained Models: A Hope for Low-Resource Language Translation?,['aclweb.org/ACL/ARR/2021/November/Paper2141/Authors'],['Anonymous'],"We investigate the capability of mBART, a sequence-to-sequence multilingual pre-trained model in translating low-resource languages under five factors:  the amount of data used in pre-training the original model, the amount of data used in fine-tuning, the noisiness of the data used for fine-tuning, the domain-relatedness between the pre-training, fine-tuning, and testing datasets, and the language relatedness. When limited parallel corpora are available, fine-tuning mBART can measurably improve translation performance over training Transformers from scratch. mBART effectively uses even domain-mismatched text, suggesting that mBART can learn meaningful representations when data is scarce. Still, it founders when too-small data in unseen languages is provided.",/pdf/be83a5955a151e53248864d2f2e3a730739f89af.pdf,/attachment/51608bd3cbc8604892553ee9294089f7696e1d14.zip,,,,anonymous|sequencetosequence_multilingual_pretrained_models_a_hope_for_lowresource_language_translation,,,,,,,,,
677,2csU2MGpRbN,EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1159/Authors'],['Anonymous'],"Multi-triple extraction is a challenging task due to the existence of informative inter-triple correlations and consequently rich interactions across the constituent entities and relations.
While existing works only explore cross-entity interactions, we propose to explicitly introduce relation representation, jointly represent it with entities, and novelly align them to identify valid triples.
We perform comprehensive experiments on document-level relation extraction and joint entity and relation extraction along with detailed ablations to demonstrate the advantage of the proposed method.",/pdf/cfeef32b42ec39afc9111fa270f98ed4cbced083.pdf,,,,,anonymous|emrel_joint_representation_of_entities_and_embedded_relations_for_multitriple_extraction,,,,,,,,,
678,jlflpf7P7QY,Learning to Ignore Adversarial Attacks,['aclweb.org/ACL/ARR/2021/November/Paper1933/Authors'],['Anonymous'],"Despite the strong performance of current NLP models, they can be brittle against adversarial attacks. To enable effective learning against adversarial inputs, we introduce the use of rationale models that can explicitly learn to ignore attack tokens. We find that the rationale models can ignore over 90\% of attack tokens. This approach leads to consistent sizable improvements ($\sim$8\%) over baseline models in robustness, for both BERT and RoBERTa, on MultiRC and FEVER, and also reliably outperforms data augmentation with adversarial examples alone. In many cases, we find that our method is able to close the gap between model performance on a clean test set and an attacked test set, eliminating the effect of adversarial attacks. ",/pdf/fbfb0689bee565611d775aa129436899ebf20568.pdf,,,,,anonymous|learning_to_ignore_adversarial_attacks,,,,,,,,,
679,W31JU1GRB1U,Sparse Progressive Distillation: Resolving  Overfitting under Pretrain-and-Finetune Paradigm,['aclweb.org/ACL/ARR/2021/November/Paper2259/Authors'],['Anonymous'],"Conventional wisdom in pruning Transformer-based language models is that pruning reduces the model expressiveness and thus is more likely to underfit rather than overfit. However, under the trending pretrain-and-finetune paradigm, we postulate a counter-traditional hypothesis, that is: pruning increases the risk of overfitting when performed at the fine-tuning phase. In this paper, 
we aim to address the overfitting problem and improve pruning performance via progressive knowledge distillation with error-bound properties. We show for the first time that reducing the risk of overfitting can help the effectiveness of pruning under the pretrain-and-finetune paradigm. Ablation studies and experiments on the GLUE benchmark show that our method outperforms the leading competitors across different tasks.",/pdf/74651220c0751a2468500a1ac0155cdcca990e97.pdf,/attachment/394f13c7872d41512ad6bc07ca6173617fccfa3a.zip,,,,anonymous|sparse_progressive_distillation_resolving_overfitting_under_pretrainandfinetune_paradigm,,,,,,,,,
680,LNj1U_Sm-l_n,Automode: Choosing the Best Machine Translation Supplier Based on Source Text,['aclweb.org/ACL/ARR/2021/November/Paper2418/Authors'],['Anonymous'],"This study presents Automode, a framework consisting of two quality estimators which, within the wide-range of options available nowadays, aims to automatically select the MT supplier which is more likely to provide a good translation to a source text in terms of fluency and mitigation of gender bias. Among six analysed MT suppliers, results show that a simple machine learning regression can learn how to highly score the supplier which is more likely to generate a fluent translation to a source text, while reducing the translation cost compared to the best performing single supplier in some scenarios. However, for gender-bias we noticed that an open-source supplier is the one which generates the less biased translations regarding gender.",/pdf/e6caaf9230aea181b0f294bbd3233189f5d7210b.pdf,,,,,anonymous|automode_choosing_the_best_machine_translation_supplier_based_on_source_text,,,,,,,,,
681,5pq2nzuClHG,Speech-to-SQL Parsing: Error Correction with Multi-modal Representations,['aclweb.org/ACL/ARR/2021/November/Paper298/Authors'],['Anonymous'],"We study the task of spoken natural language to SQL parsing (speech-to-SQL), where the goal is to map a spoken utterance to the corresponding SQL. Existing work on SQL parsing has focused on text as input (text-to-SQL). To develop a speech-to-SQL parser, we harness progress in text-to-SQL parsing, and automatic speech recognition (ASR). However, ASR is still error-prone, we therefore propose an error correction method that fixes ASR errors in the context of a DB schema. We present a novel multi-modal representation of text, audio, and DB schema with audio attention and a phoneme prediction auxiliary task. Our experiments show that our method yields better performance, is much faster to train, has greater transparency, and is parser-agnostic compared to baselines that seek to adapt to ASR errors.",/pdf/4e1e16b116b1cf2ea74795e0e84d1f68c712ae8e.pdf,,,,,anonymous|speechtosql_parsing_error_correction_with_multimodal_representations,,,,,,,,,
682,6tTmE3JCzMq,Innovative Measures of Patient and Disease Phenotyping: Optimizing Linguistic and Machine Learning Techniques in the Investigation of Electronic Health Record (EHR) Data,['aclweb.org/ACL/ARR/2021/November/Paper1666/Authors'],['Anonymous'],"The complexities of understanding symptomatology, disease progression, patient susceptibility to disease, and the general intricacies of diagnostic medicine challenge the everyday work of medical professionals, negatively impacting patient care and leading to practice variation, clinical error, and unnecessary expense. Phenotyping diseases and defining patient populations is time-consuming and is often impractical with existing tools resulting in slow progress to ascertaining understanding of the diseases and the risk of further disintegration of condition or additional system dysfunction. Although there have been many attempts to leverage electronic health record (EHR) data in the development of various machine learning (ML) models, they have been unable to deliver success in all parameters necessary for effective implementation in a clinical context: performance, transparency, trustworthiness, and interpretability. We introduce a novel ML approach driven by transdisciplinarity and intensive human feedback that offers a resolution to this problem, in which linguistic feature engineering, competitive modeling, and continual human validation delivers the success needed to improve clinical pathways.",/pdf/73f9198ebbefd88b92c38c4661f78efcae7cc104.pdf,,,,,anonymous|innovative_measures_of_patient_and_disease_phenotyping_optimizing_linguistic_and_machine_learning_techniques_in_the_investigation_of_electronic_health_record_ehr_data,,,,,,,,,
683,wVpU93kEGc,On the Effect of Isotropy on VAE Representations of Text,['aclweb.org/ACL/ARR/2021/November/Paper1686/Authors'],['Anonymous'],"Injecting desired geometric properties into text representations has attracted a lot of attention. A property that has been argued for, due to its better utilisation of representation space, is isotropy. In parallel, VAEs have been successful in  areas of NLP, but are known for their sub-optimal utilisation of the representation space. To address an aspect of this, we investigate the impact of injecting isotropy during training of VAEs. We achieve this by using an isotropic Gaussian posterior (IGP) instead of the ellipsoidal Gaussian posterior. We illustrate that IGP effectively encourages isotropy in the representations, inducing a more discriminative latent space. Compared to vanilla VAE, this translates into a much better classification performance, robustness to input perturbation, and generative behavior.  Additionally, we offer insights about the representational properties encouraged by IGP.",/pdf/9b5acff478b4c0e3ba981e0160719be25efb7374.pdf,/attachment/f9930f643c9d979e7e29863e85e70dd9ddf26729.zip,,,,anonymous|on_the_effect_of_isotropy_on_vae_representations_of_text,,,,,,/attachment/78b59a396e1ec0a93a783cc66d199a4fe24e0807.zip,,,
684,DKVhbjXs9aG,Composing Structure-Aware Batches for Pairwise Sentence Classification,['aclweb.org/ACL/ARR/2021/November/Paper1205/Authors'],['Anonymous'],"Identifying the relation between two sentences requires datasets with pairwise annotations. In many cases, these datasets contain instances that are annotated multiple times as part of different pairs. They constitute a structure that contains additional helpful information about the inter-relatedness of the text instances based on the annotations. This paper investigates how this kind of structural dataset information can be exploited during training.
We propose three batch composition strategies to incorporate such information and measure their performance over 14 heterogeneous pairwise sentence classification tasks. Our results show statistically significant improvements (up to 3.9%) - independent of the pre-trained language model - for most tasks compared to baselines that follow a standard training procedure. Further, we see that even this baseline procedure can profit from having such structural information in a low-resource setting.",/pdf/927b1d9e090505f2fe2962fe8265003ec318eb85.pdf,,,,,anonymous|composing_structureaware_batches_for_pairwise_sentence_classification,,,,,,,/attachment/6c085b71f1bd8ddf7ca61a39fd06024d741cc7d6.pdf,https://openreview.net/forum?id=Kiq348eXUHw,/attachment/31fc771f8bc428e7b7ce165cbbe915e3e766fdec.pdf
685,tVF2KuTau5g,Exploiting Data Characteristics for Document-level Event Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1164/Authors'],['Anonymous'],"Document-level event extraction (DEE) extracts structured information of events from a document. Previous studies focus on improving the model architecture. We propose to exploit data characteristics: 1) we utilize more coreference information to obtain better document-level entity representations; 2) we manually identify core roles of each event type and propose the hybrid extraction to shallow the memory and alleviate error propagation. Experiments on a large dataset demonstrate that our methods significantly improve model performance on both the role-level and record-level metrics. Our code is available at https://github.com/coszeros/CAB.
",/pdf/cc86f1579c0f79fea8d09bf352997ea7ebbf7992.pdf,,,,,anonymous|exploiting_data_characteristics_for_documentlevel_event_extraction,,,,,,,,,
686,eT83GooycXa,ReCLIP: A Strong Zero-Shot Baseline for Referring Expression Comprehension,['aclweb.org/ACL/ARR/2021/November/Paper2190/Authors'],['Anonymous'],"Training a referring expression comprehension (ReC) model for a new visual domain requires collecting referring expressions, and potentially corresponding bounding boxes, for images in the domain. While large-scale pre-trained models are useful for image classification across domains, it remains unclear if they can be applied  in a zero-shot manner  to  more  complex tasks like ReC. We present ReCLIP, a simple but strong zero-shot baseline that repurposes CLIP, a state-of-the-art large-scale model, for ReC. Motivated by  the close connection between ReC and CLIP’s contrastive pre-training objective, the first component of ReCLIP is a region-scoring method that isolates object proposals via cropping and blurring, and passes them to CLIP. However, through controlled experiments on a synthetic dataset, we find that CLIP is largely incapable of performing spatial reasoning off-the-shelf. Thus, the second component of ReCLIP is a spatial relation resolver that handles several types of spatial relations. We reduce the gap between zero-shot baselines from prior work and supervised models by as much as 30% on RefCOCOg, and on RefGTA (video game imagery), we outperform supervised ReC models trained on real images by an absolute 12%.",/pdf/f3af1ffe20e865d0f2e1d893aab8002546bf0966.pdf,,,,,anonymous|reclip_a_strong_zeroshot_baseline_for_referring_expression_comprehension,,,,,,,,,
687,U-e3OTlgXwW,Synthetic Question Value Estimation for Domain Adaptation of Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper1596/Authors'],['Anonymous'],"Synthesizing QA pairs with a question generator (QG) on the target domain has become a popular approach for domain adaptation of question answering (QA) models. Since synthetic questions are often noisy in practice, existing work adapts scores from a pretrained QA (or QG) model as criteria to select high-quality questions. However, these scores do not directly serve the ultimate goal of improving QA performance on the target domain. In this paper, we introduce a novel idea of training a question value estimator (QVE) that directly estimates the usefulness of synthetic questions for improving the target-domain QA performance. By conducting comprehensive experiments, we show that the synthetic questions selected by QVE can help achieve better target-domain QA performance, in comparison with existing techniques. We additionally show that by using such questions and only around 15% of the human annotations on the target domain, we can achieve comparable performance to the fully-supervised baselines.",/pdf/628cb979ac6335eab5dc75e48f18f141ee3af50c.pdf,,,,,anonymous|synthetic_question_value_estimation_for_domain_adaptation_of_question_answering,,,,,,,,,
688,u2Pt8ULp7Kd,Unsupervised Keyphrase Extraction via Interpretable Neural Networks,['aclweb.org/ACL/ARR/2021/November/Paper2203/Authors'],['Anonymous'],"Keyphrase extraction aims at automatically extracting a list of ""important'' phrases which represent the key concepts in a document. Traditionally, it has been approached from an information-theoretic angle using phrase co-occurrence statistics. This work proposes a novel unsupervised approach to keyphrase extraction that uses a more intuitive notion of phrase importance, inspired by interpretability research. In particular, we use a self-explaining neural model to measure the predictive impact of input phrases on downstream task performance, and consider the resulting interpretations as document keyphrases for the target task. We show the efficacy of our approach on four datasets in two domains---scientific publications and news articles---attaining state-of-the-art results in unsupervised keyphrase extraction. ",/pdf/20088e3d36d96c7d0ae6841efde34e02ab39a990.pdf,/attachment/0a8e29f149d24580ae7e150deb29d614e0d3e47c.zip,,,,anonymous|unsupervised_keyphrase_extraction_via_interpretable_neural_networks,,,,,,,,,
689,Zo4-42mBGex,Are We NER Yet? Measuring the Impact of ASR Errors on Named Entity Recognition in Spontaneous Conversation Transcripts,['aclweb.org/ACL/ARR/2021/November/Paper1399/Authors'],['Anonymous'],"Transcriptions of spontaneous human conversations present a significant obstacle for traditional NER models trained on prescriptive written language. The lack of grammatical structure of spoken utterances, combined with word errors introduced by the ASR, makes downstream NLP tasks challenging. In this paper, we examine the impact of ASR errors on the ability of NER models to recover entity mentions from transcripts of spontaneous human conversations in English. We experimentally compare several commercial ASR systems paired with state-of-the-art NER models. We use both publicly available benchmark datasets (Switchboard Named Entity Corpus, SWNE), and the proprietary, real-life dataset of gold (human-transcribed) phone conversation transcripts. To measure the performance of NER models on ASR transcripts, we introduce a new method of token alignment between transcripts. Our findings unequivocally show that NER models trained on the written language struggle when processing transcripts of spontaneous human conversations. The presence of ASR errors only exacerbates the problem.",/pdf/106a4fcc727c297f2d6d9fba71741b147b520d7e.pdf,,,,,anonymous|are_we_ner_yet_measuring_the_impact_of_asr_errors_on_named_entity_recognition_in_spontaneous_conversation_transcripts,,,,,,,,,
690,iqKzson-1Tl,Hierarchical Recurrent Aggregative Generation for Few-Shot NLG,['aclweb.org/ACL/ARR/2021/November/Paper2744/Authors'],['Anonymous'],"Large pretrained models enable transfer learning to low-resource domains for language generation tasks. However, previous end-to-end approaches do not account for the fact that some generation sub-tasks, specifically aggregation and lexicalisation, can benefit from transfer learning in different extents. To exploit these varying potentials for transfer learning, we propose a new hierarchical approach for few-shot and zero-shot generation. Our approach consists of a three-moduled jointly trained architecture: the first module independently lexicalises the distinct units of information in the input as sentence sub-units (e.g. phrases), the second module recurrently aggregates these sub-units to generate a unified intermediate output, while the third module subsequently post-edits it to generate a coherent and fluent final text. We perform extensive empirical analysis and ablation studies on few-shot and zero-shot settings across 4 datasets. Automatic and human evaluation shows that the proposed hierarchical approach is consistently capable of achieving state-of-the-art results when compared to previous work.",/pdf/18a5efb1e9e3ac6ad3026650fc7bdaf99d99734b.pdf,,,,,anonymous|hierarchical_recurrent_aggregative_generation_for_fewshot_nlg,,,,,,,/attachment/343f41984712320b4fcd7fb2e80cb70eae7fe247.pdf,https://openreview.net/forum?id=eqRNs_CGR50,/attachment/f72ce582921175c548e6be0ad71b966f6b8a5b22.pdf
691,p91q-66Svih,PREME: Preference-based Meeting Exploration through an Interactive Questionnaire,['aclweb.org/ACL/ARR/2021/November/Paper2347/Authors'],['Anonymous'],"The recent increase in the volume of online meetings necessitates automated tools for managing and organizing the material,  especially when an attendee has missed the discussion and needs assistance in quickly exploring it.  In  this work,   we propose a  novel end-to-end framework for generating interactive questionnaires for preference-based meeting exploration.  As a result, users are supplied with a list of suggested questions reflecting their preferences.  Since the task is new,  we introduce an automatic evaluation strategy.   Namely,  it measures how much the generated questions via questionnaire are answerable to ensure factual correctness and covers the source meeting for the depth of possible exploration.",/pdf/d0de745bc4c14746b649d855b7838177062c1f84.pdf,,,,,anonymous|preme_preferencebased_meeting_exploration_through_an_interactive_questionnaire,,,,,,,,,
692,4KcQD40NlSM,MIMICause: Representation and automatic extraction of causal relation types from clinical notes,['aclweb.org/ACL/ARR/2021/November/Paper850/Authors'],['Anonymous'],"Understanding causal narratives communicated in clinical notes can help make strides towards personalized healthcare. Extracted causal information from clinical notes can be combined with structured EHR data such as patients' demographics, diagnoses, and medications. This will enhance healthcare providers' ability to identify aspects of a patient's story communicated in the clinical notes and help make more informed decisions.  

In this work, we propose annotation guidelines, develop an annotated corpus and provide baseline scores to identify types and direction of causal relations between a pair of biomedical concepts in clinical notes; communicated implicitly or explicitly, identified either in a single sentence or across multiple sentences. 

We annotate a total of 2714 de-identified examples sampled from the 2018 n2c2 shared task dataset and train four different language model based architectures. Annotation based on our guidelines achieved a high inter-annotator agreement i.e. Fleiss' kappa ($\kappa$) score of 0.72, and our model for identification of causal relations achieved a macro F1 score of 0.56 on the test data. The high inter-annotator agreement for clinical text shows the quality of our annotation guidelines while the provided baseline F1 score sets the direction for future research towards understanding narratives in clinical texts. ",/pdf/6b0b526f18a3833dddea31082beb1aaf76997ea2.pdf,,,,,anonymous|mimicause_representation_and_automatic_extraction_of_causal_relation_types_from_clinical_notes,,,,,,,,,
693,xdbuU2dUa9O,Is Attention Explanation? An Introduction to the Debate,['aclweb.org/ACL/ARR/2021/November/Paper1118/Authors'],['Anonymous'],"The performance of deep learning models in NLP and other fields of machine learning has led to a rise in their popularity, and so the need for explanations of these models becomes paramount. Attention has been seen as a solution to increase performance, while providing some explanations. However, a debate has started to cast doubt on the explanatory power of attention in neural networks. Although the debate has created a vast literature thanks to contributions from various areas, the lack of communication is becoming more and more tangible. In this paper, we provide a clear overview of the insights on the debate by critically confronting works from these different areas. This holistic vision can be of great interest for future works in all the communities concerned by this debate. We sum up the main challenges spotted in these areas, and we conclude by discussing the most promising future avenues on attention as an explanation.",/pdf/731fe6330cb485130282af779eb7914457817e38.pdf,,,,,anonymous|is_attention_explanation_an_introduction_to_the_debate,,,,,,,,,
694,3n6KslGuhHD,Offensive Text Detection Across Languages and Datasets Using Rule-based and Hybrid Methods,['aclweb.org/ACL/ARR/2021/November/Paper2379/Authors'],['Anonymous'],"We investigate the potential of rule-based systems for the task of offensive text detection in English and German, and demonstrate their effectiveness in low-resource settings, as an alternative or addition to transfer learning across tasks and languages. Task definitions and annotation guidelines used by existing datasets show great variety, hence state-of-the-art machine learning models do not transfer well across datasets or languages. Furthermore, such systems lack explainability and pose a critical risk of unintended bias. We present simple rule systems based on semantic graphs for classifying offensive text in two languages and provide both quantiative and qualitative comparison of their performance with deep learning models on 5 datasets across multiple languages and shared tasks.",/pdf/ba825dd6b40a8f951c502660f565a0aecc504d6f.pdf,,,,,anonymous|offensive_text_detection_across_languages_and_datasets_using_rulebased_and_hybrid_methods,,,,,,,,,
695,FXZuJcgDpgF,A Sentence is Worth 128 Pseudo Tokens: A Semantic-Aware Contrastive Learning Framework for Sentence Embeddings,['aclweb.org/ACL/ARR/2021/November/Paper1288/Authors'],['Anonymous'],"Contrastive learning has shown great potential in unsupervised sentence embedding tasks, e.g., SimCSE \citep{gao2021simcse}.
However, these existing solutions are heavily affected by superficial features like the length of sentences or syntactic structures. In this paper, we propose a semantic-aware contrastive learning framework for sentence embeddings, termed Pseudo-Token BERT (PT-BERT), which is able to explore the pseudo-token space (i.e., latent semantic space) representation of a sentence while eliminating the impact of superficial features such as sentence length and syntax. Specifically, we introduce an additional pseudo token embedding layer independent of the BERT encoder to map each sentence into a sequence of pseudo tokens in a fixed length. Leveraging these pseudo sequences, we are able to construct same-length positive and negative pairs based on the attention mechanism to perform contrastive learning. In addition, we utilize both the gradient-updating and momentum-updating encoders to encode instances while dynamically maintaining an additional queue to store the representation of sentence embeddings, enhancing the encoder's learning performance for negative examples. Experiments show that our model outperforms the state-of-the-art baselines on six standard semantic textual similarity (STS) tasks. Furthermore, experiments on alignments and uniformity losses, as well as hard examples with different sentence lengths and syntax, consistently verify the effectiveness of our method.",/pdf/eb87f616945257f8a72c238a20b15e6c27d505c4.pdf,,,,,anonymous|a_sentence_is_worth_128_pseudo_tokens_a_semanticaware_contrastive_learning_framework_for_sentence_embeddings,,,,,,,,,
696,5jsRMDNddKZ,Top-Down Influence? Predicting CEO Personality and Risk Impact from Speech Transcripts,['aclweb.org/ACL/ARR/2021/November/Paper2742/Authors'],['Anonymous'],"How much does a CEO's personality impact the performance of their company? Management theory posits a great influence, but it is difficult to show empirically---there is a lack of publicly available self-reported personality data of top managers. Instead, we propose a text-based personality regressor based on crowd-sourced MBTI assessments. The ratings have a high internal and external validity and can be predicted with moderate to strong correlations for three out of for dimensions. Providing evidence for the upper echelons theory, we demonstrate that the predicted CEO personalities have explanatory power of financial risk.",/pdf/734cdd550a849bc3c009dbee43c5fae97ce10f2b.pdf,/attachment/36b4110a475c0fb6707d4d9300851b3965dce49b.zip,,,,anonymous|topdown_influence_predicting_ceo_personality_and_risk_impact_from_speech_transcripts,,,,,,/attachment/52384095516e6d9076257c6ba5b39a526f0f6625.zip,/attachment/c1b5ee7dc119f1ea250cda3ce310ddb8a55881ae.pdf,https://openreview.net/forum?id=h45YPjctju9,/attachment/7d8f07aea60a510989b723c7b03a6d53bcab3025.pdf
697,5f4gKU3img0,An Investigation of the (In)effectiveness of Counterfactually Augmented Data,['aclweb.org/ACL/ARR/2021/November/Paper1963/Authors'],['Anonymous'],"While pretrained language models achieve excellent performance on natural language understanding benchmarks, they tend to rely on spurious correlations and generalize poorly to out-of-distribution (OOD) data. Recent work has explored using counterfactually-augmented data (CAD)---data generated by minimally perturbing examples to flip the ground-truth label---to identify robust features that are invariant under distribution shift. However, empirical results using CAD during training for OOD generalization have been mixed. To explain this discrepancy, through a toy theoretical example and empirical analysis on two crowdsourced CAD datasets, we show that: (a) while features perturbed in CAD are indeed robust features, it may prevent the model from learning unperturbed robust features; and (b) CAD may exacerbate existing spurious correlations in the data. Our results thus show that the lack of perturbation diversity limits CAD's effectiveness on OOD generalization, calling for innovative crowdsourcing procedures to elicit diverse perturbation of examples.",/pdf/933cedd954c2fb8741e7d24450e8d5862622f035.pdf,/attachment/6917fa787ab424f438170570b8da80b39ad32453.zip,,,,anonymous|an_investigation_of_the_ineffectiveness_of_counterfactually_augmented_data,,,,,,,/attachment/404e53deb79329e1b70e8b3a0c319ae97c42ba12.pdf,https://openreview.net/forum?id=DAiDafTZE7T,/attachment/34f52abe2598c9b2261bc86491adfbcf3a5c0987.pdf
698,ps4ihHcV19,Maximum Proxy-Likelihood Estimation for Non-autoregressive Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper2599/Authors'],['Anonymous'],"Maximum Likelihood Estimation (MLE) is commonly used in machine translation, where models with higher likelihood are assumed to perform better in translation. However, this assumption does not hold in the non-autoregressive Transformers (NATs), a new family of translation models. In this paper, we present both theoretical and empirical analysis on why simply maximizing the likelihood does not produce a good NAT model. Based on the theoretical analysis, we propose Maximum Proxy-Likelihood Estimation (MPLE), a novel method to address the training issue in MLE. Additionally, MPLE provides a novel perspective to understand existing success in training NATs, namely much previous work can be regarded as implicitly optimizing our objective.",/pdf/76cb032c5e03d280535a4e5c8a34ced9cc2350a2.pdf,,,,,anonymous|maximum_proxylikelihood_estimation_for_nonautoregressive_machine_translation,,,,,,,/attachment/0263c8c85381c4faaf4f1767d2ddb900072a8ec1.pdf,https://openreview.net/forum?id=XfOsW3R9bI2,/attachment/7aef9c35585d967d4aa19fe6656515d000625806.pdf
699,A3o2LyGc9K_,Semantic-Oriented Unlabeled Priming for Large-Scale Language Models,['aclweb.org/ACL/ARR/2021/November/Paper2297/Authors'],['Anonymous'],"Due to the high costs associated with finetuning large language models, various recent works propose to adapt them to specific tasks without any parameter updates through in-context learning. Unfortunately, for in-context learning there is currently no way to leverage unlabeled data, which is often much easier to obtain in large quantities than labeled examples. In this work, we therefore investigate ways to make use of unlabeled examples to improve the zero-shot performance of pretrained language models without any finetuning: We introduce Semantic-Oriented Unlabeled Priming (SOUP), a method that classifies examples by retrieving semantically similar unlabeled examples, assigning labels to them in a zero-shot fashion, and then using them for in-context learning. We also propose bag-of-contexts priming, a new priming strategy that is more suitable for our setting and enables the usage of more examples than fit into the context window.",/pdf/85c2ec61e27560ae67bc7b1692040319bb0b3493.pdf,,,,,anonymous|semanticoriented_unlabeled_priming_for_largescale_language_models,,,,,,,,,
700,y1DoH6Y75rK,Prix-LM: Pretraining for Multilingual Knowledge Base Construction,['aclweb.org/ACL/ARR/2021/November/Paper1568/Authors'],['Anonymous'],"Knowledge bases (KBs) contain plenty of structured world and commonsense knowledge. As such, they often complement distributional text-based information and facilitate various downstream tasks. Since their manual construction is resource- and time-intensive, recent efforts have tried leveraging large pretrained language models (PLMs) to generate additional monolingual knowledge facts for KBs. However, such methods have not been attempted for building and enriching multilingual KBs. Besides wider application, such multilingual KBs can provide richer combined knowledge than monolingual (e.g., English) KBs. Knowledge expressed in different languages may be complementary and unequally distributed: this implies that the knowledge available in high-resource languages can be transferred to low-resource ones. To achieve this, it is crucial to represent multilingual knowledge in a shared/unified space. To this end, we propose a unified representation model, Prix-LM, for multilingual KB construction and completion. We leverage two types of knowledge, monolingual triples and cross-lingual links, extracted from existing multilingual KBs, and tune a multilingual language encoder XLM-R via a causal language modeling objective. Prix-LM integrates useful multilingual and KB-based factual knowledge into a single model. Experiments on standard entity-related tasks, such as link prediction in multiple languages, cross-lingual entity linking and bilingual lexicon induction, demonstrate its effectiveness, with gains reported over strong task-specialised baselines.",/pdf/3b69633f79502a6581e7da8325f5d9adc2b8079c.pdf,,,,,anonymous|prixlm_pretraining_for_multilingual_knowledge_base_construction,,,,,,,,,
701,syGBvV6axrY,SANCL: Multimodal Review Helpfulness Prediction with Selective Attention and Natural Contrastive Learning,['aclweb.org/ACL/ARR/2021/November/Paper1895/Authors'],['Anonymous'],"With the boom of e-commerce, Multimodal Review Helpfulness Prediction (MRHP) that identifies the helpfulness score of multimodal product reviews has become a research hotspot. Previous work on this task focuses on attention-based modality fusion, information integration, and relation modeling, which primarily exposes the following drawbacks: 1) the model may fail to capture the real essential information due to the indiscriminate attention formulation; 2) analysis on relations and proper formulation are missing, generating noise samples and degenerating the modeling quality. In this paper, we propose SANCL: Selective Attention and Natural Contrastive Learning for MRHP. SANCL adopts a probe-based strategy to enforce high attention weights on the regions of greater significance. It also constructs a contrastive learning framework based on natural matching properties in the dataset. Experimental results on two benchmark datasets with three categories show that SANCL achieves state-of-the-art baseline performance with lower memory consumption.",/pdf/00a07d8cfb05a19476396b2d9f3ec33f5d8f99a4.pdf,/attachment/b7c6d433ec6e922dd3aa924fb229eafa9b32aec1.tgz,,,,anonymous|sancl_multimodal_review_helpfulness_prediction_with_selective_attention_and_natural_contrastive_learning,,,,,,,,,
702,ePRpn99yhJi,Towards Few-shot Entity Recognition in Document Images: A Label-aware Sequence-to-Sequence Framework,['aclweb.org/ACL/ARR/2021/November/Paper740/Authors'],['Anonymous'],"Entity recognition is a fundamental task in understanding document images. Traditional sequence labeling framework requires extensive datasets and high-quality annotations, which are typically expensive in practice. In this paper, we aim to build an entity recognition model based on only a few shots of annotated document images. To overcome the data limitation, we propose to leverage the label surface names to better inform the model of the target entity semantics. Specifically, we go beyond sequence labeling and develop a novel label-aware seq2seq framework, LASER. We design a new labeling scheme that generates the label surface names word-by-word explicitly after generating the entities. Moreover, we design special layout identifiers to capture the spatial correspondence between regions and labels. During training, LASER refines the label semantics by updating the label surface name representations and also strengthens the label-region correlation. In this way, LASER recognizes the entities from document images through both semantic and layout correspondence. Extensive experiments on two benchmark datasets demonstrate the superiority of LASER under the few-shot setting. ",/pdf/78884769e1f20c8f1d9f8e31f403c4be9b43d544.pdf,,,,,anonymous|towards_fewshot_entity_recognition_in_document_images_a_labelaware_sequencetosequence_framework,,,,,,/attachment/d6e7df72970b5224751ac0979a5085414dd0b212.zip,,,
703,OXXX_dfeH7v,Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition,['aclweb.org/ACL/ARR/2021/November/Paper721/Authors'],['Anonymous'],"Nested entities are observed in many domains due to their compositionality, which cannot be easily recognized by the widely-used sequence labeling framework.
A natural solution is to treat the task as a span classification problem.
To learn better span representation and increase classification performance, it is crucial to effectively integrate heterogeneous factors including inside tokens, boundaries, labels, and related spans which could be contributing to nested entities recognition.
To fuse these heterogeneous factors, we propose a novel triaffine mechanism including triaffine attention and scoring.
Triaffine attention uses boundaries and labels as queries, and uses inside tokens and related spans as keys and values for span representations.
Triaffine scoring interacts with boundaries and span representations for classification.
Experiments show that our proposed method achieves the state-of-the-art $F_1$ scores on four nested NER datasets: ACE2004,  ACE2005, GENIA, and KBP2017.",/pdf/19249cd08881f1c3f229304bd18ba5c059d7c334.pdf,/attachment/57716205ebde5e119c0ced83b77ba8c367596d93.zip,,,,anonymous|fusing_heterogeneous_factors_with_triaffine_mechanism_for_nested_named_entity_recognition,,,,,,,,,
704,tN-UlSrCBgM,Continual Few-shot Relation Learning via Embedding Space Regularization and Data Augmentation,['aclweb.org/ACL/ARR/2021/November/Paper2006/Authors'],['Anonymous'],"Existing continual relation learning (CRL) methods rely on plenty of labeled training data for learning a new task, which can be hard to acquire in real scenario as getting large and representative labeled data is often expensive and time-consuming. It is therefore necessary for the model to learn novel relational patterns with very few labeled data while avoiding catastrophic forgetting of previous task knowledge. In this paper, we formulate this challenging yet practical problem as continual few-shot relation learning (CFRL). Based on the finding that learning for new emerging few-shot tasks often results in feature distributions that are incompatible with previous tasks' learned distributions, we propose a novel method based on embedding space regularization and data augmentation. Our method generalizes to new few-shot tasks and avoids catastrophic forgetting of previous tasks by enforcing extra constraints on the relational embeddings and by adding extra {relevant} data in a self-supervised manner. With extensive experiments we demonstrate that our method can significantly outperform previous state-of-the-art methods in CFRL task settings.",/pdf/adb5e17588a088715b1be2c20793709c46e12463.pdf,/attachment/c0d7bd4637c749d09bb5eab9f9d703351686afbd.zip,,,,anonymous|continual_fewshot_relation_learning_via_embedding_space_regularization_and_data_augmentation,,,,,,/attachment/11a8f2c88c902f0c283448d6b1fced697fcd19c6.zip,/attachment/c3f7a846306f4f944bc886cb079546a03c0157cb.pdf,https://openreview.net/forum?id=QbNdfN86b62,/attachment/9f61302f24523c9bc15f3e58f2892646e8cf3de1.pdf
705,Z2EA4hRCjTi,Consecutive Task-oriented Dialog Policy Learning,['aclweb.org/ACL/ARR/2021/November/Paper425/Authors'],['Anonymous'],"A practical dialog policy agent must be flexible and can handle new scenarios easily. To achieve this, the agent should be able to expand its knowledge base. This must be done, however, without affecting the agent's performance. Nevertheless, existing dialog systems fail to do so. In practice, new knowledge expansion and old experience preservation concurrently are conflicting. This is a challenging task which occurs regularly in continual learning. We present a novel model which can conduct consecutive dialog policy learning for a series of tasks without catastrophic forgetting. We tackle the issue from three different aspects: (1) For effective old task preservation, we employ a continual Q-learning module which is based on replayed experience to retain the policy trained on historic tasks. (2) For efficient new task acquisition, we integrate an invariant risk minimization module to learn a stable policy predictor to avoid spurious corrections in the training data.  (3) For saving for storing the replayed experiences, we introduce a linear-decay replay buffer management. The effectiveness of the proposed model is evaluated theoretically and experimentally by both simulation and human.",/pdf/4a9cab4d1a44c5eb1a178d4dea377c683574f7d3.pdf,,,,,anonymous|consecutive_taskoriented_dialog_policy_learning,,,,,,,,,
706,IGAZ8wmBozW,Extreme Multi-label Text Classification with Multi-layer Experts,['aclweb.org/ACL/ARR/2021/November/Paper2092/Authors'],['Anonymous'],"Extreme multi-label text classification (XMTC) is the task of tagging each document with the relevant labels from a very large space of predefined categories, which presents an open challenge in the recent development of neural classifiers.  Popular Transformer-based XMTC methods typically use the last-layer features to represent the document and to match it against candidate labels.  We argue that the last-layer features may not be sufficient for predicting labels at different levels of semantic granularity, and that multi-layer features may offer a better choice instead.  Based on this insight we propose a novel multi-expert model, namely ME-XML (Multiple Experts for XMTC), which combines multi-layer embeddings in Transformer for improving the prediction power of the model.",/pdf/2fb469f6c5be30e043572ff0f8a0882b555983c8.pdf,,,,,anonymous|extreme_multilabel_text_classification_with_multilayer_experts,,,,,,,,,
707,MgEOyth-DZQ,Towards Robust Online Dialogue Response Generation,['aclweb.org/ACL/ARR/2021/November/Paper559/Authors'],['Anonymous'],"Although pre-trained sequence-to-sequence models have achieved great success in dialogue response generation, chatbots still suffer from generating inconsistent responses in real-world practice, especially in multi-turn settings. We argue that this can be caused by a discrepancy between training and real-world testing. At training time, chatbots generate response with the golden context, while it has to generate based on the context consisting of both user utterances and the model predicted utterances during real-world testing. With the growth of the number of utterances, this discrepancy becomes more serious in the multi-turn settings. In this paper, we propose a hierarchical sampling-based method consisting of both utterance-level sampling and semi-utterance-level sampling, to alleviate the discrepancy, which implicitly increases the dialogue coherence. We further adopt reinforcement learning and re-ranking methods to explicitly optimize the dialogue coherence during training and inference, respectively. Empirical experiments show the effectiveness of the proposed methods for improving the robustness of chatbots in real practice.",/pdf/953e9fbec801473766a105e026d2bb02730e879f.pdf,/attachment/98ab10016bae877e60a0ab4e22846b2e7dbcdddd.zip,,,,anonymous|towards_robust_online_dialogue_response_generation,,,,,,,,,
708,wJTFHhrpPIU,Rewire-then-Probe: A Contrastive Recipe for Probing Biomedical Knowledge of Pre-trained Language Models,['aclweb.org/ACL/ARR/2021/November/Paper1163/Authors'],['Anonymous'],"Knowledge probing is crucial for understanding the knowledge transfer mechanism behind the pre-trained language models (PLMs). Despite the growing progress of probing knowledge for PLMs in the general domain, specialised areas such as the biomedical domain are vastly under-explored. To facilitate this, we release a well-curated biomedical knowledge probing benchmark, MedLAMA, constructed based on the Unified Medical Language System~(UMLS) Metathesaurus. We test a wide spectrum of state-of-the-art PLMs and probing approaches on our benchmark, reaching at most $3\%$ of acc@10. While highlighting various sources of domain-specific challenges that amount to this underwhelming performance, we illustrate that the underlying PLMs have a higher potential for probing tasks. To achieve this, we propose Contrastive-Probe, a novel self-supervised contrastive probing approach, that adjusts the underlying PLMs without using any probing data. While Contrastive-Probe pushes the acc@10 to $28\%$, the performance gap still remains notable. Our human expert evaluation suggests that the probing performance of our Contrastive-Probe is still under-estimated as UMLS  still does not include the full spectrum of factual knowledge. We hope MedLAMA and Contrastive-Probe facilitate further developments of more suited probing techniques for this domain.",/pdf/9f29bfe526df9cb8a9572e37e573033fa5b35df0.pdf,/attachment/ed561e08c6347c8702b4303b5b00a39e77835322.zip,,,,anonymous|rewirethenprobe_a_contrastive_recipe_for_probing_biomedical_knowledge_of_pretrained_language_models,,,,,,/attachment/7cb9b8378722f0de4fc0c5626b9073a0cefa9834.zip,,,
709,FPpE1tWkC5,Topic-Aware Response Generation in Task-Oriented Dialogue with Unstructured Knowledge Access,['aclweb.org/ACL/ARR/2021/November/Paper1910/Authors'],['Anonymous'],"To alleviate the problem of structured databases' limited coverage, recent task-oriented dialogue systems incorporate external unstructured knowledge to guide the generation of system responses. However, these usually use word or sentence level similarities to detect the relevant knowledge context, which only partially captures the topical level relevance. In this paper, we examine how to better integrate topical information in knowledge grounded task-oriented dialogue and propose ``Topic-Aware Response Generation'' (TARG), an end-to-end response generation model. TARG incorporates multiple topic-aware attention mechanisms to derive the importance weighting scheme over dialogue utterances and external knowledge sources towards a better understanding of the dialogue history. Experimental results indicate that TARG achieves state-of-the-art performance in knowledge selection and response generation, outperforming previous state-of-the-art by 3.2, 3.6, and 4.2 points in EM, F1 and BLEU-4 respectively on Doc2Dial, and performing comparably with previous work on DSTC9; both being knowledge-grounded task-oriented dialogue datasets.\footnote{Code will be made public on the paper's acceptance.}",/pdf/901c4cd5cf3c92b0d6cf315280ded51a383039c0.pdf,,,,,anonymous|topicaware_response_generation_in_taskoriented_dialogue_with_unstructured_knowledge_access,,,,,,,,,
710,i6tHdctpIc2,Cross-Utterance Conditioned VAE for Non-Autoregressive Text-to-Speech,['aclweb.org/ACL/ARR/2021/November/Paper1719/Authors'],['Anonymous'],"Modelling prosody variation is critical for synthesizing natural and expressive speech in end-to-end text-to-speech (TTS) systems. In this paper, a cross-utterance conditional VAE (CUC-VAE) is proposed to estimate a posterior probability distribution of the latent prosody features for each phoneme by conditioning on acoustic features, speaker information, and text features obtained from both past and future sentences. At inference time, instead of the standard Gaussian distribution used by VAE, CUC-VAE allows sampling from an utterance-specific prior distribution conditioned on cross-utterance information, which allows the prosody features generated by the TTS system to be related to the context and is more similar to how humans naturally produce prosody. The performance of CUC-VAE is evaluated via a qualitative listening test for naturalness, intelligibility and quantitative measurements, including word error rates and the standard deviation of prosody attributes. Experimental results on LJ-Speech and LibriTTS data show that the proposed CUC-VAE TTS system improves naturalness and prosody diversity with clear margins. ",/pdf/0bbbd41cb1a31035f195898d7b2425673b7c6439.pdf,,,,,anonymous|crossutterance_conditioned_vae_for_nonautoregressive_texttospeech,,,,,,,,,
711,i2WUdHUTHTQ,HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information,['aclweb.org/ACL/ARR/2021/November/Paper1582/Authors'],['Anonymous'],"Transformer-based language models usually treat texts as linear sequences. However, most texts also have an inherent hierarchical structure, i.,e., parts of a text can be identified using their position in this hierarchy. In addition, section titles usually indicate the common topic of their respective sentences. We propose a novel approach to extract, encode and inject hierarchical structure (HiStruct) information into an extractive summarization model (HiStruct+ model) based on a pre-trained, encoder-only language model. Our HiStruct+ model achieves SOTA extractive ROUGE scores on three public summarization datasets (CNN/DailyMail, PubMed, arXiv), the improvement is especially substantial on PubMed and arXiv. Using various experimental settings, our HiStruct+ model outperforms a strong baseline, which differs from our model only in that the HiStruct information is not injected. The ablation study demonstrates that the hierarchical position information is the main contributor to our model's SOTA performance.",/pdf/2b3b1ad795855a6dd080667635506140c1fda609.pdf,/attachment/70d78dcf9d75d5c3eb63839a868f2549669f81a3.zip,,,,anonymous|histruct_improving_extractive_text_summarization_with_hierarchical_structure_information,,,,,,/attachment/31ea8b89b235e630dc735251de01348a11759b9d.zip,,,
712,gDJtrYO-9O,NewsEdits: A Dataset of News Article Revision Histories and a Novel Approach to Document-Level Edit Reasoning,['aclweb.org/ACL/ARR/2021/November/Paper2669/Authors'],['Anonymous'],"News article revision histories have the potential to give us novel insights across varied fields of linguistics and social sciences. In this work, we present the first publicly available dataset of news revision histories, \textit{NewsEdits}. 

Our dataset is massive and multilingual; it contains 1.2 million articles with 4.6 million versions from over 22 English- and French-language newspaper sources based in three countries. We develop a highly-scalable sentence-matching algorithm which we use to reliably extract document and sentence-level edit actions: Add, Delete, Edit, Move.

We conduct analyses characterizing the nature of edits. We show that sentences that are added and deleted between article versions are more likely to contain updating events, main content and quotes compared with unchanged sentences. Finally, we introduce three novel tasks aimed at predicting the edit actions given an old version. We show that they are learnable, but challenging for current large NLP models compared with expert human judgement. By offering insights into how news articles grow and update, we hope this can spur research in narrative framing and development and the informational needs of updating news stories.",/pdf/bfd36e1dc38956d64ff6073a4118e096cd24343d.pdf,,,,,anonymous|newsedits_a_dataset_of_news_article_revision_histories_and_a_novel_approach_to_documentlevel_edit_reasoning,,,,,,,,,
713,CRBzhRdkycU,Deep Reinforcement Learning for Entity Alignment,['aclweb.org/ACL/ARR/2021/November/Paper69/Authors'],['Anonymous'],"Embedding-based methods have attracted increasing attention in recent entity alignment (EA) studies. Although great promise they can offer, there are still several limitations. The most notable is that they identify the aligned entities based on cosine similarity, ignoring the semantics underlying the embeddings themselves. Furthermore, these methods are shortsighted, heuristically selecting the closest entity as the target and allowing multiple entities to match the same candidate. To address these limitations, we model entity alignment as a sequential decision-making task, in which an agent sequentially decides whether two entities are matched or mismatched based on their representation vectors. The proposed reinforcement learning (RL)-based entity alignment framework can be flexibly adapted to most embedding-based EA methods. Our experiments demonstrate that it consistently advances the performance of several state-of-the-art methods, with a maximum improvement of 31.1% on Hits@1.",/pdf/8dcc1957c2f1542cec7dc6bba0bf33a3db71c14d.pdf,/attachment/aca0641be63d059718e40f8a5a55a62ab54b585d.zip,,,,anonymous|deep_reinforcement_learning_for_entity_alignment,,,,,,,,,
714,f1PfVBM3v0r,TwittIrish: A Universal Dependencies Treebank of Tweets in Modern Irish,['aclweb.org/ACL/ARR/2021/November/Paper1413/Authors'],['Anonymous'],"Modern Irish is a minority language lacking sufficient linguistic resources for the task of accurate automatic syntactic parsing of user-generated content. 
As with other languages, the linguistic style observed in Irish tweets differs, in terms of orthography, lexicon and syntax, to that of standard texts more commonly used in Natural Language Processing (NLP) for the development of language models and parsers.
This paper reports on the development of TwittIrish, the first Irish Universal Dependencies Twitter Treebank. We describe our bootstrapping method, and report on preliminary parsing experiments.",/pdf/5f5952cd220c5765a7efdb4e70df86eefa148994.pdf,,,,,anonymous|twittirish_a_universal_dependencies_treebank_of_tweets_in_modern_irish,,,,,,,,,
715,nIcRCffatsX,Biaffine Discourse Dependency Parsing,['aclweb.org/ACL/ARR/2021/November/Paper200/Authors'],['Anonymous'],"We provide the first study of using the biaffine model for neural discourse dependency parsing and achieve significant performance improvement compared with the baseline parsers. We compare the Eisner algorithm and the Chu-Liu-Edmonds algorithm in the task and find that using the Chu-Liu-Edmonds algorithm generates deeper trees and achieves better performance. We also evaluate the structure of the output of the parser with average maximum path length and average proportion of leaf nodes and find that the dependency trees generated by the parser are close to the gold trees. As the corpus allows non-projective structures, we analyze the complexity of non-projectivity of the corpus and find that the dependency structures in this corpus have gap degree at most one and edge degree at most one.",/pdf/0d342eb573156a177cadc06527961107f14f1a98.pdf,,,,,anonymous|biaffine_discourse_dependency_parsing,,,,,,,,,
716,9hzcBemY20,Generated Knowledge Prompting for Commonsense Reasoning,['aclweb.org/ACL/ARR/2021/November/Paper2091/Authors'],['Anonymous'],"It remains an open question whether incorporating external knowledge benefits commonsense reasoning while maintaining the flexibility of pretrained sequence models. To investigate this question, we develop generated knowledge prompting, which consists of generating knowledge from a language model, then providing the knowledge as additional input when answering a question. Our method does not require task-specific supervision for knowledge integration, or access to a structured knowledge base, yet it improves performance of large-scale, state-of-the-art models on four commonsense reasoning tasks, achieving state-of-the-art results on numerical commonsense (NumerSense), general commonsense (CommonsenseQA 2.0), and scientific commonsense (QASC) benchmarks. Generated knowledge prompting highlights large-scale language models as flexible sources of external knowledge for improving commonsense reasoning.
Our code is available at \url{github.com/anonymous_repo}.",/pdf/d3213629901385836688a9fdf66036daf6ce9d77.pdf,,,,,anonymous|generated_knowledge_prompting_for_commonsense_reasoning,,,,,,,,,
717,oDo65FJacdy,Empathetic Persuasion: Reinforcing Empathy and Persuasiveness in Dialogue Systems,['aclweb.org/ACL/ARR/2021/November/Paper2392/Authors'],['Anonymous'],"Persuasion is an intricate process involving empathetic connection between two individuals. Plain persuasive responses may make a conversation non-engaging. 
Even the most well-intended and reasoned persuasive conversations can fall through in the absence of empathetic connection between the speaker and listener. In this paper, we propose a novel task of incorporating empathy when generating persuasive responses. We develop an empathetic persuasive dialogue system by fine-tuning a maximum likelihood Estimation (MLE)-based language model in a reinforcement learning (RL) framework. To design feedbacks for our RL-agent, we define an effective and efficient reward function considering consistency, repetitiveness, emotion and persuasion rewards to ensure consistency, non-repetitiveness, empathy and persuasiveness in the generated responses. Due to lack of emotion annotated persuasive data, we first annotate the existing PersuaionForGood dataset with emotions, then build transformer based classifiers to provide emotion based feedbacks to our RL agent. Our experimental results confirm that our proposed model increases the rate of generating persuasive responses as compared to the available state-of-the-art dialogue models while making the dialogues empathetically more engaging and retaining the language quality in responses.",/pdf/0fe737eb8d9fb2a2bfdb56e5c35304ae1108e796.pdf,/attachment/aeb8dbb79e3874f2d2a0d5b3691f0bc79e4880a9.zip,,,,anonymous|empathetic_persuasion_reinforcing_empathy_and_persuasiveness_in_dialogue_systems,,,,,,/attachment/f26e36204280782ac7fdd0df31c278222655ff94.zip,,,
718,VnWsasVHGPM,PicTalky: Augmentative and Alternative Communication Software for Language Developmental Disabilities,['aclweb.org/ACL/ARR/2021/November/Paper38/Authors'],['Anonymous'],"Children with language disabilities face communication difficulties in social life. They are often deprived of the opportunity to participate in social activities due to their difficulty in understanding or using natural language. In this regard, Augmentative and Alternative Communication (AAC) is a practical means of communication for children with language disabilities. In this study, we propose PicTalky, which is an AI-based AAC system that helps children with language developmental disabilities to improve their communication skills and language comprehension abilities. PicTalky can process both text and pictograms more accurately by connecting a series of neural-based NLP modules. Moreover, we perform quantitative and qualitative analyses on the essential features of PicTalky. It is expected that those suffering from language problems will be able to express their intentions or desires more easily and improve their quality of life by using this service. We have made the models freely available alongside a demonstration of the Web interface. Furthermore, we implemented robotics AAC for the first time by applying PicTalky to the NAO robot. ",/pdf/d8798d954d3ce02f79c153694b309542d5bfd30e.pdf,,,,,anonymous|pictalky_augmentative_and_alternative_communication_software_for_language_developmental_disabilities,,,,,,,,,
719,i0HdiUT1_KI,Improving Neural Models for Radiology Report Retrieval with Lexicon-based Automated Annotation,['aclweb.org/ACL/ARR/2021/November/Paper2090/Authors'],['Anonymous'],"Many clinical informatics tasks that are based on electronic health records need relevant patient cohorts to be selected based on findings, symptoms, and diseases. Frequently, these conditions are described in radiology reports which can be retrieved using information retrieval (IR) methods. The latest of these techniques utilize neural IR models such as BERT trained on clinical text. However, these methods still lack semantic understanding of the underlying clinical conditions as well as ruled out findings, resulting in poor precision during retrieval. In this paper we combine clinical finding detection with supervised query match learning. Specifically, we use lexicon-driven concept detection to detect relevant findings in sentences. These findings are used as queries to train a Sentence-BERT (SBERT) model using triplet loss on matched and unmatched query-sentence pairs. We show that the proposed supervised training task remarkably improves the retrieval performance of SBERT. The trained model generalizes well to unseen queries and reports from different collections.",/pdf/e5472d0ea334760693f4be69fed4d977aa15bd6a.pdf,,,,,anonymous|improving_neural_models_for_radiology_report_retrieval_with_lexiconbased_automated_annotation,,,,,,,,,
720,Zey1PpxWJRz,Making Transformers Solve Compositional Tasks,['aclweb.org/ACL/ARR/2021/November/Paper1388/Authors'],['Anonymous'],"Several studies have reported the inability of Transformer models to generalize compositionally, a key type of generalization in many NLP tasks such as semantic parsing. In this paper we explore the design space of Transformer models showing that the inductive biases given to the model by several design decisions significantly impact compositional generalization. We identified Transformer configurations that generalize compositionally significantly better than previously reported in the literature in many compositional tasks. We achieve state-of-the-art results in a semantic parsing compositional generalization benchmark (COGS), and a string edit operation composition benchmark (PCFG).",/pdf/023bd1ba7d1ddee7c3d3b89ba48126b5bbb5a2fe.pdf,/attachment/62c21f555fcd92ac031dbb172936c4350c05a987.zip,,,,anonymous|making_transformers_solve_compositional_tasks,,,,,,,/attachment/ea26f24abeb9cc31d8fedcdafd76768bea4dbc35.pdf,https://openreview.net/forum?id=5S-L8drL0h7,/attachment/92658b6213c80ddc2bd9fcb4bf38e79cf8eced03.pdf
721,0r3eQftCZUT,Multimodal Sentiment Analysis with Common-sense Modulation,['aclweb.org/ACL/ARR/2021/November/Paper404/Authors'],['Anonymous'],"Our world is inherently multimodal and recent work highlights the importance of machine learning models leveraging multiple streams of information in making decisions. Multimodal sentiment analysis has been an active area of research that requires models to take advantage of the linguistic, acoustic, and visual signals available in an utterance. However, most current models do not take into account any social common-sense knowledge which is crucial in how we perceive sentiment in a conversation. To address that, in this paper, we aim to influence or modulate modality representations with common-sense knowledge obtained from a generative social common-sense knowledge base. We provide a novel way to modulate the linguistic, acoustic, and visual features corresponding to an utterance by scaling and shifting these representations. We use the knowledge base to obtain knowledge latent representations for an utterance corresponding to different states of the speaker such as the intent and the reaction, and we use it to shift and scale the three modalities. Our experiments on popular multimodal sentiment analysis benchmark datasets show that our proposed method is on par and often surpasses the current state-of-the art models.",/pdf/b6f40a3d76c5f36e1eee9a8646c421fd0197d124.pdf,,,,,anonymous|multimodal_sentiment_analysis_with_commonsense_modulation,,,,,,,,,
722,w0fxBD6tJbV,GenRE: A Generative Model for Relation Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1717/Authors'],['Anonymous'],"Relation extraction (RE) is an important information extraction task which provides essential information to many NLP applications such as knowledge base population and question answering. In this paper, we present a novel generative model for relation extraction (which we call GenRE), where RE is modeled as a sequence-to-sequence generation task. We explore various encoding schemes for the source and target sequences, and design effective schemes that enable GenRE to achieve state-of-the-art performance on three benchmark RE datasets. In addition, we introduce negative sampling and decoding scaling techniques which provide a flexible tool to tune the precision and recall performance of our GenRE model. Our approach can be extended to extract all relation triples from a sentence in one pass. Although the one-pass approach incurs certain performance loss, it is much more computationally efficient.",/pdf/713ea8a8bb3a1548219d9da3c81738ff4dd74ea7.pdf,,,,,anonymous|genre_a_generative_model_for_relation_extraction,,,,,,,,,
723,du9X3J0losl,Logic Traps in Evaluating Attribution Scores,['aclweb.org/ACL/ARR/2021/November/Paper2366/Authors'],['Anonymous'],"Modern deep learning models are notoriously opaque, which has motivated the development of methods for interpreting how deep models predict.
This goal is usually approached with attribution method, which assesses the influence of features on model predictions. 
As an explanation method, the evaluation criteria of attribution methods is how accurately it reflects the actual reasoning process of the model (faithfulness). Meanwhile, since the reasoning process of deep models is inaccessible, researchers design various evaluation methods to demonstrate their arguments.
However, some crucial logic traps in these evaluation methods are ignored in most works, causing inaccurate evaluation and unfair comparison.
This paper systematically reviews existing methods for evaluating attribution scores and summarizes the logic traps in these methods.
We further conduct experiments to demonstrate the existence of each logic trap.
Through both theoretical and experimental analysis, we hope to increase attention on the inaccurate evaluation of attribution scores. 
Moreover, with this paper, we suggest stopping focusing on improving performance under unreliable evaluation systems and starting efforts on reducing the impact of proposed logic traps.",/pdf/133d8acb6651bae9b37064e59c83b3bfefb9581a.pdf,,,,,anonymous|logic_traps_in_evaluating_attribution_scores,,,,,,,,,
724,-7JHTpEHPn,"Relevant CommonSense Subgraphs for ""What if..."" Procedural Reasoning",['aclweb.org/ACL/ARR/2021/November/Paper1929/Authors'],['Anonymous'],"This work deals with the challenge of learning causal reasoning over procedural text to answer ""What if..."" questions when external commonsense knowledge is required. We propose a novel multi-hop graph reasoning model to 1) efficiently extract a commonsense subgraph with the most relevant information from a large knowledge graph; 2) predict the causal answer by reasoning over the representations obtained from the commonsense subgraph and the contextual interactions between the questions and context. We evaluate our model on WIQA dataset and achieve state-of-the-art performance compared to the recent models.",/pdf/3b905a66a4b3f9404a7ea305afe948b549021c17.pdf,,,,,anonymous|relevant_commonsense_subgraphs_for_what_if_procedural_reasoning,,,,,,,,,
725,-TgV5Cufu58,Explicit Object Relation Alignment for Vision and Language Navigation,['aclweb.org/ACL/ARR/2021/November/Paper2474/Authors'],['Anonymous'],"We propose a neural agent to solve the navigation instruction following problem in a photo-realistic environment. We explicitly align the spatial information in both instruction and the visual environment, including landmarks and spatial relationships between the agent and landmarks. Our method significantly improves the baseline and is competitive with the SOTA in unseen environments. The qualitative analysis shows that explicitly modeled spatial reasoning improves the explainability of the action decisions and the generalizability of the model.",/pdf/e9e7217b688789314b445b4c5454221f46e73361.pdf,,,,,anonymous|explicit_object_relation_alignment_for_vision_and_language_navigation,,,,,,,,,
726,3GQN9Bwdjdv,M6-T: Exploring Sparse Expert Models and Beyond,['aclweb.org/ACL/ARR/2021/November/Paper2288/Authors'],['Anonymous'],"Sparse expert models can achieve promising results with outrageous large amount of parameters but constant computation cost, and thus it has become a trend in model scaling. Still, it is a mystery how Mixture-of-Experts (MoE) layers leveraging the parameters with sparse activation bring quality gains. In this work, we investigate several key factors in sparse expert models. We find that load imbalance may not be a significant problem affecting model quality, and auxiliary balancing loss can be removed without significant performance degrade. We further discover that larger number of sparsely activated experts $k$ may not necessarily benefit the performance on the time basis, and we observe diminishing marginal utility that the performance gap gradually narrows with the increase in $k$. We take a step forward to propose a simple method called expert prototyping that splits experts into different prototypes and applies top-$k$ routing for each prototype in parallel. Our experiments demonstrate that the prototyping strategy improves the model quality, in comparison with further increasing to a larger $k$ with comparable computation cost to prototyping. Furthermore, we conduct an exploration on training extremely large-scale models, and we figure out that the strategy shows greater effectiveness in training larger models. Notably, we push the model scale to over $1$ trillion parameters on solely $480$ NVIDIA V100-32GB GPUs. The proposed giant model M6-T with expert prototyping achieves substantial speedup in convergence over the same-size baseline.",/pdf/4265f2adcf3cdb92dd8be698ca7cd5bac7ed3459.pdf,,,,,anonymous|m6t_exploring_sparse_expert_models_and_beyond,,,,,,,,,
727,nhQlnkAoux,Data-adaptive Transfer Learning for Low-resource Translation: A Case Study in Haitian,['aclweb.org/ACL/ARR/2021/November/Paper1224/Authors'],['Anonymous'],"Multilingual transfer techniques often improve low-resource machine translation (MT). Many of these techniques are applied without considering data characteristics. We show in the context of Haitian-to-English translation that transfer effectiveness is correlated with amount of training data and relationships between knowledge-sharing languages. Our experiments suggest that beyond a threshold of authentic data, back-translation augmentation methods are counterproductive, while cross-lingual transfer during training is preferred. We complement this finding by contributing a rule-based French-Haitian orthographic and syntactic engine and a novel method for phonological embedding. When used with multilingual techniques, orthographic transformation significantly improves performance over conventional methods, and phonological transfer greatly improves performance in Jamaican MT.",/pdf/4083a46f6e021fde1e7228211b5bac78c34159e1.pdf,,,,,anonymous|dataadaptive_transfer_learning_for_lowresource_translation_a_case_study_in_haitian,,,,,,,,,
728,cFFydlVW7G,WeTS: A Benchmark for Translation Suggestion,['aclweb.org/ACL/ARR/2021/November/Paper495/Authors'],['Anonymous'],"Translation suggestion (TS), which provides alternatives for specific words or phrases given the entire documents generated by machine translation (MT), has been proven to play a significant role in post-editing (PE). There are two main pitfalls for previous researches in this line. First, most conventional works only focus on the overall performance of PE but ignore the exact performance of TS, which makes the progress of PE sluggish and less explainable; Second, as no publicly available golden dataset to support in-depth research for TS, almost all of the previous works conduct experiments on their in-house datasets or the noisy datasets built automatically, which makes their experiments hard to be reproduced and compared. To break these limitations mentioned above and spur the research in TS,  we create a benchmark dataset, called \emph{WeTS}, which is a golden corpus annotated by expert translators on four translation directions. Apart from the golden corpus, we also propose several methods to generate synthetic corpus which can be used to improve the performance substantially through pre-training. As for the model, we propose the segment-aware self-attention based Transformer for TS. Experimental results show that our approach achieves state-of-the-art results on all four directions, including English-to-German, German-to-English, Chinese-to-English, and English-to-Chinese.",/pdf/d8ffc313dbff01582e9ef86860fc59dc4dce06f4.pdf,/attachment/d1c7bcb72cfc2023e3eb3584116dde639a3412b3.zip,,,,anonymous|wets_a_benchmark_for_translation_suggestion,,,,,,/attachment/02a3f4c763f9c71cdc6b3cb170f376eabc261865.zip,,,
729,rfKyAHBUhOq,KETOD: Knowledge-Enriched Task-Oriented Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper347/Authors'],['Anonymous'],"Existing studies in dialogue system research mostly treat task-oriented dialogue and chit-chat separately. Towards building a human-like assistant that can converse naturally and seamlessly with users, the system needs to be able to conduct both types of conversations effectively. In this work, we investigate how task-oriented dialogue and knowledge-grounded chit-chat can be effectively integrated into a single model. To this end, we create a new dataset, KETOD (Knowledge-Enriched Task-Oriented Dialogue), where we naturally enrich task-oriented dialogue with chit-chats based on relevant entity knowledge. We also propose two new models, SimpleToDPlus and Combiner, for the proposed task. Experimental results on both automatic and human evaluations show that the proposed methods can significantly improve the performance in knowledge-enriched response generation while maintaining a competitive task-oriented dialog performance. We believe our new dataset will be a valuable resource for future studies. We will make the code and the dataset publicly available upon acceptance.",/pdf/86313ca76702aa3b45bc1d95f152e03745fba1fe.pdf,,,,,anonymous|ketod_knowledgeenriched_taskoriented_dialogue,,,,,,,,,
730,5cU6H8EAxpO,Autoregressive Language Model for Zero-shot Constrained Keyphrase Generation,['aclweb.org/ACL/ARR/2021/November/Paper262/Authors'],['Anonymous'],"Recently, most of the state-of-the-art keyphrase prediction models are based on a supervised generative model.
It shows significantly better than before. Nevertheless, it still faces domain robustness and building datasets on high-resource. 
To overcome these limitations, unsupervised methods have also been critical and studied. We analyzed it also have a defect in a necessary process, which extracts candidates beforehand selecting keyphrase. As not including various forms of phrases, we note that the unsupervised method can't ensure oracle keyphrase.
In this paper, we present zero-shot constrained keyphrase generation by leveraging a large-scale language model. To generate diverse keyphrases, we explore controlling a phrase during the generation. Finally, we evaluate benchmark datasets of the scholar domain. It results in better performances than unsupervised methods on several datasets without going through the candidate extraction stage. For domain robustness, we evaluate out-of-domain DUC compare with NUS. Since our method doesn't fine-tune to a corpus of a specific domain, it's better than supervised methods based on Sequence-to-Sequence.",/pdf/23fe92a0655bc3509e0a080a640918298a176e5c.pdf,/attachment/ae225d440f9e6def2b49e8920c99e18c32f8ba28.zip,,,,anonymous|autoregressive_language_model_for_zeroshot_constrained_keyphrase_generation,,,,,,,,,
731,uD89_eS35Bt,Flagging Comprehensibility Issues in Hindi Text with Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper2726/Authors'],['Anonymous'],"There is a critical need for checking the quality of translations while localizing important content across all the industries. This paper presents question-answering based techniques to check the comprehensibility of a text translation. The viability of the method is evaluated using text translated from English to Hindi, where we see comprehensibility issues identified with up to 87\% accuracy.",/pdf/5fbb71a7130343fb0ebc4532cdad2f8015b147f3.pdf,,,,,anonymous|flagging_comprehensibility_issues_in_hindi_text_with_question_answering,,,,,,,,,
732,eBltGwedCi,An Isotropy Analysis in the Multilingual BERT Embedding Space,['aclweb.org/ACL/ARR/2021/November/Paper2322/Authors'],['Anonymous'],"Several studies have explored various advantages of multilingual pre-trained models (e.g., multilingual BERT) in capturing shared linguistic knowledge. However, their limitations have not been paid enough attention to. In this paper, we investigate the representation degeneration problem and outlier dimensions in multilingual contextual word representations (CWRs) of BERT. We show that though mBERT exhibits no outliers among its representations, its multilingual embedding space is highly anisotropic. Furthermore, our experimental results demonstrate that similarly to their monolingual counterparts, increasing the isotropy of multilingual embedding spaces can significantly improve their representation power and performance. Our analysis indicates that, although the degenerated directions vary in different languages, they encode similar linguistic knowledge, suggesting a shared linguistic space among languages.
",/pdf/d734c78156a3487c5d41588965243c09f3a21c84.pdf,,,,,anonymous|an_isotropy_analysis_in_the_multilingual_bert_embedding_space,,,,,,,,,
733,abyb5WF417M,GradMask: Gradient-Guided Token Masking for Textual Adversarial Example Detection,['aclweb.org/ACL/ARR/2021/November/Paper2155/Authors'],['Anonymous'],We present a simple model-agnostic textual adversarial example detection scheme called GradMask. It uses gradient signals to detect adversarially perturbed tokens in an input sequence and occludes such tokens by a masking process. GradMask provides several advantages over existing methods including improved detection performance and a weak interpretation of its decision. Extensive evaluations on widely adopted natural language processing benchmark datasets demonstrate the efficiency and effectiveness of GradMask,/pdf/e568ef3307dec710e68134610dc9fca4079a479f.pdf,/attachment/126b86f4dbed308fa718b5601b212f966d126592.zip,,,,anonymous|gradmask_gradientguided_token_masking_for_textual_adversarial_example_detection,,,,,,,/attachment/aa02f5cde9a6b1389fec42b269aa9aacb760feaf.pdf,https://openreview.net/forum?id=fImoryxnH0Z,/attachment/c24dfae47a7c6b7d17b435aa5c5b55ffedb2b635.pdf
734,4nIFIb-uWo8,Graph Refinement for Coreference Resolution,['aclweb.org/ACL/ARR/2021/November/Paper1278/Authors'],['Anonymous'],"The state-of-the-art models for coreference resolution are based on independent mention pair-wise decisions. We propose a modelling approach that learns coreference at the document-level and takes global decisions. For this purpose, we model coreference links in a graph structure where the nodes are tokens in the text, and the edges represent the relationship between them. Our model predicts the graph in a non-autoregressive manner, then iteratively refines it based on previous predictions, allowing global dependencies between decisions. The experimental results show improvements over various baselines, reinforcing the hypothesis that document-level information improves conference resolution. ",/pdf/88b3d06756c750f3345f265b9ed92d85852a7895.pdf,,,,,anonymous|graph_refinement_for_coreference_resolution,,,,,,,,,
735,AIzlClbp3x,Right for the Right Reason: Evidence Extraction for Trustworthy Tabular Reasoning,['aclweb.org/ACL/ARR/2021/November/Paper2065/Authors'],['Anonymous'],"When pre-trained contextualized embeddings-based models developed for unstructured data are adapted for structured tabular data, they perform admirably. However, recent probing studies show that these models use spurious correlations and often ignore or focus on wrong evidence to predict labels. To study this issue, we introduce the task of Trustworthy Tabular Reasoning, where a model needs to extract evidence to be used for reasoning, in addition to predicting the label. As a case study, we propose a two-stage sequential prediction approach, which includes an evidence extraction and an inference stage. To begin, we crowdsource evidence row labels and develop several unsupervised and supervised evidence extraction strategies for InfoTabS, a tabular NLI benchmark. Our evidence extraction strategy outperforms earlier baselines. On the downstream tabular inference task, using the automatically extracted evidence as the only premise, our approach outperforms prior benchmarks. ",/pdf/de0db4e7b0e7a4d5076c8664fdbdee5b99ceb3f1.pdf,,,,,anonymous|right_for_the_right_reason_evidence_extraction_for_trustworthy_tabular_reasoning,,,,,,,,,
736,wWZCNLkK-FK,Prompting as Multimodal Fusing,['aclweb.org/ACL/ARR/2021/November/Paper1092/Authors'],['Anonymous'],"Tsimpoukelli et al. (2021) devise Frozen, empowering a language model to solve multimodal tasks by pretraining a vision encoder whose outputs are prompts fed to the language model. The vision encoder has a dual objective: extracting image features and aligning image/text representation spaces. We propose to disentangle the objectives by using prompt vectors to align the spaces; this lets the vision encoder focus on extracting image features. We show that this disentangled approach is modular and parameter-efficient for processing tasks that involve two or more modalities.",/pdf/20c70549c7e8a67193f2e5c9fadfd24c82141fd0.pdf,/attachment/eaaf033e5bfeef08e71f3b810bf6582eb9a71563.zip,,,,anonymous|prompting_as_multimodal_fusing,,,,,,,,,
737,nEPS9wayf3T,Debiased Contrastive Learning of Unsupervised Sentence Representations,['aclweb.org/ACL/ARR/2021/November/Paper2085/Authors'],['Anonymous'],"Recently, contrastive learning has shown effectiveness in fine-tuning pre-trained language models (PLM) to derive sentence representations, which pulls augmented positive examples together to improve the alignment while pushing apart irrelevant negatives for the uniformity of the whole representation space. However, previous works mostly sample negatives from the batch or training data at random. It may cause sampling bias that improper negatives (\eg false negatives and anisotropy representations) will be learned by sentence representations, and hurt the uniformity of the representation space. To solve it, we present a new framework \textbf{DCLR} to alleviate the influence of sampling bias. In DCLR, we design an instance weighting method to punish false negatives and generate noise-based negatives to guarantee the uniformity of the representation space. Experiments on 7 semantic textual similarity tasks show that our approach is more effective than competitive baselines. Our codes and data will be released to reproduce all the experiments.",/pdf/1cc6d32a6dced038ed56e9eae51237123215d3a9.pdf,,,,,anonymous|debiased_contrastive_learning_of_unsupervised_sentence_representations,,,,,,,,,
738,8htKQ54Radx,An Unsupervised Multiple-Task and Multiple-Teacher Model for Cross-lingual Named Entity Recognition,['aclweb.org/ACL/ARR/2021/November/Paper2779/Authors'],['Anonymous'],"Cross-lingual named entity recognition task is one of the critical problem for evaluating the potential transfer learning techniques on low resource languages. Knowledge distillation using pre-trained multilingual language models between source and target languages have shown their superiority. However, existing cross-lingual distillation models merely consider the potential transferability between two identical single tasks across both domain. Other possible auxiliary tasks to improve the learning performance have not been fully investigated. In this study, based on the knowledge distillation framework and multi-task learning, we introduce the similarity metric model as an auxiliary task to improve the cross-lingual NER performance on target domain. Specifically, an entity recognizer and a similarity evaluator teachers are first trained in parallel from the source domain. Then, two tasks in the student model are supervised by the two teachers simultaneously. Empirical studies on the datasets across 7 different languages confirm the effectiveness of the proposed model. ",/pdf/b9752bf1e9cf1ee3ac6833390f915a687c087267.pdf,/attachment/c8f48c4439e8065f15dce339e35ebfafee102c8e.zip,,,,anonymous|an_unsupervised_multipletask_and_multipleteacher_model_for_crosslingual_named_entity_recognition,,,,,,/attachment/76fd39ab311ead19d38209db7399e60e3f064f07.zip,,,
739,Q-YYLHfpAa,Universal Phone Recognition for Language Agnostic Keyword Search,['aclweb.org/ACL/ARR/2021/November/Paper2870/Authors'],['Anonymous'],"Recently, significant advanced have been made in universal phone recognition. Certain of these methods allow researchers to recognize phones in thousands of languages. In this paper, we explore the usage of such universal phone recognition for phonetic keyword search (KWS). That is, we apply these methods to search for specific sequences of phones, corresponding to keywords, in a set of audio files. We find that truly universal phone recognition might not be viable for KWS, but phone recognition systems can be fine-tuned with small amounts of data (3-5 hours of recordings) to produce useful results.",/pdf/c7a4f7959597cad00e830d010e43314fff416f89.pdf,,,,,anonymous|universal_phone_recognition_for_language_agnostic_keyword_search,,,,,,,,,
740,m3gyU0zoCD_,FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual Robustness,['aclweb.org/ACL/ARR/2021/November/Paper2013/Authors'],['Anonymous'],"Though current Seq2Seq summarization models are capable of generating fluent and grammatical summaries, they are still suffering from the unfaithful generation problem.In this paper, we study the faithfulness of existing systems from a new perspective of factual robustness which is the ability to correctly generate  factual information over  adversarial unfaithful information.We first define the measurement of a model's factual robustness as its success rate to defend against adversarial attacks when generating factual information. The factual robustness analysis on a wide range of current systems shows its good consistency with human judgments on faithfulness.Inspired by these findings, we propose to improve a model's faithfulness by enhancing its factual robustness.Specifically, we propose a novel training strategy, namely FRSUM, which teaches the model to defend against both explicit adversarial samples and implicit factual adversarial perturbations.Extensive automatic and human evaluation results show that FRSUM consistently improves the faithfulness of various Seq2Seq models, such as T5, BART and PEGASUS, and reduces up to 41\% target errors in summaries.",/pdf/601997bba1929ea1c0f842e6da848b3fe8ab1b76.pdf,,,,,anonymous|frsum_towards_faithful_abstractive_summarization_via_enhancing_factual_robustness,,,,,,,,,
741,bHf273tEkY9,Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data,['aclweb.org/ACL/ARR/2021/November/Paper1504/Authors'],['Anonymous'],"Retrieval-based methods have been shown to be effective in NLP tasks via introducing external knowledge. However, the indexing and retrieving of large-scale corpora bring considerable computational cost. Surprisingly, we found that REtrieving from the traINing datA (REINA) only can lead to significant gains on multiple NLG and NLU tasks. We retrieve the labeled training instances most similar to the input text and then concatenate them with the input to feed into the model to generate the output. Experimental results show that this simple method can achieve significantly better performance on a variety of NLU and NLG tasks, including summarization, machine translation, language modeling, and question answering tasks. For instance, our proposed method achieved state-of-the-art results on XSum, BigPatent, and CommonsenseQA.",/pdf/c7ceab2f085d9eb6c655f65993929fa865fec673.pdf,,,,,anonymous|training_data_is_more_valuable_than_you_think_a_simple_and_effective_method_by_retrieving_from_training_data,,,,,,,,,
742,_CMSV7FTzGI,AdaPrune: Pruning Transformer with Sparse Regularization,['aclweb.org/ACL/ARR/2021/November/Paper215/Authors'],['Anonymous'],"The key component of transformer architecture is the multi-head self-attention(MHA) and feed forward neural network (FFN). In this paper, we reveal that, across many applications, MHA component is nonsymmetric and FFN component is sparse. Leveraging this observation, we propose a new method, AdaPrune, to utilize sparse regularization to conduct structure pruning in MHA and FFN modules. This method selects task-specific valuable heads in multi-head attention modules and effective blocks in feed forward layers during the fine-tuning stage, while maintaining the original performance of full transformer model. Extensive experiments show that AdaPrune can achieve competitive performance on these tasks while significantly reduce the computation cost.",/pdf/27b717bc9b9a3ce944ad8a93bd62892cf2e6d314.pdf,,,,,anonymous|adaprune_pruning_transformer_with_sparse_regularization,,,,,,,,,
743,lf1yqoQZTfa,Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition,['aclweb.org/ACL/ARR/2021/November/Paper1771/Authors'],['Anonymous'],"Phonemes are defined by their relationship to words: changing a phoneme changes the word. Learning a phoneme inventory with little supervision has been a longstanding challenge with important applications to under-resourced speech technology. In this paper, we bridge the gap between the linguistic and statistical definition of phonemes and propose a novel neural discrete representation learning model for self-supervised learning of phoneme inventory with raw speech and word labels. Under mild assumptions, we prove that the phoneme inventory learned by our approach converges to the true one with an exponentially low error rate. Moreover, in experiments on TIMIT and Mboshi benchmarks, our approach consistently learns a better phoneme-level representation and achieves a lower error rate in a zero-resource phoneme recognition task than previous state-of-the-art self-supervised representation learning algorithms. ",/pdf/b057509efe5ddc5f0145a0df1045c49c3a601df5.pdf,,,,,anonymous|selfsupervised_semanticdriven_phoneme_discovery_for_zeroresource_speech_recognition,,,,,,,,,
744,f-NmsmAgrDL,Unsupervised Domain Adaptation with Contrastive Learning for Cross-domain Chinese NER,['aclweb.org/ACL/ARR/2021/November/Paper2538/Authors'],['Anonymous'],"Understanding and recognizing the entities of Chinese articles highly relies on the fully supervised learning based on the domain-specific annotation corpus. However, this paradigm fails to generalize over other unlabeled domain data which consists of different entities semantics and domain knowledge. To address this domain shift issue, we propose the framework of unsupervised Domain Adaptation with Contrastive learning for Chinese NER (DAC-NER). We follow Domain Separation Network (DSN) framework to leverage private-share pattern to capture domain-specific and domain-invariant knowledge. Specifically, we enhance the Chinese word by injecting external lexical knowledge base into the context-aware word embeddings, and then combine with sentence-level semantics to represent the domain knowledge. To learn the domain-invariant knowledge, we replace the conventional adversarial method with novel contrastive regularization to further improve the generalization abilities. Extensive experiments conducted over the labeled source domain MSRA and the unlabeled target domain Social Media and News show that our approach outperforms state-of-the-arts, and achieves the improvement of F1 score by 8.7% over the baseline.",/pdf/15b045897eca337c563ee5cb96413ec3e217da9c.pdf,/attachment/6a0d7f9b4b7ccc5cd723a0a4d2a5f7ea44af0a44.zip,,,,anonymous|unsupervised_domain_adaptation_with_contrastive_learning_for_crossdomain_chinese_ner,,,,,,,,,
745,vBGI0irna69,Understanding Attention in Machine Reading Comprehension,['aclweb.org/ACL/ARR/2021/November/Paper801/Authors'],['Anonymous'],"Achieving human-level performance on some of Machine Reading Comprehension (MRC) datasets is no longer challenging with the help of powerful Pre-trained Language Models (PLMs). However, the internal mechanism of these artifacts still remains unclear, placing an obstacle for further understanding these models. This paper focuses on conducting a series of analytical experiments to examine the relations between the multi-head self-attention and the final performance, trying to analyze the potential explainability in PLM-based MRC models.
We perform quantitative analyses on SQuAD (English) and CMRC 2018 (Chinese), two span-extraction MRC datasets, on top of BERT, ALBERT, and ELECTRA in various aspects. We discover that {\em passage-to-question} and {\em passage understanding} attentions are the most important ones, showing strong correlations to the final performance than other parts. Through visualizations and case studies, we also observe several general findings on the attention maps, which could be helpful to understand how these models solve the questions.",/pdf/e6ed2e3e7c13a31cdb946c4a7d5563957aa0cbe4.pdf,,,,,anonymous|understanding_attention_in_machine_reading_comprehension,,,,,,,,,
746,p6Gx8159ll4,Improve Discourse Dependency Parsing with Contextualized Representations,['aclweb.org/ACL/ARR/2021/November/Paper1195/Authors'],['Anonymous'],"Previous works show that discourse analysis benefits from modeling  intra- and inter-sentential levels separately, where proper representations for text units of different granularities are desired to capture both the information of the text units and their relation to the context. In this paper, we propose to take advantage of transformers to encode different contextualized representations of units of different levels to dynamically capture the information required for discourse dependency analysis on intra- and inter-sentential levels. Motivated by the observation of writing patterns shared across articles to improve discourse analysis, we propose to design sequence labeling methods to take advantage of such structural information from the context that substantially outperforms traditional direct classification methods. Experiments show that our model achieves state-of-the-art results on both English and Chinese datasets.",/pdf/be4699260df24a793f0da5b741c1e86f9d6f1116.pdf,,,,,anonymous|improve_discourse_dependency_parsing_with_contextualized_representations,,,,,,,,,
747,nRMGr434PuG,Measuring Fairness of Text Classifiers via Prediction Sensitivity,['aclweb.org/ACL/ARR/2021/November/Paper2365/Authors'],['Anonymous'],"With the rapid growth in language processing applications, fairness has emerged as an important consideration in data-driven solutions.  Although various fairness definitions have been explored in the recent literature, there is lack of consensus on which metrics most accurately reflect the fairness of a system. 
       In this work, we propose a new formulation -- accumulated prediction sensitivity, which measures fairness in machine learning models based on the model's prediction sensitivity to perturbations in input features. The metric attempts to quantify the extent to which a single prediction depends on a protected attribute, where the protected attribute encodes the membership status of an individual in a protected group.  
       We show that the metric can be theoretically linked with a specific notion of group fairness (statistical parity) and individual fairness. It also correlates well with humans' perception of fairness. We conduct experiments on two text classification datasets -- Jigsaw Toxicity, and Bias in Bios, and evaluate the correlations between metrics and manual annotations on whether the model produced a fair outcome. We observe that the proposed fairness metric based on prediction sensitivity is statistically significantly more correlated with human annotation than the existing counterfactual fairness metric.",/pdf/28cfd88949674f4148adaed41f02e5ad43b29238.pdf,,,,,anonymous|measuring_fairness_of_text_classifiers_via_prediction_sensitivity,,,,,,,/attachment/b6ae59c79ca228bf15b1679a9fbd86cc3e7f0679.pdf,https://openreview.net/forum?id=uOklQslIXe8,/attachment/b1b1341a238a0e71ac9734653dd3226cf442e3bb.pdf
748,mEqYnpJF8LX,Improving Syntactic Parsing with Consistency Learning,['aclweb.org/ACL/ARR/2021/November/Paper1010/Authors'],['Anonymous'],"In this paper, we propose using \emph{consistency learning} to improve constituency and dependency parsing performances on a multi-task setting. It utilizes a consistent constraint between the predictions. While multi-task learning implicitly learns shared representations for multiple sub-tasks, our method introduces an explicit consistency objective, which encourages shared representations that result in consistent predictions. Our intuition is that correct predictions are more likely consistent ones. To introduce consistent constraints, we propose a general method for introducing consistency objectives, as well as other prior knowledge, into existing neural models. This method only requires a boolean function that tells whether or not the multiple predictions are consistent, which does not need to be differentiable. We demonstrate the efficacy of our method by showing that it out-performs a state-of-the-art joint dependency and constituency parser on CTB.",/pdf/791b7db32e681897296b4e5259908f2f0d4e27a9.pdf,,,,,anonymous|improving_syntactic_parsing_with_consistency_learning,,,,,,,,,
749,Ohqq3_Q9_3L,Identifying Semantically Difficult Samples to Improve Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper2049/Authors'],['Anonymous'],"In this paper, we investigate the effect of addressing difficult samples from a given text dataset on the downstream text classification task. We define difficult samples as being non-obvious cases for text classification by analysing them in the semantic embedding space; specifically - (i) semantically similar samples that belong to different classes and (ii) semantically dissimilar samples that belong to the same class. We propose a penalty function to measure the overall difficulty score of every sample in the dataset. We conduct exhaustive experiments on 13 standard datasets to show a consistent improvement of up to 9\% and discuss qualitative results to show effectiveness of our approach in identifying difficult samples for a text classification model.",/pdf/ff53af5fcf2594627319cbbb2b948782d581e576.pdf,/attachment/d9b4e01c4a7bd9c714b440498a62f2b474812a95.zip,,,,anonymous|identifying_semantically_difficult_samples_to_improve_text_classification,,,,,,,,,
750,7BdYd9p5rV,EveMRC: A Two-stage Evidence Modeling For Multi-choice Machine Reading Comprehension,['aclweb.org/ACL/ARR/2021/November/Paper2454/Authors'],['Anonymous'],"Many impressive works have been proposed to improve the performance of Machine Reading Comprehension (MRC) systems in recent years. However, it is still difficult to interpret the predictions of existing MRC models, which makes the predictions unconvincing.
In this work, we propose a two-stage explainable framework for multi-choice MRC to model not only the correlation between answers and evidence, but also the competition among evidence. In stage 1, we select evidence sentences for both the right answer and wrong answers using the semi-supervised evidence selector. In stage 2, we employ an evidence discriminator to compare among the competitive evidence set and make final judgments. Moreover, we propose an evidence-enabled data augmentation method.  Experiments on four multi-choice MRC datasets show that: stage 1 provides strong explainability for MRC systems and stage 2 improves both the performance and robustness of MRC systems meanwhile.",/pdf/fe2db31004342ee90e7c83e1ba94aacc08aec789.pdf,,,,,anonymous|evemrc_a_twostage_evidence_modeling_for_multichoice_machine_reading_comprehension,,,,,,,,,
751,ZdKU7FFJ-79,CalBERT - Code-mixed Adaptive Language representations using BERT,['aclweb.org/ACL/ARR/2021/November/Paper574/Authors'],['Anonymous'],"A code-mixed language is a type of language that involves the combination of two or more language varieties in its script or speech. Code-mixed language has become increasingly prevalent in recent times, especially on social media. However, the exponential increase in the usage of code-mixed language, especially in a country like India which is linguistically diverse has led to various inconsistencies. Analysis of text is now becoming harder to tackle because the language present is not consistent and does not work with predefined existing models which are monolingual. We propose a novel approach to improve performance in Transformers by introducing an additional step called ""Siamese Pre-Training"", which allows pre-trained monolingual Transformers to adapt language representations for code-mixed languages with a few examples of code-mixed data. Our studies show that CalBERT is able to improve performance over existing pre-trained Transformer architectures on downstream tasks such as sentiment analysis. Multiple CalBERT architectures beat the state of the art F1-score on the Sentiment Analysis for Indian Languages (SAIL) dataset, with the highest possible improvement being 8.9%",/pdf/b1a84405aa4f91f40873cd3b4cb8e046ad6909eb.pdf,,,,,anonymous|calbert_codemixed_adaptive_language_representations_using_bert,,,,,,,,,
752,mBWEZDC3KeO,Local Structure Matters Most: Perturbation Study in NLU,['aclweb.org/ACL/ARR/2021/November/Paper1474/Authors'],['Anonymous'],"Recent research analyzing the sensitivity of natural language understanding models to word-order perturbations has shown that neural models are surprisingly insensitive to the order of words.
In this paper, we investigate this phenomenon by developing order-altering perturbations on the order of words, subwords, and characters to analyze their effect on neural models' performance on language understanding tasks.
We experiment with measuring the impact of perturbations to the local neighborhood of characters and global position of characters in the perturbed texts and observe that perturbation functions found in prior literature only affect the global ordering while the local ordering remains relatively unperturbed.
We empirically show that neural models, invariant of their inductive biases, pretraining scheme, or the choice of tokenization, mostly rely on the local structure of text to build understanding and make limited use of the global structure. ",/pdf/bca9533790f645dcdfddbc91491ba65c2cbc1685.pdf,/attachment/95a5acd549ab0849daa373f2bede8568d0c07b55.zip,,,,anonymous|local_structure_matters_most_perturbation_study_in_nlu,,,,,,,,,
753,-3D06n-Fl0b,Is Cross-lingual Evaluation Only About Cross-lingual?,['aclweb.org/ACL/ARR/2021/November/Paper2323/Authors'],['Anonymous'],"Multilingual pre-trained language models (mPLMs) have achieved great success on various cross-lingual tasks. However, we find that the higher performance on these tasks cannot be regarded as the better cross-lingual ability because models’ task-specific abilities can also influence the performance. In this work, we do a comprehensive study on two representative cross-lingual evaluation protocols: sentence retrieval and zero-shot transfer. We find that current cross-lingual evaluation results strongly depend on mPLMs' task-specific abilities so that the performance can be improved without any improvement in models' cross-lingual ability. To have more accurate comparisons of cross-lingual ability between mPLMs, we propose two new indexes based on the two evaluation protocols: calibrated sentence retrieval performance and transfer rate, and experimentally show that our proposed indexes effectively eliminate the effects of task-specific abilities on the cross-lingual evaluation.",/pdf/1a696dbe6b3765bb730473c1d21cfee3a7681cac.pdf,,,,,anonymous|is_crosslingual_evaluation_only_about_crosslingual,,,,,,,,,
754,i71yOeQ3gh8,A New Framework for Fast Automated Phonological Reconstruction Using Trimmed Alignments and Sound Correspondence Patterns,['aclweb.org/ACL/ARR/2021/November/Paper990/Authors'],['Anonymous'],"Computational approaches in historical linguistics have been increasingly applied during the past decade and many new methods that implement parts of the traditional comparative method have been proposed. Despite these increased efforts, there are not many easy-to-use and fast approaches for the task of phonological reconstruction. Here we present a new framework that combines state-of-the-art techniques for automated sequence comparison with novel techniques for phonetic alignment analysis and sound correspondence pattern detection to allow for the supervised reconstruction of word forms in ancestral languages. We test the method on a new datasets covering six groups from three different language families. The results show that our method yields promising results while at the same time being not only fast but also easy to apply and expand.",/pdf/dbad905cf8451e0bf275c000cf42455f8dbb36e5.pdf,/attachment/ee2e5ee7d93c1a25fbc1319d7c5077fc3fe4d8b7.zip,,,,anonymous|a_new_framework_for_fast_automated_phonological_reconstruction_using_trimmed_alignments_and_sound_correspondence_patterns,,,,,,/attachment/8f6aae4b2c4a6a5cfb76c1e80bea3dec684ee99c.zip,,,
755,3MhV5D3wBqX,Focus on the Target’s Vocabulary: Masked Label Smoothing for Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper1887/Authors'],['Anonymous'],"Label smoothing and vocabulary sharing are two widely used techniques in neural machine translation models. However, we argue that jointly adopting these two techniques can be conflicting and even leads to sub-optimal performance, since the soft label produced by label smoothing still considers the source-side words that would not appear at the target side. To address this issue, we propose Masked Label Smoothing (MLS), a new mechanism that masks the soft label probability of source-side words to zero. Simple yet effective, MLS manages to better integrate label smoothing with vocabulary sharing and hence improves the quality of the translation. Our extensive experiments show that MLS consistently yields improvement over original label smoothing on different datasets, including bilingual and multilingual translation in both BLEU and calibration scores.",/pdf/269f05bc9c3dccf41a37969625c04d98f0afa551.pdf,/attachment/909072032362314bc24c0467e442213733fb8494.zip,,,,anonymous|focus_on_the_targets_vocabulary_masked_label_smoothing_for_machine_translation,,,,,,,/attachment/f92100c97b7b5a41b20e598ddfe6d1d6844c5ccd.pdf,https://openreview.net/forum?id=Moh8zXa3fSC,/attachment/6a2c90cbd65386540e5cfa997fcaa88d235cdec6.pdf
756,lILSg7aInVH,Generative Prompt Tuning for Relation Classification,['aclweb.org/ACL/ARR/2021/November/Paper2619/Authors'],['Anonymous'],"Prompt tuning is proposed to better tune pre-trained language models by filling the objective gap between the pre-training process and the downstream tasks. Current methods mainly convert the downstream tasks into masked language modeling (MLM) problems, which have proven effective for tasks with simple label sets. However, when applied to relation classification tasks which often exhibit a complex label space, vanilla prompt tuning methods designed for MLM may struggle with handling complex label verbalizations with variable length as in such methods, the locations and number of masked tokens are typically fixed. Inspired by the text infilling task for pre-training generative models that can flexibly predict missing spans, we propose a novel generative prompt tuning method to reformulate relation classification as an infilling problem to eliminate the rigid prompt restrictions, which allows our method to process label verbalizations of varying lengths at multiple predicted positions and thus be able to fully leverage rich semantics of entity and relation labels. In addition, we design entity-guided decoding and discriminative relation scoring to predict relations effectively and efficiently in the inference process. Extensive experiments under low-resource settings and fully supervised settings demonstrate the effectiveness of our approach.",/pdf/1c6ea6868f2fbab99748a094daa9070ebd4df3d8.pdf,/attachment/ec289c52cdecef98acc4f8781662958e9777190c.zip,,,,anonymous|generative_prompt_tuning_for_relation_classification,,,,,,,,,
757,-FO8vu1DamB,Towards Robustness of Text-to-SQL Models Against Natural and Realistic Adversarial Table Perturbation,['aclweb.org/ACL/ARR/2021/November/Paper182/Authors'],['Anonymous'],"The robustness of Text-to-SQL parsers against adversarial perturbations plays a crucial role in delivering highly reliable applications. Previous studies along this line primarily focused on perturbations in the natural language question side, neglecting the variability of tables. Motivated by this, we propose the Adversarial Table Perturbation (ATP) as a new attacking paradigm to measure robustness of Text-to-SQL models. Following this proposition, we curate ADVETA, the first robustness evaluation benchmark featuring natural and realistic ATPs. All tested state-of-the-art models experience dramatic performance drops on ADVETA, revealing significant room of improvement. To defense against ATP, we build a systematic adversarial training example generation framework tailored for better contextualization of tabular data. Experiments show that our approach brings models best robustness improvement against ATP, while also substantially boost model robustness against NL-side perturbations. We will release ADVETA and code to facilitate future research.",/pdf/587e8b88704735e8d4e3782a7628715a939c2819.pdf,,,,,anonymous|towards_robustness_of_texttosql_models_against_natural_and_realistic_adversarial_table_perturbation,,,,,,/attachment/c33b5f55b6788d145a9df1d4421f9f82ffbdaad4.zip,,,
758,lYli-bAuK54,Evaluating the Text-to-SQL Capabilities of Large Language Models,['aclweb.org/ACL/ARR/2021/November/Paper1576/Authors'],['Anonymous'],"We perform an empirical evaluation of Text-to-SQL capabilities of the Codex language model. We find that, without any finetuning, Codex is a strong baseline on the Spider benchmark; we also analyze the failure modes of Codex in this setting. Furthermore, we demonstrate on the GeoQuery and Scholar benchmarks that a small number of in-domain examples provided in the prompt enables Codex to perform better than state-of-the-art models finetuned on such few-shot examples.",/pdf/2706eb84d5942d48c0f31ce84c22eb817de20999.pdf,,,,,anonymous|evaluating_the_texttosql_capabilities_of_large_language_models,,,,,,,,,
759,VH-Tl1iDjnd,Challenges in Region-Specific Image Captioning: A Deep Learning Approach,['aclweb.org/ACL/ARR/2021/November/Paper468/Authors'],['Anonymous'],"Region-specific image captioning is the task of generating a caption from an image such that the caption is about the specific region in that image.
This paper describes the challenges involved in region-specific image captioning and provides several methods to utilize the region-specific features to enhance the quality of the captions in addition to utilizing the features from the whole image. Our experiments on real-world data sets demonstrate that generating region-specific captions is challenging even after utilizing the information specific to the region.
We analyze the variables impacting the quality of the captions which include the bounding box size and the region-specific feature extractor.",/pdf/2e58d11bbcad05832e2ee646ec1f6a2be986fc38.pdf,,,,,anonymous|challenges_in_regionspecific_image_captioning_a_deep_learning_approach,,,,,,,,,
760,Mt65vKZERbg,Towards Automated Real-time Evaluation in Text-based Counseling,['aclweb.org/ACL/ARR/2021/November/Paper2902/Authors'],['Anonymous'],"Automated real-time evaluation of counselor-client interaction is important for ensuring quality counseling but the rules are difficult to articulate. Recent advancements in machine learning methods show the possibility of learning such rules automatically. However, these methods often demand large scale and high quality counseling data, which are difficult to collect. To address this issue, we build an online counseling platform, which allows professional psychotherapists to provide free counseling services to those are in need. In exchange, we collect the counseling transcripts. Within a year of its operation, we manage to get one of the largest set of (675) transcripts of counseling sessions. To further leverage the valuable data we have, we label our dataset using both coarse- and fine-grained labels and use a set of pretraining techniques. In the end, we are able to achieve practically useful accuracy in both labeling system. ",/pdf/20684c535a9c6de6b79afab89625227c1920b54e.pdf,,,,,anonymous|towards_automated_realtime_evaluation_in_textbased_counseling,,,,,,,,,
761,EYGbUXsmW8D,Controllable Natural Language Generation with Contrastive Prefixes,['aclweb.org/ACL/ARR/2021/November/Paper1483/Authors'],['Anonymous'],"To guide the generation of large pretrained language models (LM), previous work has focused on directly fine-tuning the language model or utilizing an attribute discriminator. In this work, we propose a novel lightweight framework for controllable GPT2 generation, which utilizes a set of small attribute-specific vectors, called prefixes (Li and Liang, 2021), to steer natural language generation. Different from Li and Liang (2021), where each prefix is trained independently, we take the relationship among prefixes into consideration and train multiple prefixes simultaneously. We propose a novel supervised method and also an unsupervised method to train the prefixes for single-aspect control while the combination of these two methods can achieve multi-aspect control. Experimental results on both single-aspect and multi-aspect control show that our methods can guide generation towards the desired attributes while keeping high linguistic quality.",/pdf/31d83e4ce99b6a296c7d1bdaef82315347078fc0.pdf,,,,,anonymous|controllable_natural_language_generation_with_contrastive_prefixes,,,,,,,/attachment/b641b35df153f86291fce9969924a8c15efe618e.pdf,https://openreview.net/forum?id=lIjFrpZCSRl,/attachment/853827853ef6c9d446eb1ce5d6d8874f6cdd36b7.pdf
762,zO6zGKsaex,A Weak Self-supervision with Transition-Based Modeling for Reference Resolution,['aclweb.org/ACL/ARR/2021/November/Paper2611/Authors'],['Anonymous'],"The reference resolution is a task to find the link between an entity and its source action in the same recipe. In this study, we introduce a weak self-supervision method with a transition-based model for reference resolution tasks for recipes, where the aim of the task is to make the syntax of the instructions used for reference resolution with self annotation. The results show that our approach to the problem outperforms the previous unsupervised methods with %8 F1. Especially, our models show %82 accuracies of pronoun, and %85 accuracies for null entity resolution.",/pdf/d93091d9364f0074cd99b7bba5b1cd2f12a4ceca.pdf,,,,,anonymous|a_weak_selfsupervision_with_transitionbased_modeling_for_reference_resolution,,,,,,,,,
763,xEWyJkPuZlI,RNG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper584/Authors'],['Anonymous'],"Existing KBQA approaches, despite achieving strong performance on i.i.d. test data, often struggle in generalizing to questions involving unseen KB schema items. Prior ranking-based approaches have shown some success in generalization, but suffer from the coverage issue. We present RnG-KBQA, a Rank-and-Generate approach for KBQA, which remedies the coverage issue with a generation model while preserving a strong generalization capability. Our approach first uses a contrastive ranker to rank a set of candidate logical forms obtained by searching over the knowledge graph. It then introduces a tailored generation model conditioned on the question and the top-ranked candidates to compose the final logical form. We achieve new state-of-the-art results on GrailQA and WebQSP datasets. In particular, our method surpasses the prior state-of-the-art by a large margin on the GrailQA leaderboard. In addition, RnG-KBQA outperforms all prior approaches on the popular WebQSP benchmark, even including the ones that use the oracle entity linking. The experimental results demonstrate the effectiveness of the interplay between ranking and generation, which leads to the superior performance of our proposed approach across all settings with especially strong improvements in zero-shot generalization.",/pdf/6ca21eff540c32e5a137e25c768d0f5ac014313b.pdf,/attachment/c5b880c1593e1e962b6835dc1108619dc600eec2.zip,,,,anonymous|rngkbqa_generation_augmented_iterative_ranking_for_knowledge_base_question_answering,,,,,,,,,
764,9hgG9q3vb5Y,A Novel Efficient and Effective Preprocessing Strategy for Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper345/Authors'],['Anonymous'],"Text classification is an essential task of natural language processing. Preprocessing, which determines the representation of text features, is one of the key steps of text classification architecture. This paper proposes a novel efficient and effective preprocessing strategy with three methods for text classification using OMP algorithm to complete the classification. The main idea of our new preprocessing strategy is that we combine regular filtering and/or stopwords removal with tokenization and lowcase convertion, which can effectively reduce  the feature dimension and improve the quality of text feature matrix to some extent. Simulation tests on 20Newsgroups dataset show compared with the existing state-of-the-art method, our new best method reduces the number of features by 19.85$\%$, 34.35$\%$, 26.25$\%$, and 38.67$\%$, and increase the speed of text classification by 17.38\%, 25.64\%, 23.76\%, and 33.38\% with similar classification accuracy on religion, computer, science and sport data, respectively.",/pdf/90af7bd640e19d4a790bc379a6de63f66132f33a.pdf,/attachment/0a8c82b307e28e3dd580eb16dfc433d33617827b.zip,,,,anonymous|a_novel_efficient_and_effective_preprocessing_strategy_for_text_classification,,,,,,,,,
765,KviNpJWXn-U,Local Differential Privacy for Privacy-Preserving NLP Tasks,['aclweb.org/ACL/ARR/2021/November/Paper625/Authors'],['Anonymous'],"In this paper, we propose a Local Differentially Private Natural Language Processing (LDP-NLP) model that protects the privacy of user input sentences for both training and inference stages while requiring no server security trust. Compared to existing methods, the novel privacy-preserving methodology significantly reduces calibrated noise power and thus improves model accuracy by incorporating (a) an LDP-layer, (b) sub-sampling and up-sampling DP amplification algorithms for training and inference, and (c) DP composition algorithms for noise calibration. This novel LDP-NLP solution guarantees privacy for the entire training/inference data for the first time,  whereas current methods can only guarantee privacy for either a single training/inference step. Furthermore, the total privacy cost is reduced to a reasonable range, i.e., less than 10, for the first time with an accuracy loss of only 2-5\%  compared to the accuracy upper bound produced by the original model without privacy guarantee.",/pdf/def656a125b07709a0631a9a42ca36b223a40117.pdf,,,,,anonymous|local_differential_privacy_for_privacypreserving_nlp_tasks,,,,,,,,,
766,Vi9Cj61ZGsR,SagDRE: Sequence-Aware Graph-Based Document-Level Relation Extraction with Adaptive Margin Loss,['aclweb.org/ACL/ARR/2021/November/Paper109/Authors'],['Anonymous'],"Relation extraction (RE) is an important task for many natural language processing applications. Document-level relation extraction aims to extract the relations within a document and poses many challenges to the RE tasks as it requires reasoning across sentences and handling multiple relations expressed in the same document. Existing state-of-the-art document-level RE models use the graph structure to better connect long-distance correlations. In this work, we propose SagDRE model, which further considers and captures the original sequential information from the text. The proposed model learns sentence-level directional edges to capture the information flow in the document and uses the token-level sequential information to encode the shortest path from one entity to the other. In addition, we propose an adaptive margin loss to maximize the margins to separate positive and negative classes. The experimental results on datasets from various domains demonstrate the effectiveness of our proposed methods.",/pdf/f8d349402ed2ea17f80cebaf8934c863359345d0.pdf,,,,,anonymous|sagdre_sequenceaware_graphbased_documentlevel_relation_extraction_with_adaptive_margin_loss,,,,,,,,,
767,7MIy2ZKIJbN,Categorial Grammar Induction as a Compositionality Measure for Understanding the Structure of Emergent Languages,['aclweb.org/ACL/ARR/2021/November/Paper1631/Authors'],['Anonymous'],"This paper proposes a method for investigating the syntactic structure of emergent languages using categorial grammar induction.
Although the structural property of emergent languages is an important topic, little has been done on syntax and its relation to semantics.
Inspired by previous work on CCG induction for natural languages, we propose to induce categorial grammars from the sentence-meaning pairs of emergent languages.
Since an emergent language born in a common environment called signaling game is represented as pairs of a message and meaning, it is straightforward to extract sentence-meaning pairs to feed to categorial grammar induction.
We also propose two compositionality measures that are based on the information obtained from induced grammars.
Our experimental results reveal that our measures can recognize compositionality.
While correlating with existing measure TopSim, our measures can gain more insights on the compositional structure of emergent languages from induced grammars.",/pdf/c8d023515b350f1f0eb050e77fc996d8d37a5728.pdf,,,,,anonymous|categorial_grammar_induction_as_a_compositionality_measure_for_understanding_the_structure_of_emergent_languages,,,,,,,,,
768,MJfmRtVReXs,Training a Turn-level User Engagingness Predictor for Dialogues with Weak Supervision,['aclweb.org/ACL/ARR/2021/November/Paper197/Authors'],['Anonymous'],"The standard approach to evaluating dialogue engagingness is by measuring conversation turns per session (CTPS), which implies that the dialogue length is the main predictor of the user engagement with a dialogue system. The main limitation of CTPS is that it can be measured only at the session level, i.e., once the dialogue is already over. However, it is crucial for a dialogue system to continuously monitor user engagement throughout the dialogue session as well. Existing approaches to measuring turn-level engagingness require human annotations for training and lack interpretability of their scores. We pioneer an alternative approach, Remaining Depth as Engagingness Predictor (RDEP), which uses the remaining depth (RD) for each turn as the heuristic weak label for engagingness. RDEP does not require human annotations and also relates closely to CTPS, thus serving as a good learning proxy for this metric. In our experiments, we show that RDEP achieves the new state-of-the-art results on the fine-grained evaluation of dialog (FED) dataset (0.38 Spearman) and the Daily-Dialog dataset (0.62 Spearman). ",/pdf/2240000dda3bdf14dcd5807e39fc3a319a23cb02.pdf,,,,,anonymous|training_a_turnlevel_user_engagingness_predictor_for_dialogues_with_weak_supervision,,,,,,,,,
769,tSfqsV1EVem,Prototypical Verbalizer for Prompt-based Few-shot Tuning,['aclweb.org/ACL/ARR/2021/November/Paper983/Authors'],['Anonymous'],"Prompt-based tuning for pre-trained language models (PLMs) has shown its effectiveness in few-shot learning. Typically, prompt-based tuning wraps the input text into a cloze question. To make predictions, the model maps the output words to labels via a verbalizer, which is either manually designed or automatically built. However, manual verbalizers heavily depend on domain-specific prior knowledge and human efforts, while finding appropriate label words automatically still remains challenging.In this work, we propose the prototypical verbalizer (ProtoVerb) which is built directly from training data. Specifically, ProtoVerb learns prototype vectors as verbalizers by contrastive learning. In this way, the prototypes summarize training instances and are able to enclose rich class-level semantics. We conduct experiments on both topic classification and entity typing tasks, and the results demonstrate that ProtoVerb significantly outperforms current automatic verbalizers, especially when training data is extremely scarce. More surprisingly, ProtoVerb consistently boosts prompt-based tuning even on untuned PLMs, indicating an elegant non-tuning way to utilize PLMs.",/pdf/bf86747a8c65da4c0e18332ad8e1111c618d192f.pdf,,,,,anonymous|prototypical_verbalizer_for_promptbased_fewshot_tuning,,,,,,,/attachment/d00082101106e5704b56492e09fba9f477be4cea.pdf,,
770,pMxb99mJYZ4,Enhancing Text Generation with Inductive Event Reasoning,['aclweb.org/ACL/ARR/2021/November/Paper172/Authors'],['Anonymous'],"How to generate informative, coherent natural language is a very important task. Previous studies mainly focus on leveraging commonsense knowledge into generative models, which can improve the informativeness of generated texts. However, these models pay little attention to discourse coherence. Instead, we propose to utilize event chains to improve the coherence of text generation. In addition, we devise an inductive encoding module to reduce the sparsity of introduced event chains and learn the useful event evolution patterns. Specifically, we first extract event chains for the input text and then connect them as a graph. The inductive graph encoding module is then used to learn the inductive and generalized event embeddings. The event reasoning flow module follows and produces the event sketch, i.e., the reasonable events conditioned by the input text. Finally, we generate the text based on the input context and the event sketch. Experimental results indicate the effectiveness of this framework in terms of coherence and informativeness of text generation.
",/pdf/6eb70754b37543ba9cb3de4268ee0e17657292bc.pdf,/attachment/33eff8df36b9244b0bb6efda2878b61f026cb1cc.zip,,,,anonymous|enhancing_text_generation_with_inductive_event_reasoning,,,,,,,,,
771,co1IsPpK5rZ,Differentiable Learning of Rules with Constants in Knowledge Graph,['aclweb.org/ACL/ARR/2021/November/Paper835/Authors'],['Anonymous'],"Knowledge reasoning, helping overcome the incompleteness issue of knowledge graph(KG), significantly contributes to the development of large KG, which consists of relations and constants. Rule mining studies the problem of capturing interpretable patterns over KG, which is one of the key tasks of knowledge reasoning. However, previous works mainly focus on the combination of different relations, and are limited for ignoring the importance of constants. In this paper, we propose that constants should be considered in rule mining process, and introduce an Elegant  Differentiable rUle learning with Constant mEthod (EduCe). Based on soft constant operator and dynamic weight, the model we proposed can mine more diverse and accurate logical rules while controlling the number of parameters, which is also a great challenge to this problem. Experiment results on several benchmark datasets demonstrate the effectiveness and accuracy of rule with constants.",/pdf/0eeff75afda8a81bd2ad772c3e17ca9636dbb1ab.pdf,/attachment/88e5639b5281cf315c40fb0b0a34a1607303d152.zip,,,,anonymous|differentiable_learning_of_rules_with_constants_in_knowledge_graph,,,,,,/attachment/aa7b23c01610e300c6bdafad0d857279af16849c.zip,,,
772,kCbUq8tjwNc,Crossword: Estimating Unknown Embeddings using Cross Attention and Alignment Strategies,['aclweb.org/ACL/ARR/2021/November/Paper906/Authors'],['Anonymous'],"Word embedding methods like word2vec and GloVe have been shown to learn strong representations of words.  However, these methods only learn representations for words in the training corpus.  This is problematic, as models using these representations need ways to handle unknown and new words, known as out-of-vocabulary (OOV) words.  As a result, there have been multiple attempts to learn OOV word representations in a similar fashion to how humans learn new words, using surrounding words (``context clues"") and word roots/subwords.  However, most current approaches suffer from two problems.  First, these models calculate context clue estimates and subword estimates separately and then combine them shallowly for a final estimate, therefore ignoring potentially important information each type can learn from the other.  Secondly, although subword embeddings are trained to estimate word vectors, we find these embeddings don't occupy the same space as word embeddings.  Current models do not take this into account, and do not align the spaces before combining them.  In response to this, we propose Crossword, a transformer based OOV estimation model that combines context and subwords at the attention level, allowing each type to influence the other for a stronger final estimate.  Crossword successfully combines these different sources of information using cross attention, along with strategies to align subword and context spaces. ",/pdf/2a5b3abc91246b13f35521cbf39248f1950b17fe.pdf,,,,,anonymous|crossword_estimating_unknown_embeddings_using_cross_attention_and_alignment_strategies,,,,,,,,,
773,peJrpYeuzEA,Last to Learn Bias: Analyzing and Mitigating a Shortcut in Question Matching,['aclweb.org/ACL/ARR/2021/November/Paper1979/Authors'],['Anonymous'],"Recent studies report that even if deep neural models make correct predictions, models may be relying on shortcut rather than understanding the semantics of the text. Previous studies indicate that the shortcut deriving from the biased data distribution in training set makes spurious correlations between features and labels. In this paper, we focus on analyzing and mitigating the biased data distribution in question matching by exploring the model behavior and performance. In particular, we define bias-word as the shortcut, and explore the following questions: (1) Will the bias affect the model? (2) How does the bias affect the model's decision? Our analysis reveals that bias-words make significantly higher contributions to model predictions than random words, and the models tend to assign labels that are highly correlated to the bias-words. To mitigate the effects of shortcut, we propose a simple approach that learns no-bias-examples first but bias-examples last. The experiments demonstrate the effectiveness of the proposed approach.",/pdf/485004bb8dd19a2b393764382b577bd40d63bed0.pdf,,,,,anonymous|last_to_learn_bias_analyzing_and_mitigating_a_shortcut_in_question_matching,,,,,,,,,
774,mcTbeq0cqBM,Understanding Gender Bias in Knowledge Base Embeddings,['aclweb.org/ACL/ARR/2021/November/Paper856/Authors'],['Anonymous'],"Knowledge base (KB) embeddings have been shown to contain gender biases. In this paper, we study two questions regarding these biases: how to quantify them, and how to trace their origins in KB? Specifically, first, we develop two novel bias measures respectively for a group of person entities and an individual person entity. Evidence of their validity is observed by comparison with real-world census data. Second, we use the influence function to inspect the contribution of each triple in KB to the overall group bias. To exemplify the potential applications of our study, we also present two strategies (by adding and removing KB triples) to mitigate gender biases in KB embeddings.",/pdf/d924ee3d15208665cbc464d2ba9d2687ba9d3a72.pdf,,,,,anonymous|understanding_gender_bias_in_knowledge_base_embeddings,,,,,,,,,
775,5BtSP5Wi7gn,Hyperlink-induced Pre-training for Passage Retrieval of Open-domain Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper894/Authors'],['Anonymous'],"To alleviate the data scarcity problem in training question answering systems, recent works propose additional intermediate pre-training for dense passage retrieval (DPR). However, there still remains a large discrepancy between the provided upstream signals and the downstream question-passage relevance, which leads to less improvement. To bridge this gap, we propose the Hyperlink-induced Pre-training (HLP), a method to pre-train the dense retriever with the text relevance induced by hyperlink-based topology within Web documents. We demonstrate that the hyperlink-based structures of dual-link and co-mention can provide effective relevance signals for large-scale pre-training that better facilitate downstream passage retrieval. We investigate the effectiveness of our approach across a wide range of open-domain QA datasets under zero-shot, few-shot, multi-hop, and out-of-domain scenarios. The experiments show our HLP outperforms the BM25 by up to 7 points as well as other pre-training methods by up to 30 points in terms of top-20 retrieval accuracy under the zero-shot scenario. Furthermore, HLP significantly outperforms other pre-training methods under the other scenarios. ",/pdf/a49d56e16698f2d02e54d0fcd48252c8b67e029c.pdf,/attachment/fa749c20a0d46773ca4fe13b62dcbb2ec0a8390a.zip,,,,anonymous|hyperlinkinduced_pretraining_for_passage_retrieval_of_opendomain_question_answering,,,,,,/attachment/910eb9ba6986404479df0295e125d1ab877a2022.zip,/attachment/dc517b73ea238e6328111711b8b7fa0fc1e13960.pdf,https://openreview.net/forum?id=3u_QlWGUHL0,/attachment/1ef5c589df9283bb1263922c31c0df6b87671ad0.pdf
776,UF7a5kIdzk,ELLE: Efficient Lifelong Pre-training for Emerging Data,['aclweb.org/ACL/ARR/2021/November/Paper1012/Authors'],['Anonymous'],"Current pre-trained language models (PLM) are typically trained with static data, ignoring that in real-world scenarios, streaming data of various sources may continuously grow. This requires PLMs to integrate the information from all the sources in a lifelong manner. Although this goal could be achieved by exhaustive pre-training on all the existing data, such a process is known to be computationally expensive. To this end, we propose ELLE, aiming at efficient lifelong pre-training for emerging data. Specifically, ELLE consists of (1) function preserved model expansion, which flexibly expands an existing PLM's width and depth to improve the efficiency of knowledge acquisition; and (2) pre-trained domain prompts, which disentangle the versatile knowledge learned during pre-training and stimulate the proper knowledge for downstream tasks. We experiment ELLE with streaming data from $5$ domains on BERT and GPT. The results show the superiority of ELLE over various lifelong learning baselines in both pre-training efficiency and downstream performances. All the data, model parameters and codes used will be available upon publication.",/pdf/95ff892a26fe227299564df821892ddabe4bcb9e.pdf,/attachment/4c6a75b34e0c50ec32c48b232e3d9f4cb80454db.zip,,,,anonymous|elle_efficient_lifelong_pretraining_for_emerging_data,,,,,,,,,
777,oeBzdJ6CHfh,From the Detection of Toxic Spans in Online Discussions to the Analysis of Toxic-to-Civil Transfer,['aclweb.org/ACL/ARR/2021/November/Paper1404/Authors'],['Anonymous'],"We study the task of toxic spans detection, which concerns the detection of the spans that make a text toxic, when detecting such spans is possible. We introduce a dataset for this task, ToxicSpans, which we release publicly. By experimenting with several methods, we show that sequence labeling models perform best, but methods that add generic rationale extraction mechanisms on top of classifiers trained to predict if a post is toxic or not are also surprisingly promising. Finally, we use ToxicSpans and systems trained on it, to provide further analysis of state-of-the-art toxic to non-toxic transfer systems, as well as human performance on that latter task. Our work highlights challenges in finer toxicity detection and mitigation.",/pdf/4d0573865875ec09d0a62e124958ea9d6c81b3e9.pdf,,,,,anonymous|from_the_detection_of_toxic_spans_in_online_discussions_to_the_analysis_of_toxictocivil_transfer,,,,,,,,,
778,53F2mLQQj8J,When More Data Hurts: A Troubling Quirk in Developing Broad-Coverage Natural Language Understanding Systems,['aclweb.org/ACL/ARR/2021/November/Paper2218/Authors'],['Anonymous'],"In natural language understanding (NLU) production systems, the end users' evolving needs necessitate the addition of new abilities, indexed by discrete symbols, requiring additional training data and resulting in dynamic, ever-growing datasets.
Dataset growth introduces new challenges: we find that when learning to map inputs to a new symbol from a fixed number of annotations, more data can in fact {\emph{reduce}} the model's performance on examples that involve this new symbol.
We show that this trend holds for multiple models on two datasets for common NLU tasks: intent recognition and semantic parsing.
We demonstrate that the performance decrease is largely associated with an effect we refer to as source signal dilution, which occurs when strong lexical cues in the training data become diluted as the dataset grows.
Selectively dropping training examples to prevent source dilution often reverses the performance decrease, suggesting a direction for improving models.
We release our code and models at \url{anonymous-link}. ",/pdf/a138fc6915ab4688a64189ae9cbc1a3112d11e97.pdf,,,,,anonymous|when_more_data_hurts_a_troubling_quirk_in_developing_broadcoverage_natural_language_understanding_systems,,,,,,,,,
779,gG0lBcnXCQw,Increasing Entity Linking upper bound through a more effective Candidate Generation System,['aclweb.org/ACL/ARR/2021/November/Paper947/Authors'],['Anonymous'],"Entity Linking (EL) aligns entity mentions in text to entries in a knowledge base. It usually comprises of two phases: candidate generation and candidate ranking. While most methods focus on the latter phase, it is candidate generation that sets the upper bound for both time and accuracy of an EL system. We propose a simple approach for improving candidate generation by efficiently embedding mention-entity pairs in dense space through a BERT-based bi-encoder. Specifically, we introduce a new pooling function and incorporate entity type side-information. We achieve a new state-of-the-art 84.28% recall of the gold entity in the Zero-shot EL dataset with just 50 candidates, compared to the previous 82.06% with 64 candidates. We report the results from extensive experimentation using our proposed model on both seen and unseen entity datasets. Our results suggest that our approach could be a useful complement to existing EL methods.",/pdf/bfb9be64080383a3c322c8b564685e84d96d1353.pdf,,,,,anonymous|increasing_entity_linking_upper_bound_through_a_more_effective_candidate_generation_system,,,,,,,,,
780,Br6vHcHuXHM,Class Embeddings for Improved Out-of-Scope Detection in Intent Classification,['aclweb.org/ACL/ARR/2021/November/Paper1086/Authors'],['Anonymous'],"This work presents a deep investigation of {\emph class embeddings} for intent classification, which had only been timidly addressed before. We show that there are advantages in representing classes as dense vectors instead of one-hot-encoded ones, similar to the way sentence embeddings became the standard representation instead of one-hot-encoding of bags of words. Some of our results corroborate previous findings showing that class embeddings can be a better approach to deal with out-of-scope examples. But this paper goes further by arguing that there are gains by simply changing from the traditional one-hot-encoding with softmax to one-hot embeddings. We also show that there is a lot of room for the better use of class embeddings by exploring random embeddings. The results suggest that optimal class embeddings could exist, with significant improvement on classification metrics, particularly out-of-scope detection. Additionally, we observe that the dimension of the class embedding might depend on the objective function, and that can open up for research on new neural network architectures to make better use of class embeddings.",/pdf/c50341264c4facb328e1c102b06d8ebf6c0d73a9.pdf,,,,,anonymous|class_embeddings_for_improved_outofscope_detection_in_intent_classification,,,,,,,,,
781,LsW-6FzpUiW,BARCOR: Towards A Unified Framework for Conversational Recommendation,['aclweb.org/ACL/ARR/2021/November/Paper1028/Authors'],['Anonymous'],"Recommendation systems focus on helping users find items of interest in the situations of information overload, where users' preferences are typically estimated by past observed behaviors. In contrast, conversational recommendation systems (CRS) aim to understand users' preferences via interactions in conversation flows. CRS is a complex problem that consists of two main tasks: (1) recommendation and (2) response generation. Previous work often tried to solve the problem in a modular manner, where recommenders and response generators are separate neural models. Such modular architectures often come with a complicated and unintuitive connection between the modules, leading to inefficient learning and other issues. In this work, we propose a unified framework based on BART for conversational recommendation, which tackles two tasks in a single model. Furthermore, we also design and collect a lightweight knowledge graph for CRS in the movie domain. The experimental results show that the proposed methods achieve the state-of-the-art.",/pdf/dfbd6fde286e8de0487ea4fd8cabd231a7517d16.pdf,/attachment/0c907aca3542cf7af28bf3aab6605158850ff193.zip,,,,anonymous|barcor_towards_a_unified_framework_for_conversational_recommendation,,,,,,,,,
782,UI0P4BMeqqy,Effective Token Graph Modeling using a Novel Labeling Strategy for Structured Sentiment Analysis,['aclweb.org/ACL/ARR/2021/November/Paper2575/Authors'],['Anonymous'],"The state-of-the-art model for structured  sentiment analysis casts the task as a dependency parsing problem, which has some limitations: (1) The label proportions for span prediction and span relation prediction are imbalanced; (2) Two nodes in a dependency graph cannot have multiple arcs, which are necessary for this task; (3) The losses of predicting the imbalanced labels are directly applied in the prediction layer, which further exacerbate the imbalance problem. In this work, we propose nichetargeting solutions for this issues. First, we introduce a novel labeling strategy, which contains two sets of token pair labels, namely essential labels and whole labels. The essential label set consists of the minimum labels for this task, which are relatively balanced and applied in the prediction layer. The whole label set includes rich labels to help our model capture various token relations, which is imbalanced but merely applied in the hidden layer to softly influence our model. Moreover, we also propose an effective model to well collaborate with our labeling strategy, which is equipped with the graph attention network to iteratively refine token representations, and the adaptive multi-label classification to dynamically predict multiple relations between token pairs. We perform extensive experiments on 5 benchmark datasets in four languages. Experimental results show that our model outperforms previous SOTA models by a large margin. We believe that our labeling strategy and model can be well extended to other structured prediction tasks.",/pdf/303712a34465478f685e5e1fb961cd61e13cdd4e.pdf,,,,,anonymous|effective_token_graph_modeling_using_a_novel_labeling_strategy_for_structured_sentiment_analysis,,,,,,,,,
783,GxjCYmQAody,N-grammer: Augmenting Transformers with latent  n-grams,['aclweb.org/ACL/ARR/2021/November/Paper302/Authors'],['Anonymous'],"Transformer models have recently emerged as one of the foundational models in natural language processing, and as a byproduct, there has been significant recent interest and investment in scaling these models. However, the training and inference costs of these large Transformer language models are prohibitive, thus necessitating more research in identifying more efficient variants. In this work, we propose a simple yet effective modification to the Transformer architecture inspired by the literature in statistical language modeling, by augmenting the model with n-grams constructed from a discrete latent representation of the text sequence. We evaluate our model, the N-grammer on language modeling on the C4 data-set, and find that it outperforms several strong baselines such as the Transformer and the Primer. We will open-source our model for reproducibility purposes upon acceptance.",/pdf/210ff42b028a5553d44a613b06b7be9cd45904d9.pdf,,,,,anonymous|ngrammer_augmenting_transformers_with_latent_ngrams,,,,,,,,,
784,cBDrOuONuhl,Phone-ing it in: Towards Flexible Multi-Modal Language Model Training by Phonetic Representations of Data,['aclweb.org/ACL/ARR/2021/November/Paper658/Authors'],['Anonymous'],"Multi-modal techniques offer significant untapped potential to unlock improved NLP functionality for local languages. However, many advances in language model pre-training are focused on text, a fact that only increases systematic inequalities in the performance of NLP tasks across the world's languages. In this work, we propose a multi-modal approach to train language models using whatever text and/or audio data might be available in a language. Initial experiments using Swahili and Kinyarwanda data suggest the viability of the approach for downstream Named Entity Recognition (NER) tasks, with models pre-trained on phone data showing an improvement of up to 6\% F1-score above models that are trained from scratch.",/pdf/6ffb67c307f94f2ea2dd89c9a25310b93f2393ed.pdf,,,,,anonymous|phoneing_it_in_towards_flexible_multimodal_language_model_training_by_phonetic_representations_of_data,,,,,,,,,
785,Jqxi0yHcghg,CodeRetriever: Unimodal and Bimodal Contrastive Learning for Code Search,['aclweb.org/ACL/ARR/2021/November/Paper98/Authors'],['Anonymous'],"In this paper, we propose the CodeRetriever model, which combines the unimodal and bimodal contrastive learning to train function-level code semantic representations, specifically for the code search task. For unimodal contrastive learning, we design a semantic-guided method to build positive code pairs based on the documentation and function name. For bimodal contrastive learning, we leverage the documentation and in-line comments of code to build text-code pairs. Both contrastive objectives can fully leverage the large-scale code corpus for pre-training. Experimental results on several public benchmarks, (i.e., CodeSearch, CoSQA, etc.) demonstrate the effectiveness of CodeRetriever in the zero-shot setting. By fine-tuning with domain/language specified downstream data, CodeRetriever achieves the new state-of-the-art performance with significant improvement over existing code pre-trained models. We will make the code, model checkpoint, and constructed datasets publicly available.",/pdf/fc19d91cdec1044200f30139092fd6d7375c55c6.pdf,,,,,anonymous|coderetriever_unimodal_and_bimodal_contrastive_learning_for_code_search,,,,,,,,,
786,CVMLX_miq8a,Fine-grained video paragraph captioning via exploring object-centered internal and external knowledge,['aclweb.org/ACL/ARR/2021/November/Paper2416/Authors'],['Anonymous'],"Video paragraph captioning task aims at generating a fine-grained, coherent and relevant paragraph for a video. Existing works often treat the objects (the potential main components in a sentence) isolated from the whole video content, and rarely explore the latent semantic relation between a certain object and the current video concepts, causing the generated description dull and even incorrect. Besides, different from images where objects are static, the temporal states of objects are changing in videos. The dynamic information could be contributed to better understand the whole video content. Towards generating a more detailed and stick-to-the-topic paragraph, we propose a novel framework that focuses on exploring the rich semantic and temporal meaning of objects, by constructing the concept graph from the external commonsense knowledge and the state graph from the internal video frames. Extensive experiments on ActivityNet captions and Youcook2 demonstrate the effectiveness of our method compared to the state-of-the-art works. We will release our code on GitHub community.",/pdf/ac4a3975f84024f65ce01b1f0480ef6d81b6910d.pdf,,,,,anonymous|finegrained_video_paragraph_captioning_via_exploring_objectcentered_internal_and_external_knowledge,,,,,,,,,
787,tiuszgEsW9,HSC-Rocket: An interactive dialogue assistant to make agents composing service better through human feedback,['aclweb.org/ACL/ARR/2021/November/Paper524/Authors'],['Anonymous'],"Facing the current dynamic service environment, fast and efficient service composition has attracted great attention in recent years. Users prefer to express their personal requirements based on natural language, and their real-time feedback could better reflect the effect of service composition to a great extent. Consequently, this paper designs an interactive dialogue assistant, HSC-Rocket, to better provide service composition by considering human feedback. Firstly, we propose a human-computer interaction dynamic service composition algorithm based on reinforcement learning. The design of the reward mechanism considers the quality of service (QoS) and real-time feedback, which can more accurately meet the demands of users. Then, the functional requirements are analyzed through word embedding, to realize the dynamic composition of abstract and concrete services. Furthermore, we utilize the sample enhancement method to alleviate the issue of fewer sample data in the initial stage of user interaction, which improves the robustness of our system. Accordingly, we have implemented the HSC-Rocket prototype, which allows users to obtain multi-domain dialogue requirements. Extensive experiments on the RapidAPI dataset have demonstrated the superiority and effectiveness of the HSC-Rocket.",/pdf/5e4cd07ed90ad179c14adbbf0e41203a0b8a86b8.pdf,,,,,anonymous|hscrocket_an_interactive_dialogue_assistant_to_make_agents_composing_service_better_through_human_feedback,,,,,,,,,
788,2XUhQv_e70d,Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets,['aclweb.org/ACL/ARR/2021/November/Paper1604/Authors'],['Anonymous'],"Natural language processing models often exploit spurious correlations between task-independent features and labels in datasets to perform well only within the distributions they are trained on, while not generalising to different task distributions. We propose to tackle this problem by generating a debiased version of a dataset, which can then be used to train a debiased, off-the-shelf model, by simply replacing its training data. Our approach consists of 1) a method for training data generators to generate high-quality, label-consistent data samples; and 2) a filtering mechanism for removing data points that contribute to spurious correlations, measured in terms of z-statistics. We generate debiased versions of the SNLI and MNLI datasets, and we evaluate on a large suite of debiased, out-of-distribution, and adversarial test sets. Results show that models trained on our debiased datasets generalise significantly better than those trained on the original datasets in all settings. On the majority of the datasets, our method outperforms or performs comparably to previous state-of-the-art debiasing strategies, and when combined with an orthogonal technique, product-of-experts, the performance improves further and achieves state-of-the-art results of SNLI-hard and MNLI-hard.",/pdf/3d8072508740e1a7eb6c3c99e343dccd8e5ccf2c.pdf,,,,,anonymous|generating_data_to_mitigate_spurious_correlations_in_natural_language_inference_datasets,,,,,,,,,
789,OETeobnKUXL,A Meta-Learning Approach for Few-Shot (Dis)Agreement Identification in Online Discussions,['aclweb.org/ACL/ARR/2021/November/Paper2826/Authors'],['Anonymous'],"Online discussions are abundant with different opinions for a common topic, and identifying agreement and disagreement between online posts enables many opinion mining applications. Realizing the increasing needs to analyze opinions for emergent new topics (e.g., from ""mask mandate"" to ""COVID vaccination"") that however tend to lack annotations, we present the first meta-learning approach for few-shot (dis)agreement identification on a new topic with few labeled instances. We further design a lexicon based regularization loss and propose  domain-aware task augmentation for meta-training to enable the meta-learner to learn both domain-invariant cues and domain-specific expressions for (dis)agreement identification. Extensive experiments on two benchmark datasets and evaluation on three topic domains demonstrate the effectiveness of the meta-learning approach that consistently and noticeably outperforms the conventional transfer learning approach based on fine-tuning. ",/pdf/ffeabcb61773d309327f0bc4946f857520efbaaa.pdf,,,,,anonymous|a_metalearning_approach_for_fewshot_disagreement_identification_in_online_discussions,,,,,,,,,
790,5qBpV_gBeM,Visual-Language Navigation Pretraining via Prompt-based Environmental Self-exploration,['aclweb.org/ACL/ARR/2021/November/Paper1936/Authors'],['Anonymous'],"Vision-language navigation (VLN) is a challenging task due to its large searching space in the environment. To address this problem, previous works have proposed some methods of fine-tuning a large model that pretrained on large-scale datasets. However, the conventional fine-tuning methods require extra human-labeled navigation data and lack self-exploration capabilities in environments, which hinders their generalization of unseen scenes.  To improve the ability of fast cross-domain adaptation, we propose Prompt-based Environmental Self-exploration (ProbES), which can self-explore the environments by sampling trajectories and automatically generates structured instructions via a large-scale cross-modal pretrained model (CLIP). Our method fully utilizes the knowledge learned from CLIP to build an in-domain dataset by self-exploration without human labeling. Unlike the conventional approach of fine-tuning, we introduce prompt tuning to achieve fast adaptation for language embeddings, which substantially improves the learning efficiency by leveraging prior knowledge. By automatically synthesizing trajectory-instruction pairs in any environment without human supervision and instruction prompt tuning, our model can adapt to diverse vision-language navigation tasks, including VLN and REVERIE. Both qualitative and quantitative results show that our ProbES significantly improves the generalization ability of the navigation model.",/pdf/160d2175ef6cf601d0fb37042a8bfa6083d73247.pdf,,,,,anonymous|visuallanguage_navigation_pretraining_via_promptbased_environmental_selfexploration,,,,,,,,,
791,VhXA2h9n860,e-CARE: a New Dataset for Exploring Explainable Causal Reasoning,['aclweb.org/ACL/ARR/2021/November/Paper284/Authors'],['Anonymous'],"Understanding causality has vital importance for various Natural Language Processing (NLP) applications. Beyond the labeled instances, conceptual explanations of the causality can provide deep understanding of the causal fact to facilitate the causal reasoning process. However, such explanation information still remains absent in existing causal reasoning resources. In this paper, we fill this gap by presenting a human-annotated explainable CAusal REasoning dataset (e-CARE), which contains over 20K causal reasoning questions, together with natural language formed explanations of the causal questions. 
Experimental results show that generating valid explanations for causal facts still remains especially challenging for the state-of-the-art models, and the explanation information can be helpful for promoting the accuracy and stability of causal reasoning models. ",/pdf/60afa2444cf7b0afb7bcd6cd7a76941075814598.pdf,,,,,anonymous|ecare_a_new_dataset_for_exploring_explainable_causal_reasoning,,,,,,/attachment/b53cb8be795000fa27ec9d0570a1c63fe70699a2.zip,,https://openreview.net/forum?id=48T0DriwGcv,
792,nYMRUKrQV5,StableMoE: Stable Routing Strategy for Mixture of Experts,['aclweb.org/ACL/ARR/2021/November/Paper2688/Authors'],['Anonymous'],"The Mixture-of-Experts (MoE) technique can scale up the model size of Transformers with an affordable computational overhead. We point out that existing learning-to-route MoE methods suffer from the routing fluctuation issue, i.e., the target expert of the same input may change along with training, but only one expert will be activated for the input during inference. The routing fluctuation tends to harm sample efficiency because the same input updates different experts but only one is finally used. In this paper, we propose StableMoE with two training stages to address the routing fluctuation problem. In the first training stage, we learn a balanced and cohesive routing strategy and distill it into a lightweight router decoupled from the backbone model. In the second training stage, we utilize the distilled router to determine the token-to-expert assignment and freeze it for a stable routing strategy. We validate our method on language modeling and multilingual machine translation. The results show that StableMoE outperforms existing MoE methods in terms of both convergence speed and performance.",/pdf/fedd446c0938f4c6021dcfea0bc9156b1dc849e3.pdf,/attachment/752bb5c448e520de0edf79802edf10d92e3fac5d.zip,,,,anonymous|stablemoe_stable_routing_strategy_for_mixture_of_experts,,,,,,,,,
793,S7bmlbwUV8,Structured Pruning Learns Compact and Accurate Models,['aclweb.org/ACL/ARR/2021/November/Paper1873/Authors'],['Anonymous'],"The growing size of neural language models has led to increased attention in model compression. Pruning methods start from a large model and gradually remove model weights---they can significantly reduce the model size but hardly achieve impressive runtime efficiency.
On the other hand, distillation methods start from a shallower, compact model and can obtain large speedups---however, they are costly to train on large amounts of unlabeled data. In this work, we show that structured pruning can match the distillation counterparts in both latency ($>$10$\times$) and accuracy ($>$92\%) and result in highly compact and efficient subnetworks. Unlike distillation, our task-specific pruning approach, {\ours}, does not need to pre-specify the model architecture nor rely on unlabeled data. Our solution is to jointly prune layers and sub-modules such as heads and hidden units in Transformer models through $l_0$ regularization while ensuring that the resulting model is parallelizable. We also propose a layerwise distillation approach to further guide pruning. Finally, our pruned structures reveal interesting patterns---for example, more than 70\% of feed-forward and 50\% of self-attention layers can be easily pruned, while the first and last 1-2 layers are likely to remain for highly compressed models.",/pdf/ad393ca5e2d07be3dc2ea4f750030cfc6ebc9146.pdf,/attachment/eb96820bc6d1850681ba153a3e7f3b5bc11c29b6.zip,,,,anonymous|structured_pruning_learns_compact_and_accurate_models,,,,,,,,,
794,j6lUruWB7m0,Towards Fully Self-Supervised Learning of Knowledge from Unstructured Text,['aclweb.org/ACL/ARR/2021/November/Paper2009/Authors'],['Anonymous'],"Pre-trained language models (PLMs) like BERT have made significant progress in various downstream NLP tasks. However, recent works find that PLMs are short in acquiring knowledge from the unstructured text, by asking models to do cloze-style tests. 
To understand the internal behavior of PLMs in retrieving knowledge, we firstly define knowledge-baring tokens and knowledge-free tokens for unstructured text and manually label on some samples. Then, we find that PLMs are more likely to predict incorrectly on K-B tokens and attend less attention to those tokens inside the self-attention module.  Based on these observations, we develop two solutions to help the model learn more knowledge from the unstructured text in a fully self-supervised manner.
Experiments on knowledge probing tasks show the effectiveness of the proposed methods. To our knowledge, we are the first to explore fully self-supervised learning of knowledge in continue pre-training.",/pdf/9b5c0369fdb22c76805759fd7990f496440f9751.pdf,/attachment/aeae1d204f2dd6f0ffe91c696dd90e56a734288a.zip,,,,anonymous|towards_fully_selfsupervised_learning_of_knowledge_from_unstructured_text,,,,,,/attachment/144dccb9333ce05776f13eb86269b315deea78ef.zip,/attachment/95210fb1eb016ae727197784ffc69791c79d4dd1.pdf,https://openreview.net/forum?id=HAR5DH8vebf&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Daclweb.org%2FACL%2FARR%2F2021%2FSeptember%2FAuthors%23your-submissions),/attachment/b6023097cf22a534c95801b0224d9684e39c8c3b.pdf
795,tKTRPNNc7A3,Open Domain Question Answering over Virtual Documents: A Unified Approach for Data and Text,['aclweb.org/ACL/ARR/2021/November/Paper772/Authors'],['Anonymous'],"Due to its potential for a universal interface over both data and text, data-to-text generation is becoming increasingly popular.
However, few prior work has focused on its application to downstream tasks, e.g. using the converted data for grounding or reasoning. 
In this work, we bridge this gap and use the data-to-text method as a means for encoding structured knowledge for knowledge-intensive applications, i.e. open-domain question answering (ODQA).
Specifically, we propose a verbalizer-retriever-reader framework for ODQA over data and text where verbalized tables from Wikipedia and graphs from Wikidata are used as augmented knowledge sources.
We show that our Unified Data and Text QA, UDT-QA.
can effectively benefit from the expanded knowledge index, leading to large gains over text-only baselines.
Notably, our approach sets the single-model state-of-the-art on Natural Questions.
Furthermore, our analyses indicate that verbalized knowledge is preferred for answer reasoning for both adapted and hot-swap settings.",/pdf/c9eb497820d96bca1b10e68bc5a4ae8333744fa0.pdf,,,,,anonymous|open_domain_question_answering_over_virtual_documents_a_unified_approach_for_data_and_text,,,,,,,,,
796,MNvpOScCfJE,Rumor Detection on Twitter Through SMOTE+RU Hybrid Top Features Extraction Model using Ensemble Method,['aclweb.org/ACL/ARR/2021/November/Paper1155/Authors'],['Anonymous'],"In today's scenario, the prevalence of social media like Twitter or Weibo has increased a lot. Such platforms allow their users to discuss and share rumors due to their open nature. As the social media platforms impacts a large section of the community, the spread of rumors on Twitter may result in economic, political & geopolitical consequences for a state. Various rumor detection techniques has been reported that tracks the rumored posts on a social media platforms automatically. Existing rumor detection techniques implement either machine learning methods (like SVM or Random Forest classifier) or deep learning methods such as Convolutional Neural Networks etc. However, the traditional techniques fail to offer the high accuracy in rumor detection. In this paper, we propose a hybrid technique for rumor detection that is based on SMOTE+RU feature extraction model. The proposed technique initially use Pearson Correlation method to find and extract the highly correlated features from the data set. Then the synthetic minority oversampling technique (SMOTE) and random under sampling (RU) are used to balance the minority and majority class data. Further, the random forest method provides the important feature extraction. Then the proposed technique use ensemble method which is the hybrid of decision tree, k-nearest neighbor, ada-boost and neural network methods. The majority voting technique is used to get the best possible prediction from the ensemble model. Our proposed rumor detection technique offers increased level of accuracy as compared to the relevant existing techniques. The experimental evaluation exhibited more than 91 % results in terms of accuracy, precision, recall and F1-score metrics.",/pdf/3dad7423d39195006afb7473869a593e90057f07.pdf,,,,,anonymous|rumor_detection_on_twitter_through_smoteru_hybrid_top_features_extraction_model_using_ensemble_method,,,,,,,,,
797,uvLxnBf2zx,GauSE: Gaussian Enhanced Self-Attention for Event Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1969/Authors'],['Anonymous'],"Event Extraction (EE) has benefited from pre-trained language models (PLMs), in which the self-attention mechanism could pay attention to the global relationship between triggers/arguments and context words to enhance performance. However, existing PLM-based methods are not good enough at capturing local trigger/argument-specific knowledge. To this end, we propose a Gaussian enhanced Self-attention Event extraction framework (GauSE), which models the syntactic-related local information of trigger/argument as a Gaussian bias for the first time, to pay more attention to the syntactic scope of the local region. Furthermore, existing methods rarely consider multiple occurrences of the same triggers/arguments in EE. We explore the global interaction strategies among multiple localness of the same triggers/arguments to fuse the corresponding distributions and capture more latent information scopes. Compared to traditional GCN-based models, our methods could introduce syntactic relationships without over-smoothing problem in deep GCN layers. Experiments on EE datasets demonstrate the effectiveness and generalization of our proposed approach.",/pdf/54b249edf3b3e0cc86db9d703e7ebef8ef3a65c5.pdf,/attachment/f9432a5ae1778dbd8bc350bf0efc8f9fa02f3252.zip,,,,anonymous|gause_gaussian_enhanced_selfattention_for_event_extraction,,,,,,/attachment/938062b8f43c8d8f789dcdd714ec9fe7de69de74.zip,,,
798,tA9LZJLqyKT,SHIELD: Defending Textual Neural Networks against Black-Box Adversarial Attacks with Stochastic Multi-Expert Patcher,['aclweb.org/ACL/ARR/2021/November/Paper1423/Authors'],['Anonymous'],"Even though several methods have proposed to defend textual neural network (NN) models against black-box adversarial attacks, they often defend against a specific text perturbation strategy and/or require re-training the models from scratch. This leads to a lack of generalization in practice and redundant computation. In particular, the state-of-the-art transformer models (e.g., BERT, RoBERTa) require great time and computation resources. By borrowing an idea from software engineering, in order to address these limitations, we propose a novel algorithm, SHIELD, which modifies and re-trains only the last layer of a textual NN, and thus it ""patches"" and ""transforms"" the NN into a stochastic weighted ensemble of multi-expert prediction heads. Considering that most of current black-box attacks rely on iterative search mechanisms to optimize their adversarial perturbations, SHIELD confuses the attackers by automatically utilizing different weighted ensembles of predictors depending on the input. In other words, SHIELD breaks a fundamental assumption of the attack, which is a victim NN model remains constant during an attack. By conducting comprehensive experiments, we demonstrate that all of CNN, RNN, BERT, and RoBERTa-based textual NNs, once patched by SHIELD, exhibit a relative enhancement of 15%--70% in accuracy on average against 14 different black-box attacks, outperforming 6 defensive baselines across 3 public datasets. All codes are to be released. ",/pdf/b27e10f7ed3091520976688dc22732c5f268e5ca.pdf,,,,,anonymous|shield_defending_textual_neural_networks_against_blackbox_adversarial_attacks_with_stochastic_multiexpert_patcher,,,,,,,/attachment/d8c45740b12ac5c5df5d378bda0f08f0d2e524b6.pdf,https://openreview.net/forum?id=F3lYBj1dpXX,/attachment/acaf14cac626a1ecce3c2373a896050f0e2df12f.pdf
799,uRVJ8qwi7aF,OpenKorPOS: Democratizing Korean Tokenization with Voting-Based Open Corpus Annotation,['aclweb.org/ACL/ARR/2021/November/Paper645/Authors'],['Anonymous'],"Korean is a language with complex morphology that uses spaces at larger-than-word boundaries, unlike other East-Asian languages. While morpheme-based text generation can provide significant semantic advantages compared to commonly used character-level approaches, Korean morphological analyzers only provide a sequence of morpheme-level tokens, losing information in the tokenization process. Two crucial issues are the loss of spacing information and subcharacter level morpheme normalization, both of which make the tokenization result challenging to reconstruct the original input string, deterring the application to generative tasks. As this problem originates from the conventional scheme used when creating a POS tagging corpus, we propose an improvement to the existing scheme, which makes it friendlier to generative tasks.

On top of that, we suggest a semi-automatic annotation of a corpus by leveraging public analyzers. We vote the surface and POS from the outcome and fill the sequence with the selected morphemes, yielding tokenization with a decent quality that incorporates space information. Our scheme is verified via an evaluation done on an external corpus, and subsequently, is adopted to Korean Wikipedia to construct an open, permissive resource. We compare morphological analyzer performance trained on our corpus with existing methods, then perform an extrinsic evaluation on a downstream task.",/pdf/56bc63ff57a2934b283c974b15716b0793a46fb0.pdf,,,,,anonymous|openkorpos_democratizing_korean_tokenization_with_votingbased_open_corpus_annotation,,,,,,/attachment/9f2aeb0f98be3f95a5a3d76f4d8471d486eb7d0b.zip,,,
800,3ahgCzy7ASM,CaM-Gen: Causally-aware Guided Text Generation,['aclweb.org/ACL/ARR/2021/November/Paper2348/Authors'],['Anonymous'],"Content is created for a well-defined purpose, often described by a metric or signal represented in the form of structured information. The relationship between the goal (metrics) of target content and the content itself is non-trivial. While large-scale language models show promising text generation capabilities, guiding the generated text with external metrics is challenging.
These metrics and content tend to have inherent relationships and not all of them may be of consequence. We introduce CaM-Gen: Causally-aware Generative Networks guided by user-defined target metrics incorporating the causal relationships between the metric and content features. We leverage causal inference techniques to identify causally significant aspects of a text that lead to the target metric and then explicitly guide generative models towards these by a feedback mechanism. We propose this mechanism for variational autoencoder and Transformer-based generative models. The proposed models beat baselines in terms of the target metric control while maintaining fluency and language quality of the generated text. To the best of our knowledge, this is one of the early attempts at controlled generation incorporating a metric guide using causal inference.",/pdf/9ee05d4c96d99e11d73decc3ce28669e0a376ba7.pdf,,,,,anonymous|camgen_causallyaware_guided_text_generation,,,,,,,,,
801,Gd-yVeT8P6w,Combining Paraphrase Pre-trained Model and Controllable Rules for Unsupervised Sentence Simplification,['aclweb.org/ACL/ARR/2021/November/Paper1838/Authors'],['Anonymous'],"Although neural sequence-to-sequence models for sentence simplification achieve some progress, they still suffer from the data sparsity problem and are lack of controllability. This paper proposes a two-stage approach for text simplification. First, considering text simplification is closely related to text summarization and paraphrase, we fine-tune the pre-trained model on the dataset of summarization and paraphrase. Further, in order to achieve interpretation and controllablity, we design controllable scorers to evaluate the simplified sentence from three aspects: adequacy, fluency and simplicity, which are applied to sort the generated sentences and output the best one. Experiments show that our approach improves the previous best performance of the unsupervised model by a considerable margin of 5.53 points, achieving a new state-of-the-art result. Our method even performs competitively with supervised models in both automatic metrics and human evaluation. ",/pdf/24656183be392e25bdb8535c7b079ee320066a7b.pdf,/attachment/d034c7df8ca893876e74a71e2ce33de872690d77.zip,,,,anonymous|combining_paraphrase_pretrained_model_and_controllable_rules_for_unsupervised_sentence_simplification,,,,,,,,,
802,yYJhaF4-dZ9,Unsupervised Dependency Graph Network,['aclweb.org/ACL/ARR/2021/November/Paper868/Authors'],['Anonymous'],"Recent work has identified properties of pretrained self-attention models that mirror those of dependency parse structures. In particular, some self-attention heads correspond well to individual dependency types. Inspired by these developments, we propose a new competitive mechanism that encourages these attention heads to model different dependency relations. We introduce a new model, the Unsupervised Dependency Graph Network (UDGN), that can induce dependency structures from raw corpora and the masked language modeling task. Experiment results show that UDGN achieves very strong unsupervised dependency parsing performance without gold POS tags and any other external information. The competitive gated heads show a strong correlation with human-annotated dependency types. Furthermore, the UDGN can also achieve competitive performance on masked language modeling and sentence textual similarity tasks. ",/pdf/7523b8f1db455732d34d0c610b0386d5b2698d1c.pdf,,,,,anonymous|unsupervised_dependency_graph_network,,,,,,,,,
803,-jZkAHbpHlk,UNICON: Unsupervised Intent Discovery via Semantic-level Contrastive Learning,['aclweb.org/ACL/ARR/2021/November/Paper2833/Authors'],['Anonymous'],"Discovering new intents is crucial for expanding domains in dialogue systems or natural language understanding (NLU) systems. A typical approach is to leverage unsupervised and semi-supervised learning to train a neural encoder to produce representations of utterances that are adequate for clustering then perform clustering on the representations to detect unseen clusters of intents. Recently, instance-level contrastive learning has been proposed to improve representation quality for better clustering. However, the proposed method suffers from semantic distortion in text augmentation and even from representation inadequacy due to limitations of using representations of pre-trained language models, typically BERT. Neural encoders can be powerful representation learners, but the initial parameters of pre-trained language models do not reliably produce representations that are suitable for capturing semantic distances. To eliminate the necessity of data augmentation and reduce the negative impact of pre-trained language models as encoders, we propose UNICON, a novel contrastive learning method that utilizes auxiliary external representations to provide powerful guidance for the encoder. Neural encoders can be powerful representation learners, but the initial parameters of pre-trained language models do not reliably produce representations that are suitable for capturing semantic distances. To eliminate the necessity of data augmentation and reduce the negative impact of pre-trained language models as encoders, we propose UNICON, a novel contrastive learning method that utilizes auxiliary external representations to provide powerful guidance for the encoder.",/pdf/cb68ee3cd0fcbf2eebb1525cfc3ddc9b9e3f939a.pdf,,,,,anonymous|unicon_unsupervised_intent_discovery_via_semanticlevel_contrastive_learning,,,,,,,,,
804,QWqNTJUZzss,UniSAr: A Unified Structure-Aware Autoregressive Language Model for Text-to-SQL,['aclweb.org/ACL/ARR/2021/November/Paper2122/Authors'],['Anonymous'],"Existing text-to-SQL semantic parsers are typically designed for particular settings such as handling queries that span multiple tables, domains or turns which makes them ineffective when applied to different settings. We present UniSAr (Unified Structure-Aware Autoregressive Language Model), which benefits from directly using an off-the-shelf language model architecture and demonstrates consistently high performance under different settings. Specifically, UniSAr extends existing autoregressive language models to incorporate three non-invasive extensions to make them structure-aware: (1) adding structure mark to encode database schema, conversation context, and their relationships;  (2) constrained decoding to decode well structured SQL for a given database schema; and (3) SQL completion to complete potential missing JOIN relationships in SQL based on database schema. On seven well-known text-to-SQL datasets including multi-domain, multi-table and multi-turn, UniSAr demonstrates highly comparable or better performance to the most advanced specifically-designed text-to-SQL models. Importantly, our UniSAr is non-invasive, such that other core model advances in text-to-SQL can also adopt our extensions to further enhance performance.",/pdf/0eef57687528d3bb3ee7ff56787e5a1c1ce6ee2b.pdf,,,,,anonymous|unisar_a_unified_structureaware_autoregressive_language_model_for_texttosql,,,,,,,,,
805,msFpRstzoXt,Learning Emotion-Aware Contextual Representations for Emotion-Cause Pair Extraction,['aclweb.org/ACL/ARR/2021/November/Paper2179/Authors'],['Anonymous'],"Emotion Cause Pair Extraction (ECPE), the task expanded from the previous emotion cause extraction (ECE) task, focuses on extracting emotion-cause pairs in text. Two reasons have made ECPE a more challenging, but more applicable task in real world scenarios: 1) an ECPE model needs to identify both emotions and their corresponding causes without the annotation of emotions. 2) the ECPE task involves finding causes for multiple emotions in the document context, while ECE is for one emotion. However, most existing methods for ECPE adopt an unified approach that models emotion extraction and cause extraction jointly through shared contextual representations, which is suboptimal in extracting multiple emotion-cause pairs. In addition, previous ECPE works are evaluated on one ECE dataset, which exhibits a bias that majority of documents have only one emotion-cause pair. In this work, we propose a simple pipelined approach that builds on two independent encoders, in which the emotion extraction model only provide input features for the cause extraction model. We reconstruct the benchmark dataset to better meet ECPE settings. Based on experiments conducted on the original and reconstructed dataset, we validate that our model can learn distinct contextual representations specific to each emotion, and thus achieves state-of-the-art performance on both datasets, while showing robustness in analyzing more complex document context.",/pdf/52bf76ba8e73e3071d6808a1ee156dab814726f8.pdf,/attachment/298032395cf05cbe1033bf497a34ca5c9655b8af.zip,,,,anonymous|learning_emotionaware_contextual_representations_for_emotioncause_pair_extraction,,,,,,/attachment/27f59b3405cd7b4b8cc10aa5818a452feffd3d27.zip,/attachment/8bd9e5d8aca2bc060361eef4ed6f8306c8b40812.pdf,https://openreview.net/forum?id=8yJ0RpqNppY,/attachment/eeb77a13e5e5d283e883031282bde1e6a2f96b64.pdf
806,Okx_NapRIiN,Temporal Language Modeling for Short Text Document Classification with Transformers,['aclweb.org/ACL/ARR/2021/November/Paper2633/Authors'],['Anonymous'],"Language models are typically trained on solely text data, not utilizing documents timestamp, which is available in most internet corpora. In this paper, we examine the impact of incorporating timestamp into transformer language model in terms of downstream classification task and masked language modeling on 2 short texts corpora. We examine different timestamp components: day of the month, month, year, weekday. We test different methods of incorporating date into the model: prefixing date components into text input and adding trained date embeddings. Our study shows, that such a temporal language model performs better than a regular language model for both documents from training data time span and unseen time span. That holds true for classification and language modeling. Prefixing date components into text performs not worse than training special date components embeddings.",/pdf/96dbd8e6a2e7bc592c35c922de4d83e6b2b573d6.pdf,,,,,anonymous|temporal_language_modeling_for_short_text_document_classification_with_transformers,,,,,,,,,
807,ePdyvmDcX2,Evaluating Extreme Hierarchical Multi-label Classification,['aclweb.org/ACL/ARR/2021/November/Paper1328/Authors'],['Anonymous'],"Several natural language processing (NLP) tasks are defined as a classification problem in its most complex form: Multi-label Hierarchical Extreme classification, in which items may be associated with multiple classes from a set of thousands of possible classes organized in a hierarchy and with a highly unbalanced distribution both in terms of class frequency and the number of labels per item. We analyze the state of the art of evaluation metrics based on a set of formal properties and we define an information theoretic based metric inspired by the Information Contrast Model (ICM). Experiments on synthetic data and a case study on real data show the suitability of the ICM for such  scenarios. ",/pdf/2b497139bc0f54263e0dceaad7f4693fe2f2142d.pdf,,,,,anonymous|evaluating_extreme_hierarchical_multilabel_classification,,,,,,,,,
808,4_SfdRz54k_,Pinyin-bert: A new solution to Chinese pinyin to character conversion task,['aclweb.org/ACL/ARR/2021/November/Paper16/Authors'],['Anonymous'],"Pinyin to Character conversion (P2C) task is the key task of Input Method Engine (IME) in commercial input software for Asian languages, such as Chinese, Japanese, Thai language, and so on. The dominant technique is Ngram language model together with smoothing technique. However, Ngram model's low capacity limits its performance. Under the trend of deep learning, this paper choose the powerful bert network architecture and propose Pinyin-bert to solve the P2C task, which achieves substantial performance improvement from Ngram model. Furthermore, we combine Pinyin-bert with Ngram model under Markov model's framework and improve performance further. Lastly, we design a way to incorporate external lexicon into Pinyin-bert so as to adapt to the out of domain.",/pdf/0a18f45ad935b907fcc5104700dd0b9206413781.pdf,,,,,anonymous|pinyinbert_a_new_solution_to_chinese_pinyin_to_character_conversion_task,,,,,,,,,
809,_9uQwEX4Hpb,"Same Neurons, Different Languages: Probing Morphosyntax in Multilingual Pre-trained Models",['aclweb.org/ACL/ARR/2021/November/Paper1818/Authors'],['Anonymous'],"The success of multilingual pre-trained models in transferring knowledge cross-lingually is underpinned by their ability to learn representations shared by multiple languages even in absence of any explicit supervision. However, it remains unclear how. In this work, we conjecture that multilingual pre-trained models can derive language-universal abstractions about grammar. In particular, we investigate whether morphosyntactic information is encoded in the same subset of neurons in different languages. We conduct the first large-scale empirical study over 43 typologically diverse languages and 14 morphosyntactic categories with a state-of-the-art neuron-level probe. Our findings show that the cross-lingual overlap between neurons is significant, but its extent may vary across categories and depends on language proximity and pre-training data size.",/pdf/a38e8c6ebb75806fd0b981a0e350960e265468a4.pdf,,,,,anonymous|same_neurons_different_languages_probing_morphosyntax_in_multilingual_pretrained_models,,,,,,,,,
810,bfFF04cLumE,DAQE: Exploring the Direct Assessment on Word-Level Quality Estimation in Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper183/Authors'],['Anonymous'],"Word-level Quality Estimation (QE) of Machine Translation (MT) helps to find out potential translation errors in translated sentences without reference. The current collection of QE datasets is typically based on the exact matching between the words from MT sentences and post-edited sentences through Translation Error Rate (TER) toolkit. However, we find that the data generated by TER cannot faithfully reflect human judgment, which can make the research deviate from the correct direction. To overcome the limitation, we for the first time collect the direct assessment (DA) dataset for the word-level QE task, namely DAQE, which contains the golden corpus annotated by expert translators on two language pairs. Furthermore, we propose two tag correcting strategies, namely tag refinement strategy and tree-based annotation strategy, to make the TER-based artificial QE tags closer to human judgement, so that the corrected TER-based data can be used to improve the QE performance during pre-training. We conduct detailed experiments on our collected DAQE dataset, as well as comparison with the TER-based QE dataset MLQE-PE. The results not only show our proposed dataset DAQE is more consistent with human judgment but also confirm the effectiveness of the pre-training approach with the tag correcting strategies.",/pdf/f13be8a812ac9964752a163258082330399f6dba.pdf,/attachment/4ba88364b2013e8b9e91a60fb909701ce803b507.zip,,,,anonymous|daqe_exploring_the_direct_assessment_on_wordlevel_quality_estimation_in_machine_translation,,,,,,/attachment/5b22ca7e91fb9b4d9516dc945f28e625a67d39d7.zip,,,
811,36uj9y9UdXS,On the Use of Entity Embeddings from Pre-Trained Language Models for Knowledge Graph Completion,['aclweb.org/ACL/ARR/2021/November/Paper1722/Authors'],['Anonymous'],"Recent work has found that entity representations can be extracted from pre-trained language models to develop knowledge graph completion models that are more robust to the naturally occurring sparsity found in knowledge graphs. In this work, we explore how to best extract and incorporate those embeddings. We explore the suitability of the extracted embeddings for direct use in entity ranking and introduce both unsupervised and supervised processing methods that can lead to improved downstream performance. We then introduce supervised embedding extraction methods and demonstrate that we can extract more informative representations. We also examine the effect of language model selection and find that the choice of model can have a significant impact. We then synthesize our findings and develop a knowledge graph completion model that significantly outperforms recent neural models.",/pdf/ba1a15c2d2c8c38603342f072511540bc685a7ef.pdf,,,,,anonymous|on_the_use_of_entity_embeddings_from_pretrained_language_models_for_knowledge_graph_completion,,,,,,,,,
812,iq4q5zvzMt9,On a Benefit of Masked Language Model Pretraining: Robustness to Simplicity Bias,['aclweb.org/ACL/ARR/2021/November/Paper400/Authors'],['Anonymous'],"Despite the success of pretrained masked language models (MLM), why MLM pretraining is useful is still a question not fully answered. In this work we theoretically and empirically that MLM pretraining makes models robust to lexicon-level spurious features, partly answering the question. Our explanation is that MLM pretraining may alleviate problems brought by simplicity bias (Shah et al., 2020), which refers to the phenomenon that a deep model tends to rely excessively on simple features. In NLP tasks, those simple features could be token-level features whose spurious association with the label can be learned easily. We show that MLM pretraining makes learning from the context easier. Thus, pretrained models are less likely to rely excessively on a single token. We also explore the theoretical explanations of MLM’s efficacy in causal settings. Compared with Wei et al. (2021), we achieve similar results with milder assumption. Finally, we close the gap between our theories and real-world practices by conducting experiments on real-world tasks.",/pdf/d642ef7ebe75c648c13b334ccffe637caf325cba.pdf,,,,,anonymous|on_a_benefit_of_masked_language_model_pretraining_robustness_to_simplicity_bias,,,,,,,,,
813,7I3KTEhKaAK,PromptBERT: Improving BERT Sentence Embeddings with Prompts,['aclweb.org/ACL/ARR/2021/November/Paper824/Authors'],['Anonymous'],"  The poor performance of the original BERT for sentence semantic similarity has been widely discussed in previous works. We find that unsatisfactory performance is mainly due to the static token embeddings biases and the ineffective BERT layers, rather than the high cosine similarity of the sentence embeddings. To this end, we propose a prompt based sentence embeddings method which can reduce token embeddings biases and make the original BERT layers more effectively. By reformulating the sentence embeddings task as the fillin-the-blanks problem, our method significantly improves the performance of original BERT. We discuss two prompt representing methods and three prompt searching methods for prompt based sentence embeddings. Moreover, we propose a novel unsupervised training objective by the technology of template denoising, which substantially shortens the performance gap between the supervised and unsupervised setting. For experiments, we evaluate our method on both non fine-tuned and fine-tuned settings. Even a non fine-tuned method can outperform the fine-tuned methods like unsupervised ConSERT on STS tasks. Our fine-tuned method outperforms the state-of-the-art method SimCSE in both unsupervised and supervised settings. Compared to SimCSE, we achieve 2.29 and 2.58 points improvements on BERT and RoBERTa respectively under the unsupervised setting. 
",/pdf/e45aac0f4307ae947773e55036786b4cbcc9900e.pdf,/attachment/f614b5a4414b74e07464e09da065af95be3cd29d.zip,,,,anonymous|promptbert_improving_bert_sentence_embeddings_with_prompts,,,,,,,,,
814,u7APnx5qszb,Structure Representation Learning by Jointly Learning to Pool and Represent,['aclweb.org/ACL/ARR/2021/November/Paper2403/Authors'],['Anonymous'],"Structure representation learning is a task to provide an overall representation for a given structure (e.g., sequential text, non-sequential graph). This representation characterizes the property of that structure. Previous methods decompose the task into an element representation learning phase and a pooling phase to aggregate element representations. Their pooling phase only considers the final representation of each element without considering the relationship between these elements that are used only to construct representations of elements. In this paper, we conjecture that classification performance suffers from the lack of relation exploitation while pooling and propose the Self-Attention Pooling to dynamically provide centrality scores for pooling based on the self-attention scores from the element representation learning.  Simply applying Self-Attention Pooling improves model performance on $3$ sentence classification tasks ({$\boldsymbol{\uparrow 2.9}$}) and $5$ graph classification tasks ({$\boldsymbol{\uparrow 2.1}$}) on average.
",/pdf/fa98505ad660e2d07d25cff5e706b9685666250a.pdf,/attachment/6775169047f345dda668853fd248cf6f85b0bf1c.zip,,,,anonymous|structure_representation_learning_by_jointly_learning_to_pool_and_represent,,,,,,,,,
815,U9KwypIe7yU,C$^3$KG: A Chinese Commonsense Conversation Knowledge Graph,['aclweb.org/ACL/ARR/2021/November/Paper2770/Authors'],['Anonymous'],"Existing commonsense knowledge bases often organize tuples in an isolated manner, which is deficient for commonsense conversational models to plan the next steps. To fill the gap, we curate a large-scale multi-turn human-written conversation corpus, and create the first Chinese commonsense conversation knowledge graph which incorporates both social commonsense knowledge and dialog flow information. To show the potential of our graph, we develop a graph-conversation matching approach, and benchmark two graph-grounded conversational tasks. All the resources in this work will be released to foster future research.",/pdf/06ec342abe4315e8b770a25c8e7737ea34223d0b.pdf,,,,,anonymous|c^3kg_a_chinese_commonsense_conversation_knowledge_graph,,,,,,,,,
816,zMcPwwJkBLv,Compact Token Representations with Contextual Quantization for Efficient Document Re-ranking,['aclweb.org/ACL/ARR/2021/November/Paper1407/Authors'],['Anonymous'],"Transformer based re-ranking models can achieve  high search relevance through context-aware soft matching of query tokens with document tokens. To alleviate runtime complexity of such inference, previous work has adopted a late interaction architecture
with pre-computed contextual token representations at the cost of a large online storage. This paper proposes contextual quantization of token embeddings by decoupling document-specific and document-independent ranking contributions during codebook-based compression. This allows effective online decompression and embedding composition for better search relevance. This paper presents  an evaluation of the above compact token representation model in terms of relevance and space efficiency.",/pdf/55be578bff1317e6f754e6bf513e92470baecf16.pdf,,,,,anonymous|compact_token_representations_with_contextual_quantization_for_efficient_document_reranking,,,,,,,,,
817,RVHhqfKskfs,A System to Filter out Unwanted Social Media Content in Real-time on iPhones,['aclweb.org/ACL/ARR/2021/November/Paper65/Authors'],['Anonymous'],"Social media users are often harassed. This paper presents a patented system to filter out harassing content before it reaches the recipient. Our first version is for the iPhone. To detect harassment, we adopted sentiment analysis with a supervised learning approach that combines Machine Learning (ML) text classifiers with a lexicon approach that provides a feedback loop to retrain the ML model with unknown terms. Because good data is essential to obtain the best output of any system, we focused on validating our labeled data. Our results on static and real-time data have an accuracy of, respectively, 90% and 94%. Our labeled data validation allows us to correct labels; we also realized the need to increase the number of sets in our lexicons. Our prototype demonstrates that we are able to build an AI infrastructure to filter out harassment on an iPhone in real-time with good results. ",/pdf/75a0c39105d8e21ddbf6b0aeaa84545057e2afdb.pdf,,,,,anonymous|a_system_to_filter_out_unwanted_social_media_content_in_realtime_on_iphones,,,,,,,,,
818,3c2BHw6EpCj,Explicit Modeling the Context for Chinese NER,['aclweb.org/ACL/ARR/2021/November/Paper2775/Authors'],['Anonymous'],"Named entity recognition (NER) is the foundation of many natural language processing tasks. Current NER models have achieved promising results. But as pointed by several studies, they fail with a high ratio on generalization tests such as invariance test because they heavily rely on name information. So, we propose a context module to explicitly model the contextual information, and a trainable balance factor is designed to incorporate the result of context module. To learn this factor, we propose several tailored data augmentation strategies to generate synthetic labels for it. These approaches help the model learn whether it should focus on the context. Our method achieves on average 1.2\% absolute improvement of F1 than BERT-CRF on three datasets. Moreover, our method performs on par with the best solutions who rely heavily on external features besides BERT. We also conduct invariance test to analyse the effect of the context information. The source code of our model and augmentation strategies will be available at anonymous.url.",/pdf/5ddd1f674a2e536ab3a171f1c2b7bb07c46f9380.pdf,,,,,anonymous|explicit_modeling_the_context_for_chinese_ner,,,,,,,,,
819,nqyFGAatdm,A Graph Fusion Approach to Cross-Lingual Machine Reading Comprehension,['aclweb.org/ACL/ARR/2021/November/Paper1601/Authors'],['Anonymous'],"Although great progress has been made for Machine Reading Comprehension (MRC) in English, scaling out to a large number of languages remains a huge challenge due to the lack of large amounts of annotated training data in non-English languages. To address this challenge, some recent efforts of cross-lingual MRC employ machine translation to transfer knowledge from English to other languages, through either explicit alignment or implicit attention. For effective knowledge transition, it is beneficial to leverage both semantic and syntactic information. However, the existing methods fail to explicitly incorporate syntax information in model learning. Consequently, the models are not robust to errors in alignment and noises in attention. In this work, we propose a novel approach, named GraFusionMRC, which jointly models the cross-lingual alignment information and the mono-lingual syntax information using a graph. We develop a series of algorithms including graph construction, learning, and pre-training. The experiments on two benchmark datasets for cross-lingual MRC show that our approach outperforms all strong baselines, which verifies the effectiveness of syntax information for cross-lingual MRC. The code will be made open-sourced on Github.",/pdf/820bc2178cdeb0fe96865dff1e4bf131801f5ff6.pdf,,,,,anonymous|a_graph_fusion_approach_to_crosslingual_machine_reading_comprehension,,,,,,,,,
820,mPLmX6RVDT2,MDG: Metaphorical Sentence Detection and Generation with Masked Metaphor Modeling,['aclweb.org/ACL/ARR/2021/November/Paper535/Authors'],['Anonymous'],"This study tackles literal to metaphorical sentence generation, presenting a framework that can potentially lead to the production of an infinite number of new metaphors. To achieve this goal, we propose a complete workflow that tackles metaphorical sentence classification and metaphor reconstruction. Unlike similar research works regarding metaphor generation, our approach does not require any custom
or closed-source model, hence with this work we introduce a complete literal to metaphorical open-source model. The obtained results show that a good ratio of originally literal sentences, coming from different data sources and topics, are turned to metaphorical. Human evaluation shows that our constructed metaphors are considered more fluent, creative and metaphorical than figurative statements created by a real person. Furthermore, by using our artificial data to increase the training size of a metaphorical sentence classification dataset, we register an improvement of 3% over the baseline.",/pdf/4ed7bf470cfc1a3cb6173ef2e816ae0061def9bb.pdf,,,,,anonymous|mdg_metaphorical_sentence_detection_and_generation_with_masked_metaphor_modeling,,,,,,,,,
821,euGE2v_UZgT,Towards Interpretable Math Word Problem Solving with Grounded Linguistic Logic Reasoning,['aclweb.org/ACL/ARR/2021/November/Paper2531/Authors'],['Anonymous'],"Automatically math word problem (MWP) solving is a challenging artificial intelligence task since a machine should be able to not only understand problem comprehensively on linguistics but also the  grounded math logic entailed in problem. Recently, lots of deep learning models have made great progress in MWP solving on answer accuracy, they rely on shallow heuristics to achieve high performance, lacking of grounded math logic reasoning, which makes them uninterpretable. To address this issue and push the research boundary of MWPs to interpretable MWP solving, we construct a large-scale and high-quality MWP dataset named InterMWP which consists of 11507 MWP data and annotates interpretable algebraic knowledge formulas as the grounded linguistic logic of each solving equation and asks for a solver to output the formulas when it decides current predicted node is a inner-node (operator) during expression reasoning. We further propose a strong baseline called InterSolver to show the effectiveness of our constructed dataset and show how to harvest these logic knowledge by fusing logic knowledge with semantic representation to improve problem solving and make a step towards providing interpretability. Experimental results shows that our InterSolver has strong logical formula-based interpretability while achieving high answer accuracy simultaneously. ",/pdf/e41a640f74f08b79986a4df3f825c796dc869c23.pdf,/attachment/dba2321dd8f3c42607736029bce90c3cd78c5447.zip,,,,anonymous|towards_interpretable_math_word_problem_solving_with_grounded_linguistic_logic_reasoning,,,,,,/attachment/d87943f2cc05baca81441a6a981cc28d5266a6cc.zip,,,
822,4SoRR0ov-bn,So Different Yet So Alike! Constrained Unsupervised Text Style Transfer,['aclweb.org/ACL/ARR/2021/November/Paper1892/Authors'],['Anonymous'],"Automatic transfer of text between domains has become popular in recent times. One of its aims is to preserve the semantic content while adapting to the target domain. However, it does not explicitly maintain other attributes between the source and translated text: e.g., text length and descriptiveness. Maintaining constraints in transfer has several downstream applications, including data augmentation and debiasing.  We introduce a method for such constrained unsupervised text style transfer by introducing two complementary losses to the generative adversarial network (GAN) family of models. Unlike the competing losses used in GANs, we introduce cooperative losses where the discriminator and the generator cooperate and reduce the same loss. The first is a contrastive loss and the second is a classification loss --- aiming to regularize the latent space further and bring similar sentences closer together. We demonstrate that such training retains lexical, syntactic and domain-specific constraints between domains for multiple benchmark datasets, including ones where more than one attribute change.  We show that the complementary cooperative losses improve text quality, according to both automated and human evaluation measures.",/pdf/d01a0327656489f2406fca9be5c755e896305d15.pdf,,,,,anonymous|so_different_yet_so_alike_constrained_unsupervised_text_style_transfer,,,,,,,/attachment/1e22f029eb26a0397ae0ec43fe995109372d0447.pdf,https://openreview.net/forum?id=qzlQNmFSClj,/attachment/05548deab1e3efec37fc4ea8d18ea34d860ad84f.pdf
823,OF82vVwrRmz,Pairwise proximity metrics for topic modelling evaluation based on BERT embeddings.,['aclweb.org/ACL/ARR/2021/November/Paper794/Authors'],['Anonymous'],"The use of topic modelling methods is a popular way to describe natural language text with a representative set of words. 
In order to evaluate such methods, objective metrics such as coherence and silhouette scores are commonly used. 
However, it has been shown that topic assessment based on such metrics does not align well with human judgment for classical document corpora such as articles, books and server logs and, at the same time, it is still unclear how appropriate they are for dialog data. 
In this paper, we investigate the most commonly used topic modelling evaluation scores in terms of their alignment with human judgment in the specific area of dialog speech. We show that there is still space for improvement in the objective evaluation of topic modelling, and propose a new group of metrics, called Pairwise Proximity metrics, that are shown to align better with human judgment, when compared to coherence and silhouette scores. ",/pdf/37dbea32833dd8764d3834a9f0c62662b5c9ff00.pdf,,,,,anonymous|pairwise_proximity_metrics_for_topic_modelling_evaluation_based_on_bert_embeddings,,,,,,,,,
824,1-FanTO4C1H,Towards Transparent Interactive Semantic Parsing via Step-by-Step Correction,['aclweb.org/ACL/ARR/2021/November/Paper1867/Authors'],['Anonymous'],"Existing studies on semantic parsing focus on mapping a natural-language utterance to a logical form (LF) in one turn. However, because natural language may contain ambiguity and variability, this is a difficult challenge. In this work, we investigate an interactive semantic parsing framework that explains the predicted LF step by step in natural language and enables the user to make corrections through natural-language feedback for individual steps. We focus on question answering over knowledge bases (KBQA) as an instantiation of our framework, aiming to increase the transparency of the parsing process and help the user trust the final answer. We construct INSPIRED, a crowdsourced dialogue dataset derived from the ComplexWebQuestions dataset. Our experiments show that this framework has the potential to greatly improve overall parse accuracy. Furthermore, we develop a pipeline for dialogue simulation to evaluate our framework w.r.t. a variety of state-of-the-art KBQA models without further crowdsourcing effort. The results demonstrate that our framework promises to be effective across such models.
",/pdf/119899f5f33e5964fcafc45645d9579409c5ae0c.pdf,,,,,anonymous|towards_transparent_interactive_semantic_parsing_via_stepbystep_correction,,,,,,,,,
825,m7x3FvidXhA,A Multi-task Event and Argument Trigger Detection in Hindi using POS Tagging as an Auxiliary Task,['aclweb.org/ACL/ARR/2021/November/Paper2698/Authors'],['Anonymous'],"The event, as well as argument trigger detection, are essential sub-tasks of the event extraction system. Lots of effort has been devoted to improving the performance of trigger detection systems. But, the effect of low-level tasks like Parts-of-Speech (POS) tagging as an auxiliary task in multi-task learning of event and argument trigger detection has not been understood well in literature. 
In our current work, we propose a BERT-based multi-task architecture that learns a shared representation from two sequence labeling tasks, trigger detection (both event and argument), and POS tagging in a multi-task setup using POS tagging as an auxiliary task. We show that our proposed approach achieves a significant performance boost as compared to single-task models. We perform our experiment in the Hindi language, unlike previously proposed works.",/pdf/7fabb6872b3273964ea61505049441efe85cf863.pdf,/attachment/c1f9f13d1029f4d3aceb4ce098a9cdcf1de9f325.zip,,,,anonymous|a_multitask_event_and_argument_trigger_detection_in_hindi_using_pos_tagging_as_an_auxiliary_task,,,,,,,,,
826,ZHJ0kw4Ry77,CBLUE: A Chinese Biomedical Language Understanding EvaluationBenchmark,['aclweb.org/ACL/ARR/2021/November/Paper112/Authors'],['Anonymous'],"Artificial Intelligence (AI), along with the recent progress in biomedical language understanding, is gradually offering great promise for medical practice. With the development of biomedical language understanding benchmarks, AI applications are widely used in the medical field. However, most benchmarks are limited to English, which makes it challenging to replicate many of the successes in English for other languages. To facilitate research in this direction, we collect real-world biomedical data and present the first Chinese Biomedical Language Understanding Evaluation (CBLUE) benchmark: a collection of natural language understanding tasks including named entity recognition, information extraction, clinical diagnosis normalization, single-sentence/sentence-pair classification, and an associated online platform for model evaluation, comparison, and analysis. To establish evaluation on these tasks, we report empirical results with the current 11  pre-trained Chinese models, and experimental results show that state-of-the-art neural models perform by far worse than the human ceiling. ",/pdf/63348ba6267b0f2d23b40c29cf0ac2509b73e9a0.pdf,/attachment/2761c01743c57e9d929507e5c507f9482afc0470.zip,,,,anonymous|cblue_a_chinese_biomedical_language_understanding_evaluationbenchmark,,,,,,/attachment/c8270691afbca297ae0838c70cb5af33b70d4faf.zip,,,
827,cpMUiyD9EA,HADE: Hierarchical Affective Dialog Encoder for Personality Recognition in Conversation,['aclweb.org/ACL/ARR/2021/November/Paper2341/Authors'],['Anonymous'],"Personality recognition in conversation aims to determine the personality traits of speakers through the dialogue content, which is of great importance in designing personalized conversational AI. Existing methods that use only linguistic patterns in utterances limit their performance. To fill in the gap, we investigate the effectiveness of incorporating affective information and modeling the interactions among speakers in conversations for personality recognition. However, available corpus with personality and explicit affective annotations is rare. Besides, modeling the dialog flow with multiple speakers is difficult. Faced with the issues, we proposed Hierarchical Affective Dialog Encoder (HADE) for effective personality recognition in conversation. HADE utilizes manual annotated Valance-Arousal-Dominance (VAD) vectors of single words and implicitly extracts affective information from utterances. Then, it introduces a hierarchical architecture with the dialog state embeddings to identify the speakers and encode the whole dialog flow. Finally, the affective information is integrated by an auxiliary VAD regression task to enhance personality recognition. Extensive experiments on a well-known dataset, \textbf{FriendsPersona}, demonstrate the effectiveness of our method compared with state-of-the-art models. Besides, we conduct an ablation study to discuss different approaches for integrating affective information and dialog flow modeling; the design of both parts in HADE is also verified to be effective for personality recognition in conversation.",/pdf/af4a6f0982f61350e07288dd24349397e7c95eb0.pdf,,,,,anonymous|hade_hierarchical_affective_dialog_encoder_for_personality_recognition_in_conversation,,,,,,,,,
828,8UJrIgq1m0j,"Hey AI, Can You Solve Complex Tasks by Talking to Agents?",['aclweb.org/ACL/ARR/2021/November/Paper2595/Authors'],['Anonymous'],"Training giant models from scratch for each complex task is resource- and data-inefficient. To help develop models that can leverage existing systems, we propose a new challenge: Learning to solve complex tasks by communicating with existing agents (or models) in natural language. We design a synthetic benchmark, CommaQA, with three complex reasoning tasks (explicit, implicit, numeric) designed to be solved by communicating with existing QA agents. For instance, using text and table QA agents to answer questions such as ""Who had the longest javelin throw from USA?"". We show that black-box models struggle to learn this task from scratch (accuracy under 50\%) even with access to each agent's knowledge and gold facts supervision. In contrast, models that learn to communicate with agents outperform black-box models, reaching scores of 100\% when given gold decomposition supervision. However, we show that the challenge of learning to solve complex tasks by communicating with existing agents \emph{without relying on any auxiliary supervision or data} still remains highly elusive. We will release CommaQA, along with a compositional generalization test split, to advance research in this direction.",/pdf/aa623becd329d66f6534763e1ce5f66143bb0159.pdf,,,,,anonymous|hey_ai_can_you_solve_complex_tasks_by_talking_to_agents,,,,,,/attachment/1955bc8d2f56db6188678f6a026d4a60a1acbb46.zip,,,
829,Qs__2rPyrl,Dynamic Entity Memory Network for Dialogue Relational Triplet Extraction,['aclweb.org/ACL/ARR/2021/November/Paper2679/Authors'],['Anonymous'],"Relational triplet extraction (RTE) is a crucial task in information extraction and has aroused extensive attention. Although advanced studies on RTE have achieved great progress, they are still insufficient for supporting practical applications, such as dialogue system and information retrieval. In this paper, we focus on relational triplet extraction in dialogue scenarios and introduce a new task named dialogue relational triplet extraction (DRTE). Instead of being treated as static texts like sentences or documents, dialogues should be regarded as dynamic ones generated with the progress of conversations. Thus, it imposes three important challenges, including extracting triplets in real-time with incomplete dialogue context, discovering cross-utterance relational triplets, and perceiving the transition of dialogue topics. To tackle these challenges, we propose a Dynamic Entity Memory Network (DEMN). Specifically, the key of our approach is an attentional context encoder and an entity memory network. The attentional context encoder learns dialogue semantics utterance by utterance and dynamically captures salient contexts for each utterance. The entity memory network is devised to store the entities extracted from previous utterances and for cross-utterance triplets extraction. Meanwhile, it also tracks topic transitions in real-time and forgets the semantics of trivial entities. To verify the effectiveness of our model, we manually build three datasets based on KdConv benchmark. Extensive experimental results demonstrate that our model achieves state-of-the-art performances.",/pdf/aa6052a92364ee5650bcd33ec4bb37e59330272d.pdf,,,,,anonymous|dynamic_entity_memory_network_for_dialogue_relational_triplet_extraction,,,,,,,,,
830,tJPQtbiO6jv,A Comparative Study of Pre-trained Encoders for Low-Resource Named Entity Recognition,['aclweb.org/ACL/ARR/2021/November/Paper158/Authors'],['Anonymous'],"Pre-trained language models (PLM) are effective components of few-shot named entity recognition (NER) approaches when augmented with continued pre-training on task-specific out-of-domain data or fine-tuning on in-domain data. However, their performance in low-resource scenarios, where such data is not available, remains an open question. We introduce an encoder evaluation framework, and use it to systematically compare the performance of state-of-the-art pre-trained representations on the task of low-resource NER. We analyze a wide range of encoders pre-trained with different strategies, model architectures, intermediate-task fine-tuning, and contrastive learning. Our experimental results across ten benchmark NER datasets in English and German show that encoder performance varies significantly, suggesting that the choice of encoder for a specific low-resource scenario needs to be carefully evaluated.",/pdf/bba48db4b29e29154d978ad734f75f5c53dd310c.pdf,/attachment/28a4326cbeb11e6aaf48af1f1d30598f21c31875.tgz,,,,anonymous|a_comparative_study_of_pretrained_encoders_for_lowresource_named_entity_recognition,,,,,,,,,
831,bLOUrQ0lPo,Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation,['aclweb.org/ACL/ARR/2021/November/Paper504/Authors'],['Anonymous'],"Generating adversarial examples for Neural Machine Translation (NMT) with single Round-Trip Translation (RTT) has achieved promising results by releasing the meaning-preserving restriction. However, a potential pitfall for this approach is that we cannot decide whether the generated examples are adversarial to the target NMT model or the auxiliary backward one, as the reconstruction error through the RTT can be related to either. To remedy this problem, we propose a new definition for NMT adversarial examples based on the Doubly Round-Trip Translation (DRTT). Specifically, apart from the source-target-source RTT, we also consider the target-source-target one, which is utilized to pick out the authentic adversarial examples for the target NMT model. Additionally, to enhance the robustness of the NMT model, we introduce the masked language models to construct bilingual adversarial pairs based on DRTT, which are used to train the NMT model directly. Extensive experiments on both the clean and noise test sets (including the artificial and natural noise) show that our approach substantially improves the robustness of NMT models.",/pdf/68a1d9164d5c1f074d3720dacab90e6c330d2d7b.pdf,,,,,anonymous|generating_authentic_adversarial_examples_beyond_meaningpreserving_with_doubly_roundtrip_translation,,,,,,,,,
832,rZV05s_kWMN,"""Is Whole Word Masking Always Better for Chinese BERT?"": Probing on Chinese Grammatical Error Correction",['aclweb.org/ACL/ARR/2021/November/Paper2113/Authors'],['Anonymous'],"Whole word masking (WWM), which masks all subwords corresponding to a word at once, makes a better English BERT model. For the Chinese language, however, there is no subword because each token is an atomic character. The meaning of a word in Chinese is different in that a word is a compositional unit consisting of multiple characters. Such difference motivates us to investigate whether WWM leads to better context understanding ability for Chinese BERT. To achieve this, we introduce two probing tasks related to grammatical error correction and ask pretrained models to revise or insert tokens in a masked language modeling manner. We construct a dataset including labels for 19,075 tokens in 10,448 sentences. We train three Chinese BERT models with standard character-level masking (CLM), WWM, and a combination of CLM and WWM, respectively. Our major findings are as follows: First, when one character needs to be inserted or replaced, the model trained with CLM performs the best. Second, when more than one character needs to be handled, WWM is the key to better performance. Finally, when being fine-tuned on sentence-level downstream tasks, models trained with different masking strategies perform comparably.",/pdf/0777479962922427c85fce0b03dab6c8a2739d9f.pdf,,,,,anonymous|is_whole_word_masking_always_better_for_chinese_bert_probing_on_chinese_grammatical_error_correction,,,,,,,,,
833,WSv53LzVXuH,Searching for fingerspelled content in American Sign Language,['aclweb.org/ACL/ARR/2021/November/Paper2361/Authors'],['Anonymous'],"Natural language processing for sign language video---including tasks like recognition, translation, and search---is crucial for making artificial intelligence technologies accessible to deaf individuals, and is gaining research interest in recent years.  In this paper, we address the problem of searching for fingerspelled keywords or key phrases in raw sign language videos.  This is an important task since significant content in sign language is often conveyed via fingerspelling, and to our knowledge the task has not been studied before.  We propose an end-to-end model for this task, FSS-Net, that jointly detects fingerspelling and matches it to a text sequence. Our experiments, done on a large public dataset of ASL fingerspelling in the wild, show the importance of fingerspelling detection as a component of a search and retrieval model.  Our model significantly outperforms baseline methods adapted from prior work on related tasks.",/pdf/c024ba10c4f08a26b4c9288aaff0ef2783eccd5b.pdf,,,,,anonymous|searching_for_fingerspelled_content_in_american_sign_language,,,,,,,,,
834,XpsjwTLMpu,Zero-Shot Script Parsing,['aclweb.org/ACL/ARR/2021/November/Paper629/Authors'],['Anonymous'],"Script knowledge (shrank, 1977) proved useful to a variety of NLP tasks. However, existing resources only covering a small number of activities, limiting its practical usefulness. In this work, we propose a zero-shot learning approach to script parsing, the task of tagging texts with pre-defined, scenario-specific event and participant types, which makes it possible to acquire script knowledge without domain-specific annotations. We (1) learn representations of potential event and participant mentions by promoting cluster consistency according to the annotated data; (2) perform clustering on the event / participant candidates from unannotated texts that belongs to an unseen scenario. We further exploit dependency and coreference information. The model achieves 68.1/74.4 average F1 for event / participant parsing, respectively, outperforming a previous CRF model that has access to domain-specific supervision.",/pdf/aa50df1787916afd243fd35fac994cf1f2fa9923.pdf,,,,,anonymous|zeroshot_script_parsing,,,,,,,,,
835,7KeiCuQtFoo,How Good is a Recommender in Machine-Assisted Cross Document Event Coreference Resolution Annotation?,['aclweb.org/ACL/ARR/2021/November/Paper1691/Authors'],['Anonymous'],"Annotating cross document event coreference links is a tedious task that requires annotators to have near-oracle knowledge of a document collection. The heavy cognitive load of this task decreases overall annotation quality while inevitably increasing latency. To support annotation efforts, machine-assisted recommenders can sample likely coreferent events for a given target event, thus eliminating the burden of examining large numbers of true negative pairs. However, there has been little to no work in evaluating the effectiveness of recommender approaches, particularly for the task of event coreference. To this end, we first create a simulated version of recommender based annotation for cross document event coreference resolution. Then, we adapt an existing method as the model governing recommendations. And finally, we introduce a novel method to assess the simulated recommender by evaluating an annotator-centric Recall-Annotation effort tradeoff.",/pdf/f1e43ccf08d95a75781a344d0fe1d8b79b811c54.pdf,/attachment/d02256f1ccea9e6bf22a57ae8dd41282f333ee2f.zip,,,,anonymous|how_good_is_a_recommender_in_machineassisted_cross_document_event_coreference_resolution_annotation,,,,,,,,,
836,PJy4IpnU7fW,Coreference Resolution as Span Boundary Alignment,['aclweb.org/ACL/ARR/2021/November/Paper1907/Authors'],['Anonymous'],"We propose a new fast and accurate solution for coreference resolution, in which the task is formulated as a span boundary alignment problem. In this solution, a mention is linked to another one via two edges modeling how likely two linked mentions point to the same entity. Specifically, for each mention, its head word (left boundary) needs to be well aligned with the head words of all other mentions that refer to the same entity, so does its tail word (right boundary).  Such a ``head-to-head'' and ``tail-to-tail'' alignment strategy greatly reduces the computational complexity of coreference decisions on any pair of mentions, mitigates the error propagation problem caused by mention pruning, and encourages the sharing of features across all mentions that refer to the same entity. Experimental results show that our solution achieves close to state-of-the-art performance on the CoNLL-2012 and GAP benchmarks with much less computational cost.",/pdf/85eec9c7eb53f421d679c3a144806ed91a6f46c0.pdf,,,,,anonymous|coreference_resolution_as_span_boundary_alignment,,,,,,,,,
837,b8lMsO5YtpR,Learning to Rank Visual Stories From Human Ranking Data,['aclweb.org/ACL/ARR/2021/November/Paper651/Authors'],['Anonymous'],"Visual storytelling (VIST) is a typical vision and language task that has seen extensive development in the natural language generation research domain. However, it remains unclear whether conventional automatic evaluation metrics for text generation are applicable on VIST. 
In this paper, we present the VHED (VIST Human Evaluation Data) dataset, which first re-purposes human evaluation results for automatic evaluation; hence we develop Vrank (VIST Ranker), a novel reference-free VIST metric for story evaluation. We first show that the results from commonly adopted automatic metrics for text generation have little correlation with those obtained from human evaluation, which motivates us to directly utilize human evaluation results to learn the automatic evaluation model. In the experiments, we evaluate the generated texts to predict story ranks using our model as well as other reference-based and reference-free metrics. Results show that Vrank prediction is significantly more aligned to human evaluation than other metrics with almost 30\% higher accuracy when ranking story pairs. Moreover, we demonstrate that only Vrank shows human-like behavior in its strong ability to find better stories when the quality gap between two stories is high. Finally, we show the superiority of Vrank by its generalizability to pure textual stories, and conclude that this reuse of human evaluation results puts Vrank in a strong position for continued future advances. ",/pdf/db01dc9bf0a9517d145a3dc4245217d002ce0b59.pdf,,,,,anonymous|learning_to_rank_visual_stories_from_human_ranking_data,,,,,,/attachment/8bb5238dc843972cc047c6bca6ae0b30b2f18260.zip,,,
838,d8xNE_8SsR-,Towards Job-Transition-Tag Graph for a Better Job Title Representation Learning,['aclweb.org/ACL/ARR/2021/November/Paper2603/Authors'],['Anonymous'],"Works on learning job title representation are mainly based on Job-Transition Graph, built from the working history of talents. However, since the records are usually messy, this graph is very sparse, which affects the quality of the learned representation and hinders further analysis. To address this specific issue, we propose to enrich the graph with additional nodes that improve the quality of job title representation. Specifically, we construct Job-Transition-Tag Graph, a heterogeneous graph containing two types of nodes, i.e., job titles and tags (i.e., words related to job responsibilities or functions). Along this line, we reformulate job title representation learning as the task of learning node embedding on the Job-Transition-Tag Graph. Experiments on a public CareerBuilder12 dataset and a private Randstad dataset show interest of our approach.",/pdf/8abd4ebf81dbec0c7e5fb2111f3c79122a4a74bb.pdf,,,,,anonymous|towards_jobtransitiontag_graph_for_a_better_job_title_representation_learning,,,,,,,,,
839,udaYBjwpU_M,Re-thinking Supertags in Linear Context-free Rewriting Systems for Constituency Parsing,['aclweb.org/ACL/ARR/2021/November/Paper212/Authors'],['Anonymous'],"Recently, a supertagging-based approach for parsing discontinuous constituent trees with linear context-free rewriting systems (LCFRS) was introduced. We reformulate their algorithm for the extraction of supertags from treebanks to be more concise. Moreover, we add some extensions that give us control over the extraction process in terms of supertag granularity and which terminal symbols are associated with supertags. Our additions lead to an increase in parsing quality with LCFRS supertagging in all three compared treebanks. The scores are among the state of the art in discontinuous constituent parsing.",/pdf/eecd1d0d8d9084993eaf6489a5853d85a70ea7b8.pdf,/attachment/8fae8eb91f7321223ca49d436d8019b322f4147c.tgz,,,,anonymous|rethinking_supertags_in_linear_contextfree_rewriting_systems_for_constituency_parsing,,,,,,,,,
840,THsPGQg0Pe4,Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning,['aclweb.org/ACL/ARR/2021/November/Paper1007/Authors'],['Anonymous'],"Why can pre-trained language models (PLMs) learn universal representations and effectively adapt to broad NLP tasks differing a lot superficially? In this work, we empirically find evidence indicating that the adaptations of PLMs to various few-shot tasks can be reparameterized as optimizing only a few free parameters in a unified low-dimensional intrinsic task subspace, which may help us understand why PLMs could easily adapt to various NLP tasks with small-scale data. To find such a subspace and examine its universality, we propose an analysis pipeline called intrinsic prompt tuning (IPT). Specifically, we resort to the recent success of prompt tuning and decompose the soft prompts of multiple NLP tasks into the same low-dimensional nonlinear subspace, then we learn to adapt the PLM to unseen data or tasks by only tuning parameters in this subspace. In the experiments, we study diverse few-shot NLP tasks and surprisingly find that in a 5-dimensional subspace found with 100 tasks, by only tuning 5 free parameters, we can recover 87% and 65% of the full prompt tuning performance for 100 seen tasks (using different training data) and 20 unseen tasks, respectively, showing great generalization ability of the found intrinsic task subspace. Besides being an analysis tool, IPT could further bring practical benefits, such as improving the prompt tuning stability.",/pdf/8aaf3993ec503a11e1cd68f3333b2a8e9fa59f68.pdf,/attachment/0b08070fe265ef86868593087d979b46b11a3834.zip,,,,anonymous|exploring_lowdimensional_intrinsic_task_subspace_via_prompt_tuning,,,,,,,,,
841,rn8YIulHv03,Program Transfer for Answering Complex Questions over Knowledge Bases,['aclweb.org/ACL/ARR/2021/November/Paper2192/Authors'],['Anonymous'],"Program induction for answering complex questions over knowledge bases (KBs) aims to decompose a question into a multi-step program, whose execution against the KB produces the final answer.  Learning to induce programs relies on a large number of parallel question-program pairs for the given KB. However, for most KBs, the gold program annotations are usually lacking, making learning difficult. In this paper, we propose the approach of program transfer, which aims to leverage the valuable program annotations on the rich-resourced KBs as external supervision signals to aid program induction for the low-resourced KBs  that lack program annotations. For program transfer, we design a novel two-stage parsing framework with an efficient ontology-guided pruning strategy. 
First, a sketch parser translates the question into a high-level program sketch, which is the composition of functions. Second, given the question and sketch, an argument parser searches the detailed arguments from the KB for functions. During the searching, we incorporate the KB ontology to prune the search space. The experiments on ComplexWebQuestions and WebQuestionSP show that our method outperforms SOTA methods significantly, demonstrating the effectiveness of program transfer and our framework.
",/pdf/c62d0b4484f000681c3ad9aaf8e082a149637dfb.pdf,,,,,anonymous|program_transfer_for_answering_complex_questions_over_knowledge_bases,,,,,,,,,
842,RMYtON1qyul,Dynamic Schema Graph Fusion Network for Multi-Domain Dialogue State Tracking,['aclweb.org/ACL/ARR/2021/November/Paper1877/Authors'],['Anonymous'],"Dialogue State Tracking (DST) aims to keep track of users' intentions during the course of a conversation. In DST, modelling the relations among domains and slots is still an under-studied problem. Existing approaches that have considered such relations generally fall short in: (1) fusing prior slot-domain membership relations and dialogue-aware dynamic slot relations explicitly, and (2) generalizing to unseen domains. To address these issues, we propose a novel \textbf{D}ynamic \textbf{S}chema \textbf{G}raph \textbf{F}usion \textbf{Net}work (\textbf{DSGFNet}), which generates a dynamic schema graph to explicitly fuse the prior slot-domain membership relations and dialogue-aware dynamic slot relations. It also uses the schemata to facilitate knowledge transfer to new domains. DSGFNet consists of a dialogue utterance encoder, a schema graph encoder, a dialogue-aware schema graph evolving network, and a schema graph enhanced dialogue state decoder. Empirical results on benchmark datasets, including SGD, MultiWOZ2.1, and MultiWOZ2.2, show that DSGFNet outperforms the existing methods.",/pdf/b25e1c3b4952074fcc70d08f76c09a6b412ecbf8.pdf,,,,,anonymous|dynamic_schema_graph_fusion_network_for_multidomain_dialogue_state_tracking,,,,,,,/attachment/0efaf2d419b0d47f7a15ef7dcb6a178d9c26cd3b.pdf,https://openreview.net/forum?id=mWwlF6--Pvw,/attachment/a3e071f7cfa74a7b09ac916db7c602db5b4ef582.pdf
843,iMNie7QL81W,UserIdentifier: Implicit User Representations for Simple and Effective Personalized Sentiment Analysis,['aclweb.org/ACL/ARR/2021/November/Paper1271/Authors'],['Anonymous'],"Conventionally trained classification models are trained to be as generalizable as possible, with user invariance considered desirable since the models are shared across multitudes of users.  As such, these models are often unable to produce personalized responses for individual users, based on their data.  Contrary to widely-used personalization techniques based on few-shot and meta learning, we  propose UserIdentifier, a novel scheme for training a single shared model for all users. Our approach produces personalized responses by prepending a fixed, user-specific non-trainable string (called ``user identifier'') to each user's input text. Unlike prior work, this method doesn't need any additional model parameters, any extra rounds of personal few-shot learning or any change made to the vocabulary. We empirically study different types of user identifiers (numeric, alphanumeric and also randomly generated) and demonstrate that, surprisingly, randomly generated user identifiers outperform the prefix-tuning based state-of-the-art approach by up to 13%, on a suite of sentiment analysis datasets. ",/pdf/22f3c80714f4ce7d3d30ff12752251fe4e48597a.pdf,,,,,anonymous|useridentifier_implicit_user_representations_for_simple_and_effective_personalized_sentiment_analysis,,,,,,,,,
844,1RPMTJ4c-kk,,,,,,,,,,,,,,,,,,,
845,cI1BZrJSZZ,,,,,,,,,,,,,,,,,,,
846,Ougcw7mdk8u,How Well Do Multi-hop Reading Comprehension Models Understand Date Information?,['aclweb.org/ACL/ARR/2021/November/Paper1668/Authors'],['Anonymous'],"Many previous works demonstrated that existing multi-hop reading comprehension datasets (e.g., HotpotQA) contain reasoning shortcuts, where the questions can be answered without performing multi-hop reasoning. Recently, several multi-hop datasets have been proposed to solve the reasoning shortcut problem or evaluate the internal reasoning process. However, the design of the reasoning chain for comparison questions in R4C and 2WikiMultiHopQA does not fully explain the answer; meanwhile, MuSiQue only focuses on bridge questions. Therefore, it is unclear about the ability of a model to perform step-by-step reasoning when finding an answer for a comparison question that requires comparison and numerical reasoning skills. To evaluate the model completely in a hierarchical manner, we first propose a dataset, HieraDate, created by reusing and enhancing two previous multi-hop datasets, HotpotQA and 2WikiMultiHopQA. Our dataset focuses on comparison questions on date information that require multi-hop reasoning for solving. We then evaluate the ability of existing models to understand date at three levels: extraction, reasoning, and robustness. Our experimental results reveal that the multi-hop models fail at the reasoning level. Comparison reasoning and numerical reasoning (e.g., subtraction) are key challenges that need to be addressed in future works.",/pdf/63e412c5c812035df8feb603b7a19e31d24f24cb.pdf,,,,,anonymous|how_well_do_multihop_reading_comprehension_models_understand_date_information,,,,,,,,,
847,TFvd4d9YyeA,MRCLens: an MRC Dataset Bias Detection Toolkit,['aclweb.org/ACL/ARR/2021/November/Paper2135/Authors'],['Anonymous'],"Many recent neural models have shown remarkable empirical results in Machine Reading Comprehension, but evidence suggests sometimes the models take advantage of dataset biases to predict and fail to generalize on out-of-sample data. While many other approaches have been proposed to address this issue from the computation perspective such as new architectures or training procedures, we believe a method that allows researchers to discover biases, adjust the data or the models in an earlier stage will be beneficial. Thus, we introduce MRCLens, a toolkit which detects whether biases exist before users train the full model. For the convenience of introducing the toolkit, we also provide a categorization of common biases in MRC.",/pdf/d6fc0a4a54a72910e542263dee0a5b17dbd1b2d4.pdf,,,,,anonymous|mrclens_an_mrc_dataset_bias_detection_toolkit,,,,,,,,,
848,fcxm95P_xO_,CREATE: A Benchmark for Chinese Short Video Retrieval and Title Generation,['aclweb.org/ACL/ARR/2021/November/Paper2534/Authors'],['Anonymous'],"Previous works of video captioning aim to objectively describe the video's actual content, lack of subjective and attractive expression, limiting its practical application scenarios. Video titling is intended to achieve this goal, but there is a lack of a proper benchmark. In this paper, we propose CREATE, the first large-scale Chinese shoRt vidEo retrievAl and Title gEneration benchmark, to facilitate research and application in video titling and video retrieval in Chinese. CREATE consists of a high-quality labeled 210K dataset and two large-scale 3M/10M pre-training datasets, covering 51 categories, 50K+ tags, 537K manually annotated titles and captions, and 10M+ short videos. Based on CREATE, we propose a novel model ALWIG which combines video retrieval and video titling tasks to achieve the purpose of multi-modal ALignment WIth Generation with the help of video tags and GPT pre-trained model. CREATE opens new directions for facilitating future research and applications on video titling and video retrieval in the field of Chinese short videos.",/pdf/3b03221fa638969f5a842e9f54c94d42a6cc9c6b.pdf,,,,,anonymous|create_a_benchmark_for_chinese_short_video_retrieval_and_title_generation,,,,,,/attachment/ba3994c4d9c386312a721372bc82f3a93872a165.zip,,,
849,A9aGzw9NRq,,,,,,,,,,,,,,,,,,,
850,ryDLEZuACp,Making Small Language Models Better Few-Shot Learners,['aclweb.org/ACL/ARR/2021/November/Paper510/Authors'],['Anonymous'],"Large-scale language models coupled with prompts have shown remarkable performance on few-shot learning. However, through systematic experiments, we find that the few-shot performance of small language models is poor, and using prompts on them brings fewer improvements than on larger ones. In this paper, we propose \textbf{SMASH}, an approach to improve \textbf{SMA}ll language models' few-\textbf{SH}ot ability by training on intermediate tasks before prompt-based fine-tuning on downstream tasks. We design intermediate tasks for sentence-pair tasks and single-sentence classification tasks by creating training examples with prompt templates similar to downstream tasks using sentences sampled from a large-scale unsupervised corpus, and apply knowledge distillation to distill from outputs of larger pre-trained models as training objective. We conduct extensive experiments and show that SMASH can make a 6-layer DistilRoBRETa-base achieve comparable performance on few-shot datasets to a 12-layer RoBERTa-base at a low cost.",/pdf/c90074637d2d2a43f002e5309c195b73b6fe0191.pdf,,,,,anonymous|making_small_language_models_better_fewshot_learners,,,,,,,,,
851,iZMEydyi6Sy,Shallow Parsing for Nepal Bhasa Complement Clauses,['aclweb.org/ACL/ARR/2021/November/Paper1694/Authors'],['Anonymous'],"Accelerating the process of data collection, annotation, and analysis is an urgent need for linguistic fieldwork and documentation of endangered languages (Bird, 2009). Our experiments describe how we maximize the quality for the Nepal Bhasa syntactic complement structure chunking model. Native speaker language consultants were trained to annotate a minimally selected raw data set (Ortiz Suárez et al.,2019). The embedded clauses, matrix verbs, and embedded verbs are annotated. We apply both statistical training algorithms and transfer learning in our training, including Naive Bayes, MaxEnt, and fine-tuning the pre-trained mBERT model (Devlin et al.,2018). We show that with limited annotated data, the model is already sufficient for the task. The modeling resources we used are largely available for many other endangered languages. The practice is easy to duplicate for training a shallow parser for other endangered languages in general. ",/pdf/f1c927b6d82ab4f8309ea5bb716c4cf5039f4187.pdf,,,,,anonymous|shallow_parsing_for_nepal_bhasa_complement_clauses,,,,,,/attachment/2031df3a9e003ba8b35442ec3e0f14f8727d0445.zip,,,
852,_WRoowuSImQ,Perturbation-based Self-supervised Attention for Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper8/Authors'],['Anonymous'],"For text classification, the traditional attention mechanism usually pays too much attention to words that appear frequently and needs a lot of labeled data for learning a good distribution. Introducing human attention is a classical method, but it needs a high cost of manual labeling. This paper proposes a perturbation-based self-supervised attention approach to guide attention learning without any annotation overheads. Specifically, we add as much noise as possible to all the words in the sentence simultaneously while without changing their semantics and predictions. According to the words that tolerate more noise are supposed to be less significant, we can obtain attention supervision information and utilize it to refine the attention distribution. Experimental results on three text classification tasks show that our approach can significantly promote the performance of current attention-based models and is more effective than existing self-supervised methods. We also provide visualization analysis to verify the effectiveness of our approach.",/pdf/135ec0aef29169953295c7c55a9862ef95232c5e.pdf,,,,,anonymous|perturbationbased_selfsupervised_attention_for_text_classification,,,,,,,,,
853,52j93pP1Bgd,HybriDialogue: An Information-Seeking Dialogue Dataset Grounded on Tabular and Textual Data,['aclweb.org/ACL/ARR/2021/November/Paper2188/Authors'],['Anonymous'],"A pressing challenge in current dialogue systems is to successfully converse with users on topics with information distributed across different modalities. Previous work in multi-turn dialogue systems has primarily focused on either text or table information. In more realistic scenarios, having a joint understanding of both is critical as knowledge is typically distributed over both unstructured and structured forms. We present a new dialogue dataset, HybriDialogue, which consists of crowdsourced natural conversations grounded on both Wikipedia text and tables. The conversations are created through the decomposition of complex multihop questions into simple, realistic multiturn dialogue interactions. We conduct several baseline experiments, including retrieval, system state tracking, and dialogue response generation. Our results show that there is still ample opportunity for improvement, demonstrating the importance of building stronger dialogue systems that can reason over the complex setting of information-seeking dialogue grounded on tables and text.",/pdf/467593c37526b9f91b768e30dc103803dba1e004.pdf,,,,,anonymous|hybridialogue_an_informationseeking_dialogue_dataset_grounded_on_tabular_and_textual_data,,,,,,/attachment/0ebe6b63c8e1cc6dec150372e069379fcc3f5f80.zip,,,
854,xvOljdhEPhc,Data Augmentation and Learned Layer Aggregation for Improved Multilingual Language Understanding in Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper569/Authors'],['Anonymous'],"Scaling dialogue systems to a multitude of domains, tasks and languages relies on costly and time-consuming data annotation for different domain-task-language configurations. The annotation efforts might be substantially reduced by the methods that generalise well in zero- and few-shot scenarios, and also effectively leverage external unannotated data sources (e.g., Web-scale corpora). We propose two methods to this aim, offering improved dialogue natural language understanding (NLU) across multiple languages: 1) Multi-SentAugment, and 2) LayerAgg. Multi-SentAugment is a self-training method which augments available (typically few-shot) training data with similar (automatically labelled) in-domain sentences from large monolingual Web-scale corpora. LayerAgg learns to select and combine useful semantic information scattered across different layers of a Transformer model (e.g., mBERT); it is especially suited for zero-shot scenarios as semantically richer representations should strengthen the model's cross-lingual capabilities. Applying the two methods with state-of-the-art NLU models obtains consistent improvements across two standard multilingual NLU datasets covering 16 diverse languages. The gains are observed in zero-shot, few-shot, and even in full-data scenarios. The results also suggest that the two methods achieve a synergistic effect: the best overall performance in few-shot setups is attained when the methods are used together. ",/pdf/5fca101b923b5f7b5d2b3e9690ba7d4194d1d127.pdf,,,,,anonymous|data_augmentation_and_learned_layer_aggregation_for_improved_multilingual_language_understanding_in_dialogue,,,,,,,,,
855,0Wky3xP0347,SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues,['aclweb.org/ACL/ARR/2021/November/Paper2562/Authors'],['Anonymous'],"Dialogue systems are usually categorized into two types, open-domain and task-oriented. The first one focuses on chatting with users and making them engage in the conversations, where selecting a proper topic to fit the dialogue context is essential for a successful dialogue.  The other one focuses on a specific task instead of casual talks, e.g., finding a movie on Friday night, playing a song. These two directions have been studied separately due to their different purposes. However, how to smoothly transition from social chatting to task-oriented dialogues is important for triggering the business opportunities, and there is no any public data focusing on such scenarios. Hence, this paper focuses on investigating the conversations starting from open-domain social chatting and then gradually transitioning to task-oriented purposes, and releases a large-scale dataset with detailed annotations for encouraging this research direction. To achieve this goal, this paper proposes a framework to automatically generate many dialogues without human involvement, in which any powerful open-domain dialogue generation model can be easily leveraged. The human evaluation shows that our generated dialogue data has a natural flow at a reasonable quality, showing that our released data has a great potential of guiding future research directions and commercial activities. Furthermore, the released models allow researchers to automatically generate unlimited dialogues in the target scenarios, which can greatly benefit semi-supervised and unsupervised approaches.",/pdf/7451628f040beb538b8bebbc5296c454ff68dda1.pdf,,,,,anonymous|salesbot_transitioning_from_chitchat_to_taskoriented_dialogues,,,,,,/attachment/2f5ee0d05df651e0a80243b09a884bcc19b2cee0.zip,,,
856,4kVErnnL_FZ,"On the Safety of Conversational Models: Taxonomy, Dataset, and Benchmark",['aclweb.org/ACL/ARR/2021/November/Paper194/Authors'],['Anonymous'],"Dialogue safety problems severely limit the real-world deployment of neural conversational models and have attracted great research interests recently. However, dialogue safety problems remain under-defined and the corresponding dataset is scarce. We propose a taxonomy for dialogue safety specifically designed to capture unsafe behaviors in human-bot dialogue settings, with focuses on context-sensitive unsafety, which is under-explored in prior works. To spur research in this direction, we compile DiaSafety, a dataset with rich context-sensitive unsafe examples. Experiments show that existing safety guarding tools fail severely on our dataset. As a remedy, we train a dialogue safety classifier to provide a strong baseline for context-sensitive dialogue unsafety detection. With our classifier, we perform safety evaluations on popular conversational models and show that existing dialogue systems still exhibit concerning context-sensitive safety problems.",/pdf/027cd8b5be84d74449dcb7fd8bb07cf725551c7f.pdf,/attachment/69ffacfa52360504b00dd0d6d598e0a91e42a266.zip,,,,anonymous|on_the_safety_of_conversational_models_taxonomy_dataset_and_benchmark,,,,,,/attachment/a04ec44fcc0d9a2e6e1aebcdb227b990bcec8812.zip,,,
857,IYnDDdoHCyO,Improving Paraphrase Generation models with machine translation generated pre-training,['aclweb.org/ACL/ARR/2021/November/Paper283/Authors'],['Anonymous'],"Paraphrase generation is a fundamental and longstanding problem in the Natural Language Processing field. With the huge success of pre-trained transformers, the pre-train–fine-tune approach has become a standard choice. At the same time, popular task-agnostic pre-trainings usually require terabyte datasets and hundreds of GPUs, while available pre-trained models are limited to architecture and size. We propose a simple and efficient pre-training approach specifically for paraphrase generation, which noticeably boosts model quality and doesn't require significant computing power. We also investigate how this procedure influences the scores across different architectures and show that it helps them all.",/pdf/57525938de87f661afb7b474492bef09c10fdd13.pdf,,,,,anonymous|improving_paraphrase_generation_models_with_machine_translation_generated_pretraining,,,,,,,,,
858,ihDJ14bJXJO,ECSpell$^{UD}$: Zero-shot Domain Adaptive Chinese Spelling Check with User Dictionary,['aclweb.org/ACL/ARR/2021/November/Paper2132/Authors'],['Anonymous'],"Spellers often work within a particular domain in real life. Due to lots of uncommon domain terms, experiments on our built domain specific dataset show that general models perform terribly. Inspired by the common practice of input methods, we propose to add an alterable user dictionary to handle the zero-shot domain adaption problem. Specifically, we attach a User Dictionary guided inference module (UD) to a general token classification based speller. Without extra fine-tuning, UD reveals an ability to improve the performance of all the tested spellers, especially for strong baselines. Therefore, to further make the domain adaptive speller practical, we develop a competitive general speller ECSpell which adopts the Error Consistent masking strategy to create data for pertaining. Domain experiments demonstrate that ECSpell$^{UD}$, namely ECSpell combined with UD, surpasses all the other baselines largely, even approaching the performance on the general benchmark.",/pdf/d5b963be4ecd1beb98640a57f2f381bb547c2ae1.pdf,,,,,anonymous|ecspell^ud_zeroshot_domain_adaptive_chinese_spelling_check_with_user_dictionary,,,,,,,,,
859,5EU8b0dwUrO,Human Language Modeling,['aclweb.org/ACL/ARR/2021/November/Paper2076/Authors'],['Anonymous'],"Natural language is generated by people, yet  traditional language modeling views words or documents as if generated independently. Here, we propose human language modeling (HuLM), a hierarchical extension to the language modeling problem where by a human- level exists to connect sequences of documents (e.g. social media messages) and capture the notion that human language is moderated by changing human states. We introduce, HaRT, a large-scale transformer model for solving HuLM, pre-trained on approximately 100,000 social media users, and demonstrate it’s effectiveness in terms of both language modeling (perplexity) for social media and fine-tuning for 4 downstream tasks spanning document- and user-levels. Results on all tasks meet or surpass the current state-of-the-art.

",/pdf/f84846d3e4beb748ca0c898144f56202d9b6d530.pdf,,,,,anonymous|human_language_modeling,,,,,,,,,
860,wsyxNOwWtoq,Teaching BERT to Wait: Balancing Accuracy and Latency for Streaming Disfluency Detection,['aclweb.org/ACL/ARR/2021/November/Paper1536/Authors'],['Anonymous'],"In modern interactive speech-based systems speech is consumed and transcribed incrementally prior to having disfluencies removed. While this post-processing step is crucial for producing clean transcripts and high performance on downstream tasks (e.g. machine translation), most current state-of-the-art NLP models such as the Transformer operate non-incrementally, potentially causing unacceptable delays for the user. In this work we propose a streaming BERT-based sequence tagging model that, combined with a novel training objective, is capable of detecting disfluencies in real-time while balancing accuracy and latency. This is accomplished by training the model to decide whether to immediately output a prediction for the current input or to wait for further context, in essence learning to dynamically size the lookahead window. Our results demonstrate that our model produces comparably accurate predictions and does so sooner than our baselines, with lower flicker. Furthermore, the model attains state-of-the-art latency and stability scores when compared with recent work on incremental disfluency detection.",/pdf/a08f744b7f4cf36ea41d2e46d2d5d487c3bbf7b1.pdf,,,,,anonymous|teaching_bert_to_wait_balancing_accuracy_and_latency_for_streaming_disfluency_detection,,,,,,,,,
861,CluDkNLKjO,Combining Feature and Instance Attribution to Detect Artifacts,['aclweb.org/ACL/ARR/2021/November/Paper1605/Authors'],['Anonymous'],"Training the deep neural networks that dominate NLP requires large datasets. These are often collected automatically or via crowdsourcing, and may exhibit systematic biases or annotation artifacts. By the latter we mean spurious correlations between inputs and outputs that do not represent a generally held causal relationship between features and classes; models that exploit such correlations may appear to perform a given task well, but fail on out of sample data. In this paper we evaluate use of different attribution methods for aiding identification of training data artifacts. We propose new hybrid approaches that combine saliency maps (which highlight ""important"" input features) with instance attribution methods (which retrieve training samples ""influential"" to a given prediction). We show that this proposed training-feature attribution can be used to efficiently uncover artifacts in training data when a challenging validation set is available. We also carry out a small user study to evaluate whether these methods are useful to NLP researchers in practice, with promising results. ",/pdf/27683626b4cec1767680a4afdea946c464272ad9.pdf,,,,,anonymous|combining_feature_and_instance_attribution_to_detect_artifacts,,,,,,,,,
862,M81iOvVXOYt,Toward Fine-grained Causality Reasoning and CausalQA,['aclweb.org/ACL/ARR/2021/November/Paper1186/Authors'],['Anonymous'],"Understanding causality is key to the success of NLP applications, especially in high-stakes domains. Causality comes in various perspectives such as enable and prevent that, despite their importance, have been largely ignored in the literature. This paper introduces a first-of-its-kind, fine-grained causal reasoning dataset that contains seven causal relations and defines a series of NLP tasks, from causality detection to event causality extraction and causal reasoning. Our dataset contains human annotations of 25K cause-effect event pairs and 24K question-answering pairs within multi-sentence samples, where each can contain multiple causal relationships. Through extensive experiments and analysis, we show that the complex relations in our dataset bring unique challenges to state-of-the-art methods across all three tasks and highlight potential research opportunities, especially in developing ''causal-thinking'' methods.",/pdf/677e6109eacab22be1777c2819e453ea96be708d.pdf,,,,,anonymous|toward_finegrained_causality_reasoning_and_causalqa,,,,,,/attachment/f95d889ac752980e3eb9b87351f455cca76fdfa5.zip,,,
863,LVqYNHP5tia,Table-based Fact Verification with Self-adaptive Mixture of Experts,['aclweb.org/ACL/ARR/2021/November/Paper2719/Authors'],['Anonymous'],"The table-based fact verification task has recently gained widespread attention and yet remains to be a very challenging problem. It inherently requires informative reasoning over natural language together with different numerical and logical reasoning on tables (e.g., count, superlative, comparative). In this paper, we present a Self-adaptive Mixture-of-Experts Network (SaMoE), a novel framework built on this fundamental property. Specifically, we have developed a mixture-of-experts neural network to recognize and execute different types of reasoning---the network is composed of multiple experts, each handling a specific part of the semantics for reasoning, whereas a management module is applied to decide the contribution of each expert network to the verification result. A self-adaptive method is developed to teach the management module combining results of different experts more efficiently without external knowledge. The experimental results illustrate that our framework achieves 85.1% accuracy on the benchmark dataset TabFact, comparable with the previous state-of-the-art models. We hope our framework can serve as a new baseline for table-based verification. Our code will be available at (URL to be released here).",/pdf/e405bb82ab14160f989bd6a311860fe15b1b5e85.pdf,,,,,anonymous|tablebased_fact_verification_with_selfadaptive_mixture_of_experts,,,,,,,,,
864,WwT4KhJC-5X,Isomorphic Cross-lingual Embeddings for Low-Resource Languages,['aclweb.org/ACL/ARR/2021/November/Paper2850/Authors'],['Anonymous'],"Recent research in cross-lingual representation learning has focused on offline mapping approaches due to their simplicity, computational efficacy, and ability to work with minimal parallel resources. However, they crucially depend on the assumption of embedding spaces being approximately isomorphic, which does not hold in practice, leading to poorer performance on low-resource and distant language pairs. In this paper, we introduce a framework to learn cross-lingual word embeddings, without assuming isometry, for low-resource pairs via joint exploitation of a related higher-resource language. Both the source and target monolingual embeddings are independently aligned to the related language, enabling the use of offline methods. We show that this approach successfully outperforms other methods on several low-resource language pairs in both bilingul lexicon induction as well as eigen value simialrity.",/pdf/a56194965ece725905a57f62dfc36439ab43bd89.pdf,,,,,anonymous|isomorphic_crosslingual_embeddings_for_lowresource_languages,,,,,,,,,
865,wSlBe6V8V8H,Flooding-X: Improving BERT's Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning,['aclweb.org/ACL/ARR/2021/November/Paper2280/Authors'],['Anonymous'],"Adversarial robustness has attracted much attention recently, and the mainstream solution is adversarial training. However, the tradition of generating adversarial perturbations for each input embedding (in the settings of NLP) scales up the training computational complexity by the number of gradient steps it takes to obtain the adversarial samples. To address this problem, we leverage Flooding method which primarily aims at better generalization and we find promising in defending adversarial attacks. We further propose an effective criterion to bring hyper-parameter-dependent flooding into effect with a narrowed-down search space by measuring how the gradient steps taken within one epoch affect the loss of each batch. Our approach requires zero adversarial sample for training, and its time consumption is equivalent to fine-tuning, which can be 2-15 times faster than standard adversarial training. We experimentally show that our method improves Bert's resistance to textual adversarial attacks by a large margin, and achieves state-of-the-art robust accuracy on various text classification and GLUE tasks.",/pdf/68e3c84cddfae2e64969e0aa65bf18af1041d25b.pdf,,,,,anonymous|floodingx_improving_berts_resistance_to_adversarial_attacks_via_lossrestricted_finetuning,,,,,,,,,
866,ATRbfIyW6sI,Causal Transformers: Improving the Robustness on Spurious Correlations,['aclweb.org/ACL/ARR/2021/November/Paper1099/Authors'],['Anonymous'],"The fully-connected dependencies in self-attention over-fit spurious correlations and limit the generalization on out-of-distribution data. Pre-trained language models (PLMs) alleviate this problem benefitted from the appreciable counterexamples in large-scale pre-training corpora. However, there is no study to resolve this problem by improving the model structure. We enforced the causal independence	 mechanism in the self-attention network, which constrains attention mapping topologies (AMGs) as causal structures. To implement it, we defined a smooth loss on the Markov boundary constrained directed acyclic graph (DAG) with the Lagrange duality, and used it to optimize the AMGs towards causal structures. Further, this causal attention network was applied on Transformer (Causal Transformer). The empirical results on two spurious correlation challenging (SCC) datasets, neural machine translation (NMT) and natural language inference (NLI) tasks demonstrated that our Causal Transformer outperforms the state-of-the-art model and improves the out-of-distribution prediction.",/pdf/fc2bc8222d8cb47c35bd554eb709e35ed83a6848.pdf,/attachment/b2fb602709f0f9cb401a3f504ce31b1ba49da9ee.zip,,,,anonymous|causal_transformers_improving_the_robustness_on_spurious_correlations,,,,,,,/attachment/54cc9f9038ca010f58e9c9c360050d20ae6da750.pdf,https://openreview.net/forum?id=lq8RsdKAV5O,/attachment/7399ff417a543ca5163a8757877285a03ed7e8d8.pdf
867,tj967uZdAvb,Weight Squeezing: Reparameterization for Knowledge Transfer and Model Compression,['aclweb.org/ACL/ARR/2021/November/Paper460/Authors'],['Anonymous'],"In this work, we present a novel approach to simultaneous knowledge transfer and model compression called \textbf{Weight Squeezing}. With this method, we perform knowledge transfer from a teacher model \textbf{by learning the mapping from its weights to smaller student model weights}.

We applied Weight Squeezing to a pre-trained text classification model based on a BERT-Medium model. We compared our method to various other knowledge transfer and model compression methods using the GLUE multitask benchmark. We observed that our approach produces better results while being significantly faster than other methods for training student models.

We also proposed a variant of Weight Squeezing called Gated Weight Squeezing, in which we combined fine-tuning a small BERT model and learning mapping from larger BERT weights. We showed that, in most cases, fine-tuning a BERT model with Gated Weight Squeezing can outperform plain fine-tuning.",/pdf/5aa30adaafbd7cbea58ea8dfb67cf16122491e27.pdf,/attachment/0f6d72dcb8b7d00e0ee3b71f0711e433aa171475.zip,,,,anonymous|weight_squeezing_reparameterization_for_knowledge_transfer_and_model_compression,,,,,,,,,
868,_5lTEMDR2e1,EIDER: Evidence-enhanced Document-level Relation Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1866/Authors'],['Anonymous'],"Document-level relation extraction (DocRE) aims to extract the semantic relations among entity pairs in a document. Typical DocRE methods blindly take the full document as input, while a subset of the sentences in a document, noted as the evidence, are often sufficient for humans to predict the relation of an entity pair. In this paper, we propose an evidence-enhanced DocRE framework called Eider that automatically extracts and leverages evidence. We first train an evidence extraction model together with relation extraction via multi-task learning, which allows the two tasks to benefit from shared representations and improve each other. Experiments show that even if human annotation of evidence is unavailable, using silver evidence labels extracted by heuristic rules still leads to better RE performance. We further design a simple yet effective evidence-enhanced inference process that makes RE predictions on both extracted evidence and the full document and fuses the predictions through a blending layer. This allows Eider to focus on the important context while still having access to all the information in the document. Extensive experiments show that \ours outperforms state-of-the-art methods on three benchmark datasets, e.g., by 1.37/1.26 Ign F1/F1 on DocRED. ",/pdf/4cb994ed39014ad252c087381c0b711b0307ec4d.pdf,/attachment/4fb820a8cdc340299196f9f2e30770fa665a57c9.zip,,,,anonymous|eider_evidenceenhanced_documentlevel_relation_extraction,,,,,,,/attachment/d64358abcf3ed1ccb9e6c4d089d12ba25b27b047.pdf,https://openreview.net/forum?id=Z9arKXstUo5,/attachment/1fddd043de370e24f90d4022f25378b2215ee7db.pdf
869,gaAA8pP7Uth,Automatic Generation of Electromyogram Diagnosis Report: Task and Dataset,['aclweb.org/ACL/ARR/2021/November/Paper2572/Authors'],['Anonymous'],"Report-writing of electromyogram can be problematic for under-experienced physicians and time-consuming for experienced physicians. In this paper, we explore to generate textual report from tabular diagnostic records of electromyogram. We construct the first dataset for this task and demonstrate results of some baseline approaches. ",/pdf/abd16b35ac788bd555d46616f67949e9ed302435.pdf,,,,,anonymous|automatic_generation_of_electromyogram_diagnosis_report_task_and_dataset,,,,,,,,,
870,pCe_bVWX6D,A Simple but Effective Pluggable Entity Lookup Table for Pre-trained Language Models,['aclweb.org/ACL/ARR/2021/November/Paper1975/Authors'],['Anonymous'],"Pre-trained language models (PLMs) cannot well recall rich factual knowledge of entities exhibited in large-scale corpora, especially those rare entities. In this paper, we propose to build a simple but effective Pluggable Entity Lookup Table (PELT) on demand by aggregating the entity's output representations of multiple occurrences in the corpora.  PELT can be compatibly plugged as inputs  to infuse supplemental entity knowledge  into PLMs. Compared to previous knowledge-enhanced PLMs,  PELT only requires 0.2%~5% pre-computation with capability of acquiring knowledge from  out-of-domain corpora for domain adaptation scenario. The experiments on knowledge-related tasks demonstrate that our method, PELT, can flexibly and effectively transfer entity knowledge from related corpora into PLMs. We will make all the data and codes publicly available to facilitate future research.",/pdf/4016165c4bf016f79b8d316b1bf1670df14c5dca.pdf,/attachment/878f37ace3026efbf9b40563914f94b136c15eb7.zip,,,,anonymous|a_simple_but_effective_pluggable_entity_lookup_table_for_pretrained_language_models,,,,,,,,,
871,R4CpCnrGPGq,Logic-Driven Context Extension and Data Augmentation for Logical Reasoning of Text,['aclweb.org/ACL/ARR/2021/November/Paper706/Authors'],['Anonymous'],"Logical reasoning of text requires identifying critical logical structures in the text and performing inference over them. Existing methods for logical reasoning mainly focus on contextual semantics of text while struggling to explicitly model the logical inference process. In this paper, we not only put forward a logic-driven context extension framework but also propose a logic-driven data augmentation algorithm. The former follows a three-step reasoning paradigm, and each step is respectively to extract logical expressions as elementary reasoning units, symbolically infer the implicit expressions following equivalence laws and extend the context to validate the options. The latter augments literally similar but logically different instances and incorporates contrastive learning to better capture logical information, especially logical negative and conditional relationships. We conduct experiments on two benchmark datasets, ReClor and LogiQA. The results show that our method achieves state-of-the-art performance on both datasets, and even surpasses human performance on the ReClor dataset.",/pdf/e05a1a4cbb2c538f72b7dd234be23a177ee9dcc8.pdf,/attachment/5636c55eb82c101cda9ec215bedb53a2408d6efe.zip,,,,anonymous|logicdriven_context_extension_and_data_augmentation_for_logical_reasoning_of_text,,,,,,,,,
872,iyuluxX9K9B,Towards Better Citation Intent Classification,['aclweb.org/ACL/ARR/2021/November/Paper777/Authors'],['Anonymous'],"Accurate classification of citation intents in a scientific article provides deeper contextual understanding of and better quantifies the contributions of cited articles. This improves scientific literature platform capabilities such as search relevance, ranking and more. To our knowledge, we present the most comprehensive survey of Transformer-based language models performance on the citation intent classification task using SciCite dataset. Here, we make three recommendations. Firstly, we propose to report model performance as a distribution in contrast to a single averaged performance value. This arises from our observation that model performance is sensitive to the random seed choice resulting in wide performance variations from multiple finetuning runs. Secondly, this provides practical insights for model selection, showing the model's best possible performance. Thus, we propose that practitioners perform multiple finetuning runs before selecting the best performing model. Thirdly, we propose a simple data augmentation to improve the distribution of model performance overall. Moving forward, we suggest exploring improvements to the finetuning and model selection process as promising future directions.",/pdf/4fc66821646194fedbe7015acd87bbbc16025fba.pdf,/attachment/0c79b18389458392ffc347134d5f8e5cc12d9529.zip,,,,anonymous|towards_better_citation_intent_classification,,,,,,,/attachment/24f196797a6c702f12ac98da6ff4346f08c52047.pdf,https://openreview.net/forum?id=K6Jvy88liK,
873,VH79jjJRZ0r,A Novel End-to-End CAPT System for L2 Children Learners,['aclweb.org/ACL/ARR/2021/November/Paper883/Authors'],['Anonymous'],"Recently, Conformer-based model shows promising results in automatic speech recognition (ASR) task. There still is a dearth of research on Conformer based model for computer-assisted pronunciation learning (CAPT) system. In this paper, a Conformer-based CAPT system is introduced to provide the mispronunciation detection and diagnosis.  We apply the Conformer as the main pronunciation error detection model in phoneme level since superior phoneme recognition performance. Then, the features, including the Log Phone Posterior (LPP), the Log Posterior Ratio (LPR) and some other features, extracted from the Conformer decoder, are trained by a XGBoost model to predict phoneme and sentence level scores labeled by experts. Both results on open datasets and our internal Chinese children data demonstrate that the Conformer-based system, which has smaller model size and detailed diagnosis, achieves better performance compared with neutral network (NN)-based system.

",/pdf/77de17eb8031cf444d381f1ba30e0839fea1484e.pdf,,,,,anonymous|a_novel_endtoend_capt_system_for_l2_children_learners,,,,,,,,,
874,VXvO80xLGwL,"Synonyms, Antonyms and Beyond",['aclweb.org/ACL/ARR/2021/November/Paper612/Authors'],['Anonymous'],"This paper examines fine-tuning for a well-studied task, synonym/antonym classification, and a novel task, VAD regression.  The proposed method is almost as good as SOTA methods on standard benchmarks, but generalizes better to a new benchmark based on the Fallows Thesaurus (1898).  Moreover the proposed method generalizes from words to (multilingual) texts: e.g., MWEs, OOVs, sentences, paragraphs.  The second task was introduced to address concerns with leakage in benchmarks.  The second task also makes it easier to study the (in)-effectiveness of transfer learning to unseen words.",/pdf/bbaf0a3c4b99cc3881764fa0378b4f6225977ad2.pdf,/attachment/9fa5b6a6df7a9e9cc44de8bb15788c75a5e711b1.zip,,,,anonymous|synonyms_antonyms_and_beyond,,,,,,/attachment/93bc3d0acc208b21eb9eaece55605b426f89d025.zip,/attachment/6e626f47717791a743b534153b86ce896e1b55af.pdf,,
875,xHBcjbi8ifL,RepAL: A Simple and Plug-and-play Method for Improving Unsupervised Sentence Representations,['aclweb.org/ACL/ARR/2021/November/Paper958/Authors'],['Anonymous'],"Unsupervised sentence representation learning is a fundamental problem in natural language processing and has been studied extensively in recent years. This paper presents Representation ALchemy (RepAL), an extremely simple post-processing method that enhances unsupervised sentence representations. The basic idea in RepAL is to extract redundant information from the representation of a sentence generated by the existing models and then refine the representation through an embedding refinement operation to filter such redundant information. In this paper, we analyze the redundant information from two levels: sentence-level and corpus-level, and the theoretical analysis for the latter is also conducted. We point out that RepAL is free of training and is a plug-and-play method that can be combined with most existing unsupervised sentence learning models. Extensive experiments demonstrate RepAL’s effectiveness and show that RepAL is a model-agnostic method for unsupervised sentence embedding enhancement. Besides, we also designed detailed ablation studies to understand why RepAL works and provided in-depth analysis and understanding of the redundant information.",/pdf/364668c09cfb638c194572d2a5fdca47aa4c7c75.pdf,/attachment/cd5bc48f48362ab50653871d74940995924be12b.zip,,,,anonymous|repal_a_simple_and_plugandplay_method_for_improving_unsupervised_sentence_representations,,,,,,,,,
876,wuDKkpRntb,A Natural Diet: Towards Improving Naturalness of Machine Translation Output,['aclweb.org/ACL/ARR/2021/November/Paper1386/Authors'],['Anonymous'],"Machine translation (MT) evaluation often focuses on accuracy and fluency, without paying much attention to translation style. This means that, even when considered accurate and fluent, MT output can still sound less natural than high quality human translations or text originally written in the target language. Machine translation output notably exhibits lower lexical diversity, and employs constructs that mirror those in the source sentence. In this work we propose a method for training MT systems to achieve a more natural style, i.e. mirroring the style of text originally written in the target language. Our method tags parallel training data according to the naturalness of the target side by contrasting language models trained on natural and translated data. Tagging data allows us to put greater emphasis on target sentences originally written in the target language. Automatic metrics show that the resulting models achieve lexical richness on par with human translations, mimicking a style much closer to sentences originally written in the target language. Furthermore, we find that their output is  preferred by human experts when compared to the baseline translations.",/pdf/d304d2b969f7bc91c03ece27ec53f9b7c3a93b39.pdf,,,,,anonymous|a_natural_diet_towards_improving_naturalness_of_machine_translation_output,,,,,,,,,
877,iK_5-G6vjeR,Investigating the Use of BERT Anchors for Bilingual Lexicon Induction with Minimal Supervision,['aclweb.org/ACL/ARR/2021/November/Paper1476/Authors'],['Anonymous'],"This paper investigates the use of static anchors from transformer architectures for the task of Bilingual Lexicon Induction. We revisit an existing approach built around the ELMo architecture and explore the use of the methodology on the BERT family of language models. Experiments are performed and analysed for three language pairs, combining English with three target languages from very different language families, Hindi, Dutch, and Russian. Although the contextualised approach is not able to outperform the SOTA VecMap method, we find that it is easily adaptable to newer transformer models and can compete with the MUSE approach. An error analysis reveals interesting trends accross languages and shows how the method could be further improved by building on the basic hypothesis that transformer embeddings can indeed be decomposed into a static anchor and a dynamic context component. We make the code, the extracted anchors (before and after alignement) and the modified train and test sets available for use.",/pdf/5529bb134ccc2b508659cab3c06dad36b9315f7f.pdf,,,,,anonymous|investigating_the_use_of_bert_anchors_for_bilingual_lexicon_induction_with_minimal_supervision,,,,,,/attachment/99e603aa8779da1d51f4eb6d7d1ffb03a56b3c1d.zip,,,
878,vaZwkmlS2aA,Effective Unsupervised Constrained Text Generation based on Perturbed Masking,['aclweb.org/ACL/ARR/2021/November/Paper897/Authors'],['Anonymous'],"Unsupervised constrained text generation aims to generate text under a given set of constraints without any supervised data. Current state-of-the-art methods stochastically sample edit positions which may cause unnecessary search steps. In this paper, we propose PMCTG to improve effectiveness by searching for the best position and action in each step. Specifically, PMCTG extends the perturbed masking technique to effectively search for the best edit position. Then it uses proposed multi-aspect scoring functions to select edit action to further reduce search difficulty. Since PMCTG does not require supervised data, it can extend to different generation tasks. We show PMCTG achieves state-of-the-art results in keywords-to-sentence generation and paraphrasing.",/pdf/71d0c4f85712a013c51967e681221baeb46a0264.pdf,,,,,anonymous|effective_unsupervised_constrained_text_generation_based_on_perturbed_masking,,,,,,,,,
879,Zl9PyU7Li2K,Improving Equation Set Problems with Label Augmentation,['aclweb.org/ACL/ARR/2021/November/Paper696/Authors'],['Anonymous'],"Math word problems solving has received considerable attention from many NLP researchers. Inspired by the encoder-decoder structure, they created a series of neural network models to solve arithmetic word problems and equation set problems. However, these encoder-decoder models used the ground truth as the only generation target, resulting in shallow heuristics to generate expressions. In this paper, we propose a simple and effective label augmentation method for equation set problems. Specifically, we transform the ground truth into several equivalent labels by normalization rules, and these new labels will be used as additional generation targets for model training. Experimental results on the English dataset DRAW1K and Chinese dataset HMWP show that the label augmentation method has at most 4.5% improvement over the state-of-the-art (SoTA) models.",/pdf/1abd50a42600d20acac025629a65dc65f299675c.pdf,,,,,anonymous|improving_equation_set_problems_with_label_augmentation,,,,,,/attachment/279389be17dd58d013756c8da19eb2de2f436a47.zip,,,
880,3cdnseDIyZP,A Generative Language Model for Few-shot Aspect-Based Sentiment Analysis,['aclweb.org/ACL/ARR/2021/November/Paper1282/Authors'],['Anonymous'],"Sentiment analysis is an important task in natural language processing. In recent works, pre-trained language models are often used to achieve state-of-the-art results, especially when training data is scarce. It is common to fine-tune on the downstream task, usually by adding task-specific layers on top of the model. In this paper, we focus on aspect-based sentiment analysis, which involves extracting aspect term, category, and predicting their corresponding polarities. In particular, we are interested in few-shot settings. We propose to reformulate the extraction and prediction tasks into the sequence generation task, using a generative language model with unidirectional attention (GPT2 is used unless stated otherwise). This way, the model learns to accomplish the tasks via language generation without the need of training task-specific layers. Our evaluation results on the single-task polarity prediction show that our approach outperforms the previous state-of-the-art (based on BERT) on average performance by a large margins in few-shot and full-shot settings. More importantly, our generative approach significantly reduces the model variance caused by  low-resource data. We further demonstrate that the proposed generative language model can handle joint and multi-tasking settings, unlike previous work. We observe that the proposed sequence generation method achieves further improved performances on polarity prediction when the model is trained via joint and multi-tasking settings. Further evaluation on similar sentiment analysis datasets, SST-2, SST-5 and OOS intent detection validates the superiority and noise robustness of generative language model in few-shot settings.",/pdf/448cbddc0d6ab758aec41e39cf57bf0967f6958f.pdf,,,,,anonymous|a_generative_language_model_for_fewshot_aspectbased_sentiment_analysis,,,,,,,,,
881,bC5NiJmbK2,DocEE: A Large-Scale and Fine-grained Benchmark for Document-level Event Extraction,['aclweb.org/ACL/ARR/2021/November/Paper970/Authors'],['Anonymous'],"Event extraction aims to identify an event and then extract the arguments participating in the event. Despite the great success in sentence-level event extraction, events are more naturally presented in the form of documents, with event arguments scattering in multiple sentences. However, a major barrier to promote document-level event extraction has been the lack of large-scale and practical training and evaluation datasets. In this paper, we present DocEE, a new document-level event extraction dataset including 20,000+ events, 100,000+ arguments. We highlight three features: large-scale manual annotations, fine-grained argument types and application-oriented settings. Experiments show that there is still a big gap between state-of-the-art models and human beings (43\% Vs 85\% in F1 score), indicating that DocEE is an open issue. We will publish DocEE upon acceptance.",/pdf/7c604f2a6394ff18d133d465a0d363faa4ca5d9d.pdf,,,,,anonymous|docee_a_largescale_and_finegrained_benchmark_for_documentlevel_event_extraction,,,,,,/attachment/6708511bdfec8f760039b3ec92837ece1c0b855d.zip,/attachment/8f955db0a7352a58ddd35d60e46744483fb65809.pdf,https://openreview.net/forum?id=t5zJTjgwngX,/attachment/177484525cd9438b594d4f7eeabf26a5f7458bed.pdf
882,-HfxetxCkWu,Question Generation for Reading Comprehension Assessment by Modeling How and What to Ask,['aclweb.org/ACL/ARR/2021/November/Paper1671/Authors'],['Anonymous'],"Reading is integral to everyday life, and yet learning to read is a struggle for many young learners.  During lessons, teachers can use comprehension questions to increase engagement, test reading skills, and improve retention. Historically such questions were written by skilled teachers, but recently language models have been used to generate comprehension questions. However, many existing Question Generation (QG) systems focus on generating extractive questions from the text, and have no way to control the type of the generated question. In this paper, we study QG for reading comprehension where inferential questions are critical and extractive techniques cannot be used. We propose a two-step model (HTA-WTA) that takes advantage of previous datasets, and can generate questions for a specific targeted comprehension skill. We propose a new reading comprehension dataset that contains questions annotated with story-based reading comprehension skills (SBRCS), allowing for a more complete reader assessment. Across several experiments, our results show that HTA-WTA outperforms multiple strong baselines on this new dataset. We show that the HTA-WTA model tests for strong SCRS by asking deep inferential questions.",/pdf/639612500867d8e4239e59efcd8aa72873e4c2cf.pdf,,,,,anonymous|question_generation_for_reading_comprehension_assessment_by_modeling_how_and_what_to_ask,,,,,,,,,
883,uSlGVF68c0w,Incremental Topic Modeling for Scientific Trend Topics Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1454/Authors'],['Anonymous'],"Caused by the exponential growth of scientific research, the number of scientific publications and reports, one of the most urgent and challenging tasks now is the early detection of trending topics. In this paper, we investigate recent topic modeling approaches to accurately extract trending topics at an early stage. The incremental training technique is suggested so that the model can operate on data in real-time. For validation, we propose a novel dataset that contains a collection of early-stage articles and a set of key collocations for each trend. The proposed metric estimates the delay in days when determining the trend, and the developed matching method suffices to calculate it automatically. The conducted experiments demonstrate that the topic model with regularization, namely ARTM, is superior to the base PLSA model. Apart from that, the best ARTM-based model is able to extract most of the labeled trends during the first year of their evolution.",/pdf/b79e6f93e3c4a9f4f730d61160e584fe6e3d6abd.pdf,,,,,anonymous|incremental_topic_modeling_for_scientific_trend_topics_extraction,,,,,,,,,
884,OnBVDG_Ceau,MarCQAp: Effective Context Modeling for Conversational Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper878/Authors'],['Anonymous'],"State-of-the-art models for Document-grounded Conversational Question Answering (DCQA) are based on the Transformer architecture. This raises two open issues: (a) Is it sufficient to concatenate the dialog history and the grounding document and perform cross-attention via a Transformer in order to capture the document/dialogue relationships? and (b) What is the best way to cope with the Transformers’ quadratic complexity, given the long inputs in DCQA? We address these issues in two dimensions. First, we introduce MarCQAp, a new modeling approach which encodes the historic answers by adding textual markups in the grounding document text, and then answers the question conditioned on the marked document. Second, we show that sparse self-attention architectures, such as the Longformer, can replace the Transformer, resolving the input length limitation. Our results demonstrate the effectiveness of each approach and their combination for explicit representation of dialogue/document relationships, significantly improving over state-of-the-art DCQA models.",/pdf/78e7d09b4464c752c791dbda47d163d8eb3f59d7.pdf,/attachment/0e8ea25611363fa7649c6c30b55340b1386fbfa8.zip,,,,anonymous|marcqap_effective_context_modeling_for_conversational_question_answering,,,,,,,,,
885,aoxXIGWZBdK,Dual-space Hierarchical Learning for Goal-guided Conversational Recommendation,['aclweb.org/ACL/ARR/2021/November/Paper311/Authors'],['Anonymous'],"Proactively and naturally guiding the dialog from the non-recommendation context~(e.g., Chit-chat) to the recommendation scenario is crucial for the Conversational Recommender System~(CRS). Prior studies mainly focus on planning the next dialog goal~(e.g., chat on a movie star) conditioned on the previous dialog. However, we find the dialog goals can be simultaneously observed at different levels, which can be utilized to improve CRS.In this paper, we propose the \textit{\textbf{D}ual-space \textbf{H}ierarchical \textbf{L}earning}~(\textbf{DHL}) to leverage multi-level goal sequences and their hierarchical relationships for conversational recommendation. Specifically, we exploit multi-level goal sequences from both the representation space and the optimization space. In the representation space, we propose the hierarchical representation learning where a cross attention module derives mutually enhanced multi-level goal representations. Additionally, we propose a soft labeling strategy to gradually guide the optimization direction. Experiments on two real-world datasets verify the effectiveness of our approach.",/pdf/3438aa3d43d81d91ad3edacd4775517f23ccd07b.pdf,,,,,anonymous|dualspace_hierarchical_learning_for_goalguided_conversational_recommendation,,,,,,,,,
886,gHwU02F1sVU,Improving Multimodal Speech Recognition by Data Augmentation and Speech Representations,['aclweb.org/ACL/ARR/2021/November/Paper593/Authors'],['Anonymous'],"Multimodal speech recognition aims to improve the performance of automatic speech recognition (ASR) systems by leveraging additional visual information that is usually associated to the audio input. While previous approaches make crucial use of strong visual representations, e.g. by finetuning pretrained image recognition networks, significantly less attention has been paid to its counterpart: the speech component. In this work, we investigate ways of improving the base speech recognition system by following similar techniques to the ones used for the visual encoder, namely, transferring representations and data augmentation. First, we show that starting from a pretrained ASR significantly improves the state-of-the-art performance; interestingly, even when building upon a strong unimodal system, we still find gains by including the visual modality. Second, we employ speech data augmentation techniques to encourage the multimodal system to attend to the visual stimuli. This technique replaces previously used word masking and comes with the benefits of being conceptually simpler and yielding consistent improvements in the multimodal setting. We back up our conclusions by empirical results on three multimodal datasets, including the newly introduced Localized Narratives.",/pdf/e52fde491842f07beb0fa6412d79204dc091eaec.pdf,,,,,anonymous|improving_multimodal_speech_recognition_by_data_augmentation_and_speech_representations,,,,,,,,,
887,4YjpGcrcGy_,"ViQuAE, a Dataset for Knowledge-based Visual Question Answering about Named Entities",['aclweb.org/ACL/ARR/2021/November/Paper159/Authors'],['Anonymous'],"Whether to retrieve, answer, translate or reason, multimodality opens up new challenges and perspectives. In this context, we are interested in Knowledge-based Visual Question Answering about named Entities (KVQAE). To benchmark the task, we provide ViQuAE, a dataset of 3.7K questions paired with images. This is the first KVQAE dataset to cover a wide range of entity types (e.g. persons, landmarks, products). The dataset is annotated  using a semi-automatic method that could be extended to larger data scales. We also propose a Knowledge Base (KB) based on Wikipedia composed of 1.5M articles paired with images. 
To set a baseline on the benchmark, we address KVQAE as a two-stage problem: Information Retrieval (IR) and Reading Comprehension (RC). IR is carried out with a combination of face recognition, image retrieval and text retrieval while RC is purely text-based. The experiments empirically demonstrate the difficulty of the task. 
This work paves the way towards better multimodal entity representations and question answering. The dataset, KB and code will be available at https://github.com/Anonymous/ViQuAE.",/pdf/450eb2f50b056890bbec3dbaa120cf212c6af31a.pdf,/attachment/5435febab8861ab66b4a37baf2f728acae2e0a0b.zip,,,,anonymous|viquae_a_dataset_for_knowledgebased_visual_question_answering_about_named_entities,,,,,,/attachment/297bd8aa153d38a4178f6c5b1161693851a2a7ae.zip,,,
888,d61NGy9bquC,BanglaBERT: Language Model Pretraining and Benchmarks for Low-Resource Language Understanding Evaluation in Bangla,['aclweb.org/ACL/ARR/2021/November/Paper2491/Authors'],['Anonymous'],"In this paper, we introduce 'BanglaBERT', a BERT-based Natural Language Understanding (NLU) model pretrained in Bangla, a widely spoken yet low-resource language in the NLP literature. To pretrain BanglaBERT, we collect 27.5 GB of Bangla pretraining data (dubbed 'Bangla2B+') by crawling 110 popular Bangla sites. We introduce a new downstream task dataset on Natural Language Inference (NLI) and benchmark on four diverse NLU tasks covering text classification, sequence labeling, and span prediction. In the process, we bring them under the first-ever Bangla Language Understanding Evaluation (BLUE) benchmark. BanglaBERT achieves state-of-the-art results outperforming multilingual and monolingual models. We will make the BanglaBERT model, the new datasets, and a leaderboard publicly available to advance Bangla NLP.",/pdf/04cf5f0984afada7815b385a098234d43222ea42.pdf,,,,,anonymous|banglabert_language_model_pretraining_and_benchmarks_for_lowresource_language_understanding_evaluation_in_bangla,,,,,,,,,
889,i6XKizCSIH3,Accurate Online Posterior Alignments for Principled Lexically-Constrained Decoding,['aclweb.org/ACL/ARR/2021/November/Paper54/Authors'],['Anonymous'],"Online alignment in machine translation refers to the task of aligning a target word to a source word when the target sequence has only been partially decoded. Good online alignments facilitate important applications such as lexically constrained translation where user-defined dictionaries are used to inject lexical constraints into the translation model. We propose a novel posterior alignment technique that is truly online in its execution and superior in terms of alignment error rates compared to existing methods. Our proposed inference technique jointly considers alignment and token probabilities in a principled manner and can be seamlessly integrated within existing constrained beam-search decoding algorithms. On five language pairs, including two distant language pairs, we achieve consistent drop in alignment error rates. When deployed on seven lexically constrained translation tasks, we achieve significant improvements in BLEU specifically around the constrained positions.",/pdf/e96a1cd216241379eb1667ee686bdcab04dc1536.pdf,,,,,anonymous|accurate_online_posterior_alignments_for_principled_lexicallyconstrained_decoding,,,,,,,/attachment/d6b9e7f8ffc877ee9ec06f2fbaf294509db8c30c.pdf,https://openreview.net/forum?id=DutjyHb33yO,/attachment/eadbad011262cbaa512313ae9f6b5740229cf3ee.pdf
890,r_3-SmfScsJ,First the worst: Finding better gender translations during beam search,['aclweb.org/ACL/ARR/2021/November/Paper160/Authors'],['Anonymous'],"Generating machine translations via beam search seeks the most likely output under a model. However, beam search has been shown to amplify demographic biases exhibited by a model. We aim to address this, focusing on gender bias resulting from systematic errors in grammatical gender translation. Almost all prior work on this problem adjusts the training data or the model itself. By contrast, our approach changes only the inference procedure. 

We explore two techniques: applying constraints during inference to improve gender diversity in n-best lists, and reranking n-best lists using gender features obtained from the source sentence. Combining these methods gives large gains in gender translation accuracy for three language pairs without requiring additional bilingual data or retraining.  
",/pdf/203796554940309a7ff0949a1f6f62c36213dbd2.pdf,/attachment/e0bb219dbb51129e6daf27d8d987c1300b50a2a5.zip,,,,anonymous|first_the_worst_finding_better_gender_translations_during_beam_search,,,,,,,,,
891,8s9M2_HIF-j,Co-VQA : Answering by Interactive Sub Question Sequence,['aclweb.org/ACL/ARR/2021/November/Paper2373/Authors'],['Anonymous'],"Most existing approaches to Visual Question Answering (VQA) answer questions directly, however, people usually decompose a complex question into a sequence of simple sub questions and finally obtain the answer to the original question after answering the sub question sequence(SQS). By simulating the process, this paper proposes a conversation-based VQA (Co-VQA) framework, which consists of three components: Questioner, Oracle, and Answerer. Questioner raises the sub questions using an extending HRED model, and Oracle answers them one-by-one.  An Adaptive Chain Visual Reasoning Model (ACVRM) for Answerer is also proposed, where the question-answer pair is used to update the visual representation sequentially. To perform supervised learning for each model, we introduce a well-designed method to build a SQS for each question on VQA 2.0 and VQA-CP v2 datasets. Experimental results show that our method achieves state-of-the-art on VQA-CP v2. Further analyses show that SQSs help build direct semantic connections between questions and images, provide question-adaptive variable-length reasoning chains, and with explicit interpretability as well as error traceability.",/pdf/6f257127603f3473bfcba92b7edaeaeaa43c97c4.pdf,,,,,anonymous|covqa_answering_by_interactive_sub_question_sequence,,,,,,,,,
892,HmJwrqjMZo,Few-Shot Knowledge Graph Completion with Data Fusion and Augmentation,['aclweb.org/ACL/ARR/2021/November/Paper516/Authors'],['Anonymous'],"This paper addresses the few-shot knowledge graph completion problem, which aims to infer facts for long-tail distributed relations for completing knowledge graphs. The few-shot knowledge graph completion task confronts with the difficulties of insufficient structural evidence caused by structure sparsity and heterogeneity, and few training samples caused by the long-tail distribution property of few-shot relations. To overcome the above difficulties, we propose to adaptively fuse entity structure information with rich textual content features, and leverage a generative approach to augment entity samples to enrich the training samples for few-shot relations. We seamlessly integrate the adaptive feature fusion and generative sample augmentation components with the few-shot learning task into an end-to-end framework, with the feature fusion and sample augmentation able to be adjusted for the few-shot learning objective through error backpropagation. We conduct few-shot knowledge graph completion experiments on two real-world knowledge graphs, showing the significant advantage of the proposed algorithm over state-of-the-art baselines, and the effectiveness of the proposed feature fusion and sample augmentation components.",/pdf/aaa35ab57ecfc586df865b6ccd1f9315bc62c782.pdf,,,,,anonymous|fewshot_knowledge_graph_completion_with_data_fusion_and_augmentation,,,,,,,,,
893,6DBkg64mzt6,Improving GPT-3 after deployment with a dynamic memory of feedback,['aclweb.org/ACL/ARR/2021/November/Paper1430/Authors'],['Anonymous'],"Large LMs such as GPT-3 while powerful, are not immune to mistakes, but are prohibitively costly to retrain. One failure mode is misinterpreting a user's instruction (e.g., GPT-3 interpreting ""What word is similar to `good'?"" to mean a homonym, while the user intended a synonym). Our goal is to allow users to correct such errors directly through interaction -- without retraining. Our approach is to pair GPT-3 with a growing memory of cases where the model misunderstood the user's intent and was provided with feedback, clarifying the instruction. Given a new query, our memory-enhanced GPT-3 uses feedback from similar, prior queries to enrich the prompt. Through simple proof-of-concept experiments, we demonstrate how a user can interactively teach a deployed GPT-3, doubling its accuracy on basic lexical tasks (e.g., generate a synonym) where users query in different, novel (often misunderstood) ways. In such scenarios, memory helps avoid  repeating similar past mistakes. Our simple idea is a first step towards strengthening deployed models, potentially broadening their utility.",/pdf/349d49bf4c6a0172d4a17c05ca07d8591a85731b.pdf,,,,,anonymous|improving_gpt3_after_deployment_with_a_dynamic_memory_of_feedback,,,,,,,,,
894,0P3TLWoQwVF,Exploiting Dialogue Act for Knowledge Selection and Response Generation,['aclweb.org/ACL/ARR/2021/November/Paper2514/Authors'],['Anonymous'],"Dialogue act (DA) is the description of the intention or function of a dialogue utterance. In document-grounded dialogue, correctly understanding the dialogue context is crucial for models to select knowledge and inject knowledge into responses. Leveraging dialogue act can help to understand the dialogue context and consequently assist the utilization of document information. In this paper, we propose a novel framework leveraging two different kinds of DAs (model-annotated and human-annotated) for \textbf{Knowledge Selection} (KS) and \textbf{Response Generation} (RG). The framework consists of two modules: the prediction module is trained with multi-task learning and learns to select knowledge and predict the next DA; the generation module uses the selected knowledge and the predicted DA for the RG. Our model achieves new state-of-the-art performance on three public datasets and the results verify that leveraging DA can help KS and RG. Our code and data will be released on github.com.",/pdf/6e1c4b650bdfe4476afee76022dd6cd56d4da3b0.pdf,,,,,anonymous|exploiting_dialogue_act_for_knowledge_selection_and_response_generation,,,,,,,,,
895,ONfJZSIkLli,Interpreting the Robustness of Neural NLP Models to Textual Perturbations,['aclweb.org/ACL/ARR/2021/November/Paper1193/Authors'],['Anonymous'],"Modern Natural Language Processing (NLP) models are known to be sensitive to input perturbations and their performance can decrease when applied to real-world, noisy data.  However, it is still unclear why models are less robust to some perturbations than others. In this work, we test the hypothesis that the extent to which a model is affected by an unseen textual perturbation (robustness) can be explained by the learnability of the perturbation (defined as how well the model learns to identify the perturbation with a small amount of evidence). We further give a causal justification for the learnability metric. We conduct extensive experiments with four prominent NLP models --- TextRNN, BERT, RoBERTa and XLNet --- over eight types of textual perturbations on three datasets. We show that a model which is better at identifying a perturbation (higher learnability) becomes worse at ignoring such a perturbation at test time (lower robustness), providing empirical support for our hypothesis.",/pdf/63ed4a7e117ea8b5bf9934cc93a2b895eaaef9ec.pdf,,,,,anonymous|interpreting_the_robustness_of_neural_nlp_models_to_textual_perturbations,,,,,,,,,
896,DZItcXicrj2,Distantly Supervised Named Entity Recognition with Category-Oriented Confidence Calibration,['aclweb.org/ACL/ARR/2021/November/Paper2996/Authors'],['Anonymous'],"In this work, we study the noisy-labeled named entity recognition under distant supervision setting. Considering that most NER systems based on confidence estimation deal with noisy labels ignoring the fact that model has different levels of confidence towards different categories, we propose a category-oriented confidence calibration(Coca) strategy with an automatically confidence threshold calculation module. We integrate our method into a teacher-student framework to improve the model performance. Our proposed approach achieves promising performance among advanced baseline models, setting new state-of-the-art performance on three existing distantly supervised NER benchmarks.",/pdf/a51428da30c2265b79d03c844021862cce13317e.pdf,,,,,anonymous|distantly_supervised_named_entity_recognition_with_categoryoriented_confidence_calibration,,,,,,,/attachment/7b35245eefa88c2cfedbd2ee39e5c9a7cad02741.pdf,https://openreview.net/forum?id=8T1pvcsmqyV,
897,lE6T0rKl5Jg,Unified Speech-Text Pre-training for Speech Translation and Recognition,['aclweb.org/ACL/ARR/2021/November/Paper818/Authors'],['Anonymous'],"In this work, we describe a method to jointly pre-train 
speech and text in an encoder-decoder modeling framework for speech translation and recognition. 
The proposed method utilizes multi-task learning to integrate four self-supervised and supervised subtasks for cross modality learning. 
A self-supervised speech subtask, which leverages unlabelled speech data, and a (self-)supervised text to text subtask, which makes use of 
abundant text training data,  take up the majority of the pre-training time. 
Two auxiliary supervised speech tasks are included to unify speech and text modeling space. 
Detailed analysis reveals learning interference among subtasks. In order to alleviate the subtask interference, two pre-training configurations are proposed for speech translation and speech recognition respectively.  
Our experiments show the proposed method can effectively fuse speech and text information into one model. It achieves between 1.7 and 2.3 BLEU improvement above the state of the art on the MuST-C speech translation dataset and comparable WERs to wav2vec 2.0 on the Librispeech speech recognition task.",/pdf/fa0f2a101ec2c18e648de101d7579bb460101782.pdf,,,,,anonymous|unified_speechtext_pretraining_for_speech_translation_and_recognition,,,,,,,,,
898,K3YndUcwA6u,Temporal Knowledge-Aware Image Captioning,['aclweb.org/ACL/ARR/2021/November/Paper1286/Authors'],['Anonymous'],"Contextualized image captioning is a task that extends beyond generating a purely visual description of the image content and aims to produce a caption that is influenced by the context and informed by the real world knowledge. In this paper, we present an approach to knowledge-aware image captioning, with a specific focus on the temporal domain. We propose a way to identify relevant information in external data sources, such as geographic databases and common knowledge bases, and then encode it in a way that is most useful for the captioning network. We develop an end-to-end caption generation system that incorporates external knowledge into the captioning process at several stages. The system is trained and tested on our novel temporal knowledge-aware captioning dataset, achieving significant improvements over multiple baselines across standardly used metrics. We demonstrate that our approach is effective for generating highly contextualized captions with both relevant and accurate temporal facts.",/pdf/0ca88cd63ce90f39f238f5a2579196b646d21f3f.pdf,,,,,anonymous|temporal_knowledgeaware_image_captioning,,,,,,,,,
899,xHoPdGc_15A,Weakly Supervised Medical Entity Extraction and Linking for Chief Complaints,['aclweb.org/ACL/ARR/2021/November/Paper1990/Authors'],['Anonymous'],"A Chief complaint (CC) is the reason for the medical visit as stated in the patient's own words. It helps medical professionals to quickly understand a patient's situation, and also serves as a short summary for medical text mining. However, chief complaint records often take a variety of entering methods, resulting in a wide variation of medical notations, which makes it difficult to standardize across different medical institutions for record keeping or text mining. In this study, we propose a weakly supervised method to automatically extract and link entities in chief complaints in the absence of human annotation. We first adopt a split-and-match algorithm to produce weak annotations, including entity mention spans and class labels, on 1.2 million real-world de-identified and IRB approved chief complaint records. Then we train a BERT-based model with generated weak labels to locate entity mentions in chief complaint text and link them to a pre-defined ontology. We conducted extensive experiments and the results showed that our Weakly Supervised Entity Extraction and Linking (WeSEEL) method produced superior performance over previous methods without any human annotation.",/pdf/c117bd23c5c479e7e40ef28ff5296f0924e8138c.pdf,,,,,anonymous|weakly_supervised_medical_entity_extraction_and_linking_for_chief_complaints,,,,,,,,,
900,Zw1MoehqT4G,A Feasibility Study of Answer-Unaware Question Generation for Education,['aclweb.org/ACL/ARR/2021/November/Paper1773/Authors'],['Anonymous'],"We conduct a feasibility study into the applicability of \textit{answer-unaware} question generation models to textbook passages. We show that a significant portion of errors in such systems arise from asking irrelevant or un-interpretable questions and that such errors can be ameliorated by providing summarized input. We find that giving these models human-written summaries instead of the original text results in a significant increase in acceptability of generated questions (33\% -> 83\%) as determined by expert annotators. We also find that, in the absence of human-written summaries, automatic summarization can serve as a good middle ground.",/pdf/2dd9f71b9208fa889d86d912a7de472669520f20.pdf,,,,,anonymous|a_feasibility_study_of_answerunaware_question_generation_for_education,,,,,,/attachment/203873e13817f5bceb5511108a9f8d512d599736.zip,,,
901,yddkHhsdsVB,"Detection, Disambiguation, Re-ranking: Autoregressive Entity Linking as a Multi-Task Problem",['aclweb.org/ACL/ARR/2021/November/Paper760/Authors'],['Anonymous'],"We propose an autoregressive entity linking model, that is trained with two auxiliary tasks, and learns to re-rank generated samples at inference time. Our proposed novelties address two weaknesses in the literature. First, as recent improvements in entity linking suggest learning mention detection explicitly could increase performance, we train mention detection as an auxiliary task. Second, previous work suggests that re-ranking could help correct prediction errors. We add a new, auxiliary task, match prediction, to learn re-ranking. Without the use of a knowledge base or candidate sets, our model sets a new state of the art in two benchmark datasets of entity linking: COMETA in the biomedical domain, and AIDA-CoNLL in the news domain. We show through ablation studies that each of the two auxiliary tasks increases performance, and that re-ranking is an important factor to the increase. Finally, our low-resource experimental results suggest that performance on the main task benefits from the knowledge learned by the auxiliary tasks, and not just from the additional training data.",/pdf/51b1f7baef894ff324bf3c0274eef967491f44ea.pdf,,,,,anonymous|detection_disambiguation_reranking_autoregressive_entity_linking_as_a_multitask_problem,,,,,,,,,
902,XaOlkixwPHf,Emotion analysis and detection during COVID-19,['aclweb.org/ACL/ARR/2021/November/Paper211/Authors'],['Anonymous'],"Understanding emotions that people express during large-scale crises helps inform policy makers and first responders about the emotional states of the population as well as provide emotional support to those who need such support. We present CovidEmo, a dataset of 3,000 English tweets labeled with emotions and temporally distributed across 18 months. Our analyses reveal the emotional toll caused by COVID-19, and changes of the social narrative and associated emotions over time. Motivated by the time-sensitive nature of crises and the cost of large-scale annotation efforts, we examine how well large pre-trained language models generalize across domains and timeline in the task of perceived emotion prediction in the context of COVID-19. Our analyses suggest that cross-domain information transfers occur, yet there are still significant gaps. We propose semi-supervised learning as a way to bridge this gap, obtaining significantly better performance using unlabeled data from the target domain.",/pdf/ebc194098341a683202fb35ad851600f818489d4.pdf,,,,,anonymous|emotion_analysis_and_detection_during_covid19,,,,,,,,,
903,kKUWbb_gzI0,It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset,['aclweb.org/ACL/ARR/2021/November/Paper2118/Authors'],['Anonymous'],"Existing question answering (QA) techniques are created mainly to answer questions asked by humans. But in educational applications, teachers and parents sometimes may not know what questions they should ask best help children to develop their narrative understanding abilities. We design an automated question-answer generation (QAG) system for education purposes: given a storybook at the kindergarten to eighth-grade level, our system can automatically produce QA pairs that are capable of testing a variety of student comprehension skills. Using a new QA dataset FairytaleQA that has 278 child-friendly storybooks with 10,580 QA pairs labeled by experts, we design a novel QAG system architecture to generate QA pairs. Automatic and human evaluations show that our model outperforms state-of-the-art QAG systems. On top of our QAG system, we also build an interactive story-telling application for future real-world deployment.",/pdf/0e25f97a51eb00089a16bc9fcbde98df18e8cd2b.pdf,,,,,anonymous|it_is_ais_turn_to_ask_human_a_question_question_and_answer_pair_generation_for_children_storybooks_in_fairytaleqa_dataset,,,,,,,,,
904,xfh3zrizcN,QA Domain Adaptation using Data Augmentation and Contrastive Adaptation,['aclweb.org/ACL/ARR/2021/November/Paper1947/Authors'],['Anonymous'],"Domain adaptation for question answering (QA) has recently shown impressive results for answering out-of-domain questions. Yet, a common challenge is to build approaches that are effective for niche domains with small text corpora. In this paper, we propose a novel framework called QADA for QA domain adaptation. QADA has two components: (1) A question generation model is used to generate synthetic question-answer samples from the target domain. Different from existing baselines, we enrich the samples via a novel pipeline for data augmentation: for questions, we introduce token-level augmentation (i.e., synonym replacement and token swapping), and, for contexts, we develop hidden-space augmentation which learns to drop context spans via a custom attentive sampling strategy. (2) The QA model is based on transformers. However, unlike existing approaches, we propose to train it via a novel attention-based contrastive adaptation. Here, we use the attention weights to sample informative tokens for discrepancy estimation that helps the QA model separate answers and generalize across source and target domain. To the best of our knowledge, our work is the first in QA domain adaptation to leverage data augmentation and attention-based contrastive adaptation. Our evaluation shows that QADA achieves considerable improvements over state-of-the-art baselines for QA domain adaptation.",/pdf/921c03827a3083cb7d9cea51c5a23ba8c36d1c80.pdf,/attachment/ffa2657a7c88b79566b01b0d9d98a96bab579c58.zip,,,,anonymous|qa_domain_adaptation_using_data_augmentation_and_contrastive_adaptation,,,,,,,,,
905,HhKMJUQeCNC,gaBERT — an Irish Language Model,['aclweb.org/ACL/ARR/2021/November/Paper1467/Authors'],['Anonymous'],"The BERT family of neural language models have become highly popular due to their ability to provide sequences of text with rich context-sensitive token encodings which are able to generalise well to many Natural Language Processing tasks. We introduce, gaBERT, a monolingual BERT model for the Irish language. We compare our gaBERT model to multilingual BERT and monolingual WikiBERT, and we show that gaBERT provides better representations for a downstream parsing task. We also show how different filtering criteria, vocabulary size and the choice of subword tokenisation model affect downstream performance. We release gaBERT and related code to the community.",/pdf/08fd44275096712b9e898244dd4f6aec47e92cc9.pdf,,,,,anonymous|gabert_an_irish_language_model,,,,,,,,,
906,3UIumdQkvm,Square One Bias in NLP: Towards a Multi-Dimensional Exploration of the Research Manifold,['aclweb.org/ACL/ARR/2021/November/Paper1084/Authors'],['Anonymous'],"The first NLP experiment many researchers performed in their careers likely involved training a standard architecture on labeled English data and optimizing for accuracy, without accounting for other dimensions such as fairness, interpretability, or computational efficiency. We show through surveys that this is indeed the case and refer to it as the square one experimental setup. NLP research often goes beyond the square one setup, e.g, focusing not only on accuracy, but also on fairness or interpretability, but typically along a single dimension. Most work focused on multilinguality, for example, considers only accuracy; most work on fairness or interpretability considers only English; and so on. We show this through manual classification of recent NLP research papers and ACL Test-of-Time award recipients. Such one-dimensionality of most research means we are only exploring a fraction of the NLP research search space. We provide historical and recent examples of how the square one bias has led researchers to draw false conclusions or make unwise choices, point to promising yet unexplored directions on the research manifold, and make practical recommendations to enable more multi-dimensional research.",/pdf/ee8bc2928b44216e359308499156eafa26e911af.pdf,,,,,anonymous|square_one_bias_in_nlp_towards_a_multidimensional_exploration_of_the_research_manifold,,,,,,,,,
907,zFRVC8BmVv_,Graph Pre-training for AMR Parsing and Generation,['aclweb.org/ACL/ARR/2021/November/Paper2558/Authors'],['Anonymous'],"Abstract meaning representation (AMR) highlights the core semantic information of text in a graph structure.
Recently, pre-trained language models (PLMs) have advanced tasks of AMR parsing and AMR-to-text generation.
However, PLMs are typically pre-trained on textual data, thus are sub-optimal for modeling structural knowledge.
To this end, we investigate graph self-supervised training to improve the structure awareness of PLMs over AMR graphs.
In particular, we introduce two graph auto-encoding strategies for graph-to-graph pre-training and four tasks to integrate text and graph information during pre-training.
We further design a unified framework to bridge the gap between pre-training and fine-tuning tasks.
Experimental results on both AMR parsing and AMR-to-text generation tasks show the superiority of our model.
To our knowledge, we are the first to consider pre-training on AMR graphs.",/pdf/2653da11348555516200ad5b12353d4882848902.pdf,/attachment/6792b186e7736b3fbd37ed671df1f66b95912991.zip,,,,anonymous|graph_pretraining_for_amr_parsing_and_generation,,,,,,,,,
908,AgGygsClU1a,Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation,['aclweb.org/ACL/ARR/2021/November/Paper773/Authors'],['Anonymous'],"Dense retrieval models, which aim at retrieving the most relevant document for an input query on a dense representation space, have gained considerable attention for their remarkable success. Yet, dense models require a vast amount of labeled training data for notable performance, whereas it is often challenging to acquire query-document pairs annotated by humans. To tackle this problem, we propose a simple but effective Document Augmentation for dense Retrieval (DAR) framework, which augments the representations of documents with their interpolation and perturbation. We validate the performance of DAR on retrieval tasks with two benchmark datasets, showing that the proposed DAR significantly outperforms relevant baselines on the dense retrieval of both the labeled and unlabeled documents.",/pdf/2aa221f0e63892cc1b86152577bff88784d12f62.pdf,,,,,anonymous|augmenting_document_representations_for_dense_retrieval_with_interpolation_and_perturbation,,,,,,,/attachment/5cb7df33fc569031dbc839d4f4fc2dacec163b7a.pdf,https://openreview.net/forum?id=vfLAxyZgaPn&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3Daclweb.org%2FACL%2FARR%2F2021%2FSeptember%2FAuthors%23your-submissions),/attachment/a7cb29c40a5d489bcfbdf9e95958f4b3270ba607.pdf
909,qlX6yLrqTYS,Substructure Distribution Projection for Zero-Shot Cross-Lingual Dependency Parsing,['aclweb.org/ACL/ARR/2021/November/Paper2206/Authors'],['Anonymous'],"We present substructure distribution projection (SubDP), a technique that projects a distribution over structures in one domain to another, by projecting substructure distributions separately. Models for the target domain can then be trained, using the projected distributions as soft silver labels. We evaluate SUBDP on zero shot cross-lingual dependency parsing, taking dependency arcs as substructures: we project the predicted dependency arc distributions in the source language(s) to target language(s), and train a target language parser on the resulting distributions. Given an English tree bank as the only source of human supervision, SUBDP achieves better unlabeled attachment score than all prior work on the Universal Dependencies v2.2 (Nivre et al., 2020) test set across eight diverse target languages, as well as the best labeled attachment score on six languages. In addition, SUBDP improves zero shot cross-lingual dependency parsing with very few (e.g., 50) supervised bitext pairs, across a broader range of target languages.",/pdf/36b1f516e8724653c3f1c738e0303c79217e7935.pdf,/attachment/cf8c0e26d36f6ec21cece3dc57c198b52a428853.zip,,,,anonymous|substructure_distribution_projection_for_zeroshot_crosslingual_dependency_parsing,,,,,,,,,
910,-uNpc9fl74A,Progressive Down-Sampling for Acoustic Encoding,['aclweb.org/ACL/ARR/2021/November/Paper1891/Authors'],['Anonymous'],"In acoustic encoding, the fine-grained frame-level features are not suited for capturing global dependencies. But condensing them into a semantically complete representation by stacked down-sampling does not work well. We find that the condensation leads to the degraded correlation of the representations in adjacent positions, which poses the risk of information loss in the stacked method. In this work, we propose a new method, progressive down-sampling (PDS), for encoding the context sufficiently before each condensation. Also, we develop a representation fusion method to alleviate information loss by combining the multi-scale representations. Experimental results on the 960h LibriSpeech automatic speech recognition task show that, for a strong Conformer-based system, our method down-samples the input speech features to 1/32 of the initial length, while yielding an improvement of 0.47 WER with a speedup of 1.42$\times$. It also achieves the state-of-the-art BLEU score (25.8) on the MuST-C En-De speech translation benchmark with no additional training data.",/pdf/3d612790d70a1787caae74f6d8b117870d99d2af.pdf,,,,,anonymous|progressive_downsampling_for_acoustic_encoding,,,,,,,,,
911,d4a9I4kFSUJ,,,,,,,,,,,,,,,,,,,
912,YMfgU0dqKC,Breaking Down Multilingual Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper590/Authors'],['Anonymous'],"While multilingual training is now an essential ingredient in machine translation (MT) systems, recent work has demonstrated that it has different effects in different multilingual settings, such as many-to-one, one-to-many, and many-to-many learning. These training settings expose the encoder and the decoder in a machine translation model with different data distributions. In this paper, we examine how different varieties of multilingual training contribute to learning these two components of the MT model. Specifically, we compare bilingual models with encoders and/or decoders initialized by multilingual training. We show that multilingual training is beneficial to encoders in general, while it only benefits decoders for low-resource languages (LRLs). We further find the important attention heads for each language pair and compare their correlations during inference. Our analysis sheds light on how multilingual translation models work and also enables us to propose methods to improve performance by training with highly related languages. Our many-to-one models for high-resource languages and one-to-many models for LRL outperform the best results reported by Aharoni et al. (2019).",/pdf/ca797258a15eecb5d404341d31fe29e4887a0318.pdf,,,,,anonymous|breaking_down_multilingual_machine_translation,,,,,,,/attachment/741cc8e1431f78cfd3437d8671a44cc3b6d0d229.pdf,https://openreview.net/forum?id=Atus2kay0Q3,/attachment/5fa595a42c88c6f5110bebbb0da5dfbbeae48d54.pdf
913,iAG3ldh1T8g,Invariant Language Modeling,['aclweb.org/ACL/ARR/2021/November/Paper1376/Authors'],['Anonymous'],"Modern pretrained language models are critical components of NLP pipelines. 
Yet, they suffer from spurious correlations, poor out-of-domain generalization, and biases.
Inspired by recent progress in causal machine learning, in particular the invariant risk minimization (IRM) paradigm,
we propose invariant language modeling, a framework for learning invariant representations that generalize better across multiple environments.
In particular, we adapt a game-theoretic implementation of IRM (IRM-games)
to language models, where the invariance emerges from a specific training schedule in which all the environments compete to optimize their own environment-specific loss by updating subsets of the model in a round-robin fashion.
In a series of controlled experiments, we demonstrate the ability of our method to (i) remove structured noise, (ii) ignore specific spurious correlations without affecting global performance, and (iii) achieve better out-of-domain generalization.
These benefits come with a negligible computational overhead compared to standard training, do not require changing the local loss, and can be applied to any language model architecture.
We believe this framework is promising to help mitigate spurious correlations and biases in language models.",/pdf/0e95b5be2df8d1afd57e33c3bf43f2c14cbc4b5f.pdf,,,,,anonymous|invariant_language_modeling,,,,,,,,,
914,3-j2OM7ASnl,Fill-in-the-Blank: A Challenging Video Understanding Evaluation Framework,['aclweb.org/ACL/ARR/2021/November/Paper1827/Authors'],['Anonymous'],"We propose fill-in-the-blanks as a video understanding evaluation framework. The task tests a model's understanding of a video by requiring the model to predict a masked noun phrase in the caption of the video, given the video and the surrounding text. To this end, we introduce a novel dataset consisting of 28,000 videos and fill-in-the-blank tests with multiple correct answers. The task and the dataset are challenging for the current state-of-the-art systems to solve. This task also does not share the weaknesses of the current state of the art language-informed video understanding tasks, namely: (1) video question answering using multiple-choice questions, where models perform relatively well because they exploit linguistic biases in the task formulation; and (2) video captioning, which relies on an open-ended evaluation framework that is often inaccurate because system answers may be perceived as incorrect if they differ in form from the ground truth.",/pdf/b81745d82e908730631c1cc22c90440c4cc0d973.pdf,,,,,anonymous|fillintheblank_a_challenging_video_understanding_evaluation_framework,,,,,,,,,
915,Csja6OkI5l,Co-training an Unsupervised Constituency Parser with Weak Supervision,['aclweb.org/ACL/ARR/2021/November/Paper1208/Authors'],['Anonymous'],"We introduce a method for unsupervised parsing that relies on bootstrapping classifiers to identify if a node dominates a specific span in a sentence. There are two types of classifiers, an inside classifier that acts on a span, and an outside classifier that acts on everything outside of a given span. Through self-training and co-training with the two classifiers, we show that the interplay between them helps improve the accuracy of both, and as a result, effectively parse. A seed bootstrapping technique prepares the data to train these classifiers. Our analyses further validate that such an approach in conjunction with weak supervision using prior branching knowledge of a known language (left/right-branching) and minimal heuristics injects strong inductive bias into the parser, achieving 63.1 F$_1$ on the English (PTB) test set. In addition, we show the effectiveness of our architecture by evaluating on treebanks for Chinese (CTB) and Japanese (KTB) and achieve new state-of-the-art results.\footnote{For code or data, please contact the authors.}",/pdf/a89677c3d101337f0cc3dc9ce05a215c5febb7bc.pdf,,,,,anonymous|cotraining_an_unsupervised_constituency_parser_with_weak_supervision,,,,,,,,,
916,Pub71Mvl87Q,Fast and Accurate Transformer-based Translation with Character-Level Encoding and Subword-Level Decoding,['aclweb.org/ACL/ARR/2021/November/Paper1834/Authors'],['Anonymous'],"The  Transformer translation model is fast to train and achieves state-of-the-art results for various translation tasks. However, unknown input words at test time remain a challenge for the  Transformer, especially when unknown words are segmented into inappropriate subword sequences that break morpheme boundaries. This paper improves the Transformer  model   to learn more accurate source representations via character-level encoding. We simply adopt character sequences instead of subword sequences as  input of the   standard  Transformer encoder and propose contextualized   character embedding (CCEmb) to help character-level encoding. Our CCEmb contains information about the current character and its context by adding the embeddings of its contextual character $n$-grams. 
The  CCEmb causes little extra computational cost  and we  show that our model with a  character-level encoder and a standard subword-level Transformer decoder can outperform   the original pure subword-level Transformer, especially for translating source sentences that contain unknown (or rare) words. 
",/pdf/451f8bef84da7c22ba23605217aa02547ab51d91.pdf,,,,,anonymous|fast_and_accurate_transformerbased_translation_with_characterlevel_encoding_and_subwordlevel_decoding,,,,,,,,,
917,pc04S6OK8To,A Multi-Document Coverage Reward for RELAXed Multi-Document Summarization,['aclweb.org/ACL/ARR/2021/November/Paper139/Authors'],['Anonymous'],"Multi-document summarization (MDS) has made significant progress in recent years, in part facilitated by the availability of new, dedicated datasets and capacious language models. However, a standing limitation of these models is that they are trained against limited references and with plain maximum-likelihood objectives. As for many other generative tasks, reinforcement learning (RL) offers the potential to improve the training of MDS models; yet, it requires a carefully-designed reward that can ensure appropriate leverage of both the reference summaries and the input documents. For this reason, in this paper we propose fine-tuning an MDS baseline with a reward that balances a reference-based metric such as ROUGE with coverage of the input documents. To implement the approach, we utilize RELAX (Grathwohl et al., 2018), a contemporary gradient estimator which is both low-variance and unbiased, and we fine-tune the baseline in a few-shot style for both stability and computational efficiency. Experimental results over the Multi-News and WCEP MDS datasets show significant improvements of up to +0.95 pp average ROUGE score and +3.17 pp METEOR score over the baseline, and competitive results with the literature. In addition, they show that the coverage of the input documents is increased, and evenly across all documents.",/pdf/48934882d4fcf86c823048b3983d50d7487fdc06.pdf,,,,,anonymous|a_multidocument_coverage_reward_for_relaxed_multidocument_summarization,,,,,,,,,
918,txfPhtRZ_SW,"As Little as Possible, as Much as Necessary: Detecting Over- and Undertranslations with Contrastive Conditioning",['aclweb.org/ACL/ARR/2021/November/Paper912/Authors'],['Anonymous'],"Omission and addition of content is a typical issue in neural machine translation. We propose a method for detecting such phenomena with off-the-shelf translation models. Using contrastive conditioning, we compare the likelihood of a full sequence under a translation model to the likelihood of its parts, given the corresponding source or target sequence. This allows to pinpoint superfluous words in the translation and untranslated words in the source even in the absence of a reference translation. The accuracy of our method is comparable to a supervised method that requires a custom quality estimation model.",/pdf/6d7d74dd3b766bc89add0f6a8e44ff8c0764ab3c.pdf,/attachment/8347433e10e6cf00f09f69fd81bb32ac93b12348.zip,,,,anonymous|as_little_as_possible_as_much_as_necessary_detecting_over_and_undertranslations_with_contrastive_conditioning,,,,,,/attachment/77275473a05cf858bca6edd3aba6b4e5682e55ed.zip,,,
919,mRUrRIL-jXh,On Systematic Style Differences between Unsupervised and Supervised MT and an Application for High-Resource Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper1525/Authors'],['Anonymous'],"Modern unsupervised machine translation (MT) systems reach reasonable translation quality under clean and controlled data conditions. As the performance gap between supervised and unsupervised MT narrows, it is interesting to ask whether the different training methods result in systematically different output beyond what is visible via quality metrics like adequacy or BLEU. We compare translations from supervised and unsupervised MT systems of similar quality, finding that unsupervised output is more fluent and more structurally different in comparison to human translation than is supervised MT. We then demonstrate a way to combine the benefits of both methods into a single system which results in improved adequacy and fluency as rated by human evaluators. Our results open the door to interesting discussions about how supervised and unsupervised MT might be different yet mutually-beneficial. ",/pdf/5fda1361364e5c558738962036046c1e23d8f427.pdf,,,,,anonymous|on_systematic_style_differences_between_unsupervised_and_supervised_mt_and_an_application_for_highresource_machine_translation,,,,,,,,,
920,dfqMpjZOgv4,Speciesist Language and Nonhuman Animal Bias in English Masked Language Models,['aclweb.org/ACL/ARR/2021/November/Paper15/Authors'],['Anonymous'],"Various existing studies have analyzed what social biases are inherited by NLP models. These biases may directly or indirectly harm people, therefore previous studies have focused only on human attributes. If the social biases in NLP models can be indirectly harmful to humans involved, then the models can also indirectly harm nonhuman animals. However, no research on social biases in NLP regarding nonhumans exists. In this paper, we analyze biases to nonhuman animals, i.e. speciesist bias, inherent in English Masked Language Models. We analyze this bias using template-based and corpus-extracted sentences which contain speciesist (or non-speciesist) language, to show that these models tend to associate harmful words with nonhuman animals. Our code for reproducing the experiments will be made available on GitHub.",/pdf/2217215ab93392ecbe483582a25d89e92103b903.pdf,,,,,anonymous|speciesist_language_and_nonhuman_animal_bias_in_english_masked_language_models,,,,,,,,,
921,ntyxtDSQ-hU,A Multilingual Bag-of-Entities Model for Zero-Shot Cross-Lingual Text Classification,['aclweb.org/ACL/ARR/2021/November/Paper58/Authors'],['Anonymous'],"We present a multilingual bag-of-entities model that effectively boosts the performance of zero-shot cross-lingual text classification by extending a multilingual pre-trained language model (e.g., M-BERT). It leverages the multilingual nature of Wikidata: entities in multiple languages representing the same concept are defined with a unique identifier. This enables entities described in multiple languages to be represented using shared embeddings.
A model trained on entity features in a resource-rich language can thus be directly applied to other languages. Our experimental results on cross-lingual topic classification (using the MLDoc and TED-CLDC datasets) and entity typing (using the SHINRA2020-ML dataset) show that the proposed model consistently outperforms state-of-the-art models.",/pdf/99903fd2a0a20a52146897bf86485bdf5193c01e.pdf,,,,,anonymous|a_multilingual_bagofentities_model_for_zeroshot_crosslingual_text_classification,,,,,,,,,
922,vtc07eXMLZP,A Flexible Multi-Task Model for BERT Serving,['aclweb.org/ACL/ARR/2021/November/Paper368/Authors'],['Anonymous'],"We present an efficient BERT-based multi-task (MT) framework that is particularly suitable for iterative and incremental development of the tasks. The proposed framework is based on the idea of partial fine-tuning, i.e. only fine-tune some top layers of BERT while keep the other layers frozen. For each task,  we train independently a single-task (ST) model using partial fine-tuning. Then we compress the task-specific layers in each ST model using knowledge distillation. Those compressed ST models are finally merged into one MT model so that the frozen layers of the former are shared across the tasks. We exemplify our approach on eight GLUE tasks, demonstrating that it is able to achieve 99.6\% of the performance of the full fine-tuning method, while reducing up to two thirds of its overhead. 
 

",/pdf/4a3851a76cd5cb1e3d129298eef493892cd42a9f.pdf,,,,,anonymous|a_flexible_multitask_model_for_bert_serving,,,,,,,,,
923,dEDH-_vQ2Wb,Entity-Conditioned Question Generation for Robust Attention Distribution in Neural Information Retrieval,['aclweb.org/ACL/ARR/2021/November/Paper1765/Authors'],['Anonymous'],"We show that supervised neural information retrieval (IR) models are prone to learning sparse attention patterns over passage tokens, which can result in key phrases including named entities receiving low attention weights, eventually leading to model under-performance. Using a novel targeted synthetic data generation method that identifies poorly attended entities and conditions the generation episodes on those, we teach neural IR to attend more uniformly and robustly to all entities in a given passage. On three public IR benchmarks, we empirically show that the proposed method helps improve both the model's attention patterns and retrieval performance, including in zero-shot settings.",/pdf/620555456b8622a2de45bf021c49f0ed3f37b400.pdf,/attachment/551d939f191176219a8e728099b56483d2c0e2bf.zip,,,,anonymous|entityconditioned_question_generation_for_robust_attention_distribution_in_neural_information_retrieval,,,,,,/attachment/178e9f1f45e4a8a3320525513f9cc02859bb7888.zip,,,
924,irGCnTg9q2Z,Fine-grained Category Discovery under Coarse-grained supervision with Hierarchical Weighted Self-contrastive Learning,['aclweb.org/ACL/ARR/2021/November/Paper962/Authors'],['Anonymous'],"In this paper, we propose a new task named Fine-grained Category Discovery under Coarse-grained supervision (FCDC). Without asking for any fine-grained knowledge, FCDC aims at discovering fine-grained categories with only coarse-grained labeled data, which can not only reduce significant labeling costs, but also adapt to novel fine-grained categories. It is also a challenging task since performing FCDC requires models to ensure fine-grained sample separability with only coarse-grained supervision and can easily make models overfit on the training set. Considering most current methods cannot transfer knowledge from coarse-grained level to fine-grained level, we propose a novel hierarchical weighted self-contrastive network to approach the FCDC task. Inspired by the hierarchy of pre-trained models (e.g. BERT), we combine supervised learning and contrastive learning to learn fine-grained knowledge from shallow to deep. Specifically, we use coarse-grained labels to train bottom layers of our model to learn surface knowledge, then we build a novel weighted self-contrastive module to train top layers of our model to learn more fine-grained knowledge. Extensive experiments on two public datasets show both effectiveness and efficiency of our model over state-of-the-art methods.",/pdf/36127257ac9001990ad1fe72e79f79611d87187e.pdf,/attachment/f830c84300f0c5040629fc0967291ae8b29f9633.zip,,,,anonymous|finegrained_category_discovery_under_coarsegrained_supervision_with_hierarchical_weighted_selfcontrastive_learning,,,,,,/attachment/25235024487ca297167d3a82a06b44e7f8372a85.zip,,,
925,z3KQb-B5Bzr,MMNet: Multimodal Fusion via Mutual Learning Network for Fake News Detection,['aclweb.org/ACL/ARR/2021/November/Paper344/Authors'],['Anonymous'],"The rapid development of social media provides a hotbed for the dissemination of fake news, which misleads readers and causes negative effects on society. We observe that a large amount of news contains images in addition to texts. Existing works on multimodal fake news detection conduct multimodal fusion by simple concatenating or co-attention networks, which is insufficient to fuse the multimodal information effectively. Considering that people judge news by alternatively exploring text-oriented and vision-oriented views, we propose a novel mutual learning based model MMNet to enhance the multimodal fusion for improving fake news detection. Additionally, in MMNet, we design a new multimodal fusion block to not only capture inter-modality interactions but also extract critical features for fake news detection. Extensive experiments on two public real datasets demonstrate that MMNet better captures the inter-dependencies of multimodal information, and outperforms state-of-the-art methods.",/pdf/a4b258f6c380c0b1303f52d9daab5156e05eb1fd.pdf,/attachment/44de82a89a105e94790295159400568341d83001.zip,,,,anonymous|mmnet_multimodal_fusion_via_mutual_learning_network_for_fake_news_detection,,,,,,,,,
926,0bHsWnmtIA-,Leveraging Visual Knowledge in Language Tasks: An Empirical Study on Intermediate Pre-training for Cross-Modal Knowledge Transfer,['aclweb.org/ACL/ARR/2021/November/Paper1517/Authors'],['Anonymous'],"Pre-trained language models are still far from human performance in tasks that need understanding of properties (e.g. appearance, measurable quantity) and affordances of everyday objects in the real world since the text lacks such information due to reporting bias.
In this work, we study whether integrating visual knowledge into a language model can fill the gap.
We investigate two types of knowledge transfer: (1) \textit{text knowledge transfer using image captions that may contain enriched visual knowledge and (2) \textit{cross-modal knowledge transfer} using both images and captions with vision-language training objectives.
On 5 downstream tasks that may need visual knowledge to solve the problem, we perform extensive empirical comparisons over the presented objectives.
Our experiments show that visual knowledge transfer can improve performance in both low-resource and fully supervised settings.",/pdf/eaede59a61e964d6ccf3dff2bf83173996a7aa32.pdf,/attachment/49978b4cf217a073ab84aed88d80c813893f8eb3.zip,,,,anonymous|leveraging_visual_knowledge_in_language_tasks_an_empirical_study_on_intermediate_pretraining_for_crossmodal_knowledge_transfer,,,,,,,,,
927,qAQCOo3IeRB,CST5: Data augmentation for Code-Switched Semantic Parsing,['aclweb.org/ACL/ARR/2021/November/Paper1728/Authors'],['Anonymous'],"Extending semantic parsers to code-switched input has been a challenging problem, primarily due to lack of labeled data for supervision.  In this work, we introduce CST5, a new data augmentation technique that finetunes a T5 model using a small seed set ($\approx$100 utterances) to generate code-switched utterances from English utterances. We demonstrate the effectiveness of CST5 by comparing baseline models which are trained without data augmentation to models which are trained with augmented data for varying amount of training data. 
By using CST5, one can achieve the same semantic parsing performance by using up to 20x less labeled data. 
To aid further research,  we release over 10k human annotated Hindi-English (Hinglish) code-switched utterances along with 170K CST5 generated code-switched utterances from the TOPv2 dataset. The generated data is of good quality deemed over 98\% natural and 89\% semantically equivalent by native annotators. 
",/pdf/efc6e49079d4b3a4549605cab7906ec1dd25dae4.pdf,,,,,anonymous|cst5_data_augmentation_for_codeswitched_semantic_parsing,,,,,,,,,
928,hzUTdaSmnzL,Semantic Matching from Different Perspectives,['aclweb.org/ACL/ARR/2021/November/Paper930/Authors'],['Anonymous'],"In this paper, we pay attention to the issue which is usually overlooked, i.e., similarity should be determined from different perspectives. To explore this issue, we release a Multi-Perspective Text Similarity (MPTS) dataset, in which sentence similarities are labeled from twelve perspectives. Furthermore, we conduct a series of experimental analysis on this task by retrofitting some famous text matching models. Finally, we obtain several conclusions and baseline models, laying the foundation for the following investigation of this issue. The dataset and code are publicly available at Github.",/pdf/95981e488f46a14b417774ad4d2ddc908d49a1b8.pdf,/attachment/8421246c7dfcecadd173d1bfad84fb46f8a6cc0e.zip,,,,anonymous|semantic_matching_from_different_perspectives,,,,,,/attachment/5f93f533ff5f16d17185e296a950032ed3f90bc5.zip,,,
929,Jpl3hYq2CItW,Coloring the Blank Slate: Pre-training Imparts a Hierarchical Inductive Bias to Sequence-to-sequence Models,['aclweb.org/ACL/ARR/2021/November/Paper1116/Authors'],['Anonymous'],"Relations between words are governed by hierarchical structure rather than linear ordering. Sequence-to-sequence (seq2seq) models, despite their success in downstream NLP applications, often fail to generalize in a hierarchy-sensitive manner when performing syntactic transformations—for example, transforming declarative sentences into questions—instead generalizing linearly using positional surface heuristics. However, syntactic evaluations of seq2seq models have only observed models that were not pre-trained on natural language data before being trained to perform syntactic transformations, in spite of the fact that pre-training has been found to induce hierarchical linguistic generalizations in language models; in other words, the syntactic capabilities of seq2seq models may have been greatly understated. Here, we make use of the pre-trained seq2seq model T5 (and its multilingual variant mT5) and evaluate whether they generalize hierarchically on two syntactic transformations in two languages: question formation and passivization in English and German. We find that T5 and mT5 generalize hierarchically when performing syntactic transformations, whereas non-pre-trained baseline models do not. This result presents additional evidence for the learnability of hierarchical syntactic information from non-annotated natural language text while also demonstrating that seq2seq models are capable of syntactic generalization.",/pdf/eeb851a50a024d7352853604e137bac3b4f37426.pdf,,,,,anonymous|coloring_the_blank_slate_pretraining_imparts_a_hierarchical_inductive_bias_to_sequencetosequence_models,,,,,,,,,
930,DUxzXsO8qRl,On Event Detection in Scientific Papers: A Multi-Domain Dataset,['aclweb.org/ACL/ARR/2021/November/Paper354/Authors'],['Anonymous'],"Given the growing number of scientific papers, automatic information extraction in scientific documents is important for efficient knowledge update and discovery. A key component in scientific papers involves rhetorical activities/events to convey new knowledge and convince readers of the correctness. This work explores a new information extraction problem for scientific documents, aiming to identify event trigger words of rhetorical events/activities, i.e., event detection (ED). To promote future research in this area, we present SciEvent, the first and new dataset for event detection in scientific documents. SciEvent annotates scientific papers of four different domains (i.e., computer science, biology, physics, and mathematics) using 8 popular event types. Our experiments on SciEvent demonstrate the challenges of scientific ED for existing models and call for further research effort in this area. We will publicly release SciEvent to facilitate future research. ",/pdf/4335fc4fffc1ac58bc4bab3a77e9c6897f1a5c19.pdf,,,,,anonymous|on_event_detection_in_scientific_papers_a_multidomain_dataset,,,,,,/attachment/095b095d2272191cd1777a528e02cbd70066a30c.zip,,,
931,WtK3-ws0P3_,LAGr: Label Aligned Graphs for Better Systematic Generalization in Semantic Parsing,['aclweb.org/ACL/ARR/2021/November/Paper2046/Authors'],['Anonymous'],"Semantic parsing is the task of producing structured meaning representations for natural language sentences. 
Recent research has pointed out that the commonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to generalize systematically, i.e. to handle examples that require recombining known knowledge in novel settings. In this work, we show that better systematic generalization can be achieved by producing the meaning representation directly as a graph and not as a sequence. To this end we propose LAGr (Label Aligned Graphs), a general framework to produce semantic parses by independently predicting node and edge labels for a complete multi-layer input-aligned graph. The strongly-supervised LAGr algorithm requires aligned graphs as inputs, whereas weakly-supervised LAGr infers alignments for originally unaligned target graphs using approximate maximum-a-posteriori inference. Experiments demonstrate that LAGr achieves significant improvements in systematic generalization upon the baseline seq2seq parsers in both strongly- and weakly-supervised settings.",/pdf/8ec9a1ce4e879e5b07f83a3208b5bc29029e7f65.pdf,,,,,anonymous|lagr_label_aligned_graphs_for_better_systematic_generalization_in_semantic_parsing,,,,,,,,,
932,WmU4nT2Avy-,Question Answering Infused Pre-training of General-Purpose Contextualized Representations,['aclweb.org/ACL/ARR/2021/November/Paper1699/Authors'],['Anonymous'],"We propose a pre-training objective based on question answering (QA) for learning general-purpose contextual representations,
motivated by the intuition that the representation of a phrase in a passage should encode all questions that the phrase can answer in context. To this end, we train a bi-encoder QA model, which independently encodes passages and questions, to match the predictions of a more accurate cross-encoder model on 80 million synthesized QA pairs. By encoding QA-relevant information, the bi-encoder's token-level representations are useful for non-QA downstream tasks without extensive (or in some cases, any) fine-tuning. We show large improvements over both RoBERTa-large and previous state-of-the-art results on zero-shot and few-shot paraphrase detection on four datasets, few-shot named entity recognition on two datasets, and zero-shot sentiment analysis on three datasets.",/pdf/5d1d99f7e24ff21a441d33d6c599cba4b3130a89.pdf,,,,,anonymous|question_answering_infused_pretraining_of_generalpurpose_contextualized_representations,,,,,,,/attachment/9709eb47b7641e74a34281af57ad6f02dc7a52ae.pdf,https://openreview.net/forum?id=m3TN7SIf7V,/attachment/5247b08a4aeca4b50575053c50e38d26f61e0fee.pdf
933,J1LYyKnaDjm,Learning to learn STEM courses,['aclweb.org/ACL/ARR/2021/November/Paper2967/Authors'],['Anonymous'],"We curate a new dataset from MIT EECS (Course 6), Physics (Course 8), Economics (Course 14), Mathematics (Course 18), Harvard Statistics, and Columbia Computer Science course questions, transform them into programming tasks using OpenAI Codex, and solve them by executing programs. We curate, transform, and solve ten courses: (i) MIT EECS 6.003 Signal Processing, (ii) MIT EECS 6.036 Introduction to Machine Learning, (iii) MIT EECS 6.042 Mathematics for Computer Science, (iv) MIT Physics 8.282 Introduction to Astronomy, (v) MIT Economics 14.01 Principles of Microeconomics, (vi) MIT Mathematics 18.05 Introduction to Probability and Statistics, (vii) MIT Mathematics 18.06 Linear Algebra, (viii) MIT Mathematics 18.781 Theory of Numbers, (ix) Harvard Statistics STATS110 Probability, and (x) Columbia University COMS3251 Computational Linear Algebra. Our approach works surprisingly well since question solutions and programs share an underlying tree representation. We are able to use Codex to correctly solve all questions by specifying both question and programming contexts such as which mathematical rules to use or which programming packages to load. In addition to generating code which solves problems the resulting code generates plots which are useful for understanding the solutions. We interactively transform the original course questions until they are solved correctly and measure the similarity between the original and transformed questions. Finally, we automatically generate novel questions for each course, providing a way to rapidly synthesize new course content. Our approach is the first scalable solution towards automatically learning to learn all university STEM courses by machine.",/pdf/b53d2ac4ed235af0bb01d617109857031a748ade.pdf,,,,,anonymous|learning_to_learn_stem_courses,,,,,,,,,
934,Euk0_paHyqD,PALBERT: Teaching ALBERT to Ponder,['aclweb.org/ACL/ARR/2021/November/Paper866/Authors'],['Anonymous'],"Currently, pre-trained models can be considered the default choice for a wide range of NLP tasks. Despite their SoTA results, there is practical evidence that these models may require a different number of computing layers for different input sequences, since evaluating all layers leads to overconfidence on wrong predictions (namely overthinking). This problem can potentially be solved by implementing adaptive computation time approaches, which were first designed to improve inference speed.

Recently proposed PonderNet may be a promising solution for performing an early exit by treating the exit layer's index as a latent variable. However, the originally proposed exit criterion, relying on sampling from trained posterior distribution on the probability of exiting from $i$-th layer, introduces major variance in model outputs, significantly reducing the resulting model's performance.

In this paper, we propose Ponder ALBERT (PALBERT) – an improvement to PonderNet with a novel deterministic Q-exit criterion and a revisited model architecture. We compared PALBERT with recent methods for performing an early exit. We observed that the proposed changes can be considered significant improvements on the original PonderNet architecture and outperform PABEE on a wide range of GLUE tasks. In addition, we also performed an in-depth ablation study of the proposed architecture to further understand Lambda layers and their performance.",/pdf/0d83d2b848611c855dcd6d04b8f0de70966e8749.pdf,/attachment/aa6f962b435b6ef58adf485e64dc4bda4cd1c65d.zip,,,,anonymous|palbert_teaching_albert_to_ponder,,,,,,,,,
935,9WuiuIZnLr2,IndicBART: A Pre-trained Model for Indic Natural Language Generation,['aclweb.org/ACL/ARR/2021/November/Paper1981/Authors'],['Anonymous'],"We study pre-trained sequence-to-sequence model for a specific-language family with a focus on Indic languages. We present IndicBART, a multilingual,  sequence-to-sequence pre-trained model focusing on 11 Indic languages and English. IndicBART utilizes the orthographic similarity between Indic scripts to improve transfer learning between similar Indic languages. We evaluate IndicBART on two NLG tasks: Neural Machine Translation (NMT) and extreme summarization. Our experiments on NMT and extreme summarization show that a language family-specific model like IndicBART is competitive with large pre-trained models like mBART50 despite being significantly smaller. It also performs well on very low-resource translation scenarios: languages not included in pre-training or fine-tuning. Script sharing, multilingual training and better utilization of limited model capacity contribute to the good performance of the compact IndicBART model.",/pdf/1f8befe5f602a6f3256f306271746d99010ac436.pdf,,,,,anonymous|indicbart_a_pretrained_model_for_indic_natural_language_generation,,,,,,,,,
936,qlQiLrEpFMR,DGMED: A Novel Document-Level Graph Convolution Network for Multi-Event Detection,['aclweb.org/ACL/ARR/2021/November/Paper746/Authors'],['Anonymous'],"Online news documents can contain thousands of characters and tens of events. To detect events in these documents, it is important to construct long-range context information. Such information, however, is not effectively created in existing event detection methods including DMBERT, MOGANED. As a result, these methods show poor event detection accuracy in production where long documents are common. To address this, this paper proposes a Document-level Graph convolution network for Multi-event Detection (DGMED). DGMED represents each sentence in a long document as a graph, and it interconnects these graphs using novel cross-sentence global neural network nodes. These nodes allow DGMED further construct accurate document-level contextual information, thus accurately extracting multiple events as required. We evaluate DGMED using a public event extraction dataset (i.e., Maven) and a production large-scale dataset (named AML). Evaluation results show that DGMED can out-perform state-of-the-art methods BERT+CRF and BiLSTM+CRF up to 0.7% in Maven and 5.7% in AML.",/pdf/b4e9c8b2dc51ee67b8536ce0fd2d60fe20c647c2.pdf,/attachment/a4dc0ccc6aa1a35dcbbcce0689be67fe974630e4.zip,,,,anonymous|dgmed_a_novel_documentlevel_graph_convolution_network_for_multievent_detection,,,,,,/attachment/d3ac2a8bae1d1bb79b5436649bb1105e29ca6542.zip,,,
937,-IqgviHAGoh,Sequence-to-Sequence Knowledge Graph Completion and Question Answering,['aclweb.org/ACL/ARR/2021/November/Paper1354/Authors'],['Anonymous'],"Knowledge graph embedding (KGE) models represent each entity and relation of a knowledge graph (KG) with low-dimensional embedding vectors. These methods have recently been applied to KG link prediction and question answering over incomplete KGs (KGQA). KGEs typically create an embedding for each entity in the graph, which results in large model sizes on real-world graphs with millions of entities. Their atomic entity representation also necessitates a multi-stage approach to downstream tasks, which limits their utility. We show that an off-the-shelf encoder-decoder Transformer model can serve as a scalable and versatile KGE model obtaining state-of-the-art results for KG link prediction and KGQA. We achieve this by posing KG link prediction as a sequence-to-sequence task and exchange the triple scoring approach taken by prior KGE methods with a generative decoding approach. Such a simple but powerful method reduces the model size up to 90% compared to conventional KGE models and attains the best performance among small-sized models. An ensemble with a traditional KGE model even sets a new state-of-the-art. After finetuning this model on the task of KGQA over incomplete KGs, our approach outperforms baselines on multiple large-scale datasets without extensive hyperparameter tuning.",/pdf/ca4700383884a7c0ba083274c4edb4eaaae4a9c2.pdf,/attachment/bccab94044d07493ce38c39330bc25dcef57763c.zip,,,,anonymous|sequencetosequence_knowledge_graph_completion_and_question_answering,,,,,,,,,
938,4nd6limglou,Investigating Logic Tensor Networks for Neural-Symbolic Argument Mining,['aclweb.org/ACL/ARR/2021/November/Paper493/Authors'],['Anonymous'],"We present an application of neural-symbolic learning to argument mining.
We use Logic Tensor Networks to train neural models to jointly fit the data and satisfy specific domain rules.
Our experiments on a corpus of scientific abstracts indicate that including symbolic rules during the training process improves classification performance, compliance with the rules, and robustness of the results.",/pdf/25f0dc73fc659b05d45b512e43061d61130c45be.pdf,/attachment/4e2a03bc5b5253e24e24bc82ffaed75a5f774509.zip,,,,anonymous|investigating_logic_tensor_networks_for_neuralsymbolic_argument_mining,,,,,,/attachment/40febdee944e28a3adf481f8278f6a814f977687.zip,/attachment/cbe6e1d3515175d260420599b650ed979aa37563.pdf,https://openreview.net/forum?id=41SZu4IPi6N,/attachment/642182a6c027d8058fab42993cef7a2a50fe87e1.pdf
939,jpofcOlD3IA,SuperShaper: Task-Agnostic Super Pre-training of BERT Models with Variable Hidden Dimensions,['aclweb.org/ACL/ARR/2021/November/Paper2378/Authors'],['Anonymous'],"Task-agnostic pre-training followed by task-specific fine-tuning is a default approach to train NLU models which need to be deployed on devices with varying resource and accuracy constraints. However, repeating pre-training and fine-tuning across tens of devices is prohibitively expensive. To address this, we propose SuperShaper, a task agnostic pre-training approach wherein we pre-train a single model which subsumes a large number of Transformer models by varying shapes, i.e., by varying the hidden dimensions across layers. 
This is enabled by a backbone network with linear bottleneck matrices around each Transformer layer which are sliced to generate differently shaped sub-networks. Despite its simple design space and efficient implementation, SuperShaper radically simplifies NAS for language models and discovers networks that effectively trade-off accuracy and model size: Discovered networks are more accurate than a range of hand-crafted and automatically searched networks on GLUE benchmarks. Further, we find two critical advantages of shape as a design variable for Neural Architecture Search (NAS): (a) networks found with these heuristics derived for good shapes, match and even improve on carefully searched networks across a range of parameter counts, and (b) the latency of networks across multiple CPUs and GPUs are insensitive to the shape and thus enable device-agnostic search.",/pdf/89a02f53513a0d90e4afe07d9f0cc77903b9ae18.pdf,,,,,anonymous|supershaper_taskagnostic_super_pretraining_of_bert_models_with_variable_hidden_dimensions,,,,,,,,,
940,SWPpMOxvAuh,Tailor: Generating and Perturbing Text with Semantic Controls,['aclweb.org/ACL/ARR/2021/November/Paper1988/Authors'],['Anonymous'],"Controlled text perturbation is useful for evaluating model generalizability and improving model robustness to dataset artifacts. However, current techniques rely on training a perturbation model for every targeted attribute, which is expensive and hard to generalize. We present Tailor, a semantically-controlled text generation system. Tailor builds on a pretrained seq2seq model, and produces textual outputs conditioning on $\textbf{control codes}$ derived from semantic representations. We craft a set of operations to modify the control codes, which in turn steer generation towards targeted attributes. These operations can be further composed into higher-level ones, allowing for flexible perturbation strategies. Tailor can be applied in various scenarios. We use it to automatically create high-quality contrast sets for four distinct natural language processing (NLP) tasks. These contrast sets contain fewer spurious biases and are complementary to manually annotated ones in terms of lexical diversity. We show that Tailor helps improve model generalization through data augmentation, with a 5.8-point gain on an NLI challenge set, by perturbing just $\sim2\%$ of training data.",/pdf/ea9470a229d2a456f4a084dff1b0d3ec07ffe1d9.pdf,,,,,anonymous|tailor_generating_and_perturbing_text_with_semantic_controls,,,,,,,/attachment/4fdf5a83e9c85c7f249046fceb867e3883b2fec4.pdf,https://openreview.net/forum?id=7ot_3041a6L,/attachment/f6c9a70c0fb174cd570f250768d099d88558eedc.pdf
941,QSjmoOagk-x,BORT: Back and Denoising Reconstruction for End-to-End Task-Oriented Dialog,['aclweb.org/ACL/ARR/2021/November/Paper1332/Authors'],['Anonymous'],"A typical end-to-end task-oriented dialog system transfers context into dialog state, and upon which generates a response, which usually faces the problem of error propagation from both previously generated inaccurate dialog states and responses, especially in low-resource scenarios. To alleviate these issues, we propose BORT, a back and denoising reconstruction approach for end-to-end task-oriented dialog system. To improve the accuracy of dialog state that is essential for the task completion of dialog system, back reconstruction is used to reconstruct the original input context from the generated dialogue state since the inaccurate dialog state cannot recover its corresponding input context. To enhance the antinoise capability of the model, denosing reconstruction is used to reconstruct the corrupted dialog state and response. Extensive experiments conducted on MultiWOZ 2.0 and CamRest676 show the effectiveness of BORT which achieves state-of-the-art performance. Furthermore, BORT demonstrates its advanced capabilities in zero-shot domain scenarios and in low-resource scenarios.",/pdf/ca8a8c0e65e969a3928dc39bf982824d9919d55b.pdf,/attachment/96e99f27ae6f061ec838046a0b4363aedd310686.zip,,,,anonymous|bort_back_and_denoising_reconstruction_for_endtoend_taskoriented_dialog,,,,,,,,,
942,1ZoG-0y2X5b,,,,,,,,,,,,,,,,,,,
943,0GzHjrL4Vq0,We need to talk about random seeds,['aclweb.org/ACL/ARR/2021/November/Paper66/Authors'],['Anonymous'],"Modern neural network libraries all take as a hyperparameter a random seed, typically used to determine the initial state of the model parameters. This position piece argues that there are some safe uses for random seeds: as part of the hyperparameter search to select a good model, creating an ensemble of several models, or measuring the sensitivity of the training algorithm to the random seed hyperparameter. It argues that some uses for random seeds are risky: using a fixed random seed for ``replicability'' and varying only the random seed to create score distributions for performance comparison. An analysis of 85 recent publications from the ACL Anthology shows that more than 50% contain risky uses of random seeds.",/pdf/ec4d1378f10f002f079d79e4b4bd28d443d373b1.pdf,,,,,anonymous|we_need_to_talk_about_random_seeds,,,,,,/attachment/43544afe8739dcbd374c8c83712de9fd7569dcd9.zip,/attachment/9a7df464f1d5238cb16ddb0cdacc7b59688024d4.pdf,https://openreview.net/forum?id=Z0lw-ozMSEe,/attachment/4f52890489ba79723c1cc4c37e7de259621351ec.pdf
944,uTBMXdimtr1,NSP-BERT: A Prompt-based Zero-Shot Learner Through an Original Pre-training Task —— Next Sentence Prediction,['aclweb.org/ACL/ARR/2021/November/Paper1784/Authors'],['Anonymous'],"Using prompts to utilize language models to perform various downstream tasks, also known as prompt-based learning or prompt-learning, has lately gained significant success in comparison to the pre-train and fine-tune paradigm. Nonetheless, virtually all prompt-based methods are token-level, meaning they all utilize GPT's left-to-right language model or BERT's masked language model to perform cloze-style tasks. In this paper, we attempt to accomplish several NLP tasks in the zero-shot scenario using a BERT original pre-training task abandoned by RoBERTa and other models—Next Sentence Prediction (NSP). Unlike token-level techniques, our sentence-level prompt-based method NSP-BERT does not need to fix the length of the prompt or the position to be predicted, allowing it to handle tasks such as entity linking with ease. Based on the characteristics of NSP-BERT, we offer several quick building templates for various downstream tasks. We suggest a two-stage prompt method for word sense disambiguation tasks in particular. Our samples-contrast method for mapping the labels significantly enhance the model's performance on sentence-pair tasks. On the Chinese benchmark FewCLUE, our NSP-BERT outperforms other zero-shot methods on most of these tasks and comes close to the few-shot methods. And on GLUE and other English datasets NSP-BERT is still competitive. Our code will be available on github.",/pdf/599f2aaa68475331c88ea69d803171c089e317d9.pdf,/attachment/44b0379d50020a16e330dfdb18355c1c6ee1d262.zip,,,,anonymous|nspbert_a_promptbased_zeroshot_learner_through_an_original_pretraining_task_next_sentence_prediction,,,,,,,,,
945,66j5tGK1qI6,QuoteR: A Benchmark of Quote Recommendation for Writing,['aclweb.org/ACL/ARR/2021/November/Paper1244/Authors'],['Anonymous'],"It is very common to use quotations (quotes) to make our writings more elegant or convincing. To help people find appropriate quotes more efficiently, the task of quote recommendation is presented, aiming to recommend quotes that fit the current context of writing. There have been various quote recommendation approaches, but they are evaluated on different unpublished datasets. To facilitate the research on this task, we build a large and fully open quote recommendation dataset called QuoteR, which comprises three parts including English, standard Chinese and classical Chinese. Any part of it is larger than previous unpublished counterparts. We conduct an extensive evaluation of existing quote recommendation methods on QuoteR. Furthermore, we propose a new quote recommendation model that significantly outperforms previous methods on all three parts of QuoteR. All the code and data of this paper will be released.",/pdf/49114911594dc2d6ee21146f473ece8d1afbfc82.pdf,/attachment/6a07ce6da9383be9d4d704af7df3899c4c740975.zip,,,,anonymous|quoter_a_benchmark_of_quote_recommendation_for_writing,,,,,,/attachment/901c8fe40f2e7fdb9fb7935e0a9c6c7253b02265.zip,,,
946,YZJl7bQkPAo,Identifying Corporate Credit Risk Sentiments from Financial News,['aclweb.org/ACL/ARR/2021/November/Paper2549/Authors'],['Anonymous'],"Credit risk management is one major practice for financial institutions, that helps them measure and understand the inherent risk within their portfolios. Historically, they relied on the assessment of default probabilities (via structural or default intensity models) and used the press as one tool to gather insights on the latest credit event developments of an entity. However, because the current news volume and coverage for companies is generally heavy, analyzing news manually by financial experts is considered a highly laborious task. To this end, we propose a novel deep learning-powered approach to automate news analysis and credit adverse events detection, with the aim of scoring the credit sentiment associated with a company in order to assist credit risk management efficiently. The result is a complete system leveraging news extraction and data enrichment (with targeted sentiment entity recognition to detect companies and text classification to identify credit events), as well as a custom scoring mechanism designed to provide the company's credit sentiment, called Credit Sentiment Score™ (CSS). Additionally, studies are shown to illustrate how CSS helps to gain knowledge about the company's credit profile but also discriminates between defaulters and non-defaulters.    ",/pdf/222f0f0dbcd39e81a52b01a2590d3866c7da9e35.pdf,,,,,anonymous|identifying_corporate_credit_risk_sentiments_from_financial_news,,,,,,,,,
947,pheR28vOKmF,Multi-Party Empathetic Dialogue Generation: A New Task for Dialog Systems,['aclweb.org/ACL/ARR/2021/November/Paper2320/Authors'],['Anonymous'],"Empathetic dialogue assembles emotion understanding, feeling projection, and appropriate response generation. Existing work for empathetic dialogue generation concentrates on the two-party conversation scenario. Multi-party dialogues, however, are pervasive in reality. Furthermore, emotion and sensibility are typically confused; a refined empathy analysis is needed for comprehending fragile and nuanced human feelings. We address these issues by proposing a novel task called Multi-Party Empathetic Dialogue Generation in this study. A new dataset MPED with 130k multi-party dialogues is correspondingly presented for this task, which makes up for the absence of a large-scale benchmark in this field. Additionally, a Static-Dynamic model for Multi-Party Empathetic Dialogue Generation, SDMPED, is introduced as a baseline by exploring the static sensibility and dynamic emotion for the multi-party empathetic dialogue learning, the aspects that help SDMPED achieve the state-of-the-art performance on MPED.",/pdf/edc6f01d1cb69b7817573fe4d955ee2da8d0f192.pdf,,,,,anonymous|multiparty_empathetic_dialogue_generation_a_new_task_for_dialog_systems,,,,,,,,,
948,CvGtHdgukK,Few-shot Named Entity Recognition with Joint Token and Sentence Awareness,['aclweb.org/ACL/ARR/2021/November/Paper514/Authors'],['Anonymous'],"Few-shot learning has been proposed and rapidly emerging as a viable means for completing various tasks. Recently, few-shot models have been used for Named Entity Recognition (NER). Prototypical network shows high efficiency on few-shot NER. However, existing prototypical methods only consider the similarity of tokens in query sets and support sets and ignore the semantic similarity among the sentences which contain these entities. We present a novel model, Few-shot Named Entity Recognition with  \textbf{J}oint \textbf{T}oken and \textbf{S}entence \textbf{A}wareness (\textbf{JTSA}), to address the issue.  The sentence awareness is introduced to probe the semantic similarity among the sentences. The Token awareness is used to explore the similarity of the tokens. To further improve the robustness and results of the model, we adopt the joint learning scheme on the few-shot NER. Experimental results demonstrate that our model outperforms state-of-the-art models on two standard Few-shot NER datasets.",/pdf/d251ddd19b807b44a9f9941bf9fbfa0aaec54365.pdf,/attachment/9405fbb8b1c10982c721ee89836db24cac76924b.zip,,,,anonymous|fewshot_named_entity_recognition_with_joint_token_and_sentence_awareness,,,,,,,,,
949,N-DZvl4bQsO,DAML: Chinese Named Entity Recognition with a fusion method of data-augmentation and meta-learning,['aclweb.org/ACL/ARR/2021/November/Paper761/Authors'],['Anonymous'],"Overfitting is still a common problem in NER with insufficient data. Latest methods such as Transfer Learning, which focuses on storing knowledge gained while solving one task and applying it to a different but related task, or Model-Agnostic Meta-Learning (MAML), which learns a model parameter initialization that generalizes better to similar tasks. However, these methods still need rich resources to pre-train. In this work, we present new perspectives on how to make the most of in-domain and out-domain information. By introducing a fusion method of data augmentation and MAML, we first use data augmentation to mine more information. With the augmented resources, we directly utilize out-domain and in-domain data with MAML, while avoiding performance degradation after domain transfer. To further improve the model’s generalization ability, we proposed a new data augmentation method based on a generative approach. We conduct experiments on six open Chinese NER datasets (MSRANER, PeopleDairyNER, CLUENER, WeiboNER, Resume NER, and BOSONNER). The results show that our method significantly reduces the impact of insufficient data and outperforms the state-of-the-art.",/pdf/55cc5b27d9f25aaee3774a8162dc4c3064de31c9.pdf,,,,,anonymous|daml_chinese_named_entity_recognition_with_a_fusion_method_of_dataaugmentation_and_metalearning,,,,,,,,,
950,lDP5HjvqdQp,On the Importance of Data Size in Probing Fine-tuned Models,['aclweb.org/ACL/ARR/2021/November/Paper2894/Authors'],['Anonymous'],"Several studies have investigated the reasons behind the effectiveness of fine-tuning, usually through the lens of probing. However, these studies often neglect the role of the size of the dataset on which the model is fine-tuned. In this paper, we highlight the importance of this factor and its undeniable role in probing performance. We show that the extent of encoded linguistic knowledge depends on the number of fine-tuning samples, specifically the number of iterations for which the model is updated. The analysis also reveals that larger training data mainly affects higher layers, and that the extent of this change is a factor of the number of iterations in fine-tuning rather than the diversity of the training samples. Finally, we show through a set of experiments that fine-tuning introduces shallow and recoverable changes to model's representation.",/pdf/be63ee5ea523331dbe061bf42b141e1437e59ec9.pdf,,,,,anonymous|on_the_importance_of_data_size_in_probing_finetuned_models,,,,,,,,,
951,mgu6JpUzgD,Delving Deep into Extractive Question Answering Data,['aclweb.org/ACL/ARR/2021/November/Paper2598/Authors'],['Anonymous'],"The impact of large-scale pre-trained language models on Question Answering in recent times is undeniably positive.
Few prior works have attempted however to provide detailed insight into  how such models learn from QA dataset component parts.
For example, what specific kinds of examples are most important for models to learn from? In this paper, we examine two English QA datasets, namely SQuAD1.1 and NewsQA, and report findings on the internal characteristics of these widely employed extractive QA datasets. Experiment results reveal: (i) Models learn relatively independently of examples from outside a given question type (the performance on each question type mainly comes from that data belonging to that same question type); (ii) Increased difficulty in the training data results in better performance; (iii) Learning from QA data approximates to the process of learning question-answer matches. ",/pdf/9c13200e56f4cdf220ba26faa2009856b20127ea.pdf,,,,,anonymous|delving_deep_into_extractive_question_answering_data,,,,,,,,,
952,8BfBSWeCqV1,Global Responses to the COVID-19 Pandemic: A Case Study of Spatiotemporal Evidence Finding and Verification,['aclweb.org/ACL/ARR/2021/November/Paper1230/Authors'],['Anonymous'],"This paper explores methods for adapting fact verification models to real-world scenarios that require spatial and temporal inference. As a case study, we search for evidence on governments’ responses to the COVID-19 pandemic. 
We demonstrate that existing fact verification models perform poorly when the verification requires reasoning about spatiotemporal information.
The suggested techniques lead to great improvements and we recommend implementing them for such uses. ",/pdf/ea6c453b1bb09cda0ffc0a7529e57d4a513b57f5.pdf,,,,,anonymous|global_responses_to_the_covid19_pandemic_a_case_study_of_spatiotemporal_evidence_finding_and_verification,,,,,,,,,
953,wlYe7xVDxLI,An Information Theoretic Measurement of Topical Relevance in Learner Essays,['aclweb.org/ACL/ARR/2021/November/Paper1787/Authors'],['Anonymous'],"We present a new approach to assess topical relevance in learner essays, leveraging recent advances in pretrained language models. Our approach is to generate features by calculating the normalized pointwise mutual information (NPMI) between prompts and sentences in an essay using a finetuned version of GPT-2. We demonstrate various desirable properties of this approach, including its strong performance under a variety of evaluation settings, its generalizability to novel prompts, and its interpretability.",/pdf/48cddf80d2b753e1a5889ababa08d5595067a68e.pdf,,,,,anonymous|an_information_theoretic_measurement_of_topical_relevance_in_learner_essays,,,,,,,,,
954,r8bh3ODovuK,On the Difficulties of using NLP for Language Revitalization,['aclweb.org/ACL/ARR/2021/November/Paper565/Authors'],['Anonymous'],"This paper is dedicated to discussing the general difficulty of using emerging Natural Language Processing (NLP) technologies to the revitalization of languages. Previous literature had described the social causes of language shift; legal prohibitions, social and economic marginalization as well as a lack of inclusion in public life have been identified as the main factors for the non-viability of minority languages. As such, as innovative as they may be, these emerging tools are not enough to rescue languages and the core issues must be addressed if meaningful results are expected.",/pdf/0446e2d7b945991e5afec9ebeef4a3fe50fa6b0b.pdf,,,,,anonymous|on_the_difficulties_of_using_nlp_for_language_revitalization,,,,,,,,,
955,_LBgoXPUoWO,Night Owls and Majestic Whales: Modeling Metaphor Comprehension as a Rational Speech Act over Vector Representations of Lexical Semantics,['aclweb.org/ACL/ARR/2021/November/Paper27/Authors'],['Anonymous'],"While they are one of the few computational models that directly capture some of the pragmatic processes underlying language reasoning, current Rational Speech Act (RSA) models of metaphor do not align well with contemporary accounts of metaphor comprehension. The following research project leverages GloVe word vectors to capture pragmatic language reasoning in metaphoric utterances using an updated RSA framework. The model yields higher posterior probabilities for the same attributes that humans deem relevant in metaphoric utterances over erroneous ones in 89% of all cases, validating the use of word vectors to generate prior probabilities in an RSA framework. When presented with biased priors like listeners are in many naturalistic conversations, the model accurately matches human judgements of the top-most relevant attribute of a topic/target indicated by a metaphoric utterance 90% of the time. ",/pdf/ecd1727f695893ad209d5cd884e3509ad7a4b096.pdf,,,,,anonymous|night_owls_and_majestic_whales_modeling_metaphor_comprehension_as_a_rational_speech_act_over_vector_representations_of_lexical_semantics,,,,,,,,,
956,5KvP-wQF7iT,ATOGAN:Adaptive Training Objective Generative Adversarial Network for Cross-lingual Word Alignment in Non-Isomorphic Embedding Spaces,['aclweb.org/ACL/ARR/2021/November/Paper1720/Authors'],['Anonymous'],"Cross-lingual word alignment is a task for word translation from monolingual word embedding spaces of two languages. Recent works are mostly based on supervised approaches, which need specific bilingual seed dictionaries. The unsupervised adversarial approaches, which utilize the generative adversarial networks to map the whole monolingual space, do not need any aligned data. However these approaches pay no attention to the problem of mode collapse and gradient disappearance in generative adversarial networks(GAN). We proposed an adaptive training objective generative adversarial network(ATOGAN). We combined particle swarm optimization(PSO) with GAN to select the training objective in GAN's training, which alleviates the problem of mode collapse and gradient disappearance. Moreover, we improved the word alignment by bi-directional mapping and consistency loss. Experimental results demonstrate that our approach is better than several state-of-the-art approaches in distant language pairs(non-isomorphic embedding spaces). ",/pdf/4171120d11c6acf7350ca4f815df9de6d977fcd4.pdf,,,,,anonymous|atoganadaptive_training_objective_generative_adversarial_network_for_crosslingual_word_alignment_in_nonisomorphic_embedding_spaces,,,,,,,,,
957,6de5DZ8nl_R,Unsupervised Multi-Granularity Summarization,['aclweb.org/ACL/ARR/2021/November/Paper2470/Authors'],['Anonymous'],"Text summarization is a user-preference based task. For one document, users often have different priorities for summary. Granularity level of the summary is a core component of these preferences. However, most existing studies focus solely on single-granularity scenarios, resulting in models that are limited to producing summaries with similar semantic coverage and are not customizable. In this paper, we propose the first unsupervised multi-granularity summarization framework, GranuSum. We regard events as basic semantic units of the original text and design a model that can take these events as anchors when generating summary. Meanwhile, by ranking these hint events and controlling the number of events, GranuSum is capable of generating summaries at different granularities in an unsupervised manner. We develop a testbed for the multi-granularity summarization task, including a new human-annotated benchmark GranuDUC where each document is paired with multiple summaries with different granularities. Extensive experiments on this benchmark and other large-scale datasets show that GranuSum substantially outperforms previous baselines. We also find that GranuSum exhibits impressive performance on conventional unsupervised abstractive summarization tasks via exploiting the event information, achieving new state-of-the-art results on three summarization datasets.",/pdf/c97ce42a4204dc7a68f2eb47cd043a8804b85d3d.pdf,,,,,anonymous|unsupervised_multigranularity_summarization,,,,,,,,,
958,NrwVVLkuiG_,Boundary Smoothing for Named Entity Recognition,['aclweb.org/ACL/ARR/2021/November/Paper241/Authors'],['Anonymous'],"Neural named entity recognition (NER) models may easily encounter the over-confidence issue, which degrades the performance and calibration. Inspired by label smoothing and driven by the ambiguity of boundary annotation in NER engineering, we propose boundary smoothing as a regularization technique for span-based neural NER models. It re-assigns entity probabilities from annotated spans to the surrounding ones. Built on a simple but strong baseline, our model achieves results better than or competitive with previous state-of-the-art systems on eight well-known NER benchmarks. Further empirical analysis suggests that boundary smoothing effectively mitigates over-confidence, improves model calibration, and brings flatter neural minima and more smoothed loss landscapes. ",/pdf/3294a793dea031ff68f34d1a771f84b6320199b6.pdf,/attachment/a33e25b2e0873bc4390d9c07bb6be856defdeca4.zip,,,,anonymous|boundary_smoothing_for_named_entity_recognition,,,,,,,,,
959,iozkB44VlOl,Speaker Profiling in Multi-party Conversations,['aclweb.org/ACL/ARR/2021/November/Paper1927/Authors'],['Anonymous'],"In a conversation, individual speakers respond uniquely. Consequently, a `one size fits all' technique is not the best way for a dialog agent to generate responses. While many studies design personalized dialog agents with the help of persona information of speakers, all of them assume that speaker persona is supplied beforehand. However, this assumption does not hold for all conversational agents. This paper attempts to address this gap by exploring the task -- Speaker Profiling in Conversations (SPC). The aim of SPC is to produce a summary of the persona characteristics for individual speakers present in a dialog. We divide this task into two subtasks -- persona discovery and persona-type identification. Given a dialog, the former subtask aims to find all its utterances that carry persona information. The latter subtask focuses on evaluating these utterances to identify the type of persona information present in them. We present SPICE, a novel dataset that is specifically curated with labels to tackle the task of SPC. We show the performance of various baselines on SPICE and benchmark it using SPOT, a neural model based on GRU and Transformer. SPOT shows an improvement of ~7% for persona discovery and ~3% for persona-type identification over the best baseline. We further present a thorough analysis of SPOT to diagnose individual modules and their limitations, both quantitatively and qualitatively.",/pdf/9ded44de1c41e38c4d7b055c7a10d2a44ee22391.pdf,/attachment/edb011010da72825ce233e842534079f3be7358f.zip,,,,anonymous|speaker_profiling_in_multiparty_conversations,,,,,,/attachment/c9a1a4424dc75c775de0e787105a911c07b28fea.zip,,,
960,B393CzcykVJ,Layout-Aware Neural Model for Resolving Hierarchical Table Structure,['aclweb.org/ACL/ARR/2021/November/Paper2233/Authors'],['Anonymous'],"While many pipelines for extracting information from tables assume simple table structure,  tables in the financial domain frequently have complex, hierarchical structure.  The main example would be parent-child relationships between header cells.  Most prior datasets of tables annotated from images or .pdf and most models for extracting table structure concentrate on the problems of table, cell, row, and column bounding box extraction.  The area of fine-grained table structure remains relatively unexplored.   In this study, we present a dataset of 887 tables, manually labeled for cell types and column hierarchy relations.  The tables are selected from IBM FinTabNet, a much larger dataset of more than 100,000 financial tables having cell, row, and column bounding boxes extracted by deep learning, but not including semantic cell type or cell-to-cell relation labels, which we add. Selection of these 887 tables is performed using heuristics which result in a much larger proportion, roughly half, of the selected tables having complex hierarchical structure, than a random sample from FinTabNet. Further, we fine-tune models based on LayoutLM on the cell-type classification task and on the identification of hiearchical relations among column headers.  We achieve F1 scores of 95% and 70% on the respective tasks.  Finally, we use the trained model to create soft labels for the entirety of FinTabNet. 
",/pdf/141f7af114896ba7404ebf4d36f4e76ff41edc51.pdf,,,,,anonymous|layoutaware_neural_model_for_resolving_hierarchical_table_structure,,,,,,,,,
961,g1cXuI-yxp7,Sentence-level Privacy for Document Embeddings,['aclweb.org/ACL/ARR/2021/November/Paper1603/Authors'],['Anonymous'],"User language data can contain highly sensitive personal content. As such, it is imperative to offer users a strong and interpretable privacy guarantee when learning from their data. In this work we propose SentDP, pure local differential privacy at the sentence level for a single user document. We propose a novel technique, DeepCandidate, that combines concepts from robust statistics and language modeling to produce high (768) dimensional, general $\epsilon$-SentDP document embeddings. This guarantees that any single sentence in a document can be substituted with any other sentence while keeping the embedding $\epsilon$-indistinguishable. Our experiments indicate that these private document embeddings are useful for downstream tasks like sentiment analysis and topic classification and even outperform baseline methods with weaker guarantees like word-level Metric DP. ",/pdf/d99b76296b29e2b4fb4d1807a7737ad93b6603f1.pdf,,,,,anonymous|sentencelevel_privacy_for_document_embeddings,,,,,,,,,
962,Sm8-5PzKW0,Meta Learning for Code Summarization,['aclweb.org/ACL/ARR/2021/November/Paper2834/Authors'],['Anonymous'],"Source code summarization is the task of generating a high-level natural language description for a segment of programming language
code. Current neural models for the task differ in their architecture and the aspects of code they consider. In this paper, we show that three
SOTA models for code summarization work well on largely disjoint subsets of a large code-base. This complementarity motivates model
combination: We propose three meta-models that select the best candidate summary for a given code segment. The two neural models improve significantly over the performance of the best individual model, obtaining an improvement of 2.1 BLEU points on a dataset of
code segments where at least one of the individual models obtains a non-zero BLEU.",/pdf/2bd9b4be1a083cf57be32aa19a663611814e0a46.pdf,/attachment/d69731f042f4196bedaae08edd25fa150c5745c2.tgz,,,,anonymous|meta_learning_for_code_summarization,,,,,,,,,
963,QFVMJKfsX6g,Things not Written in Text: Exploring Spatial Commonsense from Visual Signals,['aclweb.org/ACL/ARR/2021/November/Paper698/Authors'],['Anonymous'],"Spatial commonsense, the knowledge about spatial position and relationship between objects (like the relative size of a lion and a girl, and the position of a boy relative to a bicycle when cycling), is an important part of commonsense knowledge. Although pretrained language models (PLMs) succeed in many NLP tasks, they are shown to be ineffective in spatial commonsense reasoning. 
Starting from the observation that images are more likely to exhibit spatial commonsense than texts, we explore whether models with visual signals learn more spatial commonsense than text-based PLMs. We propose a spatial commonsense benchmark that focuses on the relative scales of objects, and the positional relationship between people and objects under different actions.
We probe PLMs and models with visual signals, including vision-language pretrained models and image synthesis models, on this benchmark, and find that image synthesis models are more capable of learning accurate and consistent spatial knowledge than other models. The spatial knowledge from image synthesis models also helps in natural language understanding tasks that require spatial commonsense.",/pdf/e4d2dd4038b6849c6fc3e7d986bafa85bc892450.pdf,/attachment/274ebea5e786fae1a327af7f8356a33803d99802.zip,,,,anonymous|things_not_written_in_text_exploring_spatial_commonsense_from_visual_signals,,,,,,/attachment/02c0ebdcb89edb63947457503938e9a158ab03ba.zip,,,
964,Z9vIuaFlIXx,SAMBERT: Improve Aspect Sentiment Triplet Extraction by Segmenting the Attention Maps of BERT,['aclweb.org/ACL/ARR/2021/November/Paper91/Authors'],['Anonymous'],"Aspect Sentiment Triplet Extraction (ASTE) performs fine-grained sentiment analysis in a unified way through extracting sentiment triplets comprised of aspect terms, opinion spans, and their sentiment relations in sentences. The previous works show the adoption of BERT, which simply leverages its last layer output as the word representation, is beneficial for recognizing triplet elements. However, their methods limit the potential of pretrained knowledge in BERT, since the different layers can capture multi-level linguistic information existing in sentences, which are useful for ASTE as well. In this work, we explore to access the rich pretrained knowledge by fully leveraging its attention maps of different layers. To this end, we propose to Segment the Attention Maps of BERT (SAMBERT) by taking the merits of semantic segmentation, which can effectively discriminate the desired objects from others in an image. In this procedure, we can further reason over the knowledge of different levels in these attention maps to distinguish aspect terms, opinion spans and their sentiment relations from other parts, which results in a same-shape tagging matrix of word pairs for deriving sentiment triplets. Through the extensive experiments on four benchmarks, we demonstrate our method can achieve a new state of the art.",/pdf/6dea8126cf3e1ad5fb9b1143db7e01022e4c3515.pdf,,,,,anonymous|sambert_improve_aspect_sentiment_triplet_extraction_by_segmenting_the_attention_maps_of_bert,,,,,,,,,
965,8Uat0t77qX_,TransSGAN: GAN based semi-superivsed learning for text classification with Transformer Encoder,['aclweb.org/ACL/ARR/2021/November/Paper2914/Authors'],['Anonymous'],"Recent semi-supervised learning for text classification uses data augmentations. However, it is a time-consuming and tricky hyperparametric approach. To overcome this problem, we present GAN-based semi-supervised learning for text classification, TransSGAN, which has a simple architecture, fewer hyperparameters, and trains for less time than current SOTA models since it does not need data augmentation. By adding one transformer encoder block to Semi-Supervised GAN, we can get comparable performances with extremely few labeled data to previous SOTA models up to 1% difference and 25% better performance than baseline GAN based model. Furthermore, we provide an analysis of our model, what the generator makes, and what multi-head self-attention layer in the generator learns. Through this, we can validate that our generator makes qualified data.",/pdf/dc99f127b830e84d3e8719d0d996758daa31e022.pdf,,,,,anonymous|transsgan_gan_based_semisuperivsed_learning_for_text_classification_with_transformer_encoder,,,,,,,/attachment/f672e40d0300bd08ca14141b690388dd156dcf6c.pdf,,
966,_pois-tbnOd,Unsupervised Preference-Aware Language Identification,['aclweb.org/ACL/ARR/2021/November/Paper810/Authors'],['Anonymous'],"Recognizing the language of ambiguous texts has become a main challenge in language identification (LID). When using multilingual applications, users have their own language preferences, which can be regarded as external knowledge for LID. Nevertheless, current studies do not consider the inter-personal variations due to the lack of user annotated training data. To fill this gap,  we introduce preference-aware LID and propose a novel unsupervised learning strategy. Concretely, we construct pseudo training set for each user by extracting training samples from a standard LID corpus according to his/her historical language distribution. Besides,  we contribute the first user labeled LID test set called ""U-LID"". Experimental results reveal that our model can incarnate user traits and significantly outperforms existing LID systems on handling ambiguous texts. Our code and dataset are released at XXX.",/pdf/9497516bbfab7c39e23fdc0a386bd43dd29d4eaf.pdf,/attachment/7c47f1ada9915bebed8022523ce29ba3f5a86d93.zip,,,,anonymous|unsupervised_preferenceaware_language_identification,,,,,,/attachment/9b9a9dd5649be3ba27821ab31c60249fdbcd8cac.zip,/attachment/c35ba7f6414008c057915f75774b06e04799cde5.pdf,,/attachment/54b4bf97f9e04f70dc4f361331a6ae5570521401.pdf
967,zd1Rjg880vp,Perturbations in the Wild: Leveraging Human-Written Text Perturbations for Realistic Adversarial Attack and Defense,['aclweb.org/ACL/ARR/2021/November/Paper1408/Authors'],['Anonymous'],"We proposes a novel algorithm, ANTHRO,  that inductively extracts over 600K human-written text perturbations in the wild and leverages them for realistic adversarial attack. Unlike existing character-based attacks which often deductively hypothesize a set of manipulation strategies, our work is grounded on actual observations from real-world texts. We find that adversarial texts generated by ANTHRO achieve the best trade-off between (1) attack success rate, (2) semantic preservation of the original text, and (3) stealthiness--i.e. indistinguishable from human writings hence harder to be flagged as suspicious. Specifically, our attacks accomplished around 83% and 91% attack success rates on BERT and RoBERTa, respectively. Moreover, it outperformed the TextBugger baseline with an increase of 50% and 40% in terms of semantic preservation and stealthiness when evaluated by both layperson and professional human workers. ANTHRO can further enhance a BERT classifier's performance in understanding different variations of human-written toxic texts via adversarial training when compared to the Perspective API. All source code will be released.",/pdf/af463f5d5f90dc469e2795c3207c259e5f1869e4.pdf,,,,,anonymous|perturbations_in_the_wild_leveraging_humanwritten_text_perturbations_for_realistic_adversarial_attack_and_defense,,,,,,,,,
968,nB4zLyclbom,"When classifying grammatical role, BERT doesn't care about word order... except when it matters",['aclweb.org/ACL/ARR/2021/November/Paper144/Authors'],['Anonymous'],"Because meaning can often be inferred from lexical semantics alone, word order is often a redundant cue in natural language. For example, the words cut, chef, and onion are more likely used to convey ""The chef cut the onion,"" not ""The onion cut the chef."" Recent work has shown large language models to be surprisingly word order invariant, but crucially has largely considered natural prototypical inputs, where compositional meaning mostly matches lexical expectations. To overcome this confound, we probe grammatical role representation in BERT and GPT-2 on non-prototypical instances. Such instances are naturally occurring sentences with inanimate subjects or animate objects, or sentences where we systematically swap the arguments to make sentences like ""The onion cut the chef"".  We find that, while early layer embeddings are largely lexical, word order is in fact crucial in defining the later-layer representations of words in semantically non-prototypical positions. Our experiments isolate the effect of word order on the contextualization process, and highlight how models use context in the uncommon, but critical, instances where it matters. ",/pdf/a4706ba88f856a5dd3fd4f4e117febc5a1263231.pdf,/attachment/554b36510e4a807a49e49ddd6a5c29174c5ed6a3.tgz,,,,anonymous|when_classifying_grammatical_role_bert_doesnt_care_about_word_order_except_when_it_matters,,,,,,/attachment/2329dddf5a7008562d523da8c78eac19252650ba.tgz,,,
969,IUhTMc9C0Yo,Improving Robustness of Language Models from a Geometry-aware Perspective,['aclweb.org/ACL/ARR/2021/November/Paper497/Authors'],['Anonymous'],"Recent studies have found that removing the norm-bounded projection and increasing search steps in adversarial training can significantly improve robustness. However, we observe that a too large number of search steps can hurt accuracy. We aim to obtain strong robustness efficiently using fewer steps. Through a toy experiment, we find that perturbing the clean data to the decision boundary but not crossing it does not degrade the test accuracy. Inspired by this, we propose friendly adversarial data augmentation (FADA) to generate ``friendly'' adversarial data. On top of FADA, we propose geometry-aware adversarial training (GAT) to perform adversarial training (e.g., FGM) on friendly adversarial data so that we can save a large number of search steps. Comprehensive experiments across two widely used datasets and three pre-trained language models demonstrate that GAT can obtain stronger robustness via less steps. In addition, we provide extensive empirical results and in-depth analyses on robustness to facilitate future studies.",/pdf/735556f457b5555c1515e8eb0f893fa53ff44f05.pdf,/attachment/324549095ade36b059f757cecd1b4e883c8c8c0c.zip,,,,anonymous|improving_robustness_of_language_models_from_a_geometryaware_perspective,,,,,,,,,
970,5I681a6DoND,Addressing Resource and Privacy Constraints in Semantic Parsing Through Data Augmentation,['aclweb.org/ACL/ARR/2021/November/Paper1535/Authors'],['Anonymous'],"We introduce a novel setup for low-resource task-oriented semantic parsing which incorporates several constraints that may arise in real-world scenarios: (1) lack of similar datasets/models from a related domain, (2) inability to sample useful logical forms directly from a grammar, and (3) privacy requirements for unlabeled natural utterances. Our goal is to improve a low-resource semantic parser using utterances collected through user interactions. In this highly challenging but realistic setting, we investigate data augmentation approaches involving generating a set of structured canonical utterances corresponding to logical forms, before simulating corresponding natural language and filtering the resulting pairs. We find that such approaches are effective despite our restrictive setup: in a low-resource setting on the complex SMCalFlow calendaring dataset (Andreas et al. 2020), we observe 33% relative improvement over a non-data-augmented baseline in top-1 match.",/pdf/5057a40c15e61e63f57d9eb20414f5b7ba8b1b0e.pdf,,,,,anonymous|addressing_resource_and_privacy_constraints_in_semantic_parsing_through_data_augmentation,,,,,,,,,
971,tXc_Wag6Pgy,Text Complexity And Linguistic Features: Is The Relationship Multilingual?,['aclweb.org/ACL/ARR/2021/November/Paper1996/Authors'],['Anonymous'],"Text complexity assessment is a challenging task requiring various linguistic aspects to be taken into consideration.  A large number of studies have been introduced in this field. Nevertheless, as the methods and corpora are quite diverse, it may be hard to draw general conclusions as to the effectiveness of linguistic information for evaluating text complexity due to the diversity of methods and corpora. Moreover, a cross-lingual impact of different features on various datasets has not been investigated.  We experimentally assessed seven commonly used feature types on six corpora for text complexity employing four common machine learning models. We showed which feature types can significantly improve the performance and analyzed their impact according to the dataset characteristics, language, and origin.",/pdf/a6e855c0f5c70cd365817151b61c4c2ff882f784.pdf,,,,,anonymous|text_complexity_and_linguistic_features_is_the_relationship_multilingual,,,,,,,,,
972,IezTlW7ERIm,Augmenting Memory Networks for Rich and Efficient Retrieval in Grounded Dialogue,['aclweb.org/ACL/ARR/2021/November/Paper1470/Authors'],['Anonymous'],"Grounded dialogue consists of conditioning a conversation on additional latent inputs (""factoids"") beyond the dialogue context, such as Wikipedia articles, IMDB reviews, persona, and images.  Due to a scarcity of <context, factoid> labels, it is common practice to jointly learn the knowledge-selection and grounded response generation tasks end-to-end. When conditioning the response on these factoids, previous work has either treated the factoids as a weighed average vector, or separately computed probabilities for each <context, factoid> pair. However, the former creates a bottleneck whilst the latter prevents factoids from being considered jointly. Our new method, PolyMemNet, learns a matrix representation of the context and factoids, allowing for multiple factoids to be jointly considered in response selection, without imposing a bottleneck. We show how this achieves up to a $17\%$ boost in knowledge-selection accuracy and $13\%$ in response-selection accuracy versus memory networks. ",/pdf/aa31e00144ce7b64085c798326984b29723b9fa9.pdf,,,,,anonymous|augmenting_memory_networks_for_rich_and_efficient_retrieval_in_grounded_dialogue,,,,,,,,,
973,SshQlYuME_,A Neural Approach to KGQA via SPARQL Silhouette Generation,['aclweb.org/ACL/ARR/2021/November/Paper496/Authors'],['Anonymous'],"Semantic  parsing  is  a  predominant  approach  to  solve  the Knowledge Graph Question Answering (KGQA) task where, natural language question is translated into a logic form such as  SPARQL.  Semantic  parsing  based  solutions  are  mostly modular/pipelined where, noise introduced by the upstream modules  for  entity/relation  linking  makes  it  hard  to  solve the  complex  questions.  Recently,  Neural  Machine  Translation (NMT) based  approaches have emerged  that are capable of handling complex questions. However, NMT-based approaches struggle with handling the large number of test entities and relations that are unseen during training. In this work,we propose a modular two-stage neural approach which combines best of both the worlds - NMT and semantic parsing pipeline. Stage-I of our approach comprises an NMT-based seq2seq module that translates a question into a sketch of the desired  SPARQL,  called  as SPARQL silhouette.  This  stage also contains a noise simulator which combines the masking scheme  with  an  entity/relation  linker  in  a  novel  manner  so as to take care of unseen entities/relation without blowing up the vocabulary of seq2seq module.
Stage-II of our approach comprises a Neural Graph Search (NGS) module which aims to distil the SPARQL silhouette in order to reduce the entity/relation linking noise.  
Experimental results show that, the quality of generated SPARQL silhouette is impressive for an ideal scenario where entity/relation linker is noise-free. For the realistic scenario (i.e. noisy linker), the quality of the SPARQL silhouette drops but  our NGS module recovers it considerably. We show that, our proposed approach improves state-of-the-art on LC-QuAD-1 dataset by an absolute margin of $3.72 \%$ $F_1$.",/pdf/2aeae185048eb88ef0600366746cf7cc34d520e5.pdf,,,,,anonymous|a_neural_approach_to_kgqa_via_sparql_silhouette_generation,,,,,,,,,
974,KWL_ElhUejN,Contextual Representation Learning beyond Masked Language Modeling,['aclweb.org/ACL/ARR/2021/November/Paper2789/Authors'],['Anonymous'],"Currently, masked language modeling (e.g., BERT) is the prime choice to learn contextualized representations. Due to the pervasiveness, it naturally raises an interesting question: how do masked language models (MLMs) learn contextual representations?  In this work, we analyze the learning dynamics of MLMs and find that it adopts sampled embeddings as anchors to estimate and inject contextual semantics to representations, which limits the efficiency and effectiveness of MLMs. To address these problems, we propose TACO, a simple yet effective representation learning approach to directly model global semantics. To be specific, TACO extracts and aligns contextual semantics hidden in contextualized representations to encourage models to attend global semantics when generating contextualized representations. Experiments on the GLUE benchmark show that TACO achieves up to 5x speedup and up to 1.2 points average improvement over MLM.",/pdf/e4eca52bc6d5e46de93cfa8fc6b7f0c29827ae68.pdf,,,,,anonymous|contextual_representation_learning_beyond_masked_language_modeling,,,,,,,,,
975,shZUViLG-DS,How do we answer complex questions: Discourse structure of long form answers,['aclweb.org/ACL/ARR/2021/November/Paper1832/Authors'],['Anonymous'],"Long form answers, consisting of multiple sentences, can provide nuanced and comprehensive answers to a broader set of questions. However, little prior work exists on this task. To better understand this complex task, we study the functional structure of long form answers on two datasets, Natural Questions~\cite{kwiatkowski2019natural} and ELI5~\cite{Fan2019ELI5LF}. Our main goal is to understand how humans organize information to craft complex answers. We develop an ontology of sentence-level functional roles for long form answers, and annotate 3.3k sentences in 542 examples. Our annotated data enables training a reliable role classifier that can be used for automatic analysis and thus reveals machine generated answers are structured worse than human written answers. Our data further yields an extractive summarization dataset for long form answers, giving models the ability to identify a concise answer to a complex query. ",/pdf/5b48a28f69436cefc59a03ef0e6f320527612e24.pdf,,,,,anonymous|how_do_we_answer_complex_questions_discourse_structure_of_long_form_answers,,,,,,/attachment/346f4808710c8395d4668f8371b01415391d9043.zip,,,
976,vTP4UpRnlDh,Heterogeneous-Graph Reasoning and Fine-Grained Aggregation for Fact Checking,['aclweb.org/ACL/ARR/2021/November/Paper341/Authors'],['Anonymous'],"Fact checking is a challenging task that requires corresponding evidences to verify the property of a claim based on reasoning. Previous studies generally i) construct the graph by treating each evidence-claim pair as node which is a simple way that ignores to exploit their implicit interaction, or building a fully-connected graph among claim and evidences where the entailment relationship between claim and evidence would be considered equally to the semantic relationship among evidences; ii) aggregate evidences equally without considering their different stances towards the verification of fact. Towards the above issues, we propose a novel heterogeneous-graph reasoning and fine-grained aggregation model, with two following modules: 1) a heterogeneous graph attention network module to distinguish different types of relationships within the constructed graph; 2) fine-grained aggregation module which learns the implicit stance of evidences towards the prediction result in details. Extensive experiments on the benchmark dataset demonstrate that our proposed model achieves much better performance than state-of-the-art methods.",/pdf/5ff4882bef10634b1d375763e4068bcfdb4cf173.pdf,,,,,anonymous|heterogeneousgraph_reasoning_and_finegrained_aggregation_for_fact_checking,,,,,,,,,
977,LJPfn2jgIrW,Divide and Denoise: Learning from Noisy Labels in Fine-grained Entity Typing with Cluster-wise Loss Correction,['aclweb.org/ACL/ARR/2021/November/Paper1782/Authors'],['Anonymous'],"Fine-grained Entity Typing(FET) has witnessed great progress since distant supervision was introduced, but still suffers from label noise. Existing noise control methods applied to FET rely on predicted distribution and deals instances isolately, thus suffers from confirmation bias. In this work, We propose to tackle the two limitations with a cluster based loss correction framework named Feature Cluster Loss Correction(FCLC). FCLC first train a coarse backbone model as feature extractor and noise estimator. Then perform loss correction on each cluster to learn directly from noisy labels. Experimental results on three public datasets show FCLC achieves the best performance over existing competitive systems. Auxiliary experiments further show FCLC is stable to hyper-paramerters and even works with extream scneriaos like no clean data is available.",/pdf/eb55d2c74de127fe1e085ee8695b7271acb0cdfb.pdf,,,,,anonymous|divide_and_denoise_learning_from_noisy_labels_in_finegrained_entity_typing_with_clusterwise_loss_correction,,,,,,,,,
978,1odAyNZsQ3M,DAWSON: Data Augmentation using Weak Supervision On Natural Language,['aclweb.org/ACL/ARR/2021/November/Paper614/Authors'],['Anonymous'],"We propose a novel data augmentation model for text, using all available data through weak supervision. To improve generalization, recent work in the field uses BERT and masked language modeling to conditionally augment data. These models all involve a small, high-quality labeled dataset, but omit the abundance of unlabeled data, which is likely to be present if one considers a model in the first place. Weak supervision methods, such as Snorkel, make use of the vastness of unlabeled data, but largely omit the available ground truth labels. We combine data augmentation and weak supervision techniques into a holistic method, consisting of 4 training phases and 2 inference phases, to efficiently train an end-to-end model when only a small amount of annotated data is available. We outperform the benchmark (Kumar et al.,2020) for the SST-2 task by 1.5, QQP task by 4.4, and QNLI task by 3.0 absolute accuracy points, and show that data augmentation is also effective for natural language understanding tasks, such as QQP and QNLI.",/pdf/edb60d7aed0f2c54cde86bbc286283869b0aef2d.pdf,/attachment/04985dddae6d089207869c12e09fb87e53f9544a.zip,,,,anonymous|dawson_data_augmentation_using_weak_supervision_on_natural_language,,,,,,/attachment/fe2ae41adcb7b8c30d2aa3d40c8c78a1a2b17dbc.zip,,,
979,-MkjWCca_zN,Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings,['aclweb.org/ACL/ARR/2021/November/Paper1156/Authors'],['Anonymous'],"Learning scientific document representations can be substantially improved through contrastive learning objectives, where the challenge lies in creating positive and negative training samples that encode the desired similarity semantics. Prior work relies on discrete citation relations to generate contrast samples. However, discrete citations enforce a hard cut-off to similarity. This is counter-intuitive to similarity-based learning, and ignores that scientific papers can be very similar despite lacking a direct citation - a core problem of finding related research. Instead, we use controlled nearest neighbor sampling over citation graph embeddings for contrastive learning. This control allows us to learn continuous similarity, to sample hard-to-learn negatives and positives, and also to avoid collisions between negative and positive samples by controlling the sampling margin between them. The resulting method SciNCL outperforms the state-of-the-art on the SciDocs benchmark. Furthermore, we demonstrate that it can train (or tune) models sample-efficiently, which improves compute efficiency, and that it can be combined with recent training-efficient methods. Perhaps surprisingly, even training a general-domain language model this way outperforms baselines pretrained in-domain.",/pdf/7e9fd6388e9f7515151217728f04d5f3ccc1ca5a.pdf,/attachment/540c1080312d149f87ce4b3076503581f84f2a17.zip,,,,anonymous|neighborhood_contrastive_learning_for_scientific_document_representations_with_citation_embeddings,,,,,,,,,
980,ymuJX_0bepq,Disentangled Sequence to Sequence Learning for Compositional Generalization,['aclweb.org/ACL/ARR/2021/November/Paper149/Authors'],['Anonymous'],"There is mounting evidence that existing neural network models, in particular the very popular sequence-to-sequence architecture, struggle to systematically generalize to unseen compositions of seen components.  We demonstrate that one of the reasons hindering compositional generalization relates to representations being entangled. We propose an extension to sequence-to-sequence models which encourage disentanglement by adaptively re-encoding (at each time step) the source input. Specifically, we condition the source representations on the newly decoded target context which makes it easier for the encoder to exploit specialized information for each prediction rather than capturing it all in a single forward pass. Experimental results on semantic parsing and machine translation empirically show that our proposal delivers more disentangled representations and better generalization.
   ",/pdf/1d7d70d1b5a9116e384e6371a549bb16d9cc5e16.pdf,,,,,anonymous|disentangled_sequence_to_sequence_learning_for_compositional_generalization,,,,,,,,,
981,faqlc3D5TV6,Multilingual Document-Level Translation Enables Zero-Shot Transfer From Sentences to Documents,['aclweb.org/ACL/ARR/2021/November/Paper951/Authors'],['Anonymous'],"Document-level neural machine translation (DocNMT) achieves coherent translations by incorporating cross-sentence context. However, for most language pairs there's a shortage of parallel documents, although parallel sentences are readily available. In this paper, we study whether and how contextual modeling in DocNMT is transferable via multilingual modeling. We focus on the scenario of zero-shot transfer from teacher languages with document level data to student languages with no documents but sentence level data, and for the first time treat document-level translation as a transfer learning problem. Using simple concatenation-based DocNMT, we explore the effect of 3 factors on the transfer: the number of teacher languages with document level data, the balance between document and sentence level data at training, and the data type of  document level data (genuine vs. back-translated). Our experiments on Europarl-7 and IWSLT-10 show the feasibility of multilingual transfer for DocNMT, particularly on document-specific metrics. We observe that more teacher languages and adequate data schedule both contribute to better transfer quality. Surprisingly, the transfer is less sensitive to the data type, where multilingual DocNMT delivers decent performance with either back-translated or genuine document pairs.",/pdf/75df4b4557eb41b9c83e5356a56cf3e37dc0e1be.pdf,,,,,anonymous|multilingual_documentlevel_translation_enables_zeroshot_transfer_from_sentences_to_documents,,,,,,,,,
982,wu3ADZaresn,Improving Document-level Relation Extraction via Context Guided Mention Integration and Inter-pair Reasoning,['aclweb.org/ACL/ARR/2021/November/Paper2555/Authors'],['Anonymous'],"Document-level Relation Extraction (DRE) aims to recognize the relations between two entities.
The entity may correspond to multiple mentions that span beyond sentence boundary.
Few previous studies have investigated the mention integration, which may be problematic because coreferential mentions do not equally contribute to a specific relation.
Moreover, prior efforts mainly focus on reasoning at entity-level rather than capturing the global interactions between entity pairs.
In this paper, we propose two novel techniques, Context Guided Mention Integration and Inter-pair Reasoning (CGM2IR), to improve the DRE.
Instead of simply applying average pooling, the contexts are utilized to guide the integration of coreferential mentions in a weighted sum manner.
Additionally, inter-pair reasoning executes an iterative algorithm on the entity pair graph, so as to model the interdependency of relations.
We evaluate our CGM2IR model on three widely used benchmark datasets, namely DocRED, CDR, and GDA. 
Experimental results show that our model outperforms previous state-of-the-art models.",/pdf/4008f01f0902084629601607bf6f1a724c811976.pdf,,,,,anonymous|improving_documentlevel_relation_extraction_via_context_guided_mention_integration_and_interpair_reasoning,,,,,,,,,
983,LXyqAJIHBIU,Integrating Vectorized Lexical Constraints for Neural Machine Translation,['aclweb.org/ACL/ARR/2021/November/Paper2533/Authors'],['Anonymous'],"Lexically constrained neural machine translation (NMT), which controls the generation of NMT models with pre-specified constraints, is important in many practical scenarios. Due to the representation gap between discrete constraints and continuous vectors of NMT models, most existing works propose to construct synthetic data or modify the decoding algorithm to impose lexical constraints, treating the NMT model as a black box. In this work, we directly integrate the constraints into NMT models through vectorizing discrete constraints into continuous keys and values that can be utilized by the attention modules of NMT models. The proposed integration method is based on the assumption that the correspondence between the keys and values in attention modules is naturally suitable for modeling constraint pairs. Experimental results show that our method consistently outperforms several representative baselines on four language pairs, demonstrating the necessity of integrating vectorized lexical constraints.",/pdf/416aed8bce8d60478685585c14d4c62343b70b1a.pdf,,,,,anonymous|integrating_vectorized_lexical_constraints_for_neural_machine_translation,,,,,,,,,
