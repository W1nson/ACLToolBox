,title,authorids,authors,TL;DR,abstract,pdf,software,preprint,consent,paperhash,existing_preprints,reviewer/Editor_reassignment_request,reviewer/Editor_reassignment_justification,previous_URL,previous_PDF,response_PDF,data
t2UJIFZVyz4,Towards Better Characterization of Paraphrases,['aclweb.org/ACL/ARR/2021/September/Paper86/Authors'],['Anonymous'],,"To effectively characterize the nature of paraphrase pairs without expert human annotation, we proposes two new metrics: word position deviation (WPD) and lexical deviation (LD). WPD measures the degree of structural alteration, while LD measures the difference in vocabulary used. We apply these metrics to better understand the commonly-used MRPC dataset and study how it differs from PAWS, another paraphrase identification dataset. We also perform a detailed study on MRPC and propose improvements to the dataset, showing that it improves generalizability of models trained on the dataset. Lastly, we apply our metrics to filter the output of a paraphrase generation model and show how it can be used to generate specific forms of paraphrases for data augmentation or robustness testing of NLP models. ",/pdf/462b2617f79caae0c0755f85283fad2b74ec1980.pdf,/attachment/db1fe0a0f5be272a2b132148e407f37c9a9b7fbc.zip,,,anonymous|towards_better_characterization_of_paraphrases,,,,,,,
mdSv9jxpdBX,Multi-Narrative Semantic Intersection Task: Evaluation and Benchmark,['aclweb.org/ACL/ARR/2021/September/Paper252/Authors'],['Anonymous'],,"In this paper, we introduce an important yet relatively unexplored NLP task called Multi-Narrative Semantic Intersection (MNSI), which entails generating a Semantic Intersection of multiple alternate narratives. As no benchmark dataset is readily available for this task, we created one by crawling 2,925 alternative narrative pairs from the web and then, went through the tedious process of manually creating 411 different ground-truth semantic intersections by engaging human annotators. As a way to evaluate this novel task, we first conducted a systematic study by borrowing the popular ROUGE metric from text summarization literature and discovered that ROUGE is not suitable for our task. Subsequently, we conducted further human annotations/validations to create 200 document-level and 1,518 sentence-level ground-truth labels which helped us formulate a new precision-recall style evaluation metric, called SEM F1 (semantic F1), based on presence, partial presence and absence of information. Experimental results show that the proposed SEM F1 metric yields higher correlation with human judgement as well as higher inter-rater agreement compared to ROUGE metric and thus, we recommend the community to use this metric for evaluating future research on this topic.",/pdf/8778ba6223706a995a0075fc28eecec630fd285d.pdf,,,,anonymous|multinarrative_semantic_intersection_task_evaluation_and_benchmark,,,,https://openreview.net/forum?id=bQ8F-y8spuo#all,/attachment/d9496aae9d8a834cebc2fe51edf2ba0b3071748d.pdf,/attachment/494b309ae71185e5c8b585182049eca40c5fd040.pdf,/attachment/ff2793c3b336e8b47b23ed6b35c0c60d719cb909.zip
Ulgk67AQfeW,Constructing Multilingual CCG Treebanks from Universal Dependencies,['aclweb.org/ACL/ARR/2021/September/Paper253/Authors'],['Anonymous'],,"This paper introduces an algorithm to convert Universal Dependencies (UD) treebanks to Combinatory Categorial Grammar (CCG) treebanks. As CCG encodes almost all grammatical information into the lexicon, obtaining a high quality CCG derivation from a dependency tree is a challenging task. Our algorithm contains four main steps: binarization of dependency trees, functor/argument identification, category assignment through hand-crafted rules, and category inference for unassigned constituents. To evaluate our converted treebanks, we perform lexical, sentential, and syntactic rule coverage analysis, as well as CCG parsing experiments. We achieve over 80% conversion rate on 68 treebanks of 44 languages, and over 90% lexical coverage on 81 treebanks of 52 languages. ",/pdf/19dda116c8ab59fb162fe44ebfc00b777a5fa729.pdf,/attachment/d1ce7e24797521d5a5a7041e94be9167fc7195ca.zip,,,anonymous|constructing_multilingual_ccg_treebanks_from_universal_dependencies,,,,,,,
PK84NwrD_9q,Multilingual Generative Language Models for Zero-Shot Cross-Lingual Event Argument Extraction,['aclweb.org/ACL/ARR/2021/September/Paper183/Authors'],['Anonymous'],,"We present a pioneering study on leveraging multilingual pre-trained generative language models for zero-shot cross-lingual event argument extraction (EAE) by formulating EAE as a language generation task. Compared to previous classification-based EAE models that build classifiers on top of pre-trained masked language models, our generative model effectively encodes the event structures and better captures the dependencies between arguments. To achieve cross-lingual transfer, we design language-agnostic templates to encode argument roles and train our models on source languages to ""generate"" arguments in the source languages to fill in the language-agnostic template. The trained model can then be directly applied to target languages to ""generate"" arguments in the target languages to fill in the template. Our experimental results demonstrate that the proposed model outperforms the current state-of-the-art results on zero-shot cross-lingual EAE. Comprehensive ablation study and error analysis are presented to better understand the advantages and the current limitations of using multilingual generative language models for cross-lingual transfer.
",/pdf/bea51275514072e6786af3f496802885775ab171.pdf,,,,anonymous|multilingual_generative_language_models_for_zeroshot_crosslingual_event_argument_extraction,,,,,,,
BkNdZ6HoX6s,Denoising Large-Scale Image Captioning from Alt-text Data using Content Selection Models,['aclweb.org/ACL/ARR/2021/September/Paper148/Authors'],['Anonymous'],,"Training large-scale image captioning (IC) models demands access to a rich and diverse set of training examples that are expensive to curate both in terms of time and man-power. Instead, alt-text based captions gathered from the web is a far cheaper alternative to scale with the downside of being noisy. Recent modeling approaches to IC often fall short in terms of performance in leveraging these noisy datasets in favor of clean annotations. We address this problem by breaking down the task into two simpler, more controllable tasks -- skeleton prediction and skeleton-based caption generation. Specifically, we show that sub-selecting content words as skeletons helps in generating improved and denoised captions when leveraging rich yet noisy alt-text--based uncurated datasets. We also show that the predicted English skeletons can further cross-lingually be leveraged to generate non-English captions, and present experimental results covering caption generation in French, Italian, German, Spanish and Hindi. We also show that skeleton-based prediction allows for better control of certain caption properties, such as length, content, and gender expression, providing a handle to perform human-in-the-loop interpretable semi-automatic corrections.",/pdf/268f9545563e300957975901bf5588a5f07fae31.pdf,,,,anonymous|denoising_largescale_image_captioning_from_alttext_data_using_content_selection_models,,,,,,,
aOl-UPZeSwt,"Relevance in Dialogue: An empirical comparison of existing metrics, and a novel simple metric",['aclweb.org/ACL/ARR/2021/September/Paper29/Authors'],['Anonymous'],,"In this work, we evaluate various existing dialogue relevance metrics, find strong dependencies on the dataset, often with poor correlation with human scores of relevance, and propose modifications to reduce data requirements while improving correlation. With these changes, our metric achieves a new state-of-the-art on the HUMOD dataset (Merdivan et al., 2020). We achieve this without fine-tuning, using only 3750 unannotated human dialogues and a single negative example. Despite these limitations, we demonstrate competitive performance on three datasets from different domains. Our code including our metric and data processing is open sourced.",/pdf/06dee7a8cbdefab2dc3bb3359ff4d7660ae30edc.pdf,/attachment/810cb348f84e67eb9406c817c17a303e8eea6cc8.zip,,,anonymous|relevance_in_dialogue_an_empirical_comparison_of_existing_metrics_and_a_novel_simple_metric,,,,,,,
vsUr1EnqSGT,Attention Mechanism with Energy-Friendly Operations,['aclweb.org/ACL/ARR/2021/September/Paper305/Authors'],['Anonymous'],,"Attention mechanism has become the dominant module in natural language processing models. It is computationally intensive and depends on massive power-hungry multiplications. In this paper, we rethink variants of attention mechanism from the energy consumption aspects. After reaching the conclusion that the energy costs of several energy-friendly operations are far less than their multiplication counterparts, we build a novel attention model by completely replacing multiplications with either selective operations or additions. Empirical results on three machine translation tasks demonstrate that the proposed method, against the vanilla one, achieves comparable accuracy while only consumes a half of energy. Our code will be released upon the acceptance.",/pdf/4dc8e2bac2024e390d61b39cbbbc6ec1acf9536f.pdf,,,,anonymous|attention_mechanism_with_energyfriendly_operations,,,,,,,
Dk8w2SYFoaS,,,,,,,,,,,,,,,,,
lZTBTihUdlc,Widely Interpretable Semantic Representation: Frameless Meaning Representation for Broader Applicability,['aclweb.org/ACL/ARR/2021/September/Paper19/Authors'],['Anonymous'],,"This paper presents a semantic representation called WISeR that overcomes challenges for Abstract Meaning Representation (AMR). Despite its richness and exapandability, AMR is not easily applied to languages or domains without predefined semantic frames, and its use of numbered arguments results in semantic role labels which are not directly interpretable and are semantically overloaded for parsers. We examine the numbered arguments of predicates in AMR and convert them to thematic roles which do not require reference to semantic frames. We create a new corpus of 1K dialogue sentences annotated in both WISeR and AMR. WISeR shows stronger inter-annotator agreement for beginner and experienced annotators, with beginners becoming proficient in WISeR annotation sooner. Finally, we train two state-of-the-art parsers on the AMR 3.0 corpus and a WISeR corpus converted from AMR 3.0. The parsers are evaluated on these corpora and our dialogue corpus. WISeR models exhibit higher accuracy than their AMR counterparts across the board, demonstrating that WISeR is easier for parsers to learn.",/pdf/8e0ca799a73ed4fae18cd75d4f2e7898fd42c943.pdf,,,,anonymous|widely_interpretable_semantic_representation_frameless_meaning_representation_for_broader_applicability,,,,,,,/attachment/fcb7f1d81b69bca1f480272237f104f2c80ecff4.zip
h45YPjctju9,Top-Down Influence? Predicting CEO Personality and Risk Impact from Speech Transcripts,['aclweb.org/ACL/ARR/2021/September/Paper296/Authors'],['Anonymous'],,"How much does a CEO’s personality influence the performance of their company? Past literature has contested the possibility of predicting the Myers–Briggs Type Indicator (MBTI) from purely textual data. However, we use Transformers to create the first supervised model to regress the MBTI personality of CEOs. We show that moderate to strong predictions can be obtained for three out of four MBTI dimensions. Finally, providing empirical evidence for the upper echelons theory, we demonstrate that the predicted CEO personalities have explanatory power of financial risk.",/pdf/0a30162870fd61ad45107023bbb6e709ae2cbeb8.pdf,/attachment/b487ff01485a44cb0ecd2828a7bc8dd7e6e20290.zip,,,anonymous|topdown_influence_predicting_ceo_personality_and_risk_impact_from_speech_transcripts,,,,,,,/attachment/a9e3aece328159bf4ead441652a3061be49802d2.zip
eqRNs_CGR50,Hierarchical Recurrent Aggregative Generation for Few-Shot NLG,['aclweb.org/ACL/ARR/2021/September/Paper307/Authors'],['Anonymous'],,"Large pretrained models enable transfer learning to low-resource domains for language generation tasks. However, previous end-to-end approaches do not account for the fact that some generation sub-tasks, specifically aggregation and lexicalisation, can benefit from transfer learning in different extents. To exploit these varying potentials for transfer learning, we propose a new hierarchical approach for few-shot and zero-shot generation. Our approach consists of a three-moduled jointly trained architecture: the first module independently lexicalises the distinct units of information in the input as sentence sub-units (e.g. phrases), the second module recurrently aggregates these sub-units to generate a unified intermediate output, while the third module subsequently post-edits it to generate a coherent and fluent final text. We perform extensive empirical analysis and ablation studies on few-shot and zero-shot settings across 4 datasets. Automatic and human evaluation shows that the proposed hierarchical approach is consistently capable of achieving state-of-the-art results when compared to previous work.
",/pdf/7ad47465c8674e02cd04e1e6917d4ad4b8ecac3e.pdf,,,,anonymous|hierarchical_recurrent_aggregative_generation_for_fewshot_nlg,,,,,,,
Dgx157I8729,SeaD: End-to-end Text-to-SQL Generation with Schema-aware Denoising,['aclweb.org/ACL/ARR/2021/September/Paper185/Authors'],['Anonymous'],,"On the WikiSQL benchmark, most methods tackle the challenge of text-to-SQL with predefined sketch slots and build sophisticated sub-tasks to fill these slots. Though achieving promising results, these methods suffer from over-complex model structure. In this paper, we present a simple yet effective approach that enables auto-regressive sequence-to-sequence model to robust text-to-SQL generation. Instead of formulating the task of text-to-SQL as slot-filling, we propose to train sequence-to-sequence model with Schema-aware Denoising (SeaD), which consists of two denoising objectives that train model to either recover input or predict output from two novel erosion and shuffle noises. These model-agnostic denoising objectives act as the auxiliary tasks for structural data modeling during sequence-to-sequence generation. In addition, we propose a clause-sensitive execution guided (EG) decoding strategy to overcome the limitation of EG decoding for generative model. The experiments show that the proposed method improves the performance of sequence-to-sequence model in both schema linking and grammar correctness and establishes new state-of-the-art on WikiSQL benchmark. Our work indicates that the capacity of sequence-to-sequence model for text-to-SQL may have been under-estimated and could be enhanced by specialized denoising task.",/pdf/78bf68f6eeb5cec31af857a9f2bdd1aff154be1a.pdf,,,,anonymous|sead_endtoend_texttosql_generation_with_schemaaware_denoising,,,,,,,
qmpCC1qsJF_,Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification,['aclweb.org/ACL/ARR/2021/September/Paper67/Authors'],['Anonymous'],,"Tuning pre-trained language models (PLMs) with task-specific prompts has been a promising approach for text classification. Particularly, previous studies suggest that prompt-tuning has remarkable superiority in the low-data scenario over the generic fine-tuning methods with extra classifiers. The core idea of prompt-tuning is to insert text pieces, i.e., template, to the input and transform a classification problem into a masked language modeling problem, where a crucial step is to construct a projection, i.e., verbalizer, between a label space and a label word space. A verbalizer is usually handcrafted or searched by gradient descent, which may lack coverage and bring considerable bias and high variances to the results. In this work, we focus on incorporating external knowledge into the verbalizer, forming a knowledgeable prompt-tuning (KPT), to improve and stabilize prompt-tuning. Specifically, we expand the label word space of the verbalizer using external knowledge bases (KBs) and refine the expanded label word space with the PLM itself before predicting with the expanded label word space. Extensive experiments on zero and few-shot text classification tasks demonstrate the effectiveness of knowledgeable prompt-tuning.",/pdf/c7b85b6c1a9b94a5546c0dd296873d0981083572.pdf,,,,anonymous|knowledgeable_prompttuning_incorporating_knowledge_into_prompt_verbalizer_for_text_classification,,,,,,,
6HUkK1levbi,Headed-Span-Based Projective Dependency Parsing,['aclweb.org/ACL/ARR/2021/September/Paper230/Authors'],['Anonymous'],," We propose a new paradigm for projective dependency parsing based on headed spans. 
In a projective dependency tree, the subtree rooted at each word covers a contiguous sequence (i.e., a span) in the surface order. We call a span marked with a root word headed span. A projective dependency tree can be represented as a collection of headed spans. We decompose the score of a dependency tree into the scores of the headed spans and design a novel $O(n^3)$ dynamic programming algorithm to enable global training and exact inference. The advantages of our headed-span-based dependency parsing include that it captures subtree information more adequately than first-order graph-based methods and performs global optimization in decoding (in contrast to transition-based methods).  We evaluate our method on PTB, CTB, and UD and it achieves competitive results in comparison with previous methods.
",/pdf/b15c2ca9af285a46c255a49a4ee34d5999e388cc.pdf,,,,anonymous|headedspanbased_projective_dependency_parsing,,,,,,,
cEA-p49sP8x,The Past Mistake is the Future Wisdom: Error-driven Contrastive Probability Optimization for Chinese Spell Checking,['aclweb.org/ACL/ARR/2021/September/Paper90/Authors'],['Anonymous'],,"Chinese Spell Checking (CSC) aims to detect and correct Chinese spelling errors, which are mainly caused by phonologically or visually similarity. Recently, due to the development of various pre-trained language models (PLMs), many CSC methods have achieved great progress. However, PLMs will pay more attention to common characters because of the pre-training settings. Therefore, there exists a gap between the learned knowledge of PLMs and the essential of CSC task. To address this issue, we propose an Error-driven COntrastive Probability Optimization (ECOPO) framework to refine the knowledge representation of PLMs for CSC. Particularly, ECOPO guides the model to avoid predicting common but improper characters through an error-driven way. Besides, ECOPO is model-agnostic so that it can be easily combined with existing CSC methods to achieve better performance. Extensive experiments and detailed analysis on three standard benchmarks demonstrate that ECOPO is simple yet effective.",/pdf/b1788924d91a7a917553541c8283ecbb36cd12f6.pdf,/attachment/1ffeef4a6874bfd059965002374c4bcb560d2fff.zip,,,anonymous|the_past_mistake_is_the_future_wisdom_errordriven_contrastive_probability_optimization_for_chinese_spell_checking,,,,,,,/attachment/c075c77ae7e45b3c60a673121290284ebf542dfd.zip
cqlqdyDfypP,Synthetic Data Generation and Joint Learning for Robust Code-Mixed Translation,['aclweb.org/ACL/ARR/2021/September/Paper276/Authors'],['Anonymous'],,"The widespread online communication in a modern multilingual world has provided opportunities to blend more than one language (aka. code-mixed language) in a single utterance. This has resulted a formidable challenge for the computational models due to the scarcity of annotated data and presence of noise. A potential solution to mitigate the data scarcity problem in low-resource setup is to leverage existing data in resource-rich language through translation. In this paper, we tackle the problem of code-mixed (Hinglish and Bengalish) to English machine translation. First, we synthetically develop HINMIX, a parallel corpus of Hinglish to English,  with ~5M sentence pairs. Subsequently, we propose JAMT, a robust perturbation based joint-training model that learns to handle noise in the real-world code-mixed text by parameter sharing across clean and noisy words. Further, we show the adaptability of JAMT in a zero-shot setup for Bengalish to English translation. Our evaluation and comprehensive analyses qualitatively and quantitatively demonstrate the superiority of JAMT over state-of-the-art code-mixed and robust translation methods.",/pdf/948810e0951a8ada5361a975763e6af7174e3028.pdf,/attachment/459b1c597d0ffe0935b42808950bbc8810c50aeb.zip,,,anonymous|synthetic_data_generation_and_joint_learning_for_robust_codemixed_translation,,,,,/attachment/e37c090411fb2e1e5cf15058d378b6e6bba2f245.pdf,/attachment/285cf6af968dd0010c8ebaad074634b80eaa9412.pdf,
4mMBs-hCrKx,Combining (Second-Order) Graph-Based and Headed-Span-Based Projective Dependency Parsing,['aclweb.org/ACL/ARR/2021/September/Paper226/Authors'],['Anonymous'],,"Graph-based methods are popular in dependency parsing for decades, which decompose the score of a dependency tree into scores of dependency arcs. Recently, (Yang and Tu, 2021) propose a headed-span-based method that decomposes the score of a dependency tree into scores of headed spans. In this paper, we combine the two types of methods by considering both arc scores and headed-span scores, designing three scoring methods and the corresponding dynamic programming algorithms for joint inference. Experiments show the effectiveness of our proposed methods.
",/pdf/d6cdcc1d692e41e664d40e6bcd294569977fc36f.pdf,,,,anonymous|combining_secondorder_graphbased_and_headedspanbased_projective_dependency_parsing,,,,,,,
kLXFm320Xit,Hansel: A Chinese Few-Shot and Zero-Shot Entity Linking Benchmark,['aclweb.org/ACL/ARR/2021/September/Paper274/Authors'],['Anonymous'],,"Modern Entity Linking (EL) systems entrench a popularity bias. However, there is no dataset focusing on tail and emerging entities in languages other than English. We present Hansel, a new benchmark in Chinese that fills the vacancy of non-English few-shot and zero-shot EL challenges. Hansel is human annotated and reviewed, with a novel method for collecting zero-shot EL datasets. It is a diverse dataset covering 8.2K documents in news, social media posts and other web articles, with Wikidata as its target Knowledge Base. We demonstrate that existing state-of-the-art EL system performs poorly on Hansel (R@1 of 35.8% on Few-Shot). We then establish a strong baseline that scores a R@1 of 43.2% on Few-Shot and 76.6% on Zero-Shot on our dataset. We also show that our baseline achieves competitive results on TAC-KBP2015 Chinese Entity Linking task.",/pdf/8aec3cf449ba9b417a4398f67cba8cc70ee188a0.pdf,,,,anonymous|hansel_a_chinese_fewshot_and_zeroshot_entity_linking_benchmark,,,,,,,/attachment/d812333421394b21c0b1e794fe8adeafcd5c69aa.zip
owR_gqXt47k,,,,,,,,,,,,,,,,,
eRRLIv7DrOX,Improving Generalizability in Implicitly Abusive Language Detection with Concept Activation Vectors,['aclweb.org/ACL/ARR/2021/September/Paper158/Authors'],['Anonymous'],,"Robustness of machine learning models on ever-changing real-world data is critical, especially for applications affecting human well-being such as content moderation.  New kinds of abusive language continually emerge in online discussions in response to current events (e.g., COVID-19), and the deployed abuse detection systems should be updated regularly to remain accurate. General abusive language classifiers tend to be fairly reliable in detecting out-of-domain explicitly abusive utterances but often fail to detect new types of more subtle, implicit abuse. We propose an interpretability technique, based on the Testing Concept Activation Vector (TCAV) method from computer vision, to quantify the sensitivity of a trained model to the human-defined concepts of explicit and implicit abusive language, and use that to explain the generalizability of the model on new data, in this case, COVID-related anti-Asian hate speech. Extending this technique, we introduce a novel metric, Degree of Explicitness, for a single instance and show that the new metric is beneficial in suggesting out-of-domain unlabeled examples to effectively enrich the training data with informative, implicitly abusive texts. ",/pdf/e88e2c41f320d9ae321d62e5c5b81f9352e16ff0.pdf,/attachment/5da1f236a6bd1441bd53df81e8a52c992491d883.zip,,,anonymous|improving_generalizability_in_implicitly_abusive_language_detection_with_concept_activation_vectors,,,,,,,/attachment/39b342a19c4fb6141f2cd86587647df68892a1ea.zip
Yw1AfyQrmUp,Digging Errors in NMT: Evaluating and Understanding Model Errors from Hypothesis Distribution,['aclweb.org/ACL/ARR/2021/September/Paper184/Authors'],['Anonymous'],,"Sound evaluation of a neural machine translation (NMT) model is key to its understanding and improvement. Current evaluation of an NMT system is usually built upon a heuristic decoding algorithm (e.g., beam search) and an evaluation metric assessing similarity between the translation and golden reference (e.g., BLEU). However, this system-level evaluation framework is prone to its evaluation over only one best hypothesis and search errors brought by heuristic decoding algorithms. To better understand NMT models, we propose a novel evaluation protocol, which defines model errors with hypothesis distribution. In particular, we first propose an exact top-$k$ decoding algorithm, which finds top-ranked hypotheses in the whole hypothesis space and avoids search errors. Then, we evaluate NMT model errors with the distance between hypothesis distribution with the ideal distribution, aiming for a comprehensive interpretation. We apply our evaluation on various NMT benchmarks and model architectures to provide an in-depth understanding of how NMT models work. We show that the state-of-the-art Transformer models are facing serious ranking errors and do not even outperform the random chance level. We further provide several interesting findings over data-augmentation techniques, dropouts, and deep/wide models. 
Additionally, we analyze beam search's lucky biases and regularization terms. Interestingly, we find these lucky biases decrease when increasing model capacity. ",/pdf/e802e5867c0e130f1400ff0152d24f6e005a6f12.pdf,,,,anonymous|digging_errors_in_nmt_evaluating_and_understanding_model_errors_from_hypothesis_distribution,,,,,,,
lJrJAPEZ4M0,,,,,,,,,,,,,,,,,
fImoryxnH0Z,GradMask: Gradient-Guided Token Masking for Textual Adversarial Example Detection,['aclweb.org/ACL/ARR/2021/September/Paper218/Authors'],['Anonymous'],,"We present a simple model-agnostic textual adversarial example detection scheme called GradMask. It uses gradient signals to detect adversarially perturbed tokens in an input sequence and occludes such tokens by a masking process. GradGask provides several advantages over existing methods including lower computational cost, improved detection performance, and a weak interpretation of its decision. Extensive evaluations on widely adopted natural language processing benchmark datasets demonstrate the efficiency and effectiveness of Gradmask.
",/pdf/b9008034054bd35df4c735612d379f95914ffb22.pdf,/attachment/6b206ad4163d10d11d2e4d73c3fb9b5d11e349b9.zip,,,anonymous|gradmask_gradientguided_token_masking_for_textual_adversarial_example_detection,,,,,,,
oIfSEEw8Xfu,DiS-ReX: A Multilingual Dataset for Distantly Supervised Relation Extraction,['aclweb.org/ACL/ARR/2021/September/Paper146/Authors'],['Anonymous'],,"Our goal is to study the novel task of distant supervision for multilingual relation extraction (Multi DS-RE). Research in Multi DS-RE has remained limited due to the absence of a reliable benchmarking dataset. The only available dataset for this task, RELX-Distant  (Köksal and Özgür, 2020), displays several unrealistic characteristics, leading to a systematic overestimation of model performance. To alleviate these concerns, we release a new benchmark dataset for the task, named DiS-ReX. We also modify the widely-used bag attention models using an mBERT encoder and provide the first baseline results on the proposed task. We show that DiS-ReX serves as a more challenging dataset than RELX-Distant, leaving ample room for future research in this domain.",/pdf/a3c1676a9d2cf80f6176a6fd0d4acdae2e996500.pdf,/attachment/32cd9fc6d36928c65fa7c072ac510d6c01e9795c.zip,,,anonymous|disrex_a_multilingual_dataset_for_distantly_supervised_relation_extraction,,,,,,,/attachment/28123885e8e2e10ccdf38705fa567016ee2c73a9.zip
uOklQslIXe8,Measuring Fairness of Text Classifiers via Prediction Sensitivity,['aclweb.org/ACL/ARR/2021/September/Paper205/Authors'],['Anonymous'],,"With the rapid growth in language processing applications, fairness has emerged as an important consideration in data-driven solutions.  Although various fairness definitions have been explored in the recent literature, there is lack of consensus on which metrics most accurately reflect the fairness of a system. 
       In this work, we propose a new formulation -- accumulated prediction sensitivity, which measures fairness in machine learning models based on the model's prediction sensitivity to perturbations in input features. The metric attempts to quantify the extent to which a single prediction depends on a protected attribute, where the protected attribute encodes the membership status of an individual in a protected group.  
       We show that the metric can be theoretically linked with a specific notion of group fairness (statistical parity) and individual fairness. It also correlates well with humans' perception of fairness. We conduct experiments on two text classification datasets -- Jigsaw Toxicity, and Bias in Bios, and evaluate the correlations between metrics and manual annotations on whether the model produced a fair outcome. We observe that the proposed fairness metric based on prediction sensitivity is statistically significantly more correlated with human annotation than the existing counterfactual fairness metric.",/pdf/7f8dada6d07e4c858dbc2469c25080bf441c7c08.pdf,,,,anonymous|measuring_fairness_of_text_classifiers_via_prediction_sensitivity,,,,,,,
F3lYBj1dpXX,Defending Textual Neural Networks against Black-Box Adversarial Attacks with Stochastic Multi-Expert Patcher,['aclweb.org/ACL/ARR/2021/September/Paper68/Authors'],['Anonymous'],,"Even though several methods have proposed to defend textual neural network (NN) models against black-box adversarial attacks, they often defend against a specific text perturbation strategy and/or require re-training the models from scratch. This leads to a lack of generalization in practice and redundant computation. In particular, the state-of-the-art transformer models (e.g., BERT, RoBERTa) require great time and computation resources. By borrowing an idea from software engineering, in order to address these limitations, we propose a novel algorithm, SHIELD, which modifies and re-trains only the last layer of a textual NN, and thus it ""patches"" and ""transforms"" the NN into a stochastic weighted ensemble of multi-expert prediction heads. Considering that most of current black-box attacks rely on iterative search mechanisms to optimize their adversarial perturbations, SHIELD confuses the attackers by automatically utilizing different weighted ensembles of predictors depending on the input. In other words, SHIELD breaks a fundamental assumption of the attack, which is a victim NN model remains constant during an attack. By conducting comprehensive experiments, we demonstrate that all of CNN, RNN, BERT, and RoBERTa-based textual NNs, once patched by SHIELD, exhibit a relative enhancement of 15%--70% in accuracy on average against 14 different black-box attacks, outperforming 6 defensive baselines across 3 public datasets. All codes are to be released. ",/pdf/8466740d137273f0541619528dc166d378c07b4f.pdf,,,,anonymous|defending_textual_neural_networks_against_blackbox_adversarial_attacks_with_stochastic_multiexpert_patcher,,,,,,,
0I_MQWeF5pE,Does BERT really agree ? Fine-grained Analysis of Lexical Dependence on a Syntactic Task,['aclweb.org/ACL/ARR/2021/September/Paper166/Authors'],['Anonymous'],,"Although transformer-based Neural Language Models obtain impressive results on a wide variety of tasks, their generalization abilities are not well understood. They have been shown to perform strongly on subject-verb number agreement in a wide array of settings, suggesting that they learned to capture syntactic dependencies during their training even without explicit supervision. In this paper, we examine the extent to which BERT relies on lexical content to solve the number agreement (NA) task. To do so, we disrupt the lexical patterns found in naturally occurring stimuli in a novel fine-grained analysis of BERT's behavior. Our results on nonce sentences suggest that the model generalizes well for simple structures, but fails to perform lexically-independent syntactic generalization when as little as one attractor is present.",/pdf/bd02ddb8fcb0d5d7dfc0fb4289a42c509f3979fe.pdf,,,,anonymous|does_bert_really_agree_finegrained_analysis_of_lexical_dependence_on_a_syntactic_task,,,,,,,
51c-7iGxPri,Commonsense Knowledge-Augmented Pretrained Language Models for Causal Reasoning Classification,['aclweb.org/ACL/ARR/2021/September/Paper167/Authors'],['Anonymous'],,"Commonsense knowledge can be leveraged for identifying causal relations in text. In this work, we convert triples in ATOMIC2020, a wide coverage commonsense reasoning knowledge graph, to natural language text and continually pretrain a BERT pretrained language model. We evaluate the resulting model on answering commonsense reasoning questions. Our results show that a continually pretrained language model augmented with commonsense reasoning knowledge outperforms our baseline on two commonsense causal reasoning benchmarks, COPA and BCOPA-CE, without additional improvement on the base model or using quality-enhanced data for fine-tuning.",/pdf/d9cfe05d04df815543f091c9bd3e060fbc67b1e2.pdf,/attachment/6ce6f89fda7391a7d5d6f9f5d3ca9f41b359a6a0.zip,,,anonymous|commonsense_knowledgeaugmented_pretrained_language_models_for_causal_reasoning_classification,,,,,,,
1y_41pnSIxC,Gender Roles from Word Embeddings in a Century of Children’s Books,['aclweb.org/ACL/ARR/2021/September/Paper25/Authors'],['Anonymous'],,"When presenting content to children, educators and parents not only want to know whether characters of different backgrounds are represented; they also want to understand how these characters are depicted. In this paper, we measure the gender portrayal of central domains of social life as depicted in highly influential children's books using word co-occurrence and word embeddings. We find that females are more likely than males to be associated with words related both to family and appearance, while males are more associated with business-related words. The gender associations with appearance and business have endured over time, whereas family word associations have become more gender-neutral. We make two main contributions: one, we create a word embeddings data set, StoryWords 1.0, of 100 years of award-winning children's literature, and two, we show inequality in the portrayal of gender in this literature, which in turn may convey messages to children about differential roles in society. We include our code and models as supplemental data associated with this manuscript.",/pdf/413359d416d97e1a1647a753e13e8b805c95c4e7.pdf,/attachment/8486e20663804f5410fd8231d4a6586cc8b6d3aa.zip,,,anonymous|gender_roles_from_word_embeddings_in_a_century_of_childrens_books,,,,,,,/attachment/fa539ae0ead2be46a42eaedb13ed17d457bd0019.zip
32tW2OOxJ5D,A Meta-framework for Spatiotemporal Quantity Extraction from Text,['aclweb.org/ACL/ARR/2021/September/Paper175/Authors'],['Anonymous'],,"News events are often associated with quantities (e.g., the number of COVID-19 patients or the number of arrests in a protest), and it is often important to extract their type, time, and location from unstructured text in order to analyze these quantity events. This paper thus formulates the NLP problem of spatiotemporal quantity extraction, and proposes the first meta-framework for solving it. This meta-framework contains a formalism that decomposes the problem into several information extraction tasks, a shareable crowdsourcing pipeline, and transformer-based baseline models. We demonstrate the meta-framework in three domains---the COVID-19 pandemic, Black Lives Matter protests, and 2020 California wildfires---to show that the formalism is general and extensible, the crowdsourcing pipeline facilitates fast and high-quality data annotation, and the baseline system can handle spatiotemporal quantity extraction well enough to be practically useful. All resources of this paper will be released for future research on this topic.",/pdf/8d006169e530d98a0f4d5d8c6465874cb0ae93a7.pdf,,,,anonymous|a_metaframework_for_spatiotemporal_quantity_extraction_from_text,,,,,,,
Drjb0jGXtGe,Supervised Relation Classification as Two-way Span-Prediction,['aclweb.org/ACL/ARR/2021/September/Paper268/Authors'],['Anonymous'],,"Most of the current supervised relation classification (RC) algorithms use a single embedding to represent the relation between a pair of entities. We argue that a better approach is to treat the RC task as a Span-Prediction (SP) problem, similar to Question Answering (QA). We present an SP-based system for RC and evaluate its performance compared to the embedding-based system. We demonstrate that by adding a few improvements, the supervised SP objective works significantly better than the standard classification-based objective. We achieve state-of-the-art results on the TACRED, SemEval task 8, and the CRE datasets.",/pdf/c6d43a164f310157e4c22dbc77d5546dbed6ea7d.pdf,,,,anonymous|supervised_relation_classification_as_twoway_spanprediction,,,,,,,
OmJpjgRuSeI,Modeling Future for Neural Machine Translation by Fusing Target Information,['aclweb.org/ACL/ARR/2021/September/Paper194/Authors'],['Anonymous'],,"Sequence-to-sequence Neural Machine Translation (NMT) models have achieved excellent performance. However, the NMT decoder only makes predictions based on the source and the target historical context, ignores the target future information completely, leading to a problem that NMT does not consider potential future information when making decisions. To alleviate this problem, we propose a simple and effective {\bf Fu}ture-fused {\bf NMT} model called \textsc{FuNMT}, which introduces a reverse decoder to explicitly model the target future information, then adopts an agreement mechanism to enable the forward decoder to learn this future information. Empirical studies on multiple benchmarks show that our proposed model significantly improves translation quality.",/pdf/6dd179354590940d55f78ddb01a4e45c365c5354.pdf,/attachment/6389a8780c255447cec6f3845eb6ad2450b8b9b2.zip,,,anonymous|modeling_future_for_neural_machine_translation_by_fusing_target_information,,,,,,,
41SZu4IPi6N,Investigating Logic Tensor Networks for Neural-Symbolic Argument Mining,['aclweb.org/ACL/ARR/2021/September/Paper56/Authors'],['Anonymous'],,"We present an application of neural-symbolic learning to argument mining.
We use Logic Tensor Networks to train neural models to jointly fit the data and satisfy specific domain rules.
Our experiments on a corpus of scientific abstracts indicate that including symbolic rules during the training process improves classification performance, compliance with the rules, and robustness of the results.",/pdf/6f149d88b1f529b6b08eb8cda8573a89e20aa85a.pdf,/attachment/70063085f36ed74df8d787db7f31cbade2a36be5.zip,,,anonymous|investigating_logic_tensor_networks_for_neuralsymbolic_argument_mining,,,,,,,/attachment/83e321a9ece5eb29a10786eaafab9efe1c7e0f58.zip
5S-L8drL0h7,Making Transformers Solve Compositional Tasks,['aclweb.org/ACL/ARR/2021/September/Paper74/Authors'],['Anonymous'],,"Several studies have reported the inability of Transformer models to generalize compositionally, a key type of generalization in many NLP tasks such as semantic parsing. In this paper we explore the design space of Transformer models showing that the inductive biases given to the model by several design decisions significantly impact compositional generalization. We identified Transformer configurations that generalize compositionally significantly better than previously reported in the literature in a diverse set of compositional tasks, and that achieve state-of-the-art results in a semantic parsing compositional generalization benchmark (COGS), and a string edit operation composition benchmark (PCFG).",/pdf/cd7a3c94eb96af341cce098e306fb6d98691e963.pdf,/attachment/f67dc8891e65a0cf3a321e3fa5c1fbf8876ecaf5.zip,,,anonymous|making_transformers_solve_compositional_tasks,,,,,,,
kJob69ydIj-,What Makes Reading Comprehension Questions Difficult? Investigating Variation in Passage Sources and Question Types,['aclweb.org/ACL/ARR/2021/September/Paper272/Authors'],['Anonymous'],,"In order for a natural language understanding benchmark to be useful in research, it has to consist of examples that are diverse and difficult enough to discriminate among current and near-future state-of-the-art systems. However, we do not yet know what kinds of passages and their sources help us collect a variety of challenging examples. In this study, we crowdsource multiple-choice reading comprehension questions for passages taken from seven qualitatively distinct sources, analyzing what attributes of passages contribute to the difficulty and question types of the collected examples. We find that passage source, length, and readability measures do not significantly affect question difficulty. Among seven question types we manually annotate, questions that require numerical reasoning and logical reasoning are relatively difficult but their frequencies depend on the passage sources. These results suggest that when creating a new benchmark dataset, we do not have to use difficult passages but select passage sources carefully so that it has questions that involve linguistic phenomena we are interested in.",/pdf/1b27f67084f13aef79f9d5d7606fed1dc2c77023.pdf,,,,anonymous|what_makes_reading_comprehension_questions_difficult_investigating_variation_in_passage_sources_and_question_types,,,,,,,
DQkcgrmTmbo,,,,,,,,,,,,,,,,,
dTnMpK6jHiv,Measuring Factual Consistency of Abstractive Summaries,['aclweb.org/ACL/ARR/2021/September/Paper44/Authors'],['Anonymous'],,"Recent abstractive summarization systems fail to generate factual consistent -- faithful -- summaries, which heavily limits their practical application. 
Commonly, these models tend to mix concepts from the source or hallucinate new content, completely ignoring the source.
Addressing the faithfulness problem is perhaps the most critical challenge for current abstractive summarization systems.
First automatic faithfulness metrics were proposed, but we argue that existing methods do not yet utilize all ""machinery"" that this field has to offer and introduce new approaches to assess factual correctness.
We evaluate existing and our proposed methods by correlating them with human judgements and find that BERTScore works well.
Next, we conduct a data analysis, which reveals common problems, ways to further improve the metrics and indicates that combining multiple metrics is promising. 
Finally, we exploit faithfulness metrics in pre- and post-processing steps to decrease factual errors made by state-of-the-art summarization systems.
We find that simple techniques like filtering training data and re-ranking generated summaries can increase the faithfulness by a substantial margin.",/pdf/8d3559ab469e0ab44a47f07eb150ecf2b0deb4dc.pdf,,,,anonymous|measuring_factual_consistency_of_abstractive_summaries,,,,,,,
Z0lw-ozMSEe,We need to talk about random seeds,['aclweb.org/ACL/ARR/2021/September/Paper70/Authors'],['Anonymous'],,"Modern neural network libraries all take as a hyperparameter a random seed, typically used to determine the initial state of the model parameters. In this position piece, I argue that there are some appropriate uses for random seeds: as part of the hyperparameter search to select a good model, creating an ensemble of several variants of a model, or measuring the sensitivity of the training algorithm to the random seed hyperparameter. I argue against some inappropriate uses for random seeds: using a fixed random seed for ""replicability"" and creating score distributions for performance comparison. I review 85 recent publications from the ACL Anthology and find that more than 50% are using random seeds inappropriately.",/pdf/c2502c836b4fed6477e37f53a75825666d82ad8b.pdf,,,,anonymous|we_need_to_talk_about_random_seeds,,,,,,,/attachment/015c953c8d8e4df4577ebdbb9b8e84e0ed3bac14.zip
aN3joeJh1LD,,,,,,,,,,,,,,,,,
1eix5Aen_54,Exploring the Effectiveness of Student Behavior in Prerequisite Relation Discovery for Concepts,['aclweb.org/ACL/ARR/2021/September/Paper227/Authors'],['Anonymous'],,"What knowledge should a student grasp before beginning a new MOOC course?  This question can be answered by discovering prerequisite relations of knowledge concepts.  In recent years, researchers have devoted intensive efforts to detecting such relations by analyzing various types of information. However, there are still a few explorations of utilizing student behaviors in this task. In this paper, we investigate the effectiveness of student behaviors in prerequisite relation discovery for course concepts. Specifically, we first construct a novel MOOC dataset to support the study. We then verify the effectiveness of student behaviors via serving as additional features for existing prerequisite relation discovery models. Moreover, we explore to better utilize student behaviors via graph-based modeling. We hope our study could call for more attention and efforts to explore the student behavior for prerequisite relation discovery.",/pdf/907b1da3adeda9c1626d4235089bf403d9776e6d.pdf,/attachment/36a5a7d38022a2cd1fa50a11dcd810c608d30184.zip,,,anonymous|exploring_the_effectiveness_of_student_behavior_in_prerequisite_relation_discovery_for_concepts,,,,,,,/attachment/c623c257d9d4a846bca6f9a0131a248b18751140.zip
wWAtD2N68cW,Comprehension of Subtitles from Re-Translating Simultaneous Speech Translation,['aclweb.org/ACL/ARR/2021/September/Paper24/Authors'],['Anonymous'],,"In simultaneous speech translation, one can vary the size of the output window,
system latency and sometimes the allowed level of rewriting. The effect of these
properties on readability and comprehensibility has not been tested with modern
neural translation systems.
In this work, we propose an evaluation method and investigate the effects on comprehension and user preferences. It is a pilot study with 14 users on 2 hours of German documentaries or speeches with online
translations into Czech. We collect continuous feedback and answers on factual
questions. Our results show that the subtitling layout or flicker have a little
effect on comprehension, in contrast to machine translation itself and
individual competence. Other results show that users with a limited knowledge of
the source language have different preferences to stability and latency than the
users with zero knowledge. The results are statistically insignificant, however, we show that our method works and can be reproduced in larger volume.",/pdf/d6d7ae51f565f17307ddf08c477bd5e37a265edc.pdf,,,,anonymous|comprehension_of_subtitles_from_retranslating_simultaneous_speech_translation,,,,,,,/attachment/830f4231240b02f907133cc35ec9c3cb8b20cc7b.zip
9FHQHJnRtfL,Remixers: A Mixer-Transformer Architecture with Compositional Operators for Natural Language Understanding,['aclweb.org/ACL/ARR/2021/September/Paper30/Authors'],['Anonymous'],,"Recent work such as MLP-Mixers (Tolstikhin et al.) have demonstrated the promise of All-MLP architectures. While All-MLP architectures have demonstrated reasonable performance in computer vision and garnered recent interest, we argue that making them effective in NLP applications is still an uphill battle. Hence, there may be no solid reason to drop the self-attention modules altogether. In this paper, we propose a new Mixer-Transformer architecture, showing that Transformers and Mixer models can be quite complementary indeed. Fundamentally, we show that Mixer models are capable of acting as persistent global memory (in a similar vein to standard MLPs) while being imbued with global receptive fields at the same time. Hence, interleaving sample-dependent and input-local self-attention with persistent Mixer modules can be an effective strategy. Additionally, we propose compositional remixing, a new way of baking compositional operators (multiplicative and subtractive composition) within the mixing process to improve the expressiveness of the model. This allows us to effectively model relationships between unmixed and mixed representations - an inductive bias that we postulate is powerful for NLU applications. Via extensive experiments on 14 challenging NLU datasets (e.g., SuperGLUE, entailment and compositional generalization), we show that the proposed architecture consistently outperforms a strong T5 baseline (Raffel et al.). We believe this work paves the way for more effective synergies between the two families of models.",/pdf/9e6d49be53e470ea56175b70694af4337bd3701f.pdf,,,,anonymous|remixers_a_mixertransformer_architecture_with_compositional_operators_for_natural_language_understanding,,,,,,,
OQBNP-eWeIO,CoDA21: Evaluating Language Understanding Capabilities of NLP Models With Context-Definition Alignment,['aclweb.org/ACL/ARR/2021/September/Paper63/Authors'],['Anonymous'],,"Pretrained language models (PLMs) have achieved superhuman performance on many benchmarks, creating a need for harder tasks. We introduce CoDA21 (Context Definition Alignment), a challenging benchmark that measures natural language understanding (NLU) capabilities of PLMs: Given a definition and a context each for k words, but not the words themselves, the task is to align the k definitions with the k contexts. CoDA21 requires a deep understanding of contexts and definitions, including complex inference and world knowledge. We find that there is a large gap between human and PLM performance, suggesting that CoDA21 measures an aspect of NLU that is not sufficiently covered in existing benchmarks.",/pdf/368ce457a0edee5810590124b02434e2f44acab4.pdf,,,,anonymous|coda21_evaluating_language_understanding_capabilities_of_nlp_models_with_contextdefinition_alignment,,,,,,,
baHiTdWOUgo,Multimodal Audio-textual Architecture for Robust Spoken Language Understanding,['aclweb.org/ACL/ARR/2021/September/Paper202/Authors'],['Anonymous'],,"Tandem spoken language understanding (SLU) systems suffer from the so-called automatic speech recognition (ASR) error propagation problem. Additionally, as the ASR is not optimized to extract semantics, but solely the linguistic content, relevant semantic cues might be left out of its transcripts. In this work, we propose a multimodal language understanding (MLU) architecture to mitigate these problems. Our solution is based on two compact unidirectional long short-term memory (LSTM) models that encode speech and text information. A fusion layer is also used to fuse audio and text embeddings. Two fusion strategies are explored: a simple concatenation of these embeddings and a cross-modal attention mechanism that learns the contribution of each modality. The first approach showed to be the optimal solution to robustly extract semantic information from audio-textual data. We found that attention is less effective at testing time when the text modality is corrupted. Our model is evaluated on three SLU datasets and robustness is tested using ASR outputs from three off-the-shelf ASR engines. Results show that the proposed approach effectively mitigates the ASR error propagation problem for all datasets.",/pdf/d54ff97d9e90cfc5e558545aad6d05da749ac8ea.pdf,,,,anonymous|multimodal_audiotextual_architecture_for_robust_spoken_language_understanding,,,,,,,
3rxgHBM48gw,RelO: An Overlapping Relation Extraction Dataset and Model,['aclweb.org/ACL/ARR/2021/September/Paper314/Authors'],['Anonymous'],,"We introduce an overlapping relation extraction dataset(RelO) constructed from Wikipedia and Wikidata. RelO consists of 308,579 sentences, representing 40 relations and three different overlapping types. We evaluate the state-of-the-art relation extraction methods on RelO and results show that RelO is challenging for these relation extraction methods. We also use RelO as a transfer learning resources and the fine-tuned two models achieve state-of-the-art results on other related datasets. To handle the overlapping relation extraction task, We extend a pipeline framework by utilizing overlapping type information and semantic distance information of relation representations. Through careful experiments, we validate the importance of these information for overlapping relation extraction. All details and resources about the dataset and baselines are released on https://github.com/disquietBookShare/Relo.",/pdf/2ace52263ab7956325aba91412c7315979eab594.pdf,,,,anonymous|relo_an_overlapping_relation_extraction_dataset_and_model,,,,,,,
9kEcqAD-V5u,BART-light: One Decoder Layer Is Enough,['aclweb.org/ACL/ARR/2021/September/Paper233/Authors'],['Anonymous'],,"BART (Lewis et al., 2020), an encoder-decoder transformer language model (LM), has reached state-of-the-art results on several tasks in natural language generation and understanding. Similar to other pretrained encoder-decoder LMs, it uses the same number of hidden layers in the encoder and the decoder. In this paper, we show that one can easily remove all but one or two decoder layers for text generation tasks and even remove the whole decoder for classification tasks, with little to no compromises on performance. Our study presents that a shallow decoder is sufficient for most tasks when a deep encoder is used.",/pdf/77b0e589dd399b7b8df777dd3378f337c81c9e07.pdf,/attachment/09fa86596897af3ab3412e468c9a2526392ab117.zip,,,anonymous|bartlight_one_decoder_layer_is_enough,,,,,,,
NFladHWUfRc,FlipDA: Effective and Robust Data Augmentation for Few-Shot Learning,['aclweb.org/ACL/ARR/2021/September/Paper27/Authors'],['Anonymous'],,"Most previous methods for text data augmentation are limited to simple tasks and weak baselines. We explore data augmentation on hard tasks (i.e., few-shot natural language understanding) and strong baselines (i.e., pretrained models with over one billion parameters). Under this setting, we reproduced a large number of previous augmentation methods and found that these methods bring marginal gains at best and sometimes degrade the performance much. To address this challenge, we propose a novel data augmentation method FlipDA that jointly uses a generative model and a classifier to generate label-flipped data. Central to the idea of FlipDA is the discovery that generating label-flipped data is more crucial to the performance than generating label-preserved data. Experiments show that FlipDA achieves a good tradeoff between effectiveness and robustness---it substantially improves many tasks while not negatively affecting the others.",/pdf/37a483a7f007aaa1b255143bbb5b6436873989fb.pdf,/attachment/b737a0dc1d6ea51c943fa452217ba0b6343778a5.zip,,,anonymous|flipda_effective_and_robust_data_augmentation_for_fewshot_learning,,,,,,,/attachment/9ebf3c7858b9146f299ecec60fd40998f26c5319.zip
dO3Kzeu8KHX,,,,,,,,,,,,,,,,,
GENmh6JWM7j,,,,,,,,,,,,,,,,,
Y5tTolyfhoP,Placing (Historical) Events on a Timeline: A Classification cum Co-ref Resolution Approach,['aclweb.org/ACL/ARR/2021/September/Paper108/Authors'],['Anonymous'],,"The event timeline provides one of the most effective ways to visualize the important historical events that occurred over a period of time, presenting the insights that may not be so apparent from reading the equivalent information in textual form. By leveraging generative adversarial learning for important event classification and by assimilating knowledge based tags for improving the performance of event coreference resolution we introduce a two staged system for event timeline generation from multiple (historical) text documents. In addition, we propose a vis-timeline based visualization technique to portray the event timeline. We demonstrate our results on two very well known historical documents --  the Collected Works of Mahatma Gandhi (CWMG) and the Collected Works of Abraham Lincoln (CWAL). Our results can be extremely helpful for historians, in advancing research in history and in understanding the socio-political landscape of a country as reflected in the writings of political leaders/scholars. Our work has some parallels with timeline summarization (TLS) tasks and therefore we use these as baselines. Rigorous experiments demonstrate that prior event detection which was hitherto absent in the TLS methods} can improve summarization performance.  In order to show that our methods are very generic we reuse our method to visualize the evolution of coronavirus related events in India from a collection of various COVID-19 articles.",/pdf/7b9e8c2d1915cfa5f7c59361fbc7a797748fd848.pdf,,,,anonymous|placing_historical_events_on_a_timeline_a_classification_cum_coref_resolution_approach,,,,,,,/attachment/83fd269de4f65228d98d1e6b59daedfb9d8d2df6.zip
dYg10Kalyc3,Divide and Rule: Effective Pre-Training for Context-Aware Multi-Encoder Translation Models,['aclweb.org/ACL/ARR/2021/September/Paper10/Authors'],['Anonymous'],,"Multi-encoder models are a broad family of context-aware neural machine translation systems that aims to improve translation quality by encoding document-level contextual information alongside the current sentence. The context encoding is undertaken by contextual parameters, trained on document-level data. In this work, we discuss the difficulty of training these parameters effectively, due to the sparsity of the words in need of context (i.e., the training signal), and their relevant context. We propose to pre-train the contextual parameters over split sentence pairs, which makes an efficient use of the available data for two reasons. Firstly, it increases the contextual training signal by breaking intra-sentential syntactic relations, and thus pushing the model to search the context for disambiguating clues more frequently. Secondly, it eases the retrieval of relevant context, since context segments become shorter. We propose four different splitting methods, and evaluate our approach with BLEU and contrastive test sets. Results show that it consistently improves learning of contextual parameters, both in low and high resource settings.",/pdf/fead8f44a64b50f4064136aab16f6af00b1bbdde.pdf,/attachment/9700b748f91ddf41910a3a23d029d07f43d53c8c.zip,,,anonymous|divide_and_rule_effective_pretraining_for_contextaware_multiencoder_translation_models,,,,,,,
idyspdwviWr,A Few-Shot Semantic Parser for Wizard-of-Oz Dialogues with the Precise ThingTalk+ Representation,['aclweb.org/ACL/ARR/2021/September/Paper200/Authors'],['Anonymous'],,"Previous attempts to build effective semantic parsers for Wizard-of-Oz (WOZ) conversations suffer from the difficulty in acquiring a high-quality, manually annotated training set. Approaches based only on dialogue synthesis are insufficient as dialogues generated from state-machine based models are poor approximations of real-life conversations. Furthermore, previously proposed dialogue state representations are ambiguous and lack the precision necessary for building an effective agent.

This paper proposes a new dialogue representation and a sample-efficient methodology that can predict precise dialogue states in WOZ conversations. We propose a precise, complete, and executable dialogue representation called ThingTalk+, which captures all information an agent needs to respond properly. Our training strategy is sample-efficient: we combine (1) few-shot data sparsely sampling the full dialogue space and (2) synthesized data covering a subset space of dialogues generated by a succinct state-based dialogue model. The completeness of the ThingTalk+ language is demonstrated with a fully operational agent, which is also used in training data synthesis. 

We demonstrate the effectiveness of our methodology on MultiWOZ 3.0, a reannotation of the MultiWOZ 2.1 dataset in ThingTalk+. ThingTalk+ can represent 98% of the test turns, while the simulator can emulate 85% of the validation set. We train a contextual semantic parser using our strategy, and obtain 79% turn-by-turn exact match accuracy on the reannotated test set.",/pdf/234445c21012c2e7b19a89d7fc14afc7c29bcebd.pdf,,,,anonymous|a_fewshot_semantic_parser_for_wizardofoz_dialogues_with_the_precise_thingtalk_representation,,,,,,,
IpiYmpJfmcg,Unsupervised Personality-Aware Language Identification,['aclweb.org/ACL/ARR/2021/September/Paper249/Authors'],['Anonymous'],,"Recognizing the language of ambiguous texts remains a main challenge in language identification (LID). When using multilingual applications, users have their own language preferences, which can be regarded as external knowledge for LID. Nevertheless, current studies marginally consider the inter-personal variations due to the lack of user annotated training data. To fill this gap,  we introduce personality-aware LID and propose a novel unsupervised learning strategy. Concretely, we extract training samples for each user from a standard LID corpus according to his/her language preference. Furthermore,  we contribute the first user labeled LID test set called ""U-LID''. Experimental results reveal that the proposed model can incarnate user traits and significantly outperforms existing LID systems on handling ambiguous texts. Our code and dataset will be released upon the acceptance.",/pdf/f4c92e1616ca2a8836b73ddcf406a8ba103cc148.pdf,/attachment/a452b2b510014e561b7063feb30749847fa6f2e6.zip,,,anonymous|unsupervised_personalityaware_language_identification,,,,,,,/attachment/f51b152031a16ab7d1d4c47a1793d293f1d5889a.zip
yf7b7w78xP8,Contrastive Word Embedding Learning for Neural Machine Translation,['aclweb.org/ACL/ARR/2021/September/Paper302/Authors'],['Anonymous'],,"Seq2seq models have shined in the field of Neural Machine Translation (NMT). However, word embeddings learned by NMT models tend to degenerate and be distributed into a narrow cone, named {\em{representation degeneration problem}}, which limits the representation capacity of word embeddings. In this paper, we propose a Contrastive Word Embedding Learning (CWEL) method to address this problem. CWEL combines the ideas of contrastive representation learning with embedding regularization, and adaptively minimizes the cosine similarity of word embeddings on the target side according to their semantic similarity. Experiments on multiple translation benchmark datasets show that CWEL significantly improves translation qualities. Additional analysis shows that the improvements mainly come from the well-learned word embeddings. ",/pdf/78658cb8f16728b8e6a3e759a892fe713896c762.pdf,/attachment/089de3e42b8e84db40cc942c6c715c404ae06ec6.zip,,,anonymous|contrastive_word_embedding_learning_for_neural_machine_translation,,,,,,,
_LrZ6g3zdZy,Context vs Target Word: Quantifying Biases When Applying Models to Lexical Semantic Datasets,['aclweb.org/ACL/ARR/2021/September/Paper71/Authors'],['Anonymous'],,"State-of-the-art contextualized models such as BERT use tasks such as WiC and WSD to evaluate their word-in-context representations. This inherently assumes that performance in these tasks reflect how well a model represents the coupled word and context semantics. This study investigates this assumption by presenting the first quantitative analysis (using probing baselines) on the context-word interaction being tested in major contextual lexical semantic tasks which have dramatically different emphasis. We found that models often exhibit excessive context and target word biases: they solve tasks like WiC as almost purely context classification and rely on target words alone when tackling medical entity linking. In the latter task, where domain reduces ambiguity, context does not improve models and in fact can degrade performance. Our case study on WiC reveals that human subjects do not share models' strong context biases (humans found semantic judgments much more difficult when the target word is missing) and models are learning spurious correlations from context alone. This study demonstrates that models are usually not being tested for word-in-context representations as such in these tasks and results are therefore open to misinterpretation. We recommend our framework as sanity check for context and target word biases of future task design and application in lexical semantics.",/pdf/301faca9e96740dcc794e730520ee1636dcc95f4.pdf,,,,anonymous|context_vs_target_word_quantifying_biases_when_applying_models_to_lexical_semantic_datasets,,,,,,,
dTwZya8uNnS,Extractive Topical Summarization With Aspects,['aclweb.org/ACL/ARR/2021/September/Paper311/Authors'],['Anonymous'],,"Extractive summarization is a task of highlighting the most important parts of the text. We introduce a new approach to extractive summarization task using hidden topical structure and information about aspects of the text. Experimental results on CNN/DailyMail demonstrate that our approach generates more accurate summarizations than baseline methods, achieving state-of-the-art results in terms of ROUGE metric. Additionally, we show that aspect information is extremely important in extractive summarization scenario.",/pdf/6c8a7300f79188e30b8c7f6b6e725846b90b5dc4.pdf,,,,anonymous|extractive_topical_summarization_with_aspects,,,,,,,
Wrtp36cbl61,Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling? An Extensive Empirical Study on Language Tasks,['aclweb.org/ACL/ARR/2021/September/Paper77/Authors'],['Anonymous'],,"There have been a lot of interest in the scaling properties of Transformer models. However, not much has been done on the front of investigating the effect of scaling properties of different inductive biases and model architectures. Do model architectures scale differently? If so, how does inductive bias affect scaling behaviour?  How does this influence upstream (pretraining) and downstream (transfer)? This paper conducts a systematic study of scaling behaviour of ten diverse model architectures such as Transformers, Switch Transformers, Universal Transformers, Dynamic convolutions, Performers, and recently proposed MLP-Mixers. Via extensive experiments, we show that (1) architecture is an indeed an important consideration when performing scaling and (2) the best performing model can fluctuate at different scales. We believe that the findings outlined in this work has significant implications to how model architectures are currently evaluated in the community.",/pdf/5290158dc2b8d14986ad7ea2c68bb71d56ddb3fc.pdf,,,,anonymous|scaling_laws_vs_model_architectures_how_does_inductive_bias_influence_scaling_an_extensive_empirical_study_on_language_tasks,,,,,,,
Lc66vCjVidE,Cross-Lingual Event Detection via Optimized Adversarial Training,['aclweb.org/ACL/ARR/2021/September/Paper173/Authors'],['Anonymous'],,"In this work, we focus on Cross-Lingual Event Detection (CLED) where a model is trained on data from a source language but its performance is evaluated on data from a second, target, language. Most recent works in this area have harnessed the language-invariant qualities displayed by pre-trained Multi-lingual Language Models (MLM). Their performance, however, reveals there is room for improvement as they mishandle delicate cross-lingual instances. We leverage the use of unlabeled data to train a Language Discriminator (LD) to discern between the source and target languages. The LD is trained in an adversarial manner so that our encoder learns to produce refined, language-invariant representations that lead to improved CLED performance. More importantly, we optimize the adversarial training by only presenting the LD with the most \textit{informative} samples. We base our intuition about \textit{what} makes a sample informative on two disparate metrics: sample similarity and event presence. Thus, we propose using Optimal Transport (OT) as a solution to naturally combine these two distinct information sources into the selection process. Extensive experiments on 8 different language pairs, using 4 languages from unrelated families, show the flexibility and effectiveness of our model that achieves new state-of-the-art results.",/pdf/4d23754d1e63c4ca8d6e2047d56a674d19bef38d.pdf,,,,anonymous|crosslingual_event_detection_via_optimized_adversarial_training,,,,,,,
dhHpdiUiwrP,"Probing, Generalization and Application of Metaphorical Knowledge in Pre-trained Language Models",['aclweb.org/ACL/ARR/2021/September/Paper284/Authors'],['Anonymous'],,"Human languages are full of metaphorical expressions. Metaphors help people understand the world by connecting new concepts and domains to more familiar ones. Large pre-trained language models (PLMs) are therefore assumed to encode metaphorical knowledge useful for NLP systems when processing language. In this paper, we investigate this hypothesis for PLMs by probing the metaphoricity knowledge in their encodings, by measuring the cross-lingual and cross-dataset generalization of this knowledge, and by analyzing the application of this knowledge when generating metaphorical expressions. We present studies in multiple metaphoricity detection datasets and four languages (i.e., English, Spanish, Russian, and Farsi). Our extensive experiments suggest that contextual representations in PLMs do encode metaphoricity information, and mostly in their middle layers, and the knowledge is transferrable between languages and datasets in most cases. Finally, we show that PLMs face more challenges in generating metaphors, especially as their novelty increases. Our findings give helpful insights for both cognitive and NLP scientists.",/pdf/c6576e91efc9bad89dde8b94762f3cbe96238b3b.pdf,,,,anonymous|probing_generalization_and_application_of_metaphorical_knowledge_in_pretrained_language_models,,,,,,,
iq_Jkbwe-kV,Consistent Crosslingual Data Transfer for Open Information Extraction,['aclweb.org/ACL/ARR/2021/September/Paper269/Authors'],['Anonymous'],,"Progress with supervised Open Information Extraction (OpenIE) has been primarily limited to English due to the scarcity of training data in other languages. In this paper, we explore techniques to automatically convert English text for training OpenIE systems in other languages. We introduce the Alignment Augmented Constrained Translation (AACTrans) model to translate English sentences and their corresponding extractions consistently with each other --- with no changes to vocabulary or semantic meaning which may result from independent translations. Using the data generated with AACTrans, we train a novel two-stage generative OpenIE model, which we call Gen2OIE, that outputs for each sentence: 1) relations in the first stage and 2) all extractions containing the relation in the second stage. Gen2OIE increases relation coverage using a training data transformation technique that is generalizable to multiple languages, in contrast to existing models that use an English-specific training loss. Evaluations on 5 languages --- Spanish, Portuguese, Chinese, Hindi and Telugu --- show that the Gen2OIE with AACTrans data outperforms prior systems by a margin of 6-40% in F1.",/pdf/8b15ac16e6031010f8ef695af27dc76cc29b7780.pdf,/attachment/b44a0a417e69b83000ebb57233c357789ebdbad4.zip,,,anonymous|consistent_crosslingual_data_transfer_for_open_information_extraction,,,,,,,/attachment/92bc647b0eb55dfe760c2e88e3fd0af3d3014029.zip
lTbIVRBq8Ta,An Empirical Study of Document-to-document Neural Machine Translation,['aclweb.org/ACL/ARR/2021/September/Paper52/Authors'],['Anonymous'],,"This paper does not aim at introducing a novel method for document NMT. Instead, we head back to the original transformer model with document-level training and hope to answer the following question: Is the capacity of current models strong enough for document-level NMT? Interestingly, we observe that the original transformer with appropriate training techniques can achieve strong results for document translation, even with a length of 2000 words. We evaluate this model and several recent approaches on nine document-level datasets and two sentence-level datasets across six languages. Experiments show that the original Transformer model outperforms sentence-level models and many previous methods in a comprehensive set of metrics, including BLEU, four lexical indices, three newly proposed assistant linguistic indicators, and human evaluation.",/pdf/3246000e75dbbb6371b3cb64941b734b9c1f9cf1.pdf,,,,anonymous|an_empirical_study_of_documenttodocument_neural_machine_translation,,,,,,,/attachment/501b6feaadb5bd95de54f6bc94980cdfd4f4b7bf.zip
dJ0jXhQ9YHd,,,,,,,,,,,,,,,,,
nyB0xsto715,Human Schema Curation via Causal Association Rule Mining,['aclweb.org/ACL/ARR/2021/September/Paper198/Authors'],['Anonymous'],,"Event schemas are structured knowledge sources defining typical real-world scenarios (e.g., going to an airport). We present a framework for efficient human-in-the-loop construction of a schema library, based on a novel mechanism for schema induction and a well-crafted interface that allows non-experts to ""program"" complex event structures. Associated with this work we release a schema library: a machine readable resource of 232 detailed event schemas, each of which describe a distinct typical scenario in terms of its relevant sub-event structure (what happens in the scenario), participants (who plays a role in the scenario), fine-grained typing of each participant, and the implied relational constraints between them.  We freely release our schema library and custom annotation interface, SchemaBlocks.",/pdf/9dd68281e03d52e1f9107055e8a557e2a27dccf5.pdf,/attachment/27dd1c2bc8b6f48be452a53d0d570fa63c14e92c.tgz,,,anonymous|human_schema_curation_via_causal_association_rule_mining,,,,,,,/attachment/ad385aaa63a530e374190848778e946947967737.tgz
IV5YUaQ4pzG,A Simple and Effective Model for Multi-Hop Question Generation,['aclweb.org/ACL/ARR/2021/September/Paper180/Authors'],['Anonymous'],,"Previous research on automated question generation has almost exclusively focused on generating factoid questions whose answers can be extracted from a single document. However, there is an increasing interest in developing systems that are capable of more complex multi-hop question generation (QG), where answering the question requires reasoning over multiple documents. In this work, we propose a simple and effective approach based on the transformer model for multi-hop QG. Our approach consists of specialized input representations, a supporting sentence classification objective, and training data weighting. Prior work on multi-hop QG considers the simplified setting of shorter documents and also advocates the use of entity-based graph structures as essential ingredients in model design. On the contrary, we showcase that our model can scale to the challenging setting of longer documents as input, does not rely on graph structures, and substantially outperforms the state-of-the-art approaches as measured by automated metrics and human evaluation.",/pdf/9fff1db99de6588d2af0c2a508c5ae693f4f5c74.pdf,,,,anonymous|a_simple_and_effective_model_for_multihop_question_generation,,,,,,,
WiZ3Z2HChE0,Modeling Multi-granularity Segmentation for Rare Words in Neural Machine Translation,['aclweb.org/ACL/ARR/2021/September/Paper287/Authors'],['Anonymous'],,"Segmenting rare words into subwords has become a commonly used and effective way to alleviate the open vocabulary problem in Neural Machine Translation (NMT). The existing dominant segmentation methods either give rare words a single segmentation or a fixed segmentation, which leads to a lack of morphological diversity in representing words. For rare words, we first obtain segmentation with different granularities through Byte Pair Encoding (BPE) and BPE-Dropout, and then propose \textsc{BPEatt} model to dynamically mix the BPE subwords and BPE-Dropout subwords, which enhances the encoder's ability to represent rich morphological information. Experiments on six translation benchmarks of different scales show that our proposed method significantly outperforms the baseline model and has obvious advantages over related methods.",/pdf/a415d38ca85823441437d37a224c1b981ec0de90.pdf,/attachment/dc6d1a3c47567fbed450aab3d8feb26572d7613c.zip,,,anonymous|modeling_multigranularity_segmentation_for_rare_words_in_neural_machine_translation,,,,,,,
lUegilCk6TY,GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates,['aclweb.org/ACL/ARR/2021/September/Paper139/Authors'],['Anonymous'],,"Biomedical entity normalization unifies the language across biomedical experiments and studies, and further enables us to obtain a holistic view of life sciences. Current approaches mainly study the normalization of more standardized entities such as diseases and drugs, while disregarding the more ambiguous but crucial entities such as pathways, functions and cell types, hindering their real-world applications. To achieve biomedical entity normalization on these under-explored entities, we first introduce an expert-curated dataset OBO-syn encompassing 70 different types of entities and 2 million curated entity-synonym pairs. To utilize the unique graph structure in this dataset, we propose GraphPrompt, a prompt-based learning approach that creates prompt templates according to the graphs. GraphPrompt obtained 41.0% and 29.9% improvement on zero-shot and few-shot settings respectively, indicating the effectiveness of these graph-based prompt templates. We envision that our method GraphPrompt and OBO-syn dataset can be broadly applied to graph-based NLP tasks, and serve as the basis for analyzing diverse and accumulating biomedical data.",/pdf/a41e5f4ca0b980ce3dc132c58418795086e7ac35.pdf,,,,anonymous|graphprompt_biomedical_entity_normalization_using_graphbased_prompt_templates,,,,,,,/attachment/d60a6ed1a3c3b426f9ada9e39326761573c305c8.zip
htpgN820kub,,,,,,,,,,,,,,,,,
yaU2ZfyVFgF,Improving Personalized Dialogue Generation Models with Data-level Distillation and Diversification,['aclweb.org/ACL/ARR/2021/September/Paper138/Authors'],['Anonymous'],,"Personalized dialogue generation is a challenging task in which a persona-consistent response needs to be generated conditioning both persona texts and dialogue utterances, being more complex than conventional dialogues. Multiple persona texts and utterances exist in one sample and some of them can be distractors for generating. Thus even strong models have difficulty posing attention to suitable personas so generating persona-irrelevant responses. Besides, the limited data scale and diversity further affect the performance. Thus, we start from data and propose to boost the model in data-level distillation and diversification (D$^3$). We first distill the original training samples into simplified persona-consistent ones, lowering the difficulty by removing redundant information in personas and dialogue history. Next in the diversification, we increase both the amount and diversity of distilled data to ease its insufficiency. A model will be trained via curricula, first on easier augmented samples and then on harder original ones. Experiments on the PersonaChat benchmark dataset illustrate the superiority of our method when packed with two strong base dialogue models (Transformer and GPT2) on various automatic metrics and human evaluation. ",/pdf/987de95581fdb9ab702bd1805157bfad7214a4ad.pdf,/attachment/8820527c58a2f2fb08b21e59e0aac0ec0d47e73b.zip,,,anonymous|improving_personalized_dialogue_generation_models_with_datalevel_distillation_and_diversification,,,,,,,
oQ43ZecmCwe,Towards Comprehensive Patent Approval Predictions:Beyond Traditional Document Classification,['aclweb.org/ACL/ARR/2021/September/Paper277/Authors'],['Anonymous'],,"Predicting the approval chance of a patent application is a challenging problem involving multiple facets. The most crucial facet is arguably the novelty --- \emph{35 U.S. Code § 102} rejects more recent applications that have very similar prior arts. Such novelty evaluations differ the patent approval prediction from conventional document classification --- Successful patent applications may share similar writing patterns; however, too-similar newer applications would receive the opposite label, thus confusing standard document classifiers (e.g., BERT). To address this issue, we propose a novel framework \our that unifies the document classifier with handcrafted features, particularly time-dependent novelty scores. Specifically, we formulate the novelty scores by comparing each application with millions of prior arts using a hybrid of efficient filters and a neural bi-encoder. Moreover, we impose a new regularization term into the classification objective to enforce the monotonic change of approval prediction w.r.t. novelty scores. From extensive experiments on the large-scale USPTO dataset, we find that our time-dependent novelty features offer a boost on top of the document classifier. Also, our monotonic regularization, while shrinking the search space, can drive the optimizer to better local optima, yielding empirical performance gains. Ex-post analysis of prediction scores further confirms that the document classifier and handcrafted features capture distinct sets of learning information. ",/pdf/010074775d98c36b2c3674f3f85f20c24fd57a5f.pdf,,,,anonymous|towards_comprehensive_patent_approval_predictionsbeyond_traditional_document_classification,,,,,,,
0B-Sz3m7KH5,EIDER: Evidence-enhanced Document-level Relation Extraction,['aclweb.org/ACL/ARR/2021/September/Paper221/Authors'],['Anonymous'],,"Document-level relation extraction (DocRE) aims to extract the semantic relations among entity pairs in a document. In DocRE, we observe that (1) a subset of the sentences in a document, noted as the evidence sentences, are often sufficient for predicting the relation between a specific entity pair; (2) these evidence sentences can be extracted in an effective and lightweight manner: by multi-task learning along with the RE model or by heuristic rules. In this paper, we propose a novel DocRE framework called Eider that automatically extracts and makes use of evidence. Eider enhances a DocRE model by combining the inference results from the evidence sentences and the original document through a blending layer. The performance can be further improved by jointly training an RE model with an evidence extraction model via multi-task learning. If human-annotated evidence is not available, we can use the evidence extracted by this joint model or by several heuristic rules. Extensive experiments show that Eider achieves state-of-the-art performance on the DocRED, CDR, and GDA datasets. Remarkably, Eider outperforms the runner-up by 1.37/1.26 Ign F1/F1 on DocRED. In particular, Eider-RoBERTa$_\text{large}$ significantly improves the performance on entity pairs requiring co-reference/multi-hop reasoning by 1.98/2.08 F1, respectively.",/pdf/3ab03c2f5a550585dea072f6df8fecf02875eb38.pdf,,,,anonymous|eider_evidenceenhanced_documentlevel_relation_extraction,,,,https://openreview.net/forum?id=Z9arKXstUo5,/attachment/1457354f1c3511d596a5e0cb52dc3232655d4f10.pdf,/attachment/a5f3b03e62c3cdc49c4ed2649b3a2aa9d27b6080.pdf,
t5zJTjgwngX,DocEE: A Large-Scale Dataset for Document-level Event Extraction,['aclweb.org/ACL/ARR/2021/September/Paper73/Authors'],['Anonymous'],,"Event extraction (EE) is the task of identifying events and their types, along with the involved arguments. Despite the great success in sentence-level event extraction, events are more naturally presented in the form of document, with event arguments scattering in multiple sentences. However, a major barrier to promote document-level event extraction has been the lack of large-scale and practical training and evaluation datasets. In this paper, we present DocEE, a new document-level EE dataset including 20,000+ events, 100,000+ arguments. We highlight three features: large-scale annotations, fine-grained event arguments and application-oriented settings. Experiments show that even SOTA models show inferior performance on DocEE, especially in cross-domain settings, indicating that DocEE is still a challenging task. We will publish DocEE upon acceptance.",/pdf/3b4222f22b53a932612a464bf41fa7b62dde8918.pdf,,,,anonymous|docee_a_largescale_dataset_for_documentlevel_event_extraction,,,,,,,/attachment/634b434429d4bb7d694c6c260c417cb58a3751f1.zip
Dys8zbWqW3C,Enhancing the Nonlinear Mutual Dependencies in Transformers with Mutual Information,['aclweb.org/ACL/ARR/2021/September/Paper21/Authors'],['Anonymous'],,"The Predictive Uncertainty problem does exist in Transformers. We present that pre-trained Transformers can be further regularized by mutual information to alleviate such issue in Neural Machine Translation (NMT). In this paper, we explicitly capture the nonlinear mutual dependencies existing in decoder self-attentions to reduce the model uncertainty concerning token-token interactions. Specifically, we adopt an unsupervised objective of mutual information maximization on self-attentions with the contrastive learning methodology and construct the estimation of mutual information by using InfoNCE. Experimental results on WMT'14 En$\rightarrow$De, WMT'14 En$\rightarrow$Fr demonstrate the consistent effectiveness and evident improvements of our model over the strong baselines. Quantifying the model uncertainty again verifies our hypothesis.  The proposed plug-and-play approach can be easily incorporated and deployed into pre-trained Transformer models. Code will be released soon.",/pdf/745a0e40b04246b6bef96ad30f01468aba2a6606.pdf,,,,anonymous|enhancing_the_nonlinear_mutual_dependencies_in_transformers_with_mutual_information,,,,,,,
6zZEZD2LsxW,AMR-to-text Generation with Graph Structure Reconstruction and Coverage,['aclweb.org/ACL/ARR/2021/September/Paper51/Authors'],['Anonymous'],,"Generating text from semantic representations such as AMR is a challenging task. Previous research formalizes this task as a graph-to-sequence learning problem and uses various graph neural networks to model the graph structure. Recently, methods based on pre-trained models improve the performance significantly due to pre-trained on a large text corpus. However, these pre-trained model-based methods take linearized AMR graphs as input and may lose the information of graph structure.  In addition, these methods don't consider the coverage of the AMR graph. Therefore, some nodes in the graph may be lost or repeated in the generated text. To address these problems, we propose a graph structure and coverage enhanced model for this task. To enhance the information of graph structure, we design two auxiliary objectives, relationship prediction and distance prediction of nodes in AMR graphs. To consider the coverage of AMR graphs, we design a coverage mechanism to solve the problem of information under-translation or over-translation in AMR-to-text generation. 
 Experimental results on three standard datasets show that our proposed method outperforms the existing methods significantly.",/pdf/1a1376986911b82c3dce85734a2e9cf92cd64a93.pdf,/attachment/64af28035595cf24b90fe0a8efd933d8757f1a37.zip,,,anonymous|amrtotext_generation_with_graph_structure_reconstruction_and_coverage,,,,,,,
l3UVZ30slvl,Rebuild and Ensemble: Exploring Defense Against Text Adversaries,['aclweb.org/ACL/ARR/2021/September/Paper4/Authors'],['Anonymous'],,"Adversarial attacks can mislead strong neural models; as such, in NLP tasks, substitution-based attacks are difficult to defend. 
Current defense methods usually assume that the substitution candidates are accessible, which cannot be widely applied against substitution-agnostic attacks. 
In this paper, we propose a \textbf{Rebuild and Ensemble} Framework to defend against adversarial attacks in texts without knowing the candidates.
We propose a rebuild mechanism to train a robust model and ensemble the rebuilt texts during inference to achieve good adversarial defense results.
Experiments show that our method can improve accuracy under the current strong attack methods. ",/pdf/1ff6b0b6b20d5b8d917f6ea43df289897d12539f.pdf,,,,anonymous|rebuild_and_ensemble_exploring_defense_against_text_adversaries,,,,,,,
8yJ0RpqNppY,Learning Emotion-Aware Contextual Representations for Emotion Cause Analysis,['aclweb.org/ACL/ARR/2021/September/Paper59/Authors'],['Anonymous'],,"Emotion Cause Analysis has been a key topic in natural language processing. Previous works focus on Emotion Cause Extraction (ECE), a clause-level classification task aimed at extracting causes of certain given emotion in text. The task has been expanded to Emotion Cause Pair Extraction (ECPE) that focus on extracting both emotions and corresponding causes in the context. Most existing methods for the ECPE task implement a joint model that performs extracting and matching of emotion and cause clauses simultaneously. However, we argue that different input features are needed for the two subtasks, thus sharing contextual representations may be suboptimal. In this work, we propose a pipelined approach that builds on two independent pre-trained encoders, in which the emotion extraction model only provide input features for the cause extraction model. Based on a series of careful experiments, we validate that our model can create distinct contextual representations according to specific emotional texts, and thus achieve state-of-the-art performance in both ECE and ECPE tasks, with the absolute F1 improvements of 1.5% and 4.72% over best previous works respectively. Besides, we apply a set of simple clause selection rules to extract multiple pairs in the document, strengthening the applicability of our approach in real world scenarios.",/pdf/68a04cdb4cb59a58049e505bb5841595c4882a79.pdf,/attachment/888b65803f9b2129520319bd66c9ec4dc9c327c0.zip,,,anonymous|learning_emotionaware_contextual_representations_for_emotion_cause_analysis,,,,,,,
wVdX61hrmpK,CDM: Combining Extraction and Generation for Definition Modeling,['aclweb.org/ACL/ARR/2021/September/Paper248/Authors'],['Anonymous'],,"Definitions are essential for term understanding. Recently, there is an increasing interest in extracting and generating definitions of terms automatically. However, existing approaches for this task are either extractive or abstractive - definitions are either extracted from a corpus or generated by a language generation model. In this paper, we propose to combine extraction and generation for definition modeling: first extract self- and correlative definitional information of target terms from the Web and then generate the final definitions by incorporating the extracted definitional information. Experiments demonstrate our framework can generate high-quality definitions for technical terms and outperform state-of-the-art models for definition modeling significantly.",/pdf/51776f2a6d7a4828142760da740384fe03ed5cf4.pdf,/attachment/1b1816bfa1602d59079c9a517c0ca5f27325d27d.zip,,,anonymous|cdm_combining_extraction_and_generation_for_definition_modeling,,,,,,,/attachment/a1187f0671bc281882896d044415372892eea93d.zip
i7DhBQrfi-e,SOS: Systematic Offensive Stereotyping Bias in Word Embeddings,['aclweb.org/ACL/ARR/2021/September/Paper37/Authors'],['Anonymous'],,"Hate speech detection models aim to provide a safe environment for marginalised social groups to express themselves. However, the bias in these models could lead to silencing those groups. In this paper, we introduce the systematic offensive stereotyping (SOS) bias metric. We propose a method to measure the SOS bias in different word embeddings and also investigate its influence on the downstream task of hate speech detection. Our results show that SOS bias against various groups exists in widely used word embeddings and that, in most cases, our SOS bias metric correlates positively with the bias statistics of published surveys on online abuse and hate. However, we found that it is not easy to prove that bias in word embeddings influences downstream task performance. Finally, we show that our SOS bias metric is more indicative of sexism and racism in the inspected word embeddings when used for sexism and racism detection than the stereotypical social biases.",/pdf/49d35afd3580040b76415bc11d0b511ae209a922.pdf,,,,anonymous|sos_systematic_offensive_stereotyping_bias_in_word_embeddings,,,,,,,
b61q_mqtf31,Graph Neural Networks for Multiparallel Word Alignment,['aclweb.org/ACL/ARR/2021/September/Paper292/Authors'],['Anonymous'],,"After a period of decrease, interest in word alignments is increasing again for their usefulness in domains  such as typological research, cross-lingual annotation projection and machine translation. Generally, alignment algorithms only use  bitext and do not make use of the fact that many parallel corpora are multiparallel. We propose to use graph neural networks (GNNs) and community detection algorithms to exploit the graph structure of multiparallel word alignments. Our GNN approach (i) utilizes information about the meaning, position and language of the input words, (ii) incorporates information from multiple parallel sentences, (iii) can remove edges from the initial alignments, and (iv) provides a prediction model that can generalize beyond the sentences it is trained on. We show that community detection algorithms can provide valuable information for multiparallel word alignment. We show on three word alignment datasets and on a downstream task that our method outperforms previous work. 
",/pdf/798799da37ec5fbe6ce17fb882db51f057dd8042.pdf,,,,anonymous|graph_neural_networks_for_multiparallel_word_alignment,,,,,,,
7SQh5IvfeLq,Achieving Reliable Human Assessment of Open-Domain Dialogue Systems,['aclweb.org/ACL/ARR/2021/September/Paper246/Authors'],['Anonymous'],,"Evaluation of open-domain dialogue systems is highly challenging and development of better techniques is highlighted time and again as desperately needed. Despite substantial efforts to carry out reliable live evaluation of systems in recent competitions, annotations have been abandoned and reported as too unreliable to yield sensible results. This is a serious problem since automatic metrics are not known to provide a good indication of what may or may not be a high-quality conversation. Answering the distress call of competitions that have emphasized the urgent need for better evaluation techniques in dialogue, we present the successful development of human evaluation that is highly reliable while still remaining feasible and low cost. Self-replication experiments reveal almost perfectly repeatable results with a correlation of $r=0.969$. Furthermore, due to the lack of appropriate methods of statistical significance testing, the likelihood of potential improvements to systems occurring due to chance is rarely taken into account in dialogue evaluation, and the evaluation we propose facilitates application of standard tests. Since we have developed a highly reliable evaluation method, new insights into system performance can be revealed. We therefore include a comparison of state-of-the-art models (i) with and without personas, to measure the contribution of personas to conversation quality, as well as (ii) prescribed versus freely chosen topics. Interestingly with respect to personas, results indicate that personas do not positively contribute to conversation quality as expected.",/pdf/fb59c5e7810c3a0cd174c307917c20ff20f5efd8.pdf,,,,anonymous|achieving_reliable_human_assessment_of_opendomain_dialogue_systems,,,,,,,
kV-PzsxIUu2,Should a Bot be Sarcastic? Understanding User Preferences Towards Sarcasm Generation,['aclweb.org/ACL/ARR/2021/September/Paper46/Authors'],['Anonymous'],,"Previous sarcasm generation research has focused on how to generate text that people perceive as sarcastic to create more human-like interactions. In this paper, we argue that we should first turn our attention to the question of when sarcasm should be generated, finding that human annotators consider many inputs to be unfit for sarcastic responses. Next, we introduce a theory-driven framework for sarcasm generation which allows us to better control the linguistic devices used during the generation process in order to measure their impact on sarcasm perception, finding that pragmatic insincerity and emotional markers are crucial elements in generating recognizable sarcasm.",/pdf/c81446d3cede1c7390b4986bc848da1b100c969e.pdf,,,,anonymous|should_a_bot_be_sarcastic_understanding_user_preferences_towards_sarcasm_generation,,,,,,,
Ch1K-07jfmy,Towards Overcoming Practical Obstacles to Deploying Deep Active Learning,['aclweb.org/ACL/ARR/2021/September/Paper26/Authors'],['Anonymous'],,"Active learning (AL) is a prominent technique for reducing the annotation effort required for training machine learning models. Deep learning offers a solution for several essential obstacles to deploying AL in practice but introduces many others. One of such problems is the excessive computational resources required to train an acquisition model and estimate its uncertainty on instances in the unlabeled pool. We propose two techniques that tackle this issue for text classification and tagging tasks, offering a substantial reduction of AL iteration duration and the computational overhead introduced by deep acquisition models in AL. We also demonstrate that our algorithm that leverages pseudolabeling and distilled models overcomes one of the obstacles revealed previously in the literature. Namely, it was shown that due to differences between an acquisition model used to select instances during AL and a successor model trained on the labeled data, the benefits of AL can diminish. We show that our algorithm, despite using a smaller and faster acquisition model, is capable of training a more expressive successor with higher performance.",/pdf/42322016e00802323ffa1c23aa5399ecdd30e2c5.pdf,,,,anonymous|towards_overcoming_practical_obstacles_to_deploying_deep_active_learning,,,,,,,
9WIYi_ruQhQ,,,,,,,,,,,,,,,,,
NVhMSb0UM0x,A Survey on Geocoding: Algorithms and Datasets for Toponym Resolution,['aclweb.org/ACL/ARR/2021/September/Paper8/Authors'],['Anonymous'],,"Geocoding, the task of converting unstructured text to structured spatial data, has recently seen progress thanks to a variety of new datasets, evaluation metrics, and machine-learning algorithms. We provide a survey to review, organize and analyze recent work on geocoding (also known as toponym resolution) where the text is matched to geospatial coordinates and/or ontologies. We summarize the findings of this research and suggest some promising directions for future work.",/pdf/2eb22fbfa54b8f115d0031c0048952052e61ebbc.pdf,,,,anonymous|a_survey_on_geocoding_algorithms_and_datasets_for_toponym_resolution,,,,https://openreview.net/forum?id=-koTfmSDsM,/attachment/183e3f8769b1ca3ffea81bd1c73ba1f0ddeb3e09.pdf,/attachment/962291b57c92a37a20d515fd12c5ff61e13c806b.pdf,
XZDvxFlNi6G,Knowledge Neurons in Pretrained Transformers,['aclweb.org/ACL/ARR/2021/September/Paper278/Authors'],['Anonymous'],,"Large-scale pretrained language models are surprisingly good at recalling factual knowledge presented in the training corpus. In this paper, we present preliminary studies on how factual knowledge is stored in pretrained Transformers by introducing the concept of knowledge neurons. Specifically, we examine the fill-in-the-blank cloze task for BERT. Given a relational fact, we propose a knowledge attribution method to identify the neurons that express the fact. We find that the activation of such knowledge neurons is positively correlated to the expression of their corresponding facts. In our case studies, we attempt to leverage knowledge neurons to edit (such as update, and erase) specific factual knowledge without fine-tuning. Our results shed light on understanding the storage of knowledge within pretrained Transformers.",/pdf/b404996d00f437174166becb92da39838f0fe16b.pdf,/attachment/7af85385ad0ad54d778a787be153dd456421029a.zip,,,anonymous|knowledge_neurons_in_pretrained_transformers,,,,,,,/attachment/292dea58d5b2f3431e1d86c43e3043ebbfc333cc.zip
8jL2PN3iY3M,Personalized News Recommendation with Candidate-aware User Modeling,['aclweb.org/ACL/ARR/2021/September/Paper72/Authors'],['Anonymous'],,"News recommendation aims to match news with personalized user interest. Existing methods for news recommendation usually model user interest from historical clicked news without the consideration of candidate news. However, each user usually has multiple interests, and it is difficult for these methods to accurately match a candidate news with a specific user interest. In this paper, we present a candidate-aware user modeling method for personalized news recommendation, which can incorporate candidate news into user modeling for better matching between candidate news and user interest. More specifically, we propose a candidate-aware self-attention network that uses candidate news as guidance to model candidate-aware global user interest. In addition, we propose a candidate-aware CNN network to incorporate candidate news into local behavior context modeling to learn candidate-aware short-term user interest. Besides, we use a candidate-aware attention network to aggregate previously clicked news weighted by their relevance with candidate news to build candidate-aware user representation. The experiments on real-world datasets show the effectiveness of our approach in improving news recommendation performance.",/pdf/20080b0f8128e3ef22530b14e298c53221b481a4.pdf,/attachment/606d6fd67d3cbe6a3c7bbe1416718c30b03b9114.zip,,,anonymous|personalized_news_recommendation_with_candidateaware_user_modeling,,,,,,,
HJSSYU3swSj,Learning Functional Distributional Semantics with Visual Data,['aclweb.org/ACL/ARR/2021/September/Paper273/Authors'],['Anonymous'],,"Functional Distributional Semantics is a recently proposed framework for learning distributional semantics that provides linguistic interpretability. It models the meaning of a word as a binary classifier rather than a numerical vector. In this work, we propose a method to train a Functional Distributional Semantics model with grounded visual data. We train it on the Visual Genome dataset, which is closer to the kind of data encountered in human language acquisition than a large text corpus. On four external evaluation datasets, our model outperforms previous work on learning semantics from Visual Genome.",/pdf/2d0568900a59f958a557f7da40021501279c1dc1.pdf,,,,anonymous|learning_functional_distributional_semantics_with_visual_data,,,,,,,
2CkBtUsrKbs,Pseudo-Error Generation for Grammatical Error Correction Based on Learner’s First Language,['aclweb.org/ACL/ARR/2021/September/Paper143/Authors'],['Anonymous'],,"We propose to adapt grammatical error correction (GEC) systems to the learners' first language (L1) by generating artificial errors that reflect the L1 influence. To this end, we employ two simple approaches: fine-tuning a back-translation model on L1-annotated data; and controlling the output of a back-translation model and generating artificial errors that follow the L1-dependant error type distribution. We demonstrate that, despite the simplicity of the model and the paucity of the L1-annotated data, our methods succeed in adapting GEC models to some languages. We also show that generating L1-adapted artificial errors is orthogonal to the existing method that directly adapts the GEC model to each L1. Lastly, we present an analysis of the pseudo errors generated by our models and show that they approximately capture the L1-specific error patterns. ",/pdf/bb3988706b7c3313ec2a577d50b83a866287212f.pdf,,,,anonymous|pseudoerror_generation_for_grammatical_error_correction_based_on_learners_first_language,,,,,,,
AnaQAjSkPXg,Benchmarking Answer Verification Methods for Question Answering-Based Summarization Evaluation Metrics,['aclweb.org/ACL/ARR/2021/September/Paper66/Authors'],['Anonymous'],,"Question answering-based summarization evaluation metrics must automatically determine whether the QA model's prediction is correct or not, a task known as answer verification. In this work, we benchmark the lexical answer verification methods which have been used by current QA-based metrics as well as two more sophisticated text comparison methods, BERTScore and LERC. We find that LERC out-performs the other methods in some settings while remaining statistically indistinguishable from lexical overlap in others. However, our experiments reveal that improved verification performance does not necessarily translate to overall QA-based metric quality: In some scenarios, using a worse verification method -- or using none at all -- has comparable performance to using the best verification method, a result that we attribute to properties of the datasets.",/pdf/ae67bdf062a2ae03523d0656d46186833170309c.pdf,,,,anonymous|benchmarking_answer_verification_methods_for_question_answeringbased_summarization_evaluation_metrics,,,,,,,
mB_pLPuO7S_,A Variational Hierarchical Model for Neural Cross-Lingual Summarization,['aclweb.org/ACL/ARR/2021/September/Paper91/Authors'],['Anonymous'],,"The goal of the cross-lingual summarization (CLS) is to convert a document in one language (e.g., English) to a summary in another one (e.g., Chinese), which is essentially the combination of machine translation (MT) and monolingual summarization (MS). Existing studies on CLS mainly focus on utilizing pipeline methods or jointly training an end-to-end model through an auxiliary MT or MS objective. However, it is very challenging for the model to directly conduct CLS as it requires both the abilities to translate and summarize. Besides, the processes of MT and MS have a hierarchical relationship with CLS. Therefore, we propose a hierarchical model for the CLS task, based on the conditional variational auto-encoder. The hierarchical model contains two kinds of latent variables at the local and global levels, respectively. At the local level, there are two latent variables, one for translation and the other for summarization. As for the global level, there is another latent variable for cross-lingual summarization conditioned on the two local-level variables. Experiments on two language directions (English-Chinese) verify the effectiveness and superiority of the proposed approach, yielding state-of-the-art performances. In addition, we show that our model is able to generate better cross-lingual summaries than comparison models in the few-shot setting.",/pdf/f1527538dda8460ddaf0c80d1780fb315291b482.pdf,/attachment/2153f573f09036a1a2c6fa88d122ba2f65e671d1.zip,,,anonymous|a_variational_hierarchical_model_for_neural_crosslingual_summarization,,,,,,,
sgmCcvG-3xH,ASSIST: Towards Label Noise-Robust Dialogue State Tracking,['aclweb.org/ACL/ARR/2021/September/Paper187/Authors'],['Anonymous'],,"The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state tracking (DST). However, substantial noise has been discovered in its state annotations. Such noise brings about huge challenges for training DST models robustly. Although several refined versions, including MultiWOZ 2.1-2.4, have been published recently, there are still lots of noisy labels, especially in the training set. Besides, it is costly to rectify all the problematic annotations. In this paper, instead of improving the annotation quality further, we propose a general framework, named ASSIST (lAbel noiSe-robuSt dIalogue State Tracking), to train DST models robustly from noisy labels. ASSIST first generates pseudo labels for each sample in the training set by using an auxiliary model trained on a small clean dataset, then puts the generated pseudo labels and vanilla noisy labels together to train the primary model. We show the validity of ASSIST theoretically. Experimental results also demonstrate that ASSIST improves the joint goal accuracy of DST by up to $28.16\%$ on the initial version MultiWOZ 2.0 and $8.41\%$ on the latest version MultiWOZ 2.4, respectively. ",/pdf/892100b0039cb2a8e9d4fac9f78f0e73aa71d9ef.pdf,/attachment/1e3646bfd04b0f545aa02b43999eb4c2e485580f.zip,,,anonymous|assist_towards_label_noiserobust_dialogue_state_tracking,,,,,,,
4VzVcbbF9Hs,Utterance Rewriting with Contrastive Learning in Multi-turn Dialogue,['aclweb.org/ACL/ARR/2021/September/Paper220/Authors'],['Anonymous'],,"Context modeling plays a significant role in building multi-turn dialogue systems. In order to make full use of context information, systems can use Incomplete Utterance Rewriting(IUR) methods to simplify the multi-turn dialogue into single-turn by merging current utterance and context information into a self-contained utterance. However, previous approaches ignore the intent consistency between the original query and rewritten query. The detection of omitted or coreferred locations in the original query can be further improved. In this paper, we introduce contrastive learning and multi-task learning to jointly model the problem. Our method benefits from carefully designed self-supervised objectives, which act as auxiliary tasks to capture semantics at both sentence-level and token-level. The experiments show that our proposed model achieves state-of-the-art performance on several public datasets.",/pdf/eb0a273fe20e4f79cba5d8914b13dde401c5b29a.pdf,,,,anonymous|utterance_rewriting_with_contrastive_learning_in_multiturn_dialogue,,,,,,,
vjwdO75bWI0,ElitePLM: An Empirical Study on General Language Ability Evaluation of Pretrained Language Models,['aclweb.org/ACL/ARR/2021/September/Paper112/Authors'],['Anonymous'],,"Pretrained language models (PLMs), such as BERT and GPT-3, have dominated the majority of NLP tasks. However, relatively little work has been conducted on systematically evaluating the language abilities of PLMs. In this paper, we present a large-scale empirical study on gen\underline{E}ral \underline{l}anguage ab\underline{i}li\underline{t}y \underline{e}valuation of PLMs (ElitePLM). We first design four evaluation dimensions in ElitePLM, including memory, comprehension, reasoning, and composition, and further measure ten widely-used PLMs within five categories. Our empirical results demonstrate that: (1) the pretraining objectives and strategies have significant impacts on PLMs performance in downstream tasks; (2) fine-tuning PLMs in downstream tasks is usually sensitive to the data size and distribution; (3) PLMs have excellent transferability between similar tasks. Our experimental results summarize several important findings, which can guide the future work to choose, apply, and design  PLMs for specific tasks. We have made all the details of experiments publicly available at https://anonymous.4open.science/r/Paper-for-ACL-4FD1.",/pdf/d62563f03fa111ec17cee737f573dc589d4a754d.pdf,,,,anonymous|eliteplm_an_empirical_study_on_general_language_ability_evaluation_of_pretrained_language_models,,,,,,,
ZA6k7c-V1wT,Transformers Can Compose Skills To Solve Novel Problems Without Finetuning,['aclweb.org/ACL/ARR/2021/September/Paper1/Authors'],['Anonymous'],,"It is possible to achieve improved prediction performance with Transformers on unseen datasets by adding disparate new training tasks to an existing multitask training regime. We demonstrate that this can be attributed to a compositional mechanism rather than memorisation. Performance on DROP, DROP-CS and ROPES datasets can be improved by over 26 percent without finetuning through application of numerical reasoning tasks, while performance on seven other question-answering datasets that would not be expected to be improved remains essentially unchanged. By filtering our evaluation datasets to only those samples that have no answer overlap to similar training samples, and then further restricting to those samples which have the least semantic similarity with the training set, we show that improved performance after adding numerical reasoning tasks was not attributable to direct lookup. Our code and filtered datasets are available at https://github.com/anonymised.",/pdf/13d775738a3b28c3402d9b7b45a65162c7085689.pdf,,,,anonymous|transformers_can_compose_skills_to_solve_novel_problems_without_finetuning,,,,,,,
QbNdfN86b62,Continual Few-shot Relation Learning via Embedding Space Regularization and Data Augmentation,['aclweb.org/ACL/ARR/2021/September/Paper105/Authors'],['Anonymous'],,"Existing continual relation learning (CRL) methods rely on plenty of labeled training data for learning a new task, which can be hard to acquire in real scenario as getting large and representative labeled data is often expensive and time-consuming. It is therefore necessary for the model to learn novel relational patterns with very few labeled data while avoiding catastrophic forgetting of previous task knowledge. In this paper, we formulate this challenging yet practical problem as continual few-shot relation learning (CFRL). Based on the finding that learning for new emerging few-shot tasks often results in feature distributions that are incompatible with previous tasks' learned distributions, we propose a novel method based on embedding space regularization and data augmentation. Our method generalizes to new few-shot tasks and avoids catastrophic forgetting of previous tasks by enforcing extra constraints on the relational embeddings and by adding extra relevant data in a self-supervised manner. With extensive experiments we demonstrate that our method can significantly outperform previous state-of-the-art methods in CFRL task settings.",/pdf/3d044f4fb5173d629931d20639e0be9a067caca2.pdf,/attachment/666589fed855cc1d826a50c7b37e1f99600defe2.zip,,,anonymous|continual_fewshot_relation_learning_via_embedding_space_regularization_and_data_augmentation,,,,,,,/attachment/f348123f8055d379fedc93c131c852ab6696c28d.zip
1I_wHy6mZAj,Machine Reading Comprehension: Generative or Extractive Reader?,['aclweb.org/ACL/ARR/2021/September/Paper84/Authors'],['Anonymous'],,"While both extractive and generative readers have been successfully applied to the Question Answering (QA) task, little attention has been paid toward the comparison of these two readers. Which reader performs better? What are the reasons for the performance differences? In this paper, we aim to answer these questions in the setting of extractive QA tasks. We design multiple transformer-based models and different scenarios to systematically compare these two readers. Our findings characterize the difference of two readers and their pros and cons, which can instruct the optimal selection of the two readers, and open up new research avenues to improve each reader.
Our major findings are:
1) generative readers perform better when the input context is long, whereas extractive readers are better when the context is short;
2) extractive readers generalize better as compared to the generative ones under out-of-domain settings, in both single- and multi-task learning scenarios.  
Our experiments also suggest that, although an encoder-only pre-trained language model (PrLM) is an intuitive choice for extractive readers, the encoder from  encoder-decoder PrLM is a strong alternative that performs competitively.",/pdf/e40b29c5eefb5b4e2a18bf0aee889fae50e1d909.pdf,,,,anonymous|machine_reading_comprehension_generative_or_extractive_reader,,,,,,,
TUL_oPO0H2u,Towards Full Utilization on Mask Task for Distilling PLMs into NMT,['aclweb.org/ACL/ARR/2021/September/Paper99/Authors'],['Anonymous'],,"Owing to being well-performed in many natural language processing tasks, the application of pre-trained language models (PLMs) in neural machine translation (NMT) is widely concerned. Knowledge distillation (KD) is one of the mainstream methods which could gain considerable promotion for NMT models without extra computational costs. However, previous methods in NMT always distill knowledge at hidden states level and can not make full use of the teacher models. For solving the aforementioned issue, we propose KD based on mask task as a more effective method utilized in NMT which includes encoder input conversion, mask task distillation, and gradient optimization mechanism. Here, we evaluate our translation systems for English→German and Chinese→English tasks and our methods clearly outperform baseline methods. Besides, our framework can get great performances with different PLMs.",/pdf/291e002e95de04c0428a3058f6f1298322e008f2.pdf,,,,anonymous|towards_full_utilization_on_mask_task_for_distilling_plms_into_nmt,,,,,,,
SvyTrJoK5uw,,,,,,,,,,,,,,,,,
48T0DriwGcv,,,,,,,,,,,,,,,,,
MjA-CuGIx95,Meta-Learning with Sparse Experience Replay for Lifelong Language Learning,['aclweb.org/ACL/ARR/2021/September/Paper76/Authors'],['Anonymous'],,"Lifelong learning requires models that can continuously learn from sequential streams of data without suffering catastrophic forgetting due to shifts in data distributions. Deep learning models have thrived in the non-sequential learning paradigm; however, when used to learn a sequence of tasks, they fail to retain past knowledge and learn incrementally. We propose a novel approach to lifelong learning of language tasks based on meta-learning with sparse experience replay that directly optimizes to prevent forgetting. We show that under the realistic setting of performing a single pass on a stream of tasks and without any task identifiers, our method obtains state-of-the-art results on lifelong text classification and relation extraction. We analyze the effectiveness of our approach and further demonstrate its low computational and space complexity.",/pdf/baead30f580269df3ad5262151ffc1b0ea9a6ff8.pdf,/attachment/24f029b16860ecd50a1d77efdec707452dc92c16.zip,,,anonymous|metalearning_with_sparse_experience_replay_for_lifelong_language_learning,,,,,,,
Moh8zXa3fSC,Focus on the Target's Vocabulary: Masked Label Smoothing for Machine Translation,['aclweb.org/ACL/ARR/2021/September/Paper119/Authors'],['Anonymous'],,"Label smoothing and vocabulary sharing are two widely used techniques in neural machine translation models. However, we argue that jointly adopting these two techniques can be conflicting and even leads to sub-optimal performance, since the soft label produced by label smoothing still considers the source-side words that would not appear at the target side. To address this issue, we propose Masked Label Smoothing (MLS), a new mechanism that masks the soft label probability of source-side words to zero. Simple yet effective, MLS manages to better integrate label smoothing with vocabulary sharing and hence improves the quality of the translation. Our extensive experiments show that MLS consistently yields improvement over original label smoothing on different datasets, including bilingual and multilingual translation in both BLEU and calibration scores.
",/pdf/6dda15218b84b178f84942a62a86cd712b46b864.pdf,/attachment/842d0f049a23618c9713a4b9dbc6d4f3417676e6.zip,,,anonymous|focus_on_the_targets_vocabulary_masked_label_smoothing_for_machine_translation,,,,,,,
231kNimht0Q,Learning Low-frequency Patterns with A Pre-trained Document-Grounded Conversation Model,['aclweb.org/ACL/ARR/2021/September/Paper144/Authors'],['Anonymous'],,"Owing to its perceived capability in recognizing the high-frequency patterns appeared in the large corpora, the Generative Pre-trained Transformer model (GPT-2) has demonstrated its remarkable performance in the document-grounded dialogue generation. Capturing low-frequency patterns, however, remains a challenging task. Here we consider a possible extension of the GPT-2 model with its improved capability of grasping the low-frequency patterns especially for task-specific dialogues. The extension consists of a semantic-oriented encoder and a GPT-2 decoder, the latter equipped with a knowledge-aware classification. The proposed encoder-decoder framework strengthens the GPT-2 in two task-specific aspects: One is in regard of a suitable way to select, on a semantic level, the crucial information of the dialogue context and the corresponding history knowledge from the documents; The other is in terms of the determination of the suitable time to generate a response with the knowledge from documents. With the enhanced capability to learn not only high-frequency and but also low-frequency patterns, the proposed extension is shown to outperform the state-of-the-art generative models.",/pdf/fd99c44af532cb0fed2eddc27abbeeeac762345b.pdf,,,,anonymous|learning_lowfrequency_patterns_with_a_pretrained_documentgrounded_conversation_model,,,,,/attachment/bf5474f880eb52f149e137eba69c235ae97f49c8.pdf,,
DutjyHb33yO,Accurate Online Posterior Alignments for Principled Lexically-Constrained Decoding,['aclweb.org/ACL/ARR/2021/September/Paper31/Authors'],['Anonymous'],,"Online alignment in machine translation refers to the task of aligning a target word to a source word when the target sequence has only been partially decoded. Good online alignments facilitate important applications such as lexically constrained translation where user-defined dictionaries are used to inject lexical constraints into the translation model. We propose a novel posterior alignment technique that is truly online in its execution and superior in terms of alignment error rates compared to existing methods. Our proposed inference technique jointly considers alignment and token probabilities in a principled manner and can be seamlessly integrated within existing constrained beam-search decoding algorithms.  On five language pairs, including two distant language pairs, we achieve consistent drop in alignment error rates. When deployed on three lexically constrained translation tasks, we achieve significant improvements in BLEU specifically around the constrained positions. We show that our alignment guided constrained inference yields additional benefits of fluency with negligible additional computational costs.
",/pdf/68be52e2f73f281a54b5ed11b5520ac471298ecb.pdf,,,,anonymous|accurate_online_posterior_alignments_for_principled_lexicallyconstrained_decoding,,,,,,,
Z38ExoQkXoc,"Draft, Command, and Edit: Controllable Text Editing in E-Commerce",['aclweb.org/ACL/ARR/2021/September/Paper288/Authors'],['Anonymous'],,"Product description generation is a challenging and under-explored task. Most such work takes a set of product attributes as inputs then generates a description from scratch in a single pass. However, this widespread paradigm might be limited when facing the dynamic wishes of users on constraining the description, such as deleting or adding the content of a user-specified attribute based on the previous version. To address this challenge, we explore a new draft-command-edit manner in description generation, leading to the proposed new task ---controllable text editing in E-commerce. More specifically, we allow systems to receive a command (deleting or adding) from the user and then generate a description by flexibly modifying the content based on the previous version. It is easier and more practical to meet the new needs by modifying previous versions than generating from scratch. To accompany this new task, we present a human-written draft-command-edit dataset called E-cEdits. Furthermore, we design a data augmentation method to remedy the low resource challenge in this task, which contains a model-based and a rule-based strategy to imitate the edit by humans. Our experimental results show that using the new data augmentation method outperforms baselines to a greater extent in both automatic and human evaluations.",/pdf/1bc1670aa8a30bda75cd989640c23dc4e4f9263c.pdf,/attachment/e2e0df135ffd4b3d92d807082f259cb3ee715c53.zip,,,anonymous|draft_command_and_edit_controllable_text_editing_in_ecommerce,,,,,,,/attachment/e8ef37301fbb83f2a015d69c43f231d469e75b09.zip
