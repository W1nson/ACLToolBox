,id,title,authorids,authors,abstract,pdf,Previous URL,Previous PDF,Response PDF,preprint,consent,paperhash,TL;DR,existing_preprints,software,data
0,r0MNmnx4gHX,A Comparison of Strategies for Source-Free Domain Adaptation,['aclweb.org/ACL/ARR/2021/August/Paper25/Authors'],['Anonymous'],"Data sharing restrictions are common in NLP, especially in the clinical domain, but there is limited research on adapting models to new domains without access to the original training data, a setting known as source-free domain adaptation. We take algorithms that traditionally assume access to the source-domain training data—active learning, self-training, and data augmentation—and adapt them for source free domain adaptation. Then we systematically compare these different strategies across multiple tasks and domains. We find that active learning yields consistent gains across all SemEval 2021 Task 10 tasks and domains, but though the shared task saw successful self-trained and data augmented models, our systematic comparison finds these strategies to be unreliable for source-free domain adaptation.",/pdf/fe56e02c010f58ae81bb4f4c8fba9eb5be9a9517.pdf,https://openreview.net/forum?id=vDoEkc92Z3t,/attachment/cacc1d98107d3628bb623c27c3bf4bc7bd381edf.pdf,/attachment/7f7cda18f6cbf9e7edb8c58104e7cc6f7b0d3c4a.pdf,,,anonymous|a_comparison_of_strategies_for_sourcefree_domain_adaptation,,,,
1,T3Pzq_CLCdg,EncT5: Fine-tuning T5 Encoder for Discriminative Tasks,['aclweb.org/ACL/ARR/2021/August/Paper34/Authors'],['Anonymous'],"Encoder-decoder transformer architectures have become popular recently with the advent of T5 models. While they demonstrate impressive performance on benchmarks such as GLUE (Wang et al., 2019), it is not clearly evident if the proposed encoder-decoder architecture is the most efficient for fine-tuning on downstream discriminative tasks. In this work, we study fine-tuning pre-trained encoderdecoder models such as T5. Particularly, we propose EncT5 as a way to efficiently finetune pre-trained encoder-decoder T5 models for classification and regression tasks by using only the encoder layers. Our experimental results show that EncT5 with less than half of the parameters of T5 performs similarly to T5 models on GLUE benchmark. We believe our proposed approach can be easily applied to any pre-trained encoder-decoder model.",/pdf/12e83e14fe7e5fd5c9315c3ef82077f012acba68.pdf,,,,,,anonymous|enct5_finetuning_t5_encoder_for_discriminative_tasks,,,,
2,TUsLgD-Ohfg,Reinforce Attack: Adversarial Attack against BERT with Reinforcement Learning,['aclweb.org/ACL/ARR/2021/August/Paper35/Authors'],['Anonymous'],"Adversarial  attacks  against  textual  data  has been drawing increasing attention in both the NLP and security domains. Current successful attack methods for text typically consist of two stages: word importance ranking and word replacement.  The first stage is usually achieved by masking each word in the sentence one at a time and obtaining the resulting output probability of the target model.  The second stage involves finding synonyms to replace “vulnerable” words by the order of ranking. In this paper, we first explore the effects of employing the model explanation tool LIME to generate word importance ranking, which has the advantage of taking the local information around the word into account to obtain word importance scores.  We then propose Reinforce Attack, a reinforcement learning (RL) based framework to  generate  adversarial  text.   Notably,  the  attack  process  is  controlled  by  a  reward  function rather than heuristics as in previous methods  to  encourage  higher  semantic  similarity and  lower  query  costs. Through  automatic and  human  evaluations,   we  show  that  our LIME + Reinforce Attack method achieves better or comparable attack success rate against other state-of-the-art attack frameworks, while the  generated  samples  preserve  significantly higher semantic similarity.",/pdf/821c61d6c68ca59395ac4b58df0a350c77b781b4.pdf,,,,,,anonymous|reinforce_attack_adversarial_attack_against_bert_with_reinforcement_learning,,,,
3,7ot_3041a6L,Tailor: Generating and Perturbing Text with Semantic Controls,['aclweb.org/ACL/ARR/2021/August/Paper18/Authors'],['Anonymous'],"Making controlled perturbations is essential for various tasks (e.g., data augmentation), but building task-specific generators can be expensive. We introduce Tailor, a task-agnostic generation system that perturbs text in a semantically-controlled way. With unlikelihood training, Tailor's generator is designed to follow a series of control codes derived from semantic roles. Through modifications of these control codes, Tailor can produce fine-grained perturbations. We implement a set of operations on control codes that can be composed into complex perturbation strategies, and demonstrate their effectiveness in three applications. First, Tailor facilitates the construction of high-quality contrast sets that are lexically diverse and less biased than original task test data. Second, paired with automated labeling heuristics, Tailor helps improve model generalization through data augmentation: we obtain an average gain of 1.73 on an (natural language inference) NLI challenge set by perturbing just $\sim5\%$ of training data. Third, without any finetuning overhead, Tailor's perturbations effectively improve compositionality in fine-grained style transfer, outperforming fine-tuned baselines on 5 transfers.",/pdf/86752b43b2b3c6ab7fe52d03c0c8b998a3bbb02f.pdf,,,,,,anonymous|tailor_generating_and_perturbing_text_with_semantic_controls,,,,
4,-0pzbYBTRmt,Multimodal Knowledge Learning for Named Entity Disambiguation,['aclweb.org/ACL/ARR/2021/August/Paper26/Authors'],['Anonymous'],"With the popularity of online social medias in recent years, massive-scale multimodal information has brought new challenges to traditional Named Entity Disambiguation (NED) tasks. Recently, Multimodal Named Entity Disambiguation (MNED) is proposed to link ambiguous mentions with the textual and visual contexts to a predefined knowledge graph.  Recent attempts handle these issues mainly by annotating multimodal mentions and adding multimodal features to traditional NED models. These methods still suffer from 1) lack of multimodal annotation data against the huge scale of unlabeled corpus  and 2) failing to model multimodal information at knowledge level. In this paper, we explore a pioneer study on leveraging multimodal knowledge learning to address the MNED task. Specifically, we propose a knowledge-guided transfer learning strategy to extract unified representation from different modalities and enrich multimodal lnowledge in a Meta Learning way which is much easier than collecting ambiguous mention corpus. Then we propose an Interactive Multimodal Learning Network (IMN), which is capable of fully utilizing the multimodal information in both mention and knowledge side. To verify the validity of the proposed method, we implemented comparisons on a public large-scale MNED dataset based on Twitter KB. Experimental results show that our method is superior to the state-of-the-art multimodal methods",/pdf/6abbe1f2232306fd19eb79ce9bfceee12a1f15c9.pdf,,,,,,anonymous|multimodal_knowledge_learning_for_named_entity_disambiguation,,,,
5,p-4qeZrTeCy,VALSE: A Task-Independent Benchmark for Vision and Language Models centered on Linguistic Phenomena,['aclweb.org/ACL/ARR/2021/August/Paper20/Authors'],['Anonymous'],"We propose VALSE (Vision And Language Structured Evaluation), a novel benchmark designed for testing general-purpose pretrained vision and language (V&L) models for specific visio-linguistic grounding capabilities. Currently, V&L models are evaluated on tasks such as visual question answering or visual reasoning, which do not address their fine-grained linguistic capabilities. VALSE addresses this gap by offering a suite of six tests targeting specific linguistic phenomena. Solving these tests requires models to ground these  phenomena in the visual modality, allowing more fine-grained evaluations than hitherto possible. We build VALSE using methods that support the construction of reliable foils, and report results from evaluating five widely-used V&L models. Our experiments suggest that current models have considerable difficulty addressing most phenomena. Hence, we expect VALSE to serve as an important benchmark to measure future progress of pretrained V&L models from a linguistic perspective, complementing the canonical task-centred V&L evaluations.",/pdf/5dbcb272de74999fa2d704ff0915521beb114e63.pdf,,,,,,anonymous|valse_a_taskindependent_benchmark_for_vision_and_language_models_centered_on_linguistic_phenomena,,,,
6,QotBd0ZQuyg,Adapting Multilingual Models for Code-Mixed Translation using Back-to-Back Translation,['aclweb.org/ACL/ARR/2021/August/Paper37/Authors'],['Anonymous'],"In this paper, we explore the problem of translating code-mixed sentences to an equivalent monolingual form. The scarcity of gold standard code-mixed to pure language parallel data makes it difficult to train a translation model that can perform this task reliably. Prior work has addressed the paucity of parallel data with data augmentation techniques. Such techniques rely heavily on external resources, which make the systems difficult to train and scale effectively for multiple languages. We present a simple yet highly effective training scheme for adapting multilingual models to the task of code-mixed translation. Our method eliminates the dependence on external resources by creating synthetic data from a novel two-stage back-translation approach that we propose. We show substantial improvement in translation quality (measured through BLEU), beating existing prior work by up to +3.8 BLEU on code-mixed Hi$\rightarrow$En, Mr$\rightarrow$En, and Bn$\rightarrow$En tasks. On the LinCE Machine Translation leader board, we achieve the highest score for code-mixed Es$\rightarrow$En, beating existing best baseline by +6.5 BLEU, and our own stronger baseline by +1.1 BLEU.",/pdf/91bcf8ea2fc2bc32bdabb480407f939bc5ffc3bf.pdf,,,,,,anonymous|adapting_multilingual_models_for_codemixed_translation_using_backtoback_translation,,,,
7,EkXAZcDorIa,Quantifying the Task-Specific Information in Text-Based Classifications,['aclweb.org/ACL/ARR/2021/August/Paper3/Authors'],['Anonymous'],"Recently, neural natural language models have attained state-of-the-art performance on a wide variety of tasks, but the high performance can result from superficial, surface-level cues (Bender and Koller, 2020; Niven and Kao, 2020). These surface cues, as the ``shortcuts'' inherent in the datasets, do not contribute to the task-specific information (TSI) of the classification tasks. While it is essential to look at the model performance, it is also important to understand the datasets. In this paper, we consider this question: Apart from the information introduced by the shortcut features, how much task-specific information is required to classify a dataset? We formulate this quantity in an information-theoretic framework. While this quantity is hard to compute, we approximate it with a fast and stable method. TSI quantifies the amount of linguistic knowledge modulo a set of predefined shortcuts -- that contributes to classifying a sample from each dataset. This framework allows us to compare across datasets, saying that, apart from a set of ``shortcut features'', classifying the Multi-NLI task involves around 0.4 nats more TSI than the Quora Question Pair.",/pdf/a89a425c61389d41235d1d8178dbacd8ceb897bd.pdf,,,,,,anonymous|quantifying_the_taskspecific_information_in_textbased_classifications,,,/attachment/bc76642d6466e5c8bfe3d687fc0b0d2540be1a46.zip,/attachment/8743706ab16431f53fe3d1d66c22f7cf0aaaf62b.zip
8,FoSbfnso_hg,Reliability and Robustness of Transformers for Automated Short-Answer Grading,['aclweb.org/ACL/ARR/2021/August/Paper9/Authors'],['Anonymous'],"Short-Answer Grading (SAG) is an application for NLP in education where student
answers to open questions are graded. This task places high demands both on the
reliability (accuracy and fairness) of label predictions and model robustness
against strategic, ""adversarial""  input. Neural approaches are powerful tools for
many problems in NLP, and transfer learning for Transformer-based models
specificially promises to support data-poor tasks as this. We analyse the
performance of a Transfomer-based SOTA model, zooming in on class- and item type
specific behavior in order to gauge reliability; we use adversarial testing to
analyze the the model's robustness towards strategic answers. We find a strong
dependence on the specifics of training and test data, and recommend that model
performance be verified for each individual use case.",/pdf/7ab15f1b6881369f7e17796948727871818b1b0f.pdf,,,,,,anonymous|reliability_and_robustness_of_transformers_for_automated_shortanswer_grading,,,/attachment/8834d7a6008b038481e119206321815b1c89c3f8.zip,
9,DxJHPnz1L0l,Deduplicating Training Data Makes Language Models Better,['aclweb.org/ACL/ARR/2021/August/Paper24/Authors'],['Anonymous'],"We find that existing language modeling datasets contain many near-duplicate examples and long repetitive substrings.
As a result, over $1\%$ of the unprompted output of language models trained on these datasets is copied verbatim from the training data.
We develop two tools that allow us to deduplicate training datasets---for example removing from C4 a single 61 word English sentence that is repeated over $60{,}000$ times.
Deduplication allows us to train models that emit memorized text ten times less frequently and require fewer training steps to achieve the same or better accuracy.
We can also reduce train-test overlap, which affects over $4\%$ of the validation set of standard datasets, thus allowing for more accurate evaluation.
",/pdf/f1488964c122f8d56a577dc99cf785a9f38ee6ff.pdf,,,,,,anonymous|deduplicating_training_data_makes_language_models_better,,,,
10,ma2eK0he7JT,QAConv: Question Answering on Informative Conversations,['aclweb.org/ACL/ARR/2021/August/Paper17/Authors'],['Anonymous'],"This paper introduces QAConv, a new question answering (QA) dataset that uses conversations as a knowledge source. We focus on informative conversations, including business emails, panel discussions, and work channels. Unlike open-domain and task-oriented dialogues, these conversations are usually long, complex, asynchronous, and involve strong domain knowledge. In total, we collect 34,608 QA pairs, including span-based and unanswerable questions, from 10,259 selected conversations with both human-written and machine-generated questions. We use a question generator and a dialogue summarizer as auxiliary tools to collect multi-hop questions. The dataset has two testing scenarios, chunk mode and full mode, depending on whether the grounded partial conversation is provided or retrieved. Experimental results show that state-of-the-art pretrained QA systems have limited zero-shot performance and tend to predict our questions as unanswerable. Our dataset provides a new training and evaluation testbed to facilitate QA on conversations research.",/pdf/2b186f89265bfd77c09234a1ca7a426e99da6f35.pdf,,,,,,anonymous|qaconv_question_answering_on_informative_conversations,,,/attachment/dc71fa21a4c78111c623c0825e61deb1b1a8ab5c.zip,/attachment/e590d06087eddf9b89f154c98803c18dc56aa8c3.zip
11,n3MFoq1WOXU,An Empirical Survey of Data Augmentation \\for Limited Data Learning in NLP,['aclweb.org/ACL/ARR/2021/August/Paper6/Authors'],['Anonymous'],"
NLP has achieved great progress in the past decade through the use of neural models and large labeled datasets. The dependence on abundant data prevents NLP models from being applied to low-resource settings or novel tasks where significant time, money, or expertise is required to label massive amounts of textual data. Recently, data augmentation methods have been explored as a means of improving data efficiency in NLP. To date, there has been no systematic empirical overview of data augmentation for NLP in the limited labeled data setting, making it difficult to understand which methods work in which settings. In this paper, we provide an empirical survey of recent progress on data augmentation for NLP in the limited labeled data setting, summarizing the landscape of methods (including token-level augmentations, sentence-level augmentations, adversarial augmentations, and hidden-space augmentations) and carrying out experiments on 11 datasets covering topics/news classification, inference tasks, paraphrasing tasks, and single-sentence tasks. Based on the results, we draw several conclusions to help practitioners choose appropriate augmentations in different settings and discuss the current challenges and future directions for limited data learning in NLP.",/pdf/00da17bb96a21b47fe41d00e481ab21cc5d545ad.pdf,,/attachment/82ef8dd11b71bba9626575994ce8707dba119307.pdf,/attachment/c314438738b9002657eb770b6c16cbf6ae31a8b2.pdf,,,anonymous|an_empirical_survey_of_data_augmentation_\\for_limited_data_learning_in_nlp,,,,
12,9ACh_V2Gbop,Semantics-aware Attention Improves Neural Machine Translation,['aclweb.org/ACL/ARR/2021/August/Paper29/Authors'],['Anonymous'],"The integration of syntactic structure into Transformer machine translation has shown positive results, but to our knowledge, no work has attempted to do so with semantic structures. In this work we propose two novel parameter-free methods for injecting semantic information into Transformers, both rely on semantics-aware masking of (some of) the attention heads. One such method operates on the encoder, through a Scene-Aware Self-Attention (SASA) head. Another on the decoder, through a Scene-Aware Cross-Attention (SACrA) head. We show a consistent improvement over the vanilla Transformer and syntax-aware models for four language pairs.
We further show an additional gain when using both semantic and syntactic structures in some language pairs.",/pdf/e200297909e245040018b43e0d2b1356b99225c4.pdf,,,,,,anonymous|semanticsaware_attention_improves_neural_machine_translation,,,,
13,_giVW90_UAV,BERT Learns to Teach: Knowledge Distillation with Meta Learning,['aclweb.org/ACL/ARR/2021/August/Paper1/Authors'],['Anonymous'],"We present Knowledge Distillation with Meta Learning (MetaDistil), a simple yet effective alternative to traditional knowledge distillation (KD) methods where the teacher model is fixed during training. We show the teacher network can learn to better transfer knowledge to the student network (i.e., learning to teach) with the feedback from the performance of the distilled student network in a meta learning framework. Moreover, we introduce a pilot update mechanism to improve the alignment between the inner-learner and meta-learner in meta learning algorithms that focus on an improved inner-learner. Experiments on various benchmarks show that MetaDistil can yield significant improvements compared with traditional KD algorithms and is less sensitive to the choice of different student capacity and hyperparameters, facilitating the use of KD on different tasks and models.",/pdf/9e75faa867d5fc29b6e8c7a59284f58bbed757e5.pdf,,,,,,anonymous|bert_learns_to_teach_knowledge_distillation_with_meta_learning,,,,
14,-mQP6w_FGZJ,On the Diversity and Limits of Human Explanations,['aclweb.org/ACL/ARR/2021/August/Paper10/Authors'],['Anonymous'],"A growing effort in NLP aims to build datasets of human explanations. However, the term explanation encompasses a broad range of notions, each with different properties and ramifications. Our goal is to provide an overview of diverse types of explanations and human limitations, and discuss implications for collecting and using explanations in NLP. Inspired by prior work in psychology and cognitive sciences, we group existing human explanations in NLP into three categories: proximal mechanism, evidence, and procedure. These three types differ in nature and have implications for the resultant explanations. For instance, procedure is not considered explanations in psychology and connects with a rich body of work on learning from instructions. The diversity of explanations is further evidenced by proxy questions that are needed for annotators to interpret and answer open-ended why questions. Finally, explanations may require different, often deeper, understandings than predictions, which casts doubt on whether humans can provide useful explanations in some tasks.",/pdf/c94ac3190c5067463f29a512bf560e2376e693db.pdf,,,,,,anonymous|on_the_diversity_and_limits_of_human_explanations,,,,
15,D8DJN2-Zmkf,Automatic Multi-Label Prompting: Simple and Interpretable Few-Shot Classification,['aclweb.org/ACL/ARR/2021/August/Paper27/Authors'],['Anonymous'],"Prompt-based learning (i.e., prompting) is an emerging paradigm for exploiting knowledge learned by a pretrained language model. In this paper, we propose Automatic Multi-Label Prompting (AMuLaP), a simple yet effective method to automatically select label mappings for few-shot text classification with prompting. Our method exploits one-to-many label mappings and a statistics-based algorithm to select label mappings given a prompt template. Our experiments demonstrate that AMuLaP achieves competitive performance on the GLUE benchmark without human effort or external resources.",/pdf/331bd4fba2ed0bf73af809aee23ee87627520591.pdf,,,,,,anonymous|automatic_multilabel_prompting_simple_and_interpretable_fewshot_classification,,,,
16,OUPw2V0lX4_,CTRLsum: Towards Generic Controllable Text Summarization,['aclweb.org/ACL/ARR/2021/August/Paper43/Authors'],['Anonymous'],"Current summarization systems yield generic summaries that are disconnected from users' preferences and expectations. To address this limitation, we present CTRLsum, a generic framework to control generated summaries through a set of keywords. During training keywords are extracted automatically without requiring additional human annotations. At test time CTRLsum features a control function to map control signal to keywords; through engineering the control function, the same trained model is able to be applied to control summaries on various dimensions, while neither affecting the model training process nor the pretrained models.  We additionally explore the combination of keywords and text prompts for more control tasks. Experiments demonstrate the effectiveness of CTRLsum on three domains of summarization datasets and five control tasks: (1) entity-centric and (2) length-controllable summarization, (3) contribution summarization on scientific papers, (4) invention purpose summarization on patent filings, and (5) question-guided summarization on news articles. Moreover, when used in a standard, unconstrained summarization setting, CTRLsum is comparable or better than the state-of-the-art systems.",/pdf/ded0b5d7a7a2fe1406061a90fb23247bd9f2893f.pdf,,,,,,anonymous|ctrlsum_towards_generic_controllable_text_summarization,,,/attachment/3242700054e38a44d0a12b1fab163dfe2b006589.zip,
17,eum8bkxrL_Z,A Latent-Variable Model for Intrinsic Probing,['aclweb.org/ACL/ARR/2021/August/Paper28/Authors'],['Anonymous'],"The success of pre-trained contextualized representations has prompted researchers to analyze them for the presence of linguistic information. Indeed, it is natural to assume that these pre-trained representations do encode some level of linguistic knowledge as they have brought about large empirical improvements on a wide variety of NLP tasks, which suggests they are learning true linguistic generalization.
In this work, we focus on intrinsic probing, an analysis technique where the goal is not only to identify whether a representation encodes a linguistic attribute, but also to pinpoint where this attribute is encoded. We propose a novel latent-variable formulation for constructing intrinsic probes and derive a tractable variational approximation to the log-likelihood. Our results show that our model is versatile and outperforms two intrinsic probes previously proposed in the literature. Finally, we find empirical evidence that pre-trained representations develop a cross-lingually entangled notion of  morphosyntax.",/pdf/5a62be84d7514d728dde0c7b81b9dc54592e022c.pdf,,,,,,anonymous|a_latentvariable_model_for_intrinsic_probing,,,,
18,DAiDafTZE7T,An Investigation of the (In)effectiveness of Counterfactually Augmented Data,['aclweb.org/ACL/ARR/2021/August/Paper30/Authors'],['Anonymous'],"While pretrained language models achieve excellent performance on natural language understanding benchmarks, they tend to rely on spurious correlations and generalize poorly to out-of-distribution (OOD) data. Recent work has explored using counterfactually-augmented data (CAD)---data generated by minimally perturbing examples to flip the ground-truth label---to identify robust features that are invariant under distribution shift. However, empirical results using CAD for OOD generalization have been mixed. To explain this discrepancy, we draw insights from a  linear Gaussian model and demonstrate the  pitfalls of CAD. Specifically, we show that (a) while CAD is effective at identifying robust features, it may prevent the model from learning unperturbed robust features; and (b) CAD may exacerbate existing spurious correlations in the data. On two crowdsourced CAD datasets, our results  show that the lack of perturbation diversity limits their effectiveness on OOD generalization, calling for innovative crowdsourcing procedures to elicit diverse perturbation of examples.",/pdf/e5cdb8e51ea9d905da5d12e52d54db63450f07ab.pdf,,,,,,anonymous|an_investigation_of_the_ineffectiveness_of_counterfactually_augmented_data,,,/attachment/29a50dadc7fa018d6ab3c3cb75f204997ca83b10.zip,
19,AiZ4qG1SFy_,,,,,,,,,,,,,,,
