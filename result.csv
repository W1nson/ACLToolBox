,Unnamed: 0,id,title,authorids,authors,TL;DR,abstract,pdf,software,preprint,paperhash,existing_preprints,consent,venue,venueid,_bibtex,data,Previous URL,response_PDF,reviewer/Editor_reassignment_request,reviewer/Editor_reassignment_justification,previous_URL,previous_PDF,preferred_venue,consent_to_review,forum
29,29,nxEqWd4Ddth,CONTaiNER: Few-Shot Named Entity Recognition via Contrastive Learning,['aclweb.org/ACL/ARR/2021/October/Paper294/Authors'],['Anonymous'],,"Named Entity Recognition (NER) in Few-Shot setting is imperative for entity tagging in low resource domains. Existing approaches only learn class-specific semantic features and intermediate representations from source domains. This affects generalizability to unseen target domains, resulting in suboptimal performances. To this end, we present CONTaiNER, a novel contrastive learning technique that optimizes the inter-token distribution distance for Few-Shot NER. Instead of optimizing class-specific attributes, CONTaiNER optimizes a generalized objective of differentiating between token categories based on their Gaussian-distributed embeddings. This effectively alleviates overfitting issues originating from training domains. Our experiments in several traditional test domains (OntoNotes, CoNLL'03, WNUT '17, GUM) and a new large scale Few-Shot NER dataset (Few-NERD) demonstrate that on average, CONTaiNER outperforms previous methods by 3%-13% absolute F1 points while showing consistent performance trends, even in challenging scenarios where previous approaches could not achieve appreciable performance. ",https://openreview.net/pdf/f4ee55395c68408570f7f989cab855f22c36c8df.pdf,,,anonymous|container_fewshot_named_entity_recognition_via_contrastive_learning,,,,,,,,,,,,,,,https://openreview.net/forum?id=nxEqWd4Ddth
0,0,5aeBigqvO-P,Few-Shot Named Entity Recognition with Biaffine Span Representation,['aclweb.org/ACL/ARR/2021/November/Paper1126/Authors'],['Anonymous'],,"While Named Entity Recognition (NER) is a widely studied task, making inferences of entities with only a few labeled data (i.e., few-shot NER) has been challenging. Correspondingly, the N-way K-shot NER task is proposed to recognize entities in the given N categories with only K labeled samples for each category. Existing methods treat this task as a sequence labeling problem, while this paper regards it as an entity span classification problem and designs a Biaffine Span Representation (BSR) method to learn contextual span dependency representation to fit into the classification algorithm. The BSR applies a biaffine pooling module to establish the dependencies of each word on the whole sentence and to reduce the dimension of word features, thus, the span representation could gain contextual dependency information to help improve recognition accuracies. Experimental study on four standard NER datasets shows that our proposed BSR method outperforms pre-trained language models and existing N-way K-shot NER algorithms in two types of adaptations (i.e., Intra-Domain Cross-Type Adaptation and Cross-Domain Cross-Type Adaptation). Notably, F_1 value has increased by an average of 13.77% and 18.30% on the 5-way 1-shot task and the 5-way 5-shot task, respectively.",https://openreview.net/pdf/7febb0779bbb9d02819a4fc044de27902056be68.pdf,https://openreview.net/attachment/a0218ab754ecfc9edcc5d9be27f9b02807edbac1.zip,,anonymous|fewshot_named_entity_recognition_with_biaffine_span_representation,,,,,,,,,,,,,,,https://openreview.net/forum?id=5aeBigqvO-P
189,189,EmJCjwPiH_i,TextMosaic: A New Data Augmentation Method for Named Entity Recognition Using Document-Level Contexts,['aclweb.org/ACL/ARR/2021/November/Paper2289/Authors'],['Anonymous'],,"Named Entity Recognition (NER) often faces the problem of lacking massive and diverse annotation data, recent advances of pre-training techniques have shown great power on such low-resource tasks.  However, the robustness of NER models is still insufficient which motivates us for efficient text enhancement method.  Inspired by the mosaic augmentation method for object detection, this paper puts forward a novel data augmentation method named TextMosaic for NER through span sampling,over-sampling, and random sampling, which takes full consideration of the context-sensitive relevance. Meanwhile, sliding window is leveraged in the sampling to effectively capture rich document-level information and solve the problem of label imbalance. Our proposed method won the Top 1 in the robustness evaluation of CCIR Cup 2021.  We also conduct extensive experiments on OntoNote 4.0 dataset, on which our method achieves higher accuracy and robustness for NER simultaneously.  Besides, it consumes less computing resources and makes the model capable of running in 1080ti GPU efficiently. The code will be open-sourced on Github.",https://openreview.net/pdf/799acbc84e71f95243e65d77023d4f2b53911c05.pdf,,,anonymous|textmosaic_a_new_data_augmentation_method_for_named_entity_recognition_using_documentlevel_contexts,,,,,,https://openreview.net/attachment/1ba186305978334dd8fb730de6af8e0f89ded27b.zip,,,,,,,,,https://openreview.net/forum?id=EmJCjwPiH_i
280,280,0gYkM3fk9Bb,Distantly Supervised Named Entity Recognition via Confidence-Based Multi-Class Positive and Unlabeled Learning,['aclweb.org/ACL/ARR/2021/November/Paper430/Authors'],['Anonymous'],,"In this paper, we study the named entity recognition (NER) problem under distant supervision. Due to the incompleteness of the external dictionaries and/or knowledge bases, such distantly annotated training data usually suffer from a high false negative rate. To this end, we formulate the Distantly Supervised NER (DS-NER) problem via Multi-class Positive and Unlabeled (MPU) learning and propose a theoretically and practically novel CONFidence-based MPU (Conf-MPU) approach. To handle the incomplete annotations, Conf-MPU consists of two steps. First, a confidence score is estimated for each token of being an entity token. Then, the proposed Conf-MPU risk estimation is applied to train a multi-class classifier for the NER task. Thorough experiments on two benchmark datasets labeled by various external knowledge demonstrate the superiority of the proposed Conf-MPU over existing DS-NER methods.",https://openreview.net/pdf/da915954d539186a5b2fb7d935631ba51a1ca7e8.pdf,https://openreview.net/attachment/84604dc001283a993c8b31cc49c94f0aa7b9f045.zip,,anonymous|distantly_supervised_named_entity_recognition_via_confidencebased_multiclass_positive_and_unlabeled_learning,,,,,,https://openreview.net/attachment/5bab13aa15812fb6a12ab08b20e6c99a9eaca831.zip,,,,,,,,,https://openreview.net/forum?id=0gYkM3fk9Bb
395,395,70mgWeTodiu,Computer Science Articles Named Entity Recognition Datasets: Survey and Our Recent Development,['aclweb.org/ACL/ARR/2021/November/Paper2703/Authors'],['Anonymous'],,"Domain-specific named entity recognition on Computer Science (CS) scholarly articles is an information extraction task that is arguably more challenging and less studied than named entity recognition (NER) for the general domain. Given that significant progress has been made on NER, we believe that scholarly domain-specific NER will receive increasing attention in the NLP community. Nevertheless, progress on the task is currently hampered in part by its recency and the lack of standardized concept types for scientific entities/terms. This paper presents a survey of the current state of research on scholarly domain-specific NER with a focus on language resources; further, it creates a novel dataset and model for CS NER.",https://openreview.net/pdf/8fbd80690920d66117febe5acea275c39ee2fdbe.pdf,https://openreview.net/attachment/0f99bd06a6e5fd15fdab81909556b3f632235b39.zip,,anonymous|computer_science_articles_named_entity_recognition_datasets_survey_and_our_recent_development,,,,,,https://openreview.net/attachment/b23eb55eb8eb7f4f93da83f71ddefeb522785f73.zip,,,,,,,,,https://openreview.net/forum?id=70mgWeTodiu
441,441,pfjbxxqih3x,Cross-domain Named Entity Recognition via Graph Matching,['aclweb.org/ACL/ARR/2021/November/Paper711/Authors'],['Anonymous'],,"Cross-domain NER is a practical yet challenging problem since the data scarcity in the real-world scenario. A common practice is first to learn a NER model in a rich-resource general domain and then adapt the model to specific domains. Due to the mismatch problem between entity types across domains, the wide knowledge in the general domain can not effectively transfer to the target domain NER model. To this end, we model the label relationship as a probability distribution and construct label graphs in both source and target label spaces. To enhance the contextual representation with label structures, we fuse the label graph into the word embedding output by BERT. By representing label relationships as graphs, we formulate cross-domain NER as a graph matching problem. Furthermore, the proposed method has good applicability with pre-training methods and is potentially capable of other cross-domain prediction tasks. Empirical results on four datasets show that our method outperforms a series of transfer learning, multi-task learning, and few-shot learning methods.",https://openreview.net/pdf/634bed2336a1be6a464d598f495b3b69133b5757.pdf,https://openreview.net/attachment/5c431d067de4bd07adf0168d914880f68cd41cd9.zip,,anonymous|crossdomain_named_entity_recognition_via_graph_matching,,,,,,https://openreview.net/attachment/fa78994d7bcbb63b96a565b4a890b675da22d475.zip,,,,,,,,,https://openreview.net/forum?id=pfjbxxqih3x
474,474,3-g3nuYuf_w,MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective,['aclweb.org/ACL/ARR/2021/November/Paper2933/Authors'],['Anonymous'],,"NER model has achieved promising performance on standard NER benchmarks. However, recent studies show that previous approaches may over-rely on entity mention information, resulting in poor performance on out-of-vocabulary(OOV) entity recognition.  In this work, we propose MINER, a novel NER learning framework, to remedy this issue from an information-theoretic perspective. The proposed approach contains two mutual information based training objectives: i) generalizing information maximization, which enhances representation via deep understanding of context and entity surface forms; ii) superfluous information minimization, which discourages representation from rotate memorizing entity names or exploiting biased cues in data. Experiments on various settings and datasets demonstrate that it achieves better performance in predicting OOV entities.",https://openreview.net/pdf/210ac70b5b28f08c3d37f6aca610b20f57aeeac6.pdf,,,anonymous|miner_improving_outofvocabulary_named_entity_recognition_from_an_information_theoretic_perspective,,,,,,,,,,,,,,,https://openreview.net/forum?id=3-g3nuYuf_w
584,584,2D3ibn1aeUS,Nested Named Entity Recognition as Latent Lexicalized Constituency Parsing,['aclweb.org/ACL/ARR/2021/November/Paper2476/Authors'],['Anonymous'],,"Nested named entity recognition (NER) has been receiving increasing attention. Recently, Fu et al. (2020) adapt a span-based constituency parser to tackle nested NER. They treat nested entities as partially-observed constituency trees and propose the masked inside algorithm for partial marginalization. However, their method cannot leverage entity heads, which have been shown useful in entity mention detection and entity typing. In this work, we resort to more expressive structures, lexicalized constituency trees in which constituents are annotated by headwords, to model nested entities. We leverage the Eisner-Satta algorithm to perform partial marginalization and inference efficiently.
In addition, we propose to use (1) a two-stage strategy (2) a head regularization loss and (3) a head-aware labeling loss in order to enhance the performance. We make a thorough ablation study to investigate the functionality of each component. Experimentally, our method achieves the state-of-the-art performance on ACE2004, ACE2005 and NNE, and competitive performance on GENIA, and meanwhile has a fast inference speed.",https://openreview.net/pdf/e134381a32ca822e70b118b940fa243ced3c54eb.pdf,,,anonymous|nested_named_entity_recognition_as_latent_lexicalized_constituency_parsing,,,,,,,,,,,,,,,https://openreview.net/forum?id=2D3ibn1aeUS
596,596,8LQwB0FkR0X,AutoTriggER: Named Entity Recognition with Auxiliary Trigger Extraction,['aclweb.org/ACL/ARR/2021/November/Paper1698/Authors'],['Anonymous'],,"Deep neural models for low-resource named entity recognition (NER) have shown impressive results by leveraging distant super-vision or other meta-level information (e.g. explanation). However, the costs of acquiring such additional information are generally prohibitive, especially in domains where existing resources (e.g. databases to be used for distant supervision) may not exist. In this paper, we present a novel two-stage framework (AutoTriggER) to improve NER performance by automatically generating and leveraging ""entity triggers"" which are essentially human-readable clues in the text that can help guide the model to make better decisions. Thus, the framework is able to both create and leverage auxiliary supervision by itself. Through experiments on three well-studied NER datasets, we show that our automatically extracted triggers are well-matched to human triggers, and AutoTriggER improves performance over a RoBERTa-CRFarchitecture by nearly 0.5 F1 points on average and much more in a low resource setting.",https://openreview.net/pdf/5652cfb41ddcf7df51d8d1e78e06dd455c87f61a.pdf,https://openreview.net/attachment/57d3f55fded48e0ab8195f01f80e0418817010cd.zip,,anonymous|autotrigger_named_entity_recognition_with_auxiliary_trigger_extraction,,,,,,,,,,,,,,,https://openreview.net/forum?id=8LQwB0FkR0X
689,689,Zo4-42mBGex,Are We NER Yet? Measuring the Impact of ASR Errors on Named Entity Recognition in Spontaneous Conversation Transcripts,['aclweb.org/ACL/ARR/2021/November/Paper1399/Authors'],['Anonymous'],,"Transcriptions of spontaneous human conversations present a significant obstacle for traditional NER models trained on prescriptive written language. The lack of grammatical structure of spoken utterances, combined with word errors introduced by the ASR, makes downstream NLP tasks challenging. In this paper, we examine the impact of ASR errors on the ability of NER models to recover entity mentions from transcripts of spontaneous human conversations in English. We experimentally compare several commercial ASR systems paired with state-of-the-art NER models. We use both publicly available benchmark datasets (Switchboard Named Entity Corpus, SWNE), and the proprietary, real-life dataset of gold (human-transcribed) phone conversation transcripts. To measure the performance of NER models on ASR transcripts, we introduce a new method of token alignment between transcripts. Our findings unequivocally show that NER models trained on the written language struggle when processing transcripts of spontaneous human conversations. The presence of ASR errors only exacerbates the problem.",https://openreview.net/pdf/106a4fcc727c297f2d6d9fba71741b147b520d7e.pdf,,,anonymous|are_we_ner_yet_measuring_the_impact_of_asr_errors_on_named_entity_recognition_in_spontaneous_conversation_transcripts,,,,,,,,,,,,,,,https://openreview.net/forum?id=Zo4-42mBGex
702,702,ePRpn99yhJi,Towards Few-shot Entity Recognition in Document Images: A Label-aware Sequence-to-Sequence Framework,['aclweb.org/ACL/ARR/2021/November/Paper740/Authors'],['Anonymous'],,"Entity recognition is a fundamental task in understanding document images. Traditional sequence labeling framework requires extensive datasets and high-quality annotations, which are typically expensive in practice. In this paper, we aim to build an entity recognition model based on only a few shots of annotated document images. To overcome the data limitation, we propose to leverage the label surface names to better inform the model of the target entity semantics. Specifically, we go beyond sequence labeling and develop a novel label-aware seq2seq framework, LASER. We design a new labeling scheme that generates the label surface names word-by-word explicitly after generating the entities. Moreover, we design special layout identifiers to capture the spatial correspondence between regions and labels. During training, LASER refines the label semantics by updating the label surface name representations and also strengthens the label-region correlation. In this way, LASER recognizes the entities from document images through both semantic and layout correspondence. Extensive experiments on two benchmark datasets demonstrate the superiority of LASER under the few-shot setting. ",https://openreview.net/pdf/78884769e1f20c8f1d9f8e31f403c4be9b43d544.pdf,,,anonymous|towards_fewshot_entity_recognition_in_document_images_a_labelaware_sequencetosequence_framework,,,,,,https://openreview.net/attachment/d6e7df72970b5224751ac0979a5085414dd0b212.zip,,,,,,,,,https://openreview.net/forum?id=ePRpn99yhJi
896,896,DZItcXicrj2,Distantly Supervised Named Entity Recognition with Category-Oriented Confidence Calibration,['aclweb.org/ACL/ARR/2021/November/Paper2996/Authors'],['Anonymous'],,"In this work, we study the noisy-labeled named entity recognition under distant supervision setting. Considering that most NER systems based on confidence estimation deal with noisy labels ignoring the fact that model has different levels of confidence towards different categories, we propose a category-oriented confidence calibration(Coca) strategy with an automatically confidence threshold calculation module. We integrate our method into a teacher-student framework to improve the model performance. Our proposed approach achieves promising performance among advanced baseline models, setting new state-of-the-art performance on three existing distantly supervised NER benchmarks.",https://openreview.net/pdf/a51428da30c2265b79d03c844021862cce13317e.pdf,,,anonymous|distantly_supervised_named_entity_recognition_with_categoryoriented_confidence_calibration,,,,,,,,,,,https://openreview.net/forum?id=8T1pvcsmqyV,/attachment/7b35245eefa88c2cfedbd2ee39e5c9a7cad02741.pdf,,,https://openreview.net/forum?id=DZItcXicrj2
948,948,CvGtHdgukK,Few-shot Named Entity Recognition with Joint Token and Sentence Awareness,['aclweb.org/ACL/ARR/2021/November/Paper514/Authors'],['Anonymous'],,"Few-shot learning has been proposed and rapidly emerging as a viable means for completing various tasks. Recently, few-shot models have been used for Named Entity Recognition (NER). Prototypical network shows high efficiency on few-shot NER. However, existing prototypical methods only consider the similarity of tokens in query sets and support sets and ignore the semantic similarity among the sentences which contain these entities. We present a novel model, Few-shot Named Entity Recognition with  \textbf{J}oint \textbf{T}oken and \textbf{S}entence \textbf{A}wareness (\textbf{JTSA}), to address the issue.  The sentence awareness is introduced to probe the semantic similarity among the sentences. The Token awareness is used to explore the similarity of the tokens. To further improve the robustness and results of the model, we adopt the joint learning scheme on the few-shot NER. Experimental results demonstrate that our model outperforms state-of-the-art models on two standard Few-shot NER datasets.",https://openreview.net/pdf/d251ddd19b807b44a9f9941bf9fbfa0aaec54365.pdf,https://openreview.net/attachment/9405fbb8b1c10982c721ee89836db24cac76924b.zip,,anonymous|fewshot_named_entity_recognition_with_joint_token_and_sentence_awareness,,,,,,,,,,,,,,,https://openreview.net/forum?id=CvGtHdgukK
949,949,N-DZvl4bQsO,DAML: Chinese Named Entity Recognition with a fusion method of data-augmentation and meta-learning,['aclweb.org/ACL/ARR/2021/November/Paper761/Authors'],['Anonymous'],,"Overfitting is still a common problem in NER with insufficient data. Latest methods such as Transfer Learning, which focuses on storing knowledge gained while solving one task and applying it to a different but related task, or Model-Agnostic Meta-Learning (MAML), which learns a model parameter initialization that generalizes better to similar tasks. However, these methods still need rich resources to pre-train. In this work, we present new perspectives on how to make the most of in-domain and out-domain information. By introducing a fusion method of data augmentation and MAML, we first use data augmentation to mine more information. With the augmented resources, we directly utilize out-domain and in-domain data with MAML, while avoiding performance degradation after domain transfer. To further improve the model’s generalization ability, we proposed a new data augmentation method based on a generative approach. We conduct experiments on six open Chinese NER datasets (MSRANER, PeopleDairyNER, CLUENER, WeiboNER, Resume NER, and BOSONNER). The results show that our method significantly reduces the impact of insufficient data and outperforms the state-of-the-art.",https://openreview.net/pdf/55cc5b27d9f25aaee3774a8162dc4c3064de31c9.pdf,,,anonymous|daml_chinese_named_entity_recognition_with_a_fusion_method_of_dataaugmentation_and_metalearning,,,,,,,,,,,,,,,https://openreview.net/forum?id=N-DZvl4bQsO
